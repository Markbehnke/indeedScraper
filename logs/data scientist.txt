ScrapedJobID1:

ScrapedJobID2:
Use quantitative analysis and the presentation of data to see beyond the numbers and understand what drives our business Build full-cycle analytics experiments, reports, and dashboards using SQL, R, Python, or other scripting and statistical tools Produce recommendations and use statistical techniques and hypothesis testing to validate your findings Provide insights to help business and product leaders understand marketplace dynamics, user behaviors, and long-term trends Identify and measure levers to help move essential metrics and make recommendations Work backwards from understanding and sizing problems to ideating solutions Report against our goals by identifying essential metrics and building executive-facing dashboards to track progress Be excited to travel (when it’s safe!) to meet with business partners and the team in each market A degree in Math, Physics, Statistics, Economics, Computer Science, or similar domain 5+ years of experience in data analytics, consulting, or related quantitative role Experience working with funnel optimization, user segmentation, cohort analyses, time series analyses, regression models, etc Expertise of SQL queries, ETL, A/B Testing, and statistical analysis (e.g. hypothesis testing, experimentation, regressions) with statistical packages, such as Matlab, R, SAS or Python Proficiency in one or more analytics & visualization tools (e.g. Chartio, Looker, Tableau) The insight to take ambiguous problems and solve them in a structured, hypothesis-driven, data-supported way The determination to initiate and lead projects to completion in a scrappy environment Prior experience working abroad or in international expansion preferred but not required Fluent English required, proficiency in additional languages a plus We are leaders - Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies. We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do - on every project, every day. We are learners - Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute. We are customer-obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility. We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights. 
ScrapedJobID3:
Initiative Team player Excellent oral communication Excellent written communication Client focus Organized Remote work available Medical Benefits Dental Benefits Life Insurance Benefits RRSP Benefits 
ScrapedJobID4:
Exploring, analysing, and deriving new insights from our data assets; Building, deploying, and maintaining statistical and machine learning models; Automating data preparation and analysis processes; and much, much more Training, deploying, and maintaining statistical and machine learning models in production environments; Carrying out novel exploratory, inferential, and predictive analyses on complex structured and unstructured data assets; Creating data visualization and communication tools and telling strong data stories; Connecting and working with your colleagues beyond ministry lines to deliver integrated data, analytics, and data science services You have experience applying a broad variety of techniques for descriptive, exploratory, inferential and predictive analytics. You have knowledge of mathematical foundations of common data science modelling approaches. You have the ability to synthesize the big picture from disparate data sources while demonstrating strong attention to detail skills. You have the ability to learn public sector policy and program research, development, and analysis principles, practices and methods. You have experience applying theories, principles and best practices in the field of data science and advanced analytics, data modelling, data mining and evidence-informed decision-making. You have experience working with data science programming languages (e.g. Python, R, Scala) and data querying languages (e.g. SQL, Hive, Cypher) to load, prepare, and use high variety / high volume data assets for reporting, analysis, and statistical / machine learning model development. You have knowledge of data/database management principles, technologies, and best practices for working with structured and unstructured data assets. You have experience in data storytelling and communication through different mediums – for example, dashboards, briefings, reports, and slide decks. You have the ability to communicate complex technical concepts with clarity to non-technical colleagues. You have consultation, consensus-building and networking skills to maintain strong relationships with internal and external stakeholders. You have persuasion and influencing skills to convince stakeholders of project relevance and necessity. You have negotiation, conflict management and consensus-building skills to resolve contentious issues, maximize team/stakeholder contribution, achieve consensus, and produce required deliverables. You can investigate complex problems, challenging assumptions, and make sense of information. You can creatively think and propose innovative ways to look at problems by using data mining approaches on the set of information available. You make sure the right questions are being asked, solicit feedback, and iterate until you reach meaningful conclusions backed by solid analysis. You have experience working on projects with diverse project teams and stakeholder groups and competing priorities. You have the ability to lead projects independently and ensure satisfactory and timely results delivery. You have the ability to learn structured project management approaches such as PMBOK, Agile, etc. 1 Temporary, duration up to 18 months, 315 Front St W, Toronto, Toronto Region W-SS-173459/21

Effective October 1, 2021, the OPS COVID-19 Safe Workplace Directive requires all Ontario Public Service employees to provide proof they are fully vaccinated, meaning they are fully vaccinated as defined by the Ministry of Health (refer to: COVID-19 Fully Vaccinated Status in Ontario), including 14 calendar days have passed since receiving their final dose of the COVID-19 vaccine.


Employees who do not provide proof of full vaccination will be deemed ‘not vaccinated' under the Directive and will be required to attend a vaccine education program and undergo regular rapid antigen testing. Employees who are not vaccinated under the policy with a valid medical exemption will not be required to attend a vaccine education program but must undergo regular rapid antigen testing.


The information that you provide for the purpose of this competition and the results from this competition may be used to fill other positions. These positions may be of various tenures including short-term assignments. Your information and the results from this competition will be retained for the purpose of filling vacancies in accordance with the applicable collective agreement or policy provisions. 
ScrapedJobID5:
Validate existing Geotab (GO) device firmware for data frequency, fidelity, quality and addition metrics. Collaborate with cross functional teams in designing and constructing, and testing firmware from data integrity perspective. Create algorithms and predictive models to extract information required to solve complex business problems. Generate queries from Geotab’s Big Data Infrastructure from Data Warehousing database (i.e. Google BigQuery). Use Machine Learning (ML) packages (e.g. Scikit-learn and Tensorflow) to develop ML models and features. Test the performance of data-driven products and make recommendations for improving Geotab’s product suite. Collaborate with internal technical teams to triage issues and gather requirements. Responsible for the design, development, and maintenance of ongoing metrics, reports, analyses, and dashboards to drive key business decisions. Support a platform providing ad-hoc and automated access to large datasets. Post-secondary Degree/Diploma with specialization in Mathematics, Computer Science, Statistics, or a related field. 1-5 years experience as a Data Scientist or a similar role. Understanding of machine learning and operations research. Highly skilled in working with and triagging real-time (RTOS/Linux) embedded software e.g. C code base, break points, debug logs, etc. Thorough knowledge of programming languages (e.g. Python, SQL, C, C++). Thorough knowledge of Big Data tools and Data Mining/Warehousing Programs (e.g. Google BigQuery). Experience with machine learning techniques (e.g. Scikit-learn, Tensorflow). Experience using/building business intelligence tools (e.g. Tableau) and data frameworks. Experience working within a technical or engineering organization, with knowledge of the high-technology industry is an asset. High accuracy and meticulous attention to detail. Highly organized and able to manage multiple tasks and projects simultaneously. Must stay relevant to technology and should have the flexibility to adapt to the growing technology and market demands. Strong analytical skills with the ability to problem solve to well-judged decisions. Strong team-player with the ability to engage with all levels of the organization. Technical competence using software programs, including but not limited to, Google Suite for business (Sheets, Docs, Slides). Entrepreneurial mindset and comfortable in a flat organization. 
ScrapedJobID6:
Identify opportunities for exploration to leverage machine learning (ML) for learner success Consult other teams interested in leveraging ML to solve problems Analyze data to help determine how to apply ML techniques like knowledge tracing Actively contribute to proof-of-concept development Experience with Jupyter Notebooks, AWS SageMaker, Pandas, NumPy, scikit-learn, Seaborn etc. Awareness of data ethics, privacy, and trust in an educational context Strong understanding of challenges, techniques, and approaches related to learning sciences, educational data mining, and learning analytics. Understanding how best to apply different machine learning algorithms and frameworks depending on the problems being solved. Experience with data visualization tools. Knowledge with data science languages like Python, R, etc. Bachelor’s degree from accredited institution in mathematics, data science, computer science, engineering, or another technical field required. 
ScrapedJobID7:

ScrapedJobID8:
Develop and test data analytics, machine learning procedures and algorithms in Python Develop and test software applications to host data analytic visualizations Monitor, test, and debug the data pipeline Help optimize and automate ongoing processes/routines. Construct classification models using developed machine learning tools Document developed features in the application Understand, support, test, and troubleshoot production machine learning applications Currently working towards a Bachelor's in Computer Engineering, Computer Science, Engineering, Science or equivalent previous experience with python previous experience with running SQL 
ScrapedJobID9:
Consulting firm Collect and document user's requirements Conduct research and provide advice to other informatics professionals regarding the selection application and implementation of database management tools Research and document data requirements, data collection and administration policy, and data access rules Conduct research and provide advice to other information systems professionals regarding the collection, availability and suitability of data Data Science SQL Python Hadoop R Criminal record check Valid driver's licence Attention to detail Tight deadlines Effective interpersonal skills Team player Excellent oral communication Excellent written communication Client focus Remote work available Medical Benefits Disability Benefits Dental Benefits Group Insurance Benefits Life Insurance Benefits Pension Plan Benefits RRSP Benefits Vision Care Benefits 
ScrapedJobID10:
Demonstrate a growth mindset and continuous learning; stay current on IBM strategies and products with hands on technical growth in data science and cloud native computing Use MLOps practices and methods to plan and create AI applications to address business challenges Be conversant and knowledgeable about technology trends and how technology is being applied to address business challenges Demonstrate strong analytical, problem solving, and troubleshooting skills combined with an agile process Motivated to lead successful projects and meet technical and business objectives Strong professional verbal, written, and interpersonal skills Registered full-time university/college student (must be minimum 2nd year) pursuing bachelor’s degree or post-secondary degree in Computer Science, Data Science, Engineering, Information Systems, or similar disciplines Experience in programming with Python (preferred), R, Spark, or language in a similar discipline English: Fluent. English & French Fluent required for Montreal position. Experience in application development is a plus Experience in data science libraries and frameworks such as Jupyter Notebooks, Scikit-learn, Pandas, Spark, and development technologies such as Git, REST, CI/CD pipelines, Linux command line, containers, Kubernetes 
ScrapedJobID11:
Analyze high-throughput experiments to assess data quality and identify hits. Build tools to streamline design of antisense oligonucleotide compounds. Support pre-clinical development programs with computational analyses BSc in Computer Science, Statistics, Bioinformatics, or related fields and two years post-graduate experience, or MSc in the related fields. Solid knowledge of Python, and some knowledge of R is desirable. Solid statistics knowledge with ability to perform various statistical analyses independently. Understanding of basic concepts in molecular biology and human genetics. Comfort working in a fast-paced and rapidly growing work environment A highly competitive salary and meaningful equity compensation (ESOPs). A wide array of company-paid benefits. Exceptional opportunities for learning and growth working alongside the world’s best team. An opportunity to work alongside a bright, collegial, highly motivated team working at the intersection of the most exciting areas of science and technology. 
ScrapedJobID12:
Use SQL and Python to interact with Geotab’s big data infrastructure Leverage learning packages like Scikit-Learn and Tensorflow to develop Machine Learning models Develop new features for Machine Learning models and visualize features Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions Use data mining, model building, and other analytical techniques to develop new datasets and data driven solutions Make recommendations for new metrics, techniques, and strategies to improve Geotab’s product suite Within final two years of a university degree in Engineering, Computer Science, Math or a related field Strong communication, organization, and time management skills, as well as a willingness to learn and strong work ethic Experience using SQL Experience using Python Experience working with Machine Learning algorithms and big data tools is an asset Previous industry work experience preferred Ping Pong and foosball skills always a plus 
ScrapedJobID13:

ScrapedJobID14:
Seek and identify new impactful areas for exploration and investigation and collaborate with stakeholders to frame clear problem statements and test hypotheses about our strategic and product goals. Collaborate with subject matter experts and other data professionals to gather business domain context to effectively prioritize and inform your investigative and experimental approaches and analytical roadmap planning and execution. Apply full-stack data mining, modeling, experimentation, and statistical techniques to data from multiple sources to identify new patterns, detect analytical opportunities and build solutions that enable impactful data-driven decisions. Define and implement metrics, interpret results, develop insights, and influence peers, stakeholders, and leadership on courses of action based on your findings. Develop, incorporate and share technical and analytical best practices, innovations and architectural enhancements to optimize analytics for stakeholder clients and contribute to a data fluent culture. 3+ years of data science, analytics and/or business intelligence experience. 3+ years of hands-on experience with EDA, data wrangling and mining using SQL, ETL, Data Warehouses and other data technologies (e.g., Synapse, Databricks, Cosmos, ADL). 2+ years of experience with R or Python scripting (or other platform-agnostic language). Excellent analytical and problem-solving skills, with hands-on experience applying them to data from disparate sources. Demonstration of statistical competency and the use of the scientific method and experimentation to strengthen and confirm analytical observations. Strong business acumen to understand project contribution to overall business and product strategy across Microsoft Clouds, Sales and Marketing, and Microsoft Learning ecosystems. Demonstrated ability to effectively engage and collaborate with stakeholders, including effective prioritization and clear communication, including the ability to synthesize complex problems/scenarios into easy-to-understand concepts. Effective presentation skills and experience engaging audiences of all levels. Comfortable and effective in rapidly evolving environments, working across organizational boundaries. Creative, innovative, organized thinker, with a high attention to detail. An outstanding teammate who seeks out collaboration opportunities, upholds a safe working environment, and values inclusivity in the workplace. 
ScrapedJobID15:
Disciplined self-starter who can work both on their own and in close collaboration with other team members in an agile development environment Fast learner Experience in the aggregates industry is an asset A senior student or bachelor’s degree in computer science or another relevant area of study Proficiency in Microsoft Office: Word, Publisher, Excel, PowerPoint and Outlook are required Written and verbal communication abilities Experience programming in Python a major asset Consult on data analytics solutions Collect and prepare data. Help identify the business data needed to produce the most useful insights and future analytics. This would include business line and possibly outside data sources Work closely with the business to achieve real value through informed decisions and improved actions Give direction and insight on data analytics initiatives/areas of focus Validate business implications Ensure that the insights generated through analytics translate to help drive better/faster/smarter data collection Perform other miscellaneous tasks associated with being a member of the Digital Technology & Innovation team and those typical of a data analyst or data scientist Data management with a Document management system Flexible working hours (Part Time or Full Time) Option to work from home Competitive salary and benefits Friendly and supportive team environment Opportunity to join a company with aggressive plans for expansion Dental care Extended health care Flexible schedule Wellness program 8 hour shift Yes 
ScrapedJobID16:
Apply statistical and machine learning techniques to assist with building models for underwriting, pricing, and claims management; Help us drive innovation, enabling new underwriting paradigms, distribution models, and data management; Build and implement solutions that enable operational units to improve quality and speed of core processes in order to generate incremental revenue or reduce expense; Proactively research new ways of modeling data to unlock actionable insights or improve processes; Collaborate across Munich Re functions and with clients to use analytics to influence business decisions; Work with existing data science groups at Munich Re and collaborate with internal partners to leverage capabilities in big data technology. Undergraduate or Graduate degree (Master’s, PhD) in Computer Science, Statistics, Data Science/Analytics, Applied Mathematics, Engineering (Physics, Bioinformatics) – or equivalent program offering coursework manipulating large datasets; Expertise in advanced predictive analytic techniques; Strong experience working with Python, or R; working knowledge of SQL (familiarity with multiple languages considered an asset); Demonstrated experience working with analytics through the modeling lifecycle including gathering data, design, model building, testing, implementation, communication, and monitoring; Excellent communication skills; spoken & written, formal/informal presentation – to effectively interpret and present actionable insights to partners; Resourceful and able to learn quickly; A drive to make a difference; Proven ability to thrive in a dynamic environment. Familiarity with cloud computing platforms (ex. AWS, Microsoft Azure); Familiarity with big data technologies (ex. Apache Spark, Hadoop, etc), natural language processing and deep learning frameworks (ex. Tensorflow, Pytorch); Previous exposure to insurance or financial services environment, or Actuarial examinations/designation. 
ScrapedJobID17:
Collaborate with several of our cross-functional teams like development, product and marketing to use data as a tool to make decisions and solve business problems Develop custom algorithms to maximize ROI and business initiatives Discover different ways of analyzing data across our full company ecosystem, and provide actionable insights before and after high impact business decisions Work with multiple data sources and inputs, and carefully choose the appropriate course of action (analysis, modeling etc.) based on their ability to solve a business problem Undergraduate Degree in a STEM program Strong skills with R, Python and SQL Experience developing custom algorithms Data visualization & story-telling Nice to have skills: experience with statistics, machine learning model deployment (clustering, NLP, decision trees) and dashboard experience (PowerBI, Tableau, Looker) A strong business acumen, problem solving aptitude as well as a robust analytical mind Ability to work with multiple data sources and inputs that are carefully chosen based on their ability to solve a business problem Top notch communication skills, both written and oral Excellent people and management skills to interact with colleagues, cross-functional teams and stakeholders A go-getter attitude and a passion for your work! 
ScrapedJobID18:
Work place : Currently regular telework because of the pandemic. Position located in Lévis or Montreal, depending on the applicant selected. The work arrangement for the position is hybrid work #LI-Hybrid Temporary work : scheduled to end on January 20, 2023 Number of job available : 1 Bachelor’s degree in a related field A minimum of four years of relevant experience For vacant positions available in Quebec, please note that knowledge of French is required 
ScrapedJobID19:
Data analysis experience using (one or more): Python, Could ML (AWS, GCP, Azure), or similar tools 1+ years (Consultant) or 3+ years (Senior Consultant) relevant work experience with applying analytics or working with data in any industry Strong experience with statistical analytical techniques, data mining, and predictive models is required Database and programming languages experience and data manipulation and integration skills using (one or more) SQL, Oracle, Hadoop, NoSQL Databases, or similar tools is required Experience with social media analytics and/or natural language processing and/or optimization is an asset Knowledge using either AWS, Azure or GCP Strong experience with Machine Learning Project management experience is an asset Ability to work with data with significant ambiguity, develop creative approaches to analytical problems, and interpret data and results from a business/industry perspective Enthusiastic about solving complex problems with a variety of analytical tools Professional services, consulting, or advisory experience is an asset Strong oral and written communication skills Interest in continuing to develop analytical and business development skills BA/BSc degree in Computer Science, Applied Mathematics, Statistics, or related field is required. Advanced degree (MA/MSc, equivalent or higher) is preferred. You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster. You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful. You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work. 
ScrapedJobID20:
Exploring, analysing, and deriving new insights from our data assets; Building, deploying, and maintaining statistical and machine learning models; Automating data preparation and analysis processes; and much, much more Retrieving, cleaning, assessing, preparing, and documenting data assets for use in data science projects; Carrying out novel descriptive, exploratory, inferential, and predictive analyses, and presenting results to key decision makers; Creating novel data visualization and communication tools and telling strong data stories; Connecting and working with your colleagues beyond ministry lines to deliver integrated data, analytics, and data science services You have knowledge and experience applying techniques for descriptive and exploratory analytics, such as aggregation, summarization, group-wise analysis, and data visualization. You have knowledge of data science approaches, methods, and techniques, such as predictive analytics and machine learning, and ability to learn the corresponding data requirements. You have the ability to synthesize the big picture from disparate data sources while demonstrating strong attention to detail skills. You have the ability to learn public sector policy and program research, development, and analysis principles, practices and methods. You have knowledge and experience applying theories, principles and best practices in the field of data science and advanced analytics, data modelling, data mining and evidence-informed decision-making. You have knowledge and experience working with data querying languages (e.g. SQL, Hive, Cypher) and/or data science programming languages (e.g. Python, R, Scala) to load, clean, aggregate, integrate, and otherwise prepare data for analytics/data science use. You have knowledge of data management principles, technologies, and best practices for working with high-volume structured and unstructured data assets. You have the ability to communicate complex technical concepts with clarity to non-technical colleagues. You have the ability to effectively articulate ideas and options that involve data analysis, interpretation and assessment. You have the ability to create standard analytics products for communication of analytics results, such as slide decks, reports, and methodology documents. You have experience building and maintaining effective and lasting relationships with clients, project teams, and external partners to gather input, build consensus and deliver on priorities. You can investigate complex problems, challenging assumptions, and make sense of information. You can creatively think and propose innovative ways to look at problems by using data mining approaches on the set of information available. You make sure the right questions are being asked, solicit feedback, and iterate until you reach meaningful conclusions backed by solid analysis. You have experience working on projects with multiple team members and competing priorites. You have the ability to learn Agile project management methodologies. You have the ability to learn basic principles of software development lifecycles and how they affect data operations. 2 Temporary, duration up to 18 months, 315 Front St W, Toronto, Toronto Region W-SS-173187/21(2)

Effective October 1, 2021, the OPS COVID-19 Safe Workplace Directive requires all Ontario Public Service employees to provide proof they are fully vaccinated, meaning they are fully vaccinated as defined by the Ministry of Health (refer to: COVID-19 Fully Vaccinated Status in Ontario), including 14 calendar days have passed since receiving their final dose of the COVID-19 vaccine.


Employees who do not provide proof of full vaccination will be deemed ‘not vaccinated' under the Directive and will be required to attend a vaccine education program and undergo regular rapid antigen testing. Employees who are not vaccinated under the policy with a valid medical exemption will not be required to attend a vaccine education program but must undergo regular rapid antigen testing.

The information that you provide for the purpose of this competition and the results from this competition may be used to fill other positions. These positions may be of various tenures including short-term assignments. Your information and the results from this competition will be retained for the purpose of filling vacancies in accordance with the applicable collective agreement or policy provisions. 
ScrapedJobID21:
Proactively work with product management and development teams to solve complex problems across multiple domains. Apply specialized skills and fundamental data science methods (e.g. research design, testing, evaluation and iteration) to develop algorithmic approaches to add to our
platform. Define and advance best practices within data science and product teams. Work with customers to understand their requirements and data. Apply EDA skills to design and deliver analytics within our platform based on existing suites of algorithms. Research relevant methods and keep up-to-date with advancements in the field. Support other team members in their data science work and provide constructive feedback. Contribute to the technical vitality and collective knowledge of the team. Data Visualization and Communication: You know that storytelling with data is an important skill. You understand how to communicate analytic insights to everyday people without resorting
to jargon. Science/Statistics: You are comfortable with key mathematical concepts and have empirical thinking at your core. You may have acquired these skills by studying Math, statistics or you have
a scientific or engineering background. Statisticians, Biologists, Chemists, Physicists or Engineers-are all relevant fields. Machine Learning: You are fluent in machine learning techniques; you know how logistic regression works and you can jump in and train a neural net model on data and understand if
your results are any good. Experience with a range of unsupervised methods is an asset. Data Munging: You know how to work with data, shape it and manipulate it at will. Wizarding skills with data are highly desirable and knowledge of one or all of SQL, Python, TensorFlow, R is
essential. Software Engineering: You are comfortable writing high-quality code in a professional setting. Experience working with agile development teams and GitHub is useful. Independent Working: You are able to work independently with minimal supervision. Have an enquiring mind, you are collaborative and like working with colleagues and clients to change the world. Have the ability to think strategically, self-direct and believe in bringing their best every day. Have strong Python programming skills; experience with DASK is highly desirable but not essential. Have a BS (MS/PhD Preferred) in quant discipline (e.g. Math/Hard Science, Stats, CS, EE, Econ). Are fluent in written and oral English. Fulfill requirements necessary to obtain full background check. 
ScrapedJobID22:
Flexible schedule Work from home 8 hour shift Monday to Friday This position is funded by a Federal funding program. To be eligible for this funding, candidates must be Canadian Citizens, Permanent Residents, and under 30 years of age. Do you meet these qualifications? machine learning: 2 years (preferred) Regression, Classification, Clustering, Neural Networks: 2 years (preferred) Temporarily due to COVID-19 
ScrapedJobID23:
You’ll be part of a diverse, cross-functional team of Data Scientists, Machine Learning Engineers, Developers, Analysts, Product Managers, and UX Designers You’ll focus on driving machine learning research into a variety of areas focused around empowering our customers to create high converting content, optimize their ad campaigns, and provide data driven insights to increase their ROI You’ll be exposed to a wide array of machine learning areas, such as cutting-edge NLP utilizing attention based and generative models, image analysis, and reinforcement learning You’ll help Data Products plan its overall strategy, vision, and planning 2-4 years of experience working with machine learning and data science Proficient with Python and the associated data science/machine learning packages (e.g. scikit-learn, pandas, xgboost, numpy, scipy) Experience with one or more deep learning approaches (NLP, machine vision, generative models) and proficiency with a deep learning framework such as PyTorch or TensorFlow. Relational databases (we principally use MySQL and Postgres) Agile development, version control, software development best practices, and code review processes You can communicate clearly and empathetically with developers, product managers, and UX designers to explain the abilities and limitations of ML systems You are not afraid to ask questions to find the best solution and are equally unafraid to have your ideas challenged A remote friendly office with flexible hours - for this role we will consider all applications from those based in Canada with the option to work from our Vancouver office 4 weeks vacation plus Christmas Holiday Closure - you're entitled to the week of Christmas off with pay through to and including Jan 1st Vacation bonus - $1,000.00 12 Personal Wellness Days (This includes: Personal day, Moving day, Sick day, etc) Health and Wellness budget - $500.00 Networking budget - $500.00 A paid day off for your birthday One paid Volunteer day per year One day every 2 weeks of dedicated professional development time 
ScrapedJobID24:
Build comprehensive analytical solutions to provide tools for decision-making. Perform advanced analysis to guide the company in its strategic choices. Support the various GSoft teams in : Best practices in terms of data collection and usage; Defining and tracking team metrics and goals; Development of the GSoft data culture. Develop statistical and predictive models that allow us to improve the company's processes. Create centralized dashboards and support teams in creating their own data visualizations in different tools. Be proactive in maintaining and improving data quality. Support the Culture & Organization team in leveraging their data (People Analytics). Train the teams in the use of data visualization features of different tools. Set up the foundation to track the customer journey through our different products. Develop lead scoring models to support marketing and sales teams. Continuous improvement of our data warehouses and visualization tools to increase data quality (creation of a single source of truth). Have a few years of experience in data analysis and/or analytical model design. Experience in programming (SQL, Python, R, DAX, etc.). Experience in data visualization and presentation (PowerBI, Tableau, Looker, etc.). Have knowledge of : Statistics and mathematics; Modeling methods (prediction, classification, etc.); Data preparation (extraction, cleaning, etc.); Data models, architectures, warehouses and data environment (basic knowledge). Advanced data analysis techniques. Ability to understand business issues, transform them into technology requirements and clearly communicate analysis results. Ability to collaborate with different teams and support them in their data development. Be able to adapt quickly to a change in context. 
ScrapedJobID25:
Selecting features, building and optimizing classifiers using machine learning techniques Enhancing data collection procedures to include information that is relevant for building analysis Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Integration with 3rd party API’s for data collection and analysis, including weather data, time-series data, and event-based data sets 1-2 years experience in similar roles Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc. Experience with common data science toolkits. Great verbal and written communication skills Experience with data visualization tools, such as D3.js, Highcharts.js etc. Proficiency in using query languages like SQL. Good applied statistics skills, such as distributions, statistical testing, regression, etc. Good scripting and programming skills Data-oriented personality Competitive salary Benefits The opportunity to work with passionate and driven individuals Flexible schedule 
ScrapedJobID26:
Work with finance experts to understand and document data problems Work with technical teams to build data solutions Join meetings with technical teams as class schedule allows Present your work to technical and business teams Develop a specialization plan targeting one of these areas:
Data Engineering
Data Governance and Stewardship
Data Visualization
Data Analysis
Data Science Data Engineering Data Governance and Stewardship Data Visualization Data Analysis Data Science Currently pursuing a Bachelor’s or Master’s degree from an accredited college or university. Must be available to start between January 2022 and September 2022 Ability to discover, analyze, and find data patterns Ability to apply technology to data problems Excellent communication and presentation skills Ability to work with an international team Willingness to operate under a high level of autonomy Finance, legal, or research background Coding experience, especially with Python, Java, or C# Cloud computing experience Data visualization design experience 
ScrapedJobID27:
You will work on the development of innovative ML and AI solutions for smart homes use state-of-the-art computing technologies in the cloud where data from millions of smart devices are captured. constructing advanced mathematical models that describe physical state of a building Analyzing and validating product performance at all stages of the R&D cycle Present scientific findings to development and product teams Support occasional product analytic requests from product and sales teams Develop data pipelines, automated data processing systems in collaboration with data engineers You have a background in a technical field such as computer science, applied mathematics, computer/electrical/mechanical engineering You have strong command of Python, SQL and can write production ready codes Experience and a thorough understanding of machine learning algorithms Experience with cloud technologies You have experience with visualization tools like Matplotlib, Seaborn, Plotly, Tableau You have knowledge of statistics and research methods Just so you know: The hired candidate will be required to complete a background check A 30-minute phone/video call with a member in Talent Acquisition If your first round interview goes well, you can expect to choose from a take home case study (technical) or a pair programming session. If you choose the take home, you will get between 2-4 days to work on it – you'll then come in virtually to present your solution to the team in a 1.5 hour interview If you choose the pair programming session we will set up a 2 hour interview for you which will include technical as well as values segment In the final interview, you will meet our VP of Data Science and 1-2 Senior Data Scientists on the team Be part of something big: Get to work in a fresh, dynamic, and ever-growing industry. Make an environmental difference: Make a sustainable impact while on your daily job, and after it through programs like ecobee acts. Expand your career: Learn with our in-house learning enablement team, grow with our quarterly hackathons, and enjoy our generous professional learning budget. Put people first: Benefit from competitive salaries, health benefits, and a progressive Parental Top-Up Program (75% top-up or five bonus days off). Play a part on an exceptional culture: Enjoy a fun and casual workplace with an open concept office, located at Corus Quay. ecobee Leeds is based at our riverside office on the Calls. We're a remote-first workplace until April 2022 Celebrate diversity: Be part of a truly welcoming workplace. We offer a mentorship program and bias training. 
ScrapedJobID28:
Collaborates in a team to find effective solutions to data challenges Cleanses and verifies the integrity of the data used for analysis Provides support in exploratory data analysis and provides insight to other teams Translates advanced data analytics problems into technical approaches that result in actionable recommendations Develops data models from the early stages to deployment to maintaining the models Uses data analytics languages such as Python and SQL on a daily basis to produce solutions for analysis, prediction, and reporting Tests solutions for functionality, troubleshoots and resolves errors Master’s degree in Data Science, Computer Science, Engineering, Statistics, or other relevant disciplines Expert knowledge in data science and statistics Experience designing, conducting, analyzing, and interpreting experiments Strong understanding of machine learning techniques (supervised and unsupervised) Strong programming skills (Python, SQL or equivalent) Experience with Keras or Tensorflow Strong analytical skills Strong communication skills Experience with scalability and cloud computing Knowledge of cellphone communication networks 
ScrapedJobID29:
Collaborate closely with our flight, hotel, and pricing business partners Leverage data analyses, modeling, and visualization tools such as R and/or Python, Oracle SQL, BigQuery, MySQL, Tableau, and others Mine rich data sets and develop models to evaluate sales performance, supply health, pricing performance, and other cross-functional use-cases Provide insights into the flight and hotel business, monitor performance by defining and refining critical KPIs Present the technical material to both technical and non-technical audiences Devise tests, experiments, and monitoring to validate model performance Partner with Data Engineers to build and maintain data infrastructure Conduct analysis on strategic projects and provide actionable recommendations Answer tough questions with data 3+ years of data science and/or analytics experience building quantitative and/or machine learning models. Travel / flight / ecommerce industry experience preferred Bachelor’s Degree or higher from top university in a quantitative subject (e.g., science or math) Experience in Python and/or R along with their associated ML/AI Libraries. BigQuery/GCP, Tableau, and Excel experience are nice to have. Excellent written and verbal communication; proficient in presentation writing tools (e.g., Power Point, Slides) Have experience in developing frameworks and performing gap analysis Project management and work structure skills – excellent attention to detail and ability to work independently Hands-on, extensive knowledge and experience working with large databases, data mining and business intelligence tools Strong analytical and problem-solving skills Ability to communicate complex concepts in a simple way to senior leadership is a must Ability to work under pressure and multi-task in a fast-paced/rapidly changing environment Comfortable with ambiguity Passion for travel and business 
ScrapedJobID30:
Currently pursuing or completed a bachelor's or master's degree in computer science, engineering, or related field. Some Engineering experience and or project course work using large data systems on SQL, Hadoop, etc. Proficiency using one or more programming or scripting language to work with data such as: Python, Perl, or C#. Some experience and or project course work performing data analysis and applying statistics working with tools such as: Excel, R, MATLAB, AMPL, or SAS. Some experience and or project course work with product and service telemetry systems. Some A/B Testing or experimentation (this can be from conducting real life science experiments, hypothesis testing in stats etc.) Not required but ideal. Some experience or course work applying basic ML to a type of data and or used algorithms to conduct experiments on data. Machine Learning strongly encouraged. Passion to learn from your peers, manager, and other stakeholders in the Data Science domain. Ability to interact with peers and stakeholders to drive product and business impact. Strong interpersonal and communications skills. 
ScrapedJobID31:
You are highly analytical with a knack for analysis, math and statistics You’ve got critical thinking and problem-solving skills which are essential for interpreting data You have a passion for machine-learning and research! Build pragmatic, scalable and rigorous ML and AI solutions that enables data driven improvements for healthcare businesses projects such as AI/Virtual coaching, Clinical Decision Support, customer intent models, etc. Use deep learning, machine learning and analytical techniques to create scalable solutions to address healthcare needs Deliver effective business solutions from ideation to QA and deployment Work collaboratively with colleagues to define problem statements, collect data and define solution approaches Build and maintain ML models, experiments, and forecasting analytics. Leverage Python, Hadoop, Spark and similar Big Data frameworks to deliver efficient analytics Communicate clearly the methods, impact and processes you have taken with clients and other stakeholders Masters or Ph.D. degree in a STEM field (e.g. Computer Science, Engineering, Physics, Mathematics, Statistics, Economics, or related field); 3 to 5 years of industry experience solving analytical problems using ML approaches; Experience performing data extraction, data cleaning, exploratory data analysis and sharing results over medium to large datasets; Strong Python or R, and SQL skills; Experience with one or more of Scikits-learn, Tensorflow, Keras, Theano or Pytorch; Excellent analytical skills to self-assess robustness and performance of machine learning models; Experience in Agile delivery methodologies Good communication skills to explain insights and methods; Experience with Big Data systems and frameworks (Hadoop, AWS, GCP, Spark, etc) is a plus Enjoy learning new data science methods and technologies Strong attention to detail Strong understanding of a relevant healthcare area - bioinformatics, hospital data systems, population health or other related area Track record scoping, designing and delivering ML healthcare projects through to production Strong working connaissance of deep learning, machine learning and statistics Hands-on experience building models with deep learning frameworks such as MXNet, TensorFlow, Caffe, or similar Experience of building effective solution architectures Experience hiring or mentoring more junior colleagues Strong communication and data presentation skills The motivation to achieve results in a fast-paced environment Comfortable working in a fast paced, highly collaborative, dynamic work environment Fluency in at least one other language We are a group of people who are bright, kind, and motivated by challenge. We are a successful, fast-growing company at the forefront of tech and healthcare. We love solving problems, thinking creatively, and trying new things. We believe in autonomy & taking initiative. We take what we do seriously, but we also know how to have fun. We have a smart, experienced leadership team that wants to do it right & is open to new ideas. We offer competitive compensation packages and comprehensive health benefits. You can be your authentic self here and are empowered to encourage others to do the same! 
ScrapedJobID32:

ScrapedJobID33:
Define, develop and lead a data science program which identifies exploitation opportunities, and provides solutions and capabilities to address them. Conduct research and recommend potential initiatives to analysts, and branch management and senior executive staff. Autonomously find, enrich, transform, interpret, and exploit data to create intelligence products. Act as a Service representative on joint projects related to data science and participate in collaborative efforts where applicable. Provide mentorship and guidance to fellow Data Scientists and Data Exploitation Analysts, regarding intelligence analysis and associated activities pursued in response to the mandate. Recommend new data exploitation projects in annual work plans by identifying analytical gaps and suitable solutions. Regularly update knowledge of academic and industry data science practices and standards. Effectively communicate and present findings to specialists, management and non-technical audiences. Clearly document methodologies employed in research and data exploitation solutions. Mathematics Statistics Computer Science Computer Engineering Field of study related to data analytics Undergraduate degree and seven (7) years of experience Experience performing complex data exploitation on large volumes of data to provide tactical and strategic insights directly to analysts, business owners, and decision makers. Experience gathering requirements and identifying opportunities to apply data science towards business objectives. Experience prototyping and developing data exploitation capabilities using Python, in a Jupyter environment. Experience visualizing analytics, writing reports, producing functional notebooks, and designing and delivering presentations. Experience working with one or more of the following technologies: TensorFlow, PyTorch, Spark, Scala. Experience with supervised and unsupervised machine learning. Experience in the creation and implementation of algorithms and statistical techniques to resolve data science problems. Experience with text analytics and natural language processing (NLP). Experience in the design, creation, and implementation of graph analytics. Experience with complex data processing for time series and patterns of life analyses. Communication Initiative Innovation Creativity Ingenuity Analytical skills Coaching Salary Grade Breakdown 
ScrapedJobID34:
Use SQL and Python to interact with Geotab’s big data infrastructure Leverage learning packages like Scikit-Learn and Tensorflow to develop Machine Learning models Develop new features for Machine Learning models and visualize features Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions Use data mining, model building, and other analytical techniques to develop new datasets and data driven solutions Make recommendations for new metrics, techniques, and strategies to improve Geotab’s product suite Within final two years of a university degree in Engineering, Computer Science, Math or a related field Strong communication, organization, and time management skills, as well as a willingness to learn and strong work ethic Experience using SQL Experience using Python Experience working with Machine Learning algorithms and big data tools is an asset Previous industry work experience preferred Ping Pong and foosball skills always a plus 
ScrapedJobID35:
The OAG takes pride in having a workplace that respects and values our employees’ different backgrounds and talents, which are highlighted through cultural festivals and awareness campaigns. We recognize our employees’ personal needs outside the office and promote a healthy, balanced lifestyle through flexible work arrangements and generous time-off policies. We offer peace of mind through a comprehensive benefits package, which includes a pension plan, a health and dental plan, disability benefits, and an employee assistance program. data analytics services, such as
exploring and assessing the available data sources to deepen our understanding of the business and its data to support audit risk assessments and recommend audit approaches
wrangling and preparing data for analysis
modeling data to provide audit evidence
evaluating and concluding on results exploring and assessing the available data sources to deepen our understanding of the business and its data to support audit risk assessments and recommend audit approaches wrangling and preparing data for analysis modeling data to provide audit evidence evaluating and concluding on results advice on research methods and reviews of services for subjects such as
research methodologies and results measurement
survey design
sampling and extrapolation
results reporting research methodologies and results measurement survey design sampling and extrapolation results reporting support to our Professional Development team as subject matter experts responsible to ensure ongoing relevance and completeness of training materials support to the OAG’s innovation activities as they relate to data analytics and research methods participating in data analytics engagements, ensuring that the audit methodology and the OAG’s policies are properly followed supporting the implementation of innovative solutions that leverage data analytics supporting professional development activities providing on-the-job coaching to new team members identify opportunities to improve the efficiency, quality, and the added value of both financial and performance audits by replacing traditional audit procedures with data analytics models and implement the proposed models develop, test, and implement data analytics solutions to be used by auditors across various audits work with large-scale data extraction, management, validation, cleaning, data mining, data analytics, and predictive analytics as sources of audit evidence in support of OAG audits provide recommendations and advice on data acquisition methods, data analytics approaches, and data presentation review audit reports and other documents for accuracy, completeness, and clarity review analytics, statistical, and methodological approaches used by audited entities in support of OAG audits provide advice and support on the design, administration, analysis, and reporting of internal and external surveys develop and provide training on research methods and data analytics develop audit methodology and guides related to research methodology and data analytics represent the OAG to deliver presentations and speeches 2-page-maximum curriculum vitae (CV) 2-page-maximum cover letter (or document) that includes specific examples demonstrating how you meet the essential qualifications (education and experience) Microsoft Word PDF Recent* experience in large-scale** data extraction, management, validation, and cleaning Recent* experience with research methodology and data analytics Recent* experience in programming in SAS Python, in similar programs that include data set joins and macro processing, or in Python Minimum 2 years post CPA designation or master’s degree as of the date of appointment Recent* experience in large-scale** data extraction, management, validation, and cleaning Recent* experience with research methodology and data analytics Recent* experience in programming in SAS Python, similar programs that include data set joins and macro processing, or Python Recent is defined as experience gained within the last 2 years. Experience in programming in SQL or VBA Experience in programming in R Experience in programming in C# Experience with Power BI Experience with IDEA Experience with data warehousing solutions Experience in building static and dynamic data visualizations Experience in using the following tools: Hadoop, MapReduce, Spark, D3, Shiny, Tableau, or Qlik Experience in working with unstructured data Experience in designing, constructing, administering, analyzing, and reporting for web-based surveys that incorporate branching and piping Experience in working with Government of Canada expenditure management and people management data Recent* experience in developing and providing training on research methodology and data analytics Recent is defined as experience gained within the last 2 years. Integrity and respect Technical subject matter expertise Personal effectiveness and project management skills Personal and people development skills Strategic thinking, rigorous analysis, and sound judgment Productive and collaborative relationships with partners and stakeholders Innovation and ability to guide change Clear and influential communication 
ScrapedJobID36:
Validate existing Geotab (GO) device firmware for data frequency, fidelity, quality and addition metrics. Collaborate with cross functional teams in designing and constructing, and testing firmware from data integrity perspective. Create algorithms and predictive models to extract information required to solve complex business problems. Generate queries from Geotab’s Big Data Infrastructure from Data Warehousing database (i.e. Google BigQuery). Use Machine Learning (ML) packages (e.g. Scikit-learn and Tensorflow) to develop ML models and features. Test the performance of data-driven products and make recommendations for improving Geotab’s product suite. Collaborate with internal technical teams to triage issues and gather requirements. Responsible for the design, development, and maintenance of ongoing metrics, reports, analyses, and dashboards to drive key business decisions. Support a platform providing ad-hoc and automated access to large datasets. Post-secondary Degree/Diploma with specialization in Mathematics, Computer Science, Statistics, or a related field. 1-5 years experience as a Data Scientist or a similar role. Understanding of machine learning and operations research. Highly skilled in working with and triagging real-time (RTOS/Linux) embedded software e.g. C code base, break points, debug logs, etc. Thorough knowledge of programming languages (e.g. Python, SQL, C, C++). Thorough knowledge of Big Data tools and Data Mining/Warehousing Programs (e.g. Google BigQuery). Experience with machine learning techniques (e.g. Scikit-learn, Tensorflow). Experience using/building business intelligence tools (e.g. Tableau) and data frameworks. Experience working within a technical or engineering organization, with knowledge of the high-technology industry is an asset. High accuracy and meticulous attention to detail. Highly organized and able to manage multiple tasks and projects simultaneously. Must stay relevant to technology and should have the flexibility to adapt to the growing technology and market demands. Strong analytical skills with the ability to problem solve to well-judged decisions. Strong team-player with the ability to engage with all levels of the organization. Technical competence using software programs, including but not limited to, Google Suite for business (Sheets, Docs, Slides). Entrepreneurial mindset and comfortable in a flat organization. 
ScrapedJobID37:
Currently pursuing or completed a bachelor's or master's degree in computer science, engineering, or related field. Some Engineering experience and or project course work using large data systems on SQL, Hadoop, etc. Proficiency using one or more programming or scripting language to work with data such as: Python, Perl, or C#. Some experience and or project course work performing data analysis and applying statistics working with tools such as: Excel, R, MATLAB, AMPL, or SAS. Some experience and or project course work with product and service telemetry systems. Some A/B Testing or experimentation (this can be from conducting real life science experiments, hypothesis testing in stats etc.) Not required but ideal. Some experience or course work applying basic ML to a type of data and or used algorithms to conduct experiments on data. Machine Learning strongly encouraged. Passion to learn from your peers, manager, and other stakeholders in the Data Science domain. Ability to interact with peers and stakeholders to drive product and business impact. Strong interpersonal and communications skills. 
ScrapedJobID38:
Build comprehensive analytical solutions to provide tools for decision-making. Perform advanced analysis to guide the company in its strategic choices. Support the various GSoft teams in : Best practices in terms of data collection and usage; Defining and tracking team metrics and goals; Development of the GSoft data culture. Develop statistical and predictive models that allow us to improve the company's processes. Create centralized dashboards and support teams in creating their own data visualizations in different tools. Be proactive in maintaining and improving data quality. Support the Culture & Organization team in leveraging their data (People Analytics). Train the teams in the use of data visualization features of different tools. Set up the foundation to track the customer journey through our different products. Develop lead scoring models to support marketing and sales teams. Continuous improvement of our data warehouses and visualization tools to increase data quality (creation of a single source of truth). Have a few years of experience in data analysis and/or analytical model design. Experience in programming (SQL, Python, R, DAX, etc.). Experience in data visualization and presentation (PowerBI, Tableau, Looker, etc.). Have knowledge of : Statistics and mathematics; Modeling methods (prediction, classification, etc.); Data preparation (extraction, cleaning, etc.); Data models, architectures, warehouses and data environment (basic knowledge). Advanced data analysis techniques. Ability to understand business issues, transform them into technology requirements and clearly communicate analysis results. Ability to collaborate with different teams and support them in their data development. Be able to adapt quickly to a change in context. 
ScrapedJobID39:
Graduated (or will be graduating) between 2020 and September 2022 Have an Associate’s Degree, College Diploma, Bachelor’s Degree, or Master’s Degree (Exception: The Associates Program does not accept MBA or PhD candidates/graduates) Have maximum 2 years of full-time, professional work experience Are within commuting distance of Toronto/Calgary, with flexibility to travel 80-100% of the time Are eligible to work in Canada without current or future need for visa sponsorship Toronto Calgary Communicate with technical and non-technical stakeholders to understand and define business needs and translate them to a data science context Work in an agile, collaborative environment, partnering with other scientists, engineers, consultants, and database administrators to integrate the latest predictive analytics with enterprise-level application development Build teams or write programs to cleanse and integrate data sources in an efficient and reusable manner, resulting in high-quality, clean datasets Incorporate a variety of statistical and machine learning techniques on big data, using leading edge tools such as R (ggplot2) and Python (scikit-learn, tensor-flow), combined with IBM tools and AI application suites Implement and validate predictive models with the end user, using quick feedback loops to iterate and develop the most usable models for the specific use case Deploy and maintain machine learning models using established best practices, allowing the client to consistently gain high value from advanced analytics projects Strong fundamentals in Mathematics and Computer Science (algorithms) Demonstrated programming proficiency and experience with at least one programming language, preferably Java or JavaScript Proficiency in least one or more statistical programming languages (e.g. R, Python, Scala, SAS, SPSS, MATLAB) Basic understanding of or experience with predictive/prescriptive modeling Exposure to Cloud (e.g. AWS, Azure, Google Cloud, IBM Cloud) is an asset Ability to translate business requirements into technical solutions Ability to thrive in an ever-changing, technology-based consulting environment, using agile development techniques 
ScrapedJobID40:
Apply advanced analytics to large data sets to drive the development of use cases that meet customer needs Work with subject matter experts to determine relevant use cases Collaborate with Data Engineers to develop use cases into deployable models Develop tools to monitor and analyze the effectiveness of use cases and new data sources Remain current with cyber threat trends to enhance use cases Other related data analytics support as may be required Master’s degree in Computer Science, Mathematics, Machine Learning or similar 5+ years related work experience with advanced analytics and machine learning Experience with Spark, R, Python, Java, SQL, Hadoop Knowledge of advanced statistical and machine learning techniques General knowledge of enterprise data security Working knowledge of Unix/Linux command line tools Excellent written and verbal communication skills and experience presenting Experience in GCP machine learning and big data tools is an asset Dental care Extended health care Vision care Master's Degree (preferred) Data Science: 3 years (required) Yes 
ScrapedJobID41:
Collaborate closely with our flight, hotel, and pricing business partners Leverage data analyses, modeling, and visualization tools such as R and/or Python, Oracle SQL, BigQuery, MySQL, Tableau, and others Mine rich data sets and develop models to evaluate sales performance, supply health, pricing performance, and other cross-functional use-cases Provide insights into the flight and hotel business, monitor performance by defining and refining critical KPIs Present the technical material to both technical and non-technical audiences Devise tests, experiments, and monitoring to validate model performance Partner with Data Engineers to build and maintain data infrastructure Conduct analysis on strategic projects and provide actionable recommendations Answer tough questions with data 3+ years of data science and/or analytics experience building quantitative and/or machine learning models. Travel / flight / ecommerce industry experience preferred Bachelor’s Degree or higher from top university in a quantitative subject (e.g., science or math) Experience in Python and/or R along with their associated ML/AI Libraries. BigQuery/GCP, Tableau, and Excel experience are nice to have. Excellent written and verbal communication; proficient in presentation writing tools (e.g., Power Point, Slides) Have experience in developing frameworks and performing gap analysis Project management and work structure skills – excellent attention to detail and ability to work independently Hands-on, extensive knowledge and experience working with large databases, data mining and business intelligence tools Strong analytical and problem-solving skills Ability to communicate complex concepts in a simple way to senior leadership is a must Ability to work under pressure and multi-task in a fast-paced/rapidly changing environment Comfortable with ambiguity Passion for travel and business 
ScrapedJobID42:
Available in all 3,143 U.S. counties. Nearly 4.5 million customers in the last 12 months Hundreds of thousands of local professionals on our platform 65 million projects started on Thumbtack Over 7 million 5-star reviews left for stellar pros Characterize marketplace dynamics. Thumbtack's marketplaces are comprised of thousands of active markets across our service categories and U.S. cities. Via exploratory data analysis and experimental design, our team works to understand trends and behaviors within these markets. Improve customer and service provider matching. Matching and optimization algorithms are fundamental to Thumbtack's product: we now service millions of matches per week. Identifying better matches between customers and service providers has an incredible impact on the experience of customers and professionals transacting on our platform. Model complex relationships in the presence of many confounding factors. Predictive modeling problems are everywhere across our product. Our team works to scope, design and implement machine learning models to support Thumbtack's product. Design and execute experiments, collect and analyze data to characterize our product Architect and deploy machine learning systems to production Design and implement metrics that align with company goals Analyze a wide variety of data: structured and unstructured, observational and experimental Collaborate with engineering, marketing, and economists to use sound statistical practices. M.S. or equivalent experience in Computer Science, Economics, Engineering, Math, Statistics, or other relevant technical field Expert knowledge of machine learning techniques: regression and classification, clustering, neural networks, boosted decision trees, etc. Ability to effectively read, write, and debug code in programming languages such as Python Good knowledge of probability and statistics, including experimental design, optimization, and causal inference Excellent written and verbal technical communication skills Ph.D. in Computer Science, Economics, Engineering, Math, or Statistics
Expert knowledge of probability and statistics, including experimental design, predictive modeling, optimization, and causal inference
Experience with large-scale distributed systems Ph.D. in Computer Science, Economics, Engineering, Math, or Statistics Expert knowledge of probability and statistics, including experimental design, predictive modeling, optimization, and causal inference Experience with large-scale distributed systems See what it's like to work here Meet the pros who inspire us Learn about engineers on a mission Follow us on LinkedIn Discover our virtual first plan 
ScrapedJobID43:
Use data to improve CI/CD practices Build and deploy models supporting product features that help 100,000+ developers ship code faster Help build company-wide practices to enable model discovery, deployment, monitoring, and governance Data science experience: Two or more years in data science, analytics, or comparable roles. At least one year focused on models and algorithms. Experience with model selection. Creativity in adapting tools and techniques. Instinct for product discovery: Experience with product management and the discovery of data products. Effective data-product prototyping. Able to uncover insights in data sources. Effective juggler of scope, time, and value. Able to build multi-functional partnerships. 
ScrapedJobID44:
Strong ability to create, generate and leverage relevant, actionable insights based on iterative data analysis, translate data driven output into business language, and make appropriate recommendations to respective business stakeholders Automates analytics and reporting tasks by developing appropriate code for refreshing results & repeatability Improve existing scripts for custom, in-house built software solutions for performance and scalability, to further develop and identify opportunities to create unique insights usable by the business owners Visualizes and delivers results of analyses by creating reports, infographics, and dashboards that benefit other departments within the organization Works with IT to ensure data is consistent with company requirements, builds data tables and integrates with other companies’ systems where appropriate Assist in the creation of scripts to ingest and process raw data into databases and data warehouse Maintains data health and integrity across systems Documents developments and reporting processes to ensure continuity of delivered materials Stays current with innovations in data acquisition, modelling and analytics Has an innate understanding of the business value chain and customer lifecycle. Aligns project support with broader business strategy, including core drivers of business value Performs other duties as required Advanced degree in Statistics, Mathematics, Computer Science, or Engineering; or Bachelor’s degree with equivalent technical experience Proficiency with general purpose programming language (e.g. Python) and associated libraries for scientific/computing, including various statistical and visualization packages (e.g. Pandas, Matplotlib, NumPy, SciPy) Proficiency with Business Intelligence Software (e.g. PowerBI) and dashboard development Proficiency with developing, testing and deploying machine learning models in a production environment Effective analytical, mathematical, and problem-solving skills Innovative / creative mindset Sound organizational/prioritization skills Able to work under pressure in a fast-paced environment Able to work in a collaborative and cooperative way with the various stakeholders and communicate information effectively Previous experience in a similar role is an asset Periodic overtime to meet deadlines or accommodate time zone differences 
ScrapedJobID45:
Apply statistical modelling to optimization tests Develop machine learning systems to mine our data warehouse Develop costing models for risk and value for our transaction processor Run statistical analyses to discover insights about our customers and leads Provide training as our in-house statistics professor Generate ideas as we brainstorm new ways to leverage our existing data Master’s Degree, PhD or equivalent education At least 5 years working experience using Machine Learning Extensive experience performing in depth analytics and testing Experience in Azure ML and R an asset, but not required Strong multi-tasking, organizational and time management skills Keen attention to detail and ability to work independently Outside of the box thinking, someone who is not afraid to ask questions and look for new/different solutions. Unlimited paid vacations Liberal Work-from-Home policy Flexible hours Group RRSP program Regular in-person company events Support for continuous learning and development 
ScrapedJobID46:
Work in partnership with content creators to design shared services Design, develop and implement cloud-based AI and machine learning production pipelines Ensure AI and machine learning production pipelines are scalable, repeatable, cloud agnostic and secure Apply current and emerging techniques in deep learning, computer vision and other machine learning areas Collect, clean, manage, analyze, and visualize large sets of data using multiple data platforms, tools and techniques A minimum of 2+ years of experience in data science Bachelor’s degree in a related field Strong expertise in deep learning, in particular computer vision Expertise in automating machine learning models and building end to end products Experience with source code management (Perforce, Git) Effective within public Cloud environments Understanding of containerization for deploying our solutions Experience with CI/CD pipelines 
ScrapedJobID47:
Create project charters involving business problem definition, business value, performance metrics, success criteria, scope, and milestones. Coordinate analysis with others. Respond to inquiries and follow up on data validations Provide recommendations based on the results to facilitate business strategy. Collaborate with cross-functional teams (such as customers and internal IT teams) to understand business needs, ensure data integrity and flow efficiency, and to create tools for customer utilization. Provide quality validations and on-going support of client and projects. Ensure quality control to evaluate the accuracy of deliverable and/or project analysis. Interpret Third Party reports to the business Drive implementations of Privacy redactions with Internal Teams. Finalize and deliver the results of assigned projects to internal clients Collaborates with IT group to transform and prepare data for analysis. Balances the quantity/quality of own work with the business situation; demonstrates enthusiasm, drive and a sense of urgency when completing work. Excellent verbal, written and presentation skills. Strong analytical and assessments skills. Strong project management skills. Strong ability to translate data driving insights into decisions and actions. Strong ability to think strategically and be proactive and collaborative. Heavy experience in Python, especially with machine learning toolkits such as scikit-learn, pytorch, and TensorFlow, and Natural Language Processing toolkits such as NLTK or spaCy. Experience in cleaning and transforming data for machine learning. 2+ years’ relevant experience. Experience working with Natural Language Processing preferred. Knowledge of machine learning and predictive modeling. Experience using Python. Knowledge of database operations such as those found in pandas and relational database query languages such as SQL. Experience in Spark, AWS, Hadoop, or other distributed computing environments. Master’s degree or international equivalent in Computer Science, Statistics, Data Science, Mathematics or similar analytical fields. Experience in handling time-series and image data is a bonus. 2+ year’s experience in the healthcare industry preferred Equivalent combination of education, training, and relevant experience may be considered in place of the education and experience stated above. All employees must read, write and speak fluent English and host country language. This job description is intended to present the general content and requirements for the performance of this job. The description is not to be construed as an exhaustive statement of duties, responsibilities, or requirements. 
ScrapedJobID48:
Participate in analysis of client data and formulate well-defined problem statements and recommendations for advanced analytical workflows that are usually provided as very open-ended problems Create and design dashboards by using different data visualization tools to present reports and insights, and support business decision making Design and develop ETL workflows for serving data to the dashboards as needed Write complex SQL queries with multiple joins to automate and manipulate data extracts Perform exploratory data analysis to identify patterns from historical data, generate and test hypotheses, and provide product owners with actionable insights Create advanced analytical models using advanced statistics, machine learning or other methods for client-specific use cases Create production-worthy ML workflows and pipelines. Participate in the creation of Statements of Work and other Prospecting activities that require technical expertise and inputs. Participate in end to end analytical system design when needed, including end to end ETL, reporting and visualization workflows, ML pipelines (continuous training, continuous serving) and data modelling as required Design testing process, create and execute test cases for advanced analytical workflows Troubleshoot and resolve issues and defects Maintain and exceed client satisfaction with StackPros Inc.’s deliverables, day-to-day work and overall value as a partner Cultivate opportunities for company growth, always seek areas where StackPros Inc.’s role could be expanded Adapt to ever-changing client needs and expectations Maintain dedication toward achieving excellence in StackPros Inc.’s delivery against client needs, and overall success as an organization Be an enthusiastic, positive and generally awesome team mate, mentor & constantly curious learner Stay up-to-date on relevant technologies, plug into user groups, understand trends and opportunities to ensure we are using the best possible techniques and tools Enthusiasm to take on new challenges Ability to learn and adapt quickly 1+ years experience working on Data systems and advanced analytical workflows built on the cloud. GCP, AWS or Azure preferred Strong understanding of statistical analysis of data including correlation analysis, outlier analysis and hypothesis testing Strong understanding of data visualization concepts, different types of visualisation charts and choosing the appropriate visualisations to convey insights effectively 1+ years of experience building interactive dashboards using at least 1 data visualization tool such as Data Studio, Tableau, PowerBI or Looker. Experience building visualisations exclusively using Python or other programmatic libraries will also be considered. 2+ years of experience using Python. Java or other programming language experience will also be considered 2+ years of experience using SQL. Experience writing large dynamic analytical queries will be a strong asset Strong understanding of regression models, classification models, neural networks, decision tree models and unsupervised learning models such as k-means clustering. Ability to analyze a problem and make decisions on the appropriate candidate models for the problem Experience building machine learning models on large datasets Experience in hyperparameter tuning and evaluation of ML models Experience using data science libraries such as pandas, matplotlib, scikit-learn, keras, nltk etc. Experience using Tensorflow is a strong asset Strong understanding of Feature Selection and Feature Engineering concepts Experience using ETL/orchestration/workflow management frameworks like Apache Airflow preferred, but not required Strong understanding of and experience with large scale OLAP databases and data warehouses. Strong understanding of Google Cloud BigQuery preferred Understanding of digital marketing ecosystems and tools like Google Marketing Platform, GA360, Google Ads, Adobe Suite etc. a strong asset Technical understanding of a range of marketing concepts such as cookie-based data collection, setting and leveraging audience segments, attribution modelling, A/B testing, knowledge of marketing KPIs and their calculation will be a strong asset. Excellent written & verbal communication skills are essential; candidate should be comfortable presenting and participating in group discussions of concepts with internal and external stakeholders 100% employer-paid benefits package Monthly yoga and meditation classes Regular Lunch and Learns from your Team Mates Fun Employee Events and Activities Participation in Community Engagement 
ScrapedJobID49:
Design, develop, test, advocate and build predictive models and segmentations Effectively communicate the analytics approach and how it will meet and address objectives to business partners. Advocate and educate on the value of data-driven decision making; focus on the "how and why" . Identify and develop long-term processes, frameworks, tools, methods and standards. Coordinate with different functional teams to implement data engineering, models and monitor outcomes Assists in the development of strategic plans. Understands and analyzes complex business problem, then formulates data-driven hypotheses to drive business value. Develops experimental design approaches to validate findings or test hypotheses. Diagnoses and resolves predictive / analytical model performance issues while monitoring system performance and implementation of efficiency improvements. Applies innovative and best practices to advanced analytics services to ensure high quality standards. Sets up change control and testing processes to ensure the quality and consistency of ongoing maintenance work. Develops analytical solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs. Works with various data owners to discover and select available data from internal sources and external vendors Applies scripting / programming skills to assemble various types of source data (unstructured, semi-structured, and structured) into well-prepared data sets with multiple levels of granularities (e.g., demographics, customers, products, transactions). Summarizes statistical findings and draws conclusions, presents actionable business recommendations. Presents findings & recommendations in a simple, clear way to drive action. Performs experimental design approaches to validate finding or test hypotheses. Supports development of tools and delivers training for data analytics and AI. Typically, between 5 - 7 years of relevant experience and post-secondary degree in related field of study or an equivalent combination of education and experience. Advanced degree (Master/Ph.D. preferred) in Computer Science, Mathematics, Physics, Engineering, Statistics, or other quantitative disciplines and/or equivalent experience Experience with distributed computing language & cloud technologies Experience with programming languages and machine learning /deep learning algorithms/packages, supervised learning, clustering, natural language processing, recommender engines, time series analysis, A/B testing, network/link analysis, sentiment analysis and data visualization. Deep proficiency in statistical analysis, quantitative analytics, forecasting/predictive analytics, multivariate testing, and optimization algorithms. Deep knowledge and technical proficiency gained through extensive education and business experience. Competitive salary and benefits package Associate discount up to 40% including top brands Flexible work environment that allows for work-life balance 
ScrapedJobID50:

ScrapedJobID51:
Graduated (or will be graduating) between 2020 and September 2022 Have an Associate’s Degree, College Diploma, Bachelor’s Degree, or Master’s Degree (Exception: The Associates Program does not accept MBA or PhD candidates/graduates) Have maximum 2 years of full-time, professional work experience Are within commuting distance of Toronto/Calgary, with flexibility to travel 80-100% of the time Are eligible to work in Canada without current or future need for visa sponsorship Toronto Calgary Communicate with technical and non-technical stakeholders to understand and define business needs and translate them to a data science context Work in an agile, collaborative environment, partnering with other scientists, engineers, consultants, and database administrators to integrate the latest predictive analytics with enterprise-level application development Build teams or write programs to cleanse and integrate data sources in an efficient and reusable manner, resulting in high-quality, clean datasets Incorporate a variety of statistical and machine learning techniques on big data, using leading edge tools such as R (ggplot2) and Python (scikit-learn, tensor-flow), combined with IBM tools and AI application suites Implement and validate predictive models with the end user, using quick feedback loops to iterate and develop the most usable models for the specific use case Deploy and maintain machine learning models using established best practices, allowing the client to consistently gain high value from advanced analytics projects Strong fundamentals in Mathematics and Computer Science (algorithms) Demonstrated programming proficiency and experience with at least one programming language, preferably Java or JavaScript Proficiency in least one or more statistical programming languages (e.g. R, Python, Scala, SAS, SPSS, MATLAB) Basic understanding of or experience with predictive/prescriptive modeling Exposure to Cloud (e.g. AWS, Azure, Google Cloud, IBM Cloud) is an asset Ability to translate business requirements into technical solutions Ability to thrive in an ever-changing, technology-based consulting environment, using agile development techniques 
ScrapedJobID52:

ScrapedJobID53:
Transformation of complex data sets into meaningful conclusions & recommendations Develop innovative solutions for pattern recognition using machine learning and statistical approaches Maintenance of expanding set of data mining tools, frameworks & approaches Communicate actionable recommendations based on insights/model results Driving co-ordination/delivery accountability of project and BAU delivery based on timelines & direction Driving conformance/Alignment to IT/Enterprise Architecture standards (where applicable) An educational background in computer-science or engineering, math, statistics, physics or related field. A minimum of MSc is required and Phd preferred. 5+ years of experience with model development and working with large datasets. This can include experience from any industry or academia (post-doc experience). 5+ programming experience in Python or R with good grasp of software engineering standard methodologies such as code-reusability, modularity, use of repos, etc. A growth mindset with versatile skills and able to work through problems from first-principles. A portfolio of projects that demonstrate your ability to draw inferences from data. This includes participation within the broader data science community including Kaggle competitions or any personal projects with open data. A can-do teammate who is willing to roll-up the sleeves and do whatever is needed to move projects forward. That means at times you will wear different hats and be a project manager, developer, modeler and chief communicator of solutions. Amazing people skills and able to translate and communicate complex algorithms to non-technical individuals. Someone who understands that it is not enough to just have a phenomenal algorithm but meaningful to build an agreement for the solution from different partners. The best problems in the industry are yet to be articulated. We need someone who is creative, self-motivated and can lead projects independently. Competitive rewards package including base compensation, eligibility for annual bonus, retirement savings, share plan, health benefits, personal wellness, and volunteer opportunities. Exceptional Career Development opportunities. We’ll support your professional development education 
ScrapedJobID54:
Application of machine learning to an automated financial services platform. Design of sophisticated algorithms that work on large datasets in real-time. Tackling sophisticated analytical problems to find business solutions. Implementing the changes to production and evaluating the impact. Developing risk strategies to assess the implications of the new projects. Support credit risk management by assessing losses by customer profiling. Formulating, suggesting, and managing data-driven projects independently which are geared at furthering the business's interests. Selecting and employing advanced statistical procedures to obtain actionable insights. Cross-validating models to ensure their generalizability. Suggesting ways in which insights obtained might be used to inform business strategies. You’ll be transforming data into action by working cross-functionally with stakeholders across Thinking Capital. Use your quantitative mindset to direct the implementation of solutions informed through everything ranging from data quality investigations and adjustments to data structures to overall data program management. Diagnosing, documenting, and reporting drivers of unexpected changes to portfolio/origination composition and credit performance. Communicating your findings including future impacts to losses and proposed recommendations to Senior Management as required. A master or graduate degree in statistics or equivalent 3+ years of hands-on experience acting as a Data Scientist. Machine learning and artificial intelligence Statistical methodology (eg linear & logistic regression, time series models, hypothesis testing, etc) Python (Pandas), R (tidyverse) and SQL Algorithms, data structures, and computational mathematics Experience with analytics for large messy data sets Obtaining data from websites via scraping, APIs, and third parties Proficiency with Linux command-line Working autonomously and being highly resourceful * We believe in innovation and vibrant culture* - work for an innovative, people-first, financial services firm that values entrepreneurialism We believe in a flexible work structure – A flexible hybrid work model that empowers you to do your best work whether at home or at the office We care about your rewards - Competitive compensation including equity programs We care about your health – comprehensive group health and dental benefits and life insurance, including a Lifestyle Spending Account for all your wellness needs We care about your rest - a flexible paid-time-off policy with unlimited vacation days, flexible sick and mental health days We care about your family - Paid parental leave for eligible employees with top-up We care about your future – Group RRSP matching and TFSA program in Purpose funds We care about your development – subsidies are available for courses and tuition 
ScrapedJobID55:

ScrapedJobID56:
You are working in an interdisciplinary team of sales, marketing, finance, and IT experts, willing to share knowledge and expertise with you. You help gather data from multiple sources; document and catalog into a central repository system on AWS. You support the setup of KPI-oriented / data-based reports and analysis for all levels of management and enhance digital transformation of BMW Group Canada. Processing raw data to desired output format and performing analysis on it. Creating data visualizations and establishing data pipelines to Tableau dashboards. Driving automation of reports and ensuring availability of accurate data in dashboards. Collaborating within Agile Working Model and processes such as Scrum, Kanban using JIRA platform. Current student or recent graduate in Data Science, Data Analytics or a comparable course of studies. Minimum one-year experience within Sales, Marketing, Business Development or IT. Relevant analytics and/or BI related working experience is preferred. Strong knowledge in MS Office, especially PowerPoint and Excel. Knowledge in data visualization programs like Tableau, Qlik, or Power BI. Coding experience in data processing, aggregation (R, Python) and database management (SQL) is an asset. Analytical thinking and first knowledge in analyzing and visualizing data. Fast learner and willingness to work with Data Analytics Software. Teamwork and communication skills. Openness, motivation and hands-on mentality. 
ScrapedJobID57:
Provides expertise on mathematical concepts for the broader applied analytics team and inspires the adoption of advanced analytics and data science across the organization. Help to interprets the meaning of new strategic directions and sets objectives and measurements. Implements monitoring and feedback systems to evaluate progress and identify ways of making continuous improvements. Solicits and offers ideas for improving business processes through insights with the objective of improving effectiveness and efficiency Educates the organization both from IT and the business perspectives on new approaches, such as testing hypotheses and statistical validation of results. Helps the organization understand the principles and the math behind the scientist process to drive organizational alignment Converses with, writes reports and creates/delivers presentations to colleagues and peer groups in ways that support problem solving and planning. Explains the context of multiple inter-related situations, asks searching, probing questions, and solicits expert advice prior to taking action and making recommendations. Provides business metrics for projects and initiatives to show improvements (contribution to the improvement should be monitored initially and over multiple iterations). Demonstrates the scientist qualities in results: clarity, accuracy, precision, relevance, depth, breadth, logic, significance, and fairness. Gathers and analyzes information or data on current and future trends of best practice. Seeks information on issues impacting the progress of organizational and process issues. Translates up to date information into continuous improvement activities that enhance performance Research organizational and professional trends. Evaluates information sources, and collates and compares findings for bias, omission, and accuracy. Conducts objective analysis. Provides insight into leading analytic practices, designs and leads iterative learning and development cycles, and ultimately produces new and creative analytic solutions that will become part of core deliverables. Improves organizational performance though the application of original thinking to existing and emerging methods, processes, products, and services. Employs sound judgment in determining how innovations will be deployed to produce return on investment. Challenges conventional thinking and traditional ways of operating and invites stakeholders to identify issues and opportunities. Seeks out opportunities to improve, streamline, reinvent work processes. Explores multiple potential solutions and evaluates each with data. Identifies what data is available and relevant, including internal and external data sources, leveraging new data collection processes such as smart meters and geo-location information or social media. Diagnose problems using formal advanced problem-solving tools and techniques from multiple angles and probes underlying issues to generate multiple potential solutions Works in iterative processes with partners and validates findings. Develops experimental design approaches to validate finding or test hypotheses. Identifies and analyzes patterns in the volume of data supporting the initiative, the type of data (e.g., images, text, clickstream, or metering data) and the speed or sudden variations in data collection. Collaborates with other members of formal and informal groups in the pursuit of common missions, vision, values, and mutual goals. Actively solicits ideas and opinions from others to quickly accomplish specific objectives targeted at defined business outcomes. Works with IT teams to support data collection, integration, and retention requirements based on the input collected with the business. Assesses, with the business, the expected qualification and assurance of the information in support of the use case. Defines the validity of the information, how long the information is meaningful, and what other information it is related to Collaborates with data stewards to ensure that the information used follows the compliance, access management, and control policies and that it meets the qualification and assurance requirements of Meridian. Partners with data stewards to define the data quality expectation in the context of the specific use case. Typically requires 2+ years of relevant quantitative and qualitative research and analytics experience. Minimum 2 years of strong experience using python, data management (SQL and SAS) and statistical modeling (SAS or R). Experience using machine learning algorithms. Proficiency in the use of statistical packages. Proficiency in statistical analysis, quantitative analytics, forecasting/predictive analytics, multivariate testing, and optimization algorithms. Bachelor’s degree in mathematics, statistics or computer science or related field; Master degree preferred. Solid knowledge of statistical techniques. Experience in report automation and report analytics. Advance knowledge in MS Office with visual basic. Demonstrated ability to come up with solutions to loosely defined business problems by leveraging pattern detection over potentially large datasets. Strong communication and interpersonal skills. Knowledge of one or more business/functional areas. Ability to travel on a frequent basis within St. Catharine’s and Toronto is a requirement potentially in the future Opportunity to work within, create, and drive a culture of growth and innovation. Inspire a positive work environment and help champion quality service, innovation, teamwork to assist our Members. Learn voraciously, stretch you and your team’s thinking, share your knowledge, and educate others! Cultivate winning relationships & building trust Share our commitment to productivity, effectiveness, and operational efficiency. Be an agent of change, help others to embrace it and watch amazing things happen! Help your community through a variety of outreach programs! 
ScrapedJobID58:
Powering revenue growth through the design and implementation of algorithms, machine learning & decision intelligence. This includes promo, price & assortment optimization, including dynamic personalized recommendations at the customer & product level Researching, designing and implementing analytical models and algorithms that will be utilized for promotion, pricing, product, media & revenue optimization. Analyzing & distilling loyalty insights from diverse data sets (member, segment & program level) Enabling best in class offer generation (customer targeting & offer assignment) & optimization based on all the available data, scores & model outputs. Elevate the data science discipline by providing coaching & thought leadership to junior members of the technical team. Degree in quantitative field (e.g. Computer Science, Engineering, Mathematics, Statistics, Operations Research or other related field) 3+ years experience in developing and implementing data science solutions, including but not limited to econometric modeling, classification and prediction models, time series analysis, clustering, recommender systems Proficient in writing complex SQL queries to extract and transform data from multiple data sources Experience in using one or more statistical programming languages (Python would be preferred) Familiarity with data warehousing, data processing pipelines and data structures Natural curiosity to solve problems and find meaning in complex data sets & customer behaviour analysis. Strong business acumen to apply recommendations in the proper commercial context. 
ScrapedJobID59:
Be proficient in all stages of model building – data sourcing, exploratory data analysis, data profiling, data cleaning, data preparation, feature engineering, scaling, model development, validation techniques, and model deployment to production Given a problem statement, be able to identify machine learning method (supervised/unsupervised) and categorize the problem into regression/classification/clustering models Ability to explore large datasets, visualize the data, and unearth the hidden data patterns Assess and understand data quality, and prepare quality datasets for training machine learning models Identify suitable machine learning algorithms, derive feature importance, define accuracy metrics to build, and validate models Define validation strategy, rank models, and choose the best model Must be able to explain the model outcome Ability to code in Python, write complex SQL and use AI/ML tools on cloud platforms (Azure, GCP, AWS) Be self-driven and welcome new learning opportunity to grow skills Guide and share knowledge with the team on approaching different data science problems Work in a fast growing and exciting organization with professionals who are eminent in their respective field Have challenging and interesting work in a team environment Continue your development throughout your career to reinforce and expand your chosen career path Minimum of 5 years of relevant experience. Experience as a Data Scientist in end to end machine learning life cycle Experience in Python, NumPy, Pandas, scikit-learn, statsmodels, TensorFlow, PyTorch, and/or predictive/cognitive analytics technologies Experience in R is an asset Working experience with predictive/cognitive modeling Knowledge or experience with AI/ML tools on a cloud platform (e.g. Azure) such as Azure ML, Azure Cognitive Services, etc. is considered a strong asset Experience in SQL queries for data sourcing Experience with one or more database and unified analytics engines: DB2, Azure SQL, Spark, HANA Demonstrated ability to deal with structured, unstructured data and ability to prepare it for analytic operations Demonstrated ability to integrate data from multiple sources with varied formats Exposure to MLOps on any platform is a preferred Knowledge in NLP techniques is nice to have Experience in working with Transformer based models like BERT, RoBERTa, T5 is nice to have Lead the way: Deloitte is not only leading the profession, but reinventing it for the future. We’re also committed to creating opportunity and leading the way to a more sustainable world. Serve with integrity: Deloitte has earned the trust of employees, clients, regulators, and the public for 175 years. Upholding that trust is our single most important responsibility. Take care of each other: We look out for one another and prioritize respect, fairness, development, and well-being. Foster inclusion: We are at our best when we foster an inclusive culture and embrace diversity in all forms. We know this attracts top talent, enables innovation, and helps us deliver well-rounded client solutions. Collaborate for measurable impact: We approach our work with a collaborative mind¬set, teaming across businesses, geographies, and skill sets to deliver tangible, measurable, attributable impact. 
ScrapedJobID60:
Understanding and applying latest AI techniques Processing huge amount of data and extracting relevant information from them Deploying the models for various use cases Handle ambiguity and able to move forward with imperfect information and get things done in a rapidly changing environment Must be comfortable working in an environment where ideas are challenged; Astute in aligning effort & resources to achieve desired results. Expertize in production deployments. Solid understanding of ML/NLP algorithms including supervised and unsupervised learning, support vector machines, word vector representations, language/sequence modelling, parsing, sentiment analysis, sentence classification, sequence to sequence learning In depth knowledge of deep learning methods including recurrent neural networks, Long short-term memory (LSTM) networks, recursive neural networks, autoencoders Demonstrated expertise in solving business problems using ML/NLP solutions Strong programming skills in C++/java/R and python Experience with libraries such as Natural Language Toolkit (NLTK), Stanford CoreNLP, OpenNLP Preferred - Masters or PhD in Computer Science, MIS or equivalent from a Tier 1 school Good knowledge of deep learning hardware and software TensorFlow, PyTorch, Caffe Experience with deploying machine/deep learning solutions in the cloud 3-8 years of overall experience in building machine learning solutions. A self-starter, independent-thinker, curious and creative person with ambition and passion Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next. Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way. Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs. Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs. 
ScrapedJobID61:
Annotating, training, testing, iterating, and production monitoring of computer vision models. Deploying computer vision models into an edge environment. Developing machine learning models for crop performance and pests/disease propagation. This includes developing techniques for analyzing time series and spatiotemporal patterns and distributions. Developing production-ready code with robust algorithms for consistent operation in a production environment. Analyzing customer horticultural data to provide meaningful insights. Occasional field visits to greenhouses to collect data, develop or test approaches. Bachelor’s degree in Computer Science, Data Science, or any other related field. 1+ years of experience developing, training, optimizing deep neural networks using one or more deep learning frameworks such as Tensorflow, Darknet, Pytorch, etc. Experience applying various machine learning techniques. Experience in turning computer vision models into production code and deploying them into an edge environment. 1+ years of experience with Python. Excellent communication skills. Ability to find practical solutions in a highly innovative and fast-paced environment. Experience with agricultural and/or biological systems. Familiarity with Amazon Web Services. Experience is valuable, but the willingness and ability to learn quickly are even more important. A friendly-but-relentless approach to work is important for this role. 
ScrapedJobID62:

ScrapedJobID63:
You are highly analytical with a knack for analysis, math and statistics You’ve got critical thinking and problem-solving skills which are essential for interpreting data You have a passion for machine-learning and research! Build pragmatic, scalable and rigorous ML and AI solutions that enables data driven improvements for healthcare businesses projects such as AI/Virtual coaching, Clinical Decision Support, customer intent models, etc. Use deep learning, machine learning and analytical techniques to create scalable solutions to address healthcare needs Deliver effective business solutions from ideation to QA and deployment Work collaboratively with colleagues to define problem statements, collect data and define solution approaches Build and maintain ML models, experiments, and forecasting analytics. Leverage Python, Hadoop, Spark and similar Big Data frameworks to deliver efficient analytics Communicate clearly the methods, impact and processes you have taken with clients and other stakeholders Masters or Ph.D. degree in a STEM field (e.g. Computer Science, Engineering, Physics, Mathematics, Statistics, Economics, or related field); 3 to 5 years of industry experience solving analytical problems using ML approaches; Experience performing data extraction, data cleaning, exploratory data analysis and sharing results over medium to large datasets; Strong Python or R, and SQL skills; Experience with one or more of Scikits-learn, Tensorflow, Keras, Theano or Pytorch; Excellent analytical skills to self-assess robustness and performance of machine learning models; Experience in Agile delivery methodologies Good communication skills to explain insights and methods; Experience with Big Data systems and frameworks (Hadoop, AWS, GCP, Spark, etc) is a plus Enjoy learning new data science methods and technologies Strong attention to detail Strong understanding of a relevant healthcare area - bioinformatics, hospital data systems, population health or other related area Track record scoping, designing and delivering ML healthcare projects through to production Strong working connaissance of deep learning, machine learning and statistics Hands-on experience building models with deep learning frameworks such as MXNet, TensorFlow, Caffe, or similar Experience of building effective solution architectures Experience hiring or mentoring more junior colleagues Strong communication and data presentation skills The motivation to achieve results in a fast-paced environment Comfortable working in a fast paced, highly collaborative, dynamic work environment Fluency in at least one other language We are a group of people who are bright, kind, and motivated by challenge. We are a successful, fast-growing company at the forefront of tech and healthcare. We love solving problems, thinking creatively, and trying new things. We believe in autonomy & taking initiative. We take what we do seriously, but we also know how to have fun. We have a smart, experienced leadership team that wants to do it right & is open to new ideas. We offer competitive compensation packages and comprehensive health benefits. You can be your authentic self here and are empowered to encourage others to do the same! 
ScrapedJobID64:
Graduated (or will be graduating) between 2020 and September 2022 Have an Associate’s Degree, College Diploma, Bachelor’s Degree, or Master’s Degree (Exception: The Associates Program does not accept MBA or PhD candidates/graduates) Have maximum 2 years of full-time, professional work experience Are within commuting distance of Toronto/Calgary, with flexibility to travel 80-100% of the time Are eligible to work in Canada without current or future need for visa sponsorship Toronto Calgary Communicate with technical and non-technical stakeholders to understand and define business needs and translate them to a data science context Work in an agile, collaborative environment, partnering with other scientists, engineers, consultants, and database administrators to integrate the latest predictive analytics with enterprise-level application development Build teams or write programs to cleanse and integrate data sources in an efficient and reusable manner, resulting in high-quality, clean datasets Incorporate a variety of statistical and machine learning techniques on big data, using leading edge tools such as R (ggplot2) and Python (scikit-learn, tensor-flow), combined with IBM tools and AI application suites Implement and validate predictive models with the end user, using quick feedback loops to iterate and develop the most usable models for the specific use case Deploy and maintain machine learning models using established best practices, allowing the client to consistently gain high value from advanced analytics projects Strong fundamentals in Mathematics and Computer Science (algorithms) Demonstrated programming proficiency and experience with at least one programming language, preferably Java or JavaScript Proficiency in least one or more statistical programming languages (e.g. R, Python, Scala, SAS, SPSS, MATLAB) Basic understanding of or experience with predictive/prescriptive modeling Exposure to Cloud (e.g. AWS, Azure, Google Cloud, IBM Cloud) is an asset Ability to translate business requirements into technical solutions Ability to thrive in an ever-changing, technology-based consulting environment, using agile development techniques 
ScrapedJobID65:
Perform exploratory data analysis on auction data to form hypothesis Build models to test the hypothesis Optimize auction strategies using statistics and machine learning techniques Collaborate with other developers to make the models reproducible and production-ready 1-2 years of professional experience in data analysis using Python Highly knowledgeable in statistics and probability Experienced in conducting hypothesis testing Have good understanding of classical machine learning techniques Knowledgeable in reinforcement learning algorithms is a plus Proficiency in SQL, pandas, NumPy, scikit-learn, Matplotlib, etc. Collaboration: Working remotely on complex projects necessitates that you work together with your team and share knowledge. Communication Skills: You are comfortable communicating in English at all levels, have strong spoken and written communication skills and are an active listener. Teamwork: You value team synergy and are excited about helping your team succeed. Interpersonal Skills: You are able to get along, work well and coordinate with others. Conflict Management: As a team, we are proactive in dealing with conflict. You are able to find constructive ways of resolving issues with other team members. Technology: A MonetizeMore developer is proficient in all stages of web development, from conception to deployment. You are a one-person army, ready and willing to attack any technical challenge that crosses your path Analytical and Problem Solving Skills: You work hard to understand technical issues and to resolve them in an effective manner. Detail Orientation: You work on many parts of an application or system at the same time and are able to focus on each detail meticulously. Initiative: You work well in a team, with little supervision, making well-reasoned and effective technical decisions. Reliability and Responsibility: You demonstrate reliability at all times. You give reasonable expectations within the Agile Scrum framework and work hard and smart to achieve and surpass those expectations. You communicate what you are going to do, then meet that commitment. Thought Leadership: You analyze MonetizeMore’s tech stack, systems and processes with the goal to iterate on a regular basis. You look for opportunities to improve to increase value to MonetizeMore and suggest them to the team. 
ScrapedJobID66:
Build advanced machine learning models with a direct impact on Upwork users’ experience. Improve Upwork’s search and recommendation relevance using Deep Collaborate closely with data scientists, engineers, designers and product managers to build products end-to-end on key initiatives. Strong problem-solving skills with an emphasis on product development. Deep knowledge of machine learning, neural networks, recommender systems, natural language processing or related fields. Industry experience delivering and maintaining production models at scale using Spark, Python, SQL, Scala, Tensorflow (or similar alternative). Excellent English skills - verbal and written communication. Full-time (40 hrs/week). Flexible, fully remote working hours with a required overlap for communication with a team in California (9am to 12 pm PST). Casual dress Extended health care Flexible schedule Wellness program Work from home Monday to Friday Machine Learning: 1 year (preferred) Yes 
ScrapedJobID67:
Integrate, explore, transform and analyze data from different sources and work environments, such as SAS, Databricks, Snowflake, Azure, AWS and Oracle Develop relevant analytics solutions (exploratory analysis, profiling, segmentation, predictive models for propensity, cross-selling, up-selling, attrition and recommendation) in order to solve complex business problems Extract useful knowledge and insights, offer recommendations and propose action plans aligned with strategic objectives and business priorities Prepare and deliver clear and informative presentations to a variety of audiences at all levels Support the product and marketing strategy teams in creating and developing initiatives Identify opportunities to implement analytics initiatives to improve the client experience A bachelor’s degree in statistics, engineering, sciences, mathematics or a related field and 3 years of relevant experience OR a master’s degree in a related field and 1 year of relevant experience In-depth knowledge and solid skills in data science methods and techniques, including segmentation, clustering, classification, regression, time series, neural networks, deep learning, etc. Excellent programming skills and experience, including with SQL, SAS(asset) and Python Experience in cloud computing: Databricks, and Snowflake on Azure and AWS - asset Excellent communication skills and ability to explain concepts in plain language Strong analytical mindset Good business intuition and initiative Bilingualism, both spoken and written (French) - functional English Business knowledge of Personal Banking, cards, payments and transaction accounts and experience using transactional data or analytical experience in other sectors Advanced knowledge of data science, programming languages and cloud development environments Intense curiosity and passion for learning and excellent ability to explain your work to non-technical audiences. Health and wellness program, including many benefits Flexible group insurance Defined benefit pension plan Employee Share Ownership Plan Employee and Family Assistance Program Preferential banking services Community involvement program Telemedicine Virtual sleep clinic 
ScrapedJobID68:

ScrapedJobID69:
Independently leads data consulting projects with stakeholders, involving client facing experiences. Communicates with clients to assess the state of their records when designing data management and related technical solutions. Meets project deadlines for accountable deliverables; have the ability to anticipate delays or foreseeable barriers to progress, and the ability to escalate issues when necessary. Participates and leads data quality and data cleaning initiatives. Participates in data validation and data correctness processes. Explores and proposes new analytic solutions to meet different business requirements and opportunities. Assists with other data related tasks as necessary. With a degree in statistics, data science, or related fields. Embrace a "startup mindset" that is curious, growth oriented and take pride in the integrity and ownership of one's work Experience in working with raw data; assessing data correctness and transforming data into a usable form. Experience leading analytics projects with stakeholders and having client facing experience in a data role is an asset. Experience working with geographic data and creating visualizations for geographic data using programs such as Tableau, Data Studio or similar ones is an asset. Knowledge of basic database joins and data mapping. Strong oral and written communication skills with experience in relating complex concepts to non-technical users, including presentation and storytelling with data. High level of integrity and understanding of the importance of confidentiality. Flexible schedule Work from home Monday to Friday Have a degree or obtaining a degree in statistics, data science or related fields. English (required) Yes 
ScrapedJobID70:
The CIC NS is one of IBM’s highest performing delivery centres worldwide – for retention, client satisfaction and utilization. Our employees are empowered to stay and grow within IBM. We are very focused on continuous skill development – staff training is our third largest annual Centre investment. Employees are immersed in a culture of learning and constant growth Investment in key partnership with universities, government and private sector groups which has resulted in IBM having a key influencing role in Nova Scotia’s ICT industry, especially in talent development. Ability to work with the client directly to understand and meet their requirements Excellent verbal and written communication abilities: must effectively communicate with technical and non-technical teams Participate in teams working in an Agile/Scrum or Waterfall process and ensure the stories/tasks are well defined and have all the information and tools to be successful Ability to work independently on tasks with minimal supervision Ability to work in teams and be open to comments and feedback Ability to learn quickly and to adapt to a fast-paced environment Knowledge in AI, Machine Learning, and Deep learning Experience with data modelling a must Experience using Python or R Experience in Python libraries such as Pandas, NumPy, SciKitLearn, MatPlotLib, Keras Bachelor’s Degree in Mathematics, Statistics, Computer Science, Computer Engineering or Software Engineering (other backgrounds are considered combined with the right experience Fluency in English both oral and written Experience in banking industry a strong asset Experience with fraud analysis an asset 
ScrapedJobID71:
Accountable for the manipulation of complex and extremely varied data sets within Air Canada and external sources to solve real world problems Design, develop and evaluate innovative models, data science products and solutions for internal clients as well as for our data science team Oversee the day-to-day operations including the testing and maintenance of data science solutions Write highly optimized code to advance our internal Data Science Toolbox and practice Work in a multi-disciplinary environment with specialists in machine learning, data engineering and design and provide acquired expertise in these areas Ensure the optimization of data science models, including feature selection and build, using different techniques in the data science toolbox Accountable for the integrity of Air Canada's data extended to third party sources Ensure the continued enhancement of data collection procedures, including information that is relevant for the building analytical solutions Accountable for the integrity of data used for analysis and modeling Develop automated processes for large scale data analysis Provide technical guidance to junior members of the team Mandatory Covid-19 Vaccination Required as of October 31st 2021 MSc or PhD level in the field of Computer Science, Machine Learning, Applied Statistics, or Mathematics 5 to 9 years of experience as a data scientist or in a similar role Experience in statistical modelling and machine learning techniques Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc. Experience with common data science toolkits, such as Scikit learn, XGBoost, Numpy, fbprophet, etc Experience with cloud machine learning tools (Azure ML, databricks), an asset Programming experience in at least two of the following languages: R, Python, Scala, SQL Experience in applying data science methods to business problems Experience in applying advanced analytical and statistical methods in the commercial world Strong presentation and communication skills, with the ability to explain complex analytical concepts to people from other fields Knowledge of distributed computing language such as pyspark Experience with data visualization tools such as plotly, seaborn, matplotlib, etc. Proficiency in using query languages such as SQL, Hive, Pig Experience with NoSQL databases, such as MongoDB, Cassandra, HBase Good applied statistics skills, such as distributions, statistical testing, regression, etc. Good scripting and programming skills Data-oriented personality Candidates must be eligible to work in the country of interest, at the time any offer of employment is made and seeking any required work permits/visas or other authorizations which may be required is the sole responsibly of the candidates applying for this position. 
ScrapedJobID72:
MobSquad solves the significant and growing technology talent shortage faced by US-based start-ups and scale-ups by enabling its clients to quickly have a turnkey "virtual" Canadian subsidiary. MobSquad ensures technology professionals with US work visa challenges remain working with their current company, but nearshore from Canada. This is accomplished via MobSquad's unique partnership with the Canadian Government, enabling work visas to be issued for technology professionals and their respective families within four to six weeks, and Canadian permanent residency within six to eight months. Additionally, MobSquad has unfettered access to top-tier global technology talent which it relocates to Canada and pairs with American as well as Canadian clients on an exclusive, long-term basis, helping firms not only retain their existing world-class technology talent base, but grow it substantially. We're a Certified B corporation, and have made numerous contributions to charitable organizations, as well as a financial commitment to the Upside Foundation. We believe we are playing a key role in enhancing Canada's innovation economy, and have received financial support from the Government of Canada, Province of Alberta, Province of Nova Scotia, and City of Calgary, to support this ambition. For our workplace culture, we were recognized as the 3rd best place to work in Canada (for a small company) in 2020, as well as recognized specifically for being one of the best workplaces nationally for: inclusion; mental wellness; giving back; youth; and technology. We were also recognized as one of the best start-ups to work for across Canada. For our innovative business model, we have been featured in numerous media outlets including: Asian Pacific Post; BetaKit; Bloomberg; CBC; Global News; Gothamist; International Business Times; MIT Technology Review; Nearshore Americas; Nikkei Asian Review; NPR; The Economic Times of India; The Financial Times; The Globe and Mail; The Information; The New York Times; and_ The Washington Post._ Harvard Business School published a case study on MobSquad last fall, and Harvard Business Review featured us multiple times in an article that appeared on the cover of their November/December 2020 edition. You can learn more about us on our website. You have a bachelor's degree in Computer Science, Engineering, or a comparable field from an accredited institution You have advanced skills in Python You have experience with data analysis tools (e.g., R, NumPy, Pandas, scikit-learn, SQL) You have over five years of experience applying state of the art computer vision and NLP techniques to extract data from unstructured sources You have experience with exploratory data analysis and developing predictive models (regression, classification, clustering) on terabyte-sized structured and unstructured datasets You have experience applying statistical methods (e.g., distribution analysis, classification, clustering, etc.) You have strong coding skills with data-frames on platforms including Pandas, Spark, R, and MATLAB You have proven experience working in cloud-based systems including Amazon Web Services, Microsoft Azure, and/or Google Cloud You have experience with SQL and NoSQL databases You have demonstrated ability to develop high-quality code adhering to industry best practices (e.g., code review, unit testing, revision control) A full-time position that offers competitive compensation A benefits program delivered through our bespoke digital platform, giving you control, choice, and flexibility. We give you the ability to build your package of benefits covering health (e.g., medical, dental, vision), wellness (e.g., gym, workout gear, massage, transit), and RRSP (retirement savings) A downtown office location with first-rate amenities, surrounded by great restaurants and easily-accessible transit For international candidates, sponsorship for an immediate work permit, expedited permanent residency, and Canadian citizenship within four years 
ScrapedJobID73:
Use our modern tech stack, AWS (Redshift & Kinesis), Databricks and PySpark, Airflow, and Tableau to develop innovative tools Work closely with marketing teams to craft, test, verify and implement machine learning models to optimize Zynga audience growth Apply statistical methodologies to evaluate performance and account for uncertainties in major initiatives Design and develop using standard practices within a GitHub environment BS in Computer Science, Math, Statistics, Economics, or other quantitative field; Masters or PhD strongly preferred 3+ years of work experience in data science, machine learning or analytics role Demonstrated experience with some or all of the following: machine learning, data mining, predictive modeling, statistics, experimental design, computational analytics, econometric modeling, data visualization Proficient in Python, SQL, and other programming languages; Experience in applying machine learning on large datasets, preferably using Spark on Databricks Strong written and oral communication skills Zynga Stock RSUs and Bonus Plan Full medical, dental, vision benefits as well as life insurance Generous Paid Maternity/Paternity leave Open vacation policy for all full time employees Flexible working hours on many teams Work alongside driven individuals towards a common goal 
ScrapedJobID74:
Recruiting and onboarding new creators for Floatplane Assistance in marketing Floatplane as a platform Working with the team to identify new business opportunities, including additional products or value-adds. Finding new business opportunities and following those things through At least 2 years of sales experience Experience in account or creator management is preferred Prior experience with digital marketing and/or social media Strong writing and organizational skills Ability to work with a team or independently Must have an interest in technology Must possess a positive, can-do attitude Automate benchmarking processes where possible Create new systems and processes in order to evaluate products Develop software for new products(Not NECESSARILY the front end) Applicable bachelor's degree OR roughly equivalent experience OR impressive portfolio Highly proficient with python Highly proficient with C and C++ Ability to work with a team or independently Must possess a positive, can-do attitude Experienced in building and maintaining a variety of systems Data gathering Data cleaning Data analysis Data interpretation/explanation Theorycrafting/Hypothesising ways for teams to perform better Tool creation for other team members to be able to use your created data sets to validate work, etc Applicable bachelor's degree OR roughly equivalent experience OR impressive portfolio Highly proficient with python Ability to work with a team or independently Must possess a positive, can-do attitude Experienced in building and maintaining systems at scale. 
ScrapedJobID75:
Managing the creation, update, extension, and deletion of the master data sets for all the business units. Implement transformative rulesets and data cleansing techniques to improve the quality, accuracy, uniformity, and integrity of existing data Devising and applying models and algorithms to mine the stores of big data Analyzing data to identify patterns and trends and convert that into solutions and opportunities Processing confidential data and information according to data governance guidelines. Works closely with other data consumers within the business to gather and populate data warehouse table structure Managing, designing, and developing reports and the reporting environment, including data sources, security, and metadata. Assist the Data Engineers with creation ETL processes and data identification and support Providing technical expertise in data storage structures, data mining, and data cleansing Provide guidance and best practice for data visualization and report generation specifically with visual data modelling tools such as Power BI Provide documentation and training to end-users on new reports and dashboards. Bachelor's degree in Computer Science, Data Science, Information Technology, Information Systems or related field, or equivalent work experience Minimum 3 years' experience in the field of Data Science and/or Data Analysis Strong capabilities around dimensional modelling, data mining and data visualization preferably with tools such as Power BI Expert ability to draft, analyse and debug SQL queries and be proficient in scripting languages such as Java, Python, C Sharp, Perl, and others. Creative thinker with excellent analytical thinking and problem-solving skills Attention to detail and accuracy with strong analytical skills Able to multi-task and prioritize workload Deep passion for data analytic technologies as well as analytical and dimensional modeling. Strong communication skills with the ability to present information to technical and non-technical stakeholders Experience with Google Big Query or Snowflake an asset Experience in hospitality and/or travel industry preferred 
ScrapedJobID76:
Effective October 26th, all new hires to Fraser Health will need to have full COVID 19 vaccination (have received a full series of a World Health Organization “WHO” approved vaccine against infection by SARS-COV-2, or a combination of approved WHO vaccines). Please note this applies to all postings, and individual medical exemptions must be approved by the Provincial Health Officer. Working as the lead Data Scientist and strategist for the System Optimization department, cultivating and developing a proven and sustainable machine learning foundation and competency for Fraser Health. Working closely with clinical and leadership teams across the health authority to strategize and develop artificial intelligence (AI) products. Identifying, cleaning, and integrating large sets of structured and unstructured datasets from disparate sources for use in ML models and products. Enhancing data collection procedures to include information that is meaningful for building a ML models. Using advanced ML processes to convert data from non-functional forms, such as scanned image text, to functional forms ready for use in further ML models. Using advanced ML models to identify patterns, trends, and opportunities that can make predictions or reduce workload across various clinical domains within Fraser Health. Implementing ML models into production by collaborating and guiding developers. Identifying, engaging, and collaborating with specific partners as required for the development of AI products. Communicating analytic solutions to leadership and making recommendations regarding strategic actions to maintain the ML development pipeline, analytic architectures, and life cycle to avoid potential negative consequences and system failures. PhD in Statistics, Mathematics, Computer Science or another quantitative field Five (5) to seven (7) years of experience working with large datasets and machine learning models 
ScrapedJobID77:
Leverage data to identify, quantify and influence tangible business gain. Design and interpret quantitative experiments to objectively guide key business decision making Uplift modeling to identify what audiences we should or should not target with our different marketing tools Perform advanced analysis to guide the company in its strategic choices Oversee the day-to-day operations including the testing and maintenance of data science solutions Set up experimentation to measure the incremental impact of our marketing actions to different audiences. Have the capacity to thrive in our fast-paced environment, adapt quickly and take ownership of your work Experience solving real problems using data mining techniques and with statistical rigor and translating business problems into data problems Strong programming skills (Python) specifically with packages like TensorFlow, Pytorch, SkLearn, Numpy and Pandas Working knowledge of MySql, Clickhouse Strong knowledge of data management (schema design, data pipelines, workflows) Deep understanding of modern machine learning classification/regression techniques such as ANNs, SVMs, Naive Bayes and Decision Trees, as well as various ensemble methods such as boosting and bagging Strong knowledge of the possibilities and limitations of different types of data analysis and/or data science modelling Experience productionizing real-time machine learning models is a plus Please note this position is in Montreal, Quebec. Exploiter les données pour identifier, quantifier et influencer un gain commercial tangible. Concevoir et interpréter des expériences quantitatives pour guider objectivement la prise de décisions commerciales clés. Modélisation de l'uplift pour identifier les audiences que nous devons ou non cibler avec nos différents outils marketing. Réaliser des analyses avancées pour guider l'entreprise dans ses choix stratégiques Superviser les opérations quotidiennes, notamment les tests et la maintenance des solutions de science des données. Mettre en place des expérimentations pour mesurer l'impact incrémental de nos actions marketing auprès de différentes audiences. Avoir la capacité de s'épanouir dans notre environnement au rythme rapide, de s'adapter rapidement et de s'approprier son travail. Expérience de la résolution de problèmes réels à l'aide de techniques d'exploration de données et avec une rigueur statistique et traduction de problèmes commerciaux en problèmes de données. Solides compétences en programmation (Python), en particulier avec des progiciels tels que TensorFlow, Pytorch, SkLearn, Numpy et Pandas. Connaissance pratique de MySQL, Clickhouse Connaissance approfondie de la gestion des données (conception de schémas, pipelines de données, flux de travail) Connaissance approfondie des techniques modernes de classification/régression par apprentissage automatique, telles que les ANN, SVM, Naive Bayes et les arbres décisionnels, ainsi que de diverses méthodes d'ensemble telles que le boosting et le bagging. Connaissance approfondie des possibilités et des limites des différents types d'analyse de données et/ou de modélisation de la science des données. Une expérience de la production de modèles d'apprentissage automatique en temps réel est un atout. 
ScrapedJobID78:
Managing the creation, update, extension, and deletion of the master data sets for all the business units. Implement transformative rulesets and data cleansing techniques to improve the quality, accuracy, uniformity, and integrity of existing data Devising and applying models and algorithms to mine the stores of big data Analyzing data to identify patterns and trends and convert that into solutions and opportunities Processing confidential data and information according to data governance guidelines. Works closely with other data consumers within the business to gather and populate data warehouse table structure Managing, designing, and developing reports and the reporting environment, including data sources, security, and metadata. Assist the Data Engineers with creation ETL processes and data identification and support Providing technical expertise in data storage structures, data mining, and data cleansing Provide guidance and best practice for data visualization and report generation specifically with visual data modelling tools such as Power BI Provide documentation and training to end-users on new reports and dashboards. Bachelor's degree in Computer Science, Data Science, Information Technology, Information Systems or related field, or equivalent work experience Minimum 3 years' experience in the field of Data Science and/or Data Analysis Strong capabilities around dimensional modelling, data mining and data visualization preferably with tools such as Power BI Expert ability to draft, analyse and debug SQL queries and be proficient in scripting languages such as Java, Python, C Sharp, Perl, and others. Creative thinker with excellent analytical thinking and problem-solving skills Attention to detail and accuracy with strong analytical skills Able to multi-task and prioritize workload Deep passion for data analytic technologies as well as analytical and dimensional modeling. Strong communication skills with the ability to present information to technical and non-technical stakeholders Experience with Google Big Query or Snowflake an asset Experience in hospitality and/or travel industry preferred 
ScrapedJobID79:
Create project charters involving business problem definition, business value, performance metrics, success criteria, scope, and milestones. Coordinate analysis with others. Respond to inquiries and follow up on data validations Provide recommendations based on the results to facilitate business strategy. Collaborate with cross-functional teams (such as customers and internal IT teams) to understand business needs, ensure data integrity and flow efficiency, and to create tools for customer utilization. Provide quality validations and on-going support of client and projects. Ensure quality control to evaluate the accuracy of deliverable and/or project analysis. Interpret Third Party reports to the business Drive implementations of Privacy redactions with Internal Teams. Finalize and deliver the results of assigned projects to internal clients Collaborates with IT group to transform and prepare data for analysis. Balances the quantity/quality of own work with the business situation; demonstrates enthusiasm, drive and a sense of urgency when completing work. Excellent verbal, written and presentation skills. Strong analytical and assessments skills. Strong project management skills. Strong ability to translate data driving insights into decisions and actions. Strong ability to think strategically and be proactive and collaborative. Heavy experience in Python, especially with machine learning toolkits such as scikit-learn, pytorch, and TensorFlow, and Natural Language Processing toolkits such as NLTK or spaCy. Experience in cleaning and transforming data for machine learning. 2+ years’ relevant experience. Experience working with Natural Language Processing preferred. Knowledge of machine learning and predictive modeling. Experience using Python. Knowledge of database operations such as those found in pandas and relational database query languages such as SQL. Experience in Spark, AWS, Hadoop, or other distributed computing environments. Master’s degree or international equivalent in Computer Science, Statistics, Data Science, Mathematics or similar analytical fields. Experience in handling time-series and image data is a bonus. 2+ year’s experience in the healthcare industry preferred Equivalent combination of education, training, and relevant experience may be considered in place of the education and experience stated above. All employees must read, write and speak fluent English and host country language. This job description is intended to present the general content and requirements for the performance of this job. The description is not to be construed as an exhaustive statement of duties, responsibilities, or requirements. 
ScrapedJobID80:
Rio Tinto was named Canada’s Top 100 Employer and one of Canada’s Top Employers for Young People for 3 consecutive years Diverse & challenging projects with our PACE Analytics team Learn and gain exposure to the state-of-the-art data science solutions 4-month summer 2022 internship opportunity, with possibility to extend Successfully completed 2+ years in a bachelor or master’s degree* in Mathematics, Statistics, Computer Science, Electrical Engineering or other quantitative field English proficiency, Bilingual (English/French) an asset Strong analytical and problem-solving skills Highly driven, keen to learn and develop Effective communication skills and ability to work in a team Able to be autonomous and effective at prioritizing A safety-focused and inclusive working environment A competitive salary An exciting and rewarding experience Opportunity to build relationships with the Rio Tinto team and community A great chance to prepare yourself to join our Graduate Development Program 
ScrapedJobID81:
Prototype, develop and test new detection and calling algorithms for Genomadix’s rapid DNA tests Assisting the assay development team in interpreting the data it gathers, and participating in Genomadix’s assay development process Ideally, you will be able to assist software team members in taking your algorithms all the way into production You will be working within a medical device software life cycle process (example: IEC 62304) Assist in developing, maintaining and deploying data analysis tools Work collaboratively with cross-functional teams including product managers, other software developers and testers, and other scientists 1+ years of experience with Python scientific programming (numpy, scipy, jupyter notebooks/lab, pandas) Prior experience working in multi-disciplinary teams (Optional) Experience with formal software life cycle processes such as IEC 62304 (Optional) Prior experience or knowledge of PCR Casual dress Company events Dental care Disability insurance Employee assistance program Extended health care Flexible schedule On-site parking Paid time off Vision care Work from home Monday to Friday Yes 
ScrapedJobID82:
Implement currently available time series forecasting models Develop customized forecasting algorithms required by specifications of each project Prototype, simulate and benchmark accuracy of algorithms Develops production-ready codes in R Works with main stakeholders including but not limited to: Account Executives, Management, Project Managers and Consulting Teams Performs various other duties as delegated or assigned. Graduate degree in a Statistics, Math Computer Science or Engineering program; Proficient in time series analysis and forecasting Fundamental knowledge of supervised and unsupervised Machine Learning Experience with data preprocessing, anomaly/outlier detection Advanced programming skills in R language is mandatory; Knowledge of pharmaceutical industry is an asset; Capability to adapt in fast changing environment and eager to learn The ability to travel and work outside regular business hours as required; Proven, motivated self-starter with the ability to lead by example and approach and solve business problems; Experience working in cross-functional teams with the agility to learn new software applications and technologies; Demonstrated time management, problem solving and decision making competencies; Ability to work autonomously and in teams to effectively prioritize multiple projects and associated deliverables; Proven excellent communication, including presentation, hands on analytical with business savviness and customer relationship abilities; Proven ability to comprehend, analyze and research problems of a complex nature, make decisions and/or present recommendations; 
ScrapedJobID83:
Loves to work on a great cross functional team collaborating effectively with various groups to understand business objectives, customer needs and gaps, and deliver on the team objectives. Will use their exceptional development skills to build innovative and sustainable solutions that solve our customer’s problems. Has current experience in modern programming languages and frameworks such as go, rust, typescript, microservice design. Has a strong foundation in math and applied experience in data science platforms and tools such as Flink, Matlab, scikit, numpy, scala. Has experience in data visualization techniques and tools such as d3, seaborn. Has experience in networking, network security and cloud platforms including AWS, GCP. Works fluently on a variety of platforms at varying heights in the software stack and is comfortable with low level and embedded domains as well as high level stacks. Is a creative thinker that believes in end-end thinking to solve current and future customer problems. Has knowledge or experience developing secure code and/or working in the security domain. Has a bachelor of computer science degree (or equivalent). 
ScrapedJobID84:
Recruiting and onboarding new creators for Floatplane Assistance in marketing Floatplane as a platform Working with the team to identify new business opportunities, including additional products or value-adds. Finding new business opportunities and following those things through At least 2 years of sales experience Experience in account or creator management is preferred Prior experience with digital marketing and/or social media Strong writing and organizational skills Ability to work with a team or independently Must have an interest in technology Must possess a positive, can-do attitude Automate benchmarking processes where possible Create new systems and processes in order to evaluate products Develop software for new products(Not NECESSARILY the front end) Applicable bachelor's degree OR roughly equivalent experience OR impressive portfolio Highly proficient with python Highly proficient with C and C++ Ability to work with a team or independently Must possess a positive, can-do attitude Experienced in building and maintaining a variety of systems Data gathering Data cleaning Data analysis Data interpretation/explanation Theorycrafting/Hypothesising ways for teams to perform better Tool creation for other team members to be able to use your created data sets to validate work, etc Applicable bachelor's degree OR roughly equivalent experience OR impressive portfolio Highly proficient with python Ability to work with a team or independently Must possess a positive, can-do attitude Experienced in building and maintaining systems at scale. 
ScrapedJobID85:
Apply statistical and machine learning techniques to assist with building models for underwriting, pricing, and claims management; Help us drive innovation, enabling new underwriting paradigms, distribution models, and data management; Build and implement solutions that enable operational units to improve quality and speed of core processes in order to generate incremental revenue or reduce expense; Proactively research new ways of modeling data to unlock actionable insights or improve processes; Collaborate across Munich Re functions and with clients to use analytics to influence business decisions; Work with existing data science groups at Munich Re and collaborate with internal partners to leverage capabilities in big data technology. Undergraduate or Graduate degree (Master’s, PhD) in Computer Science, Statistics, Data Science/Analytics, Applied Mathematics, Engineering (Physics, Bioinformatics) – or equivalent program offering coursework manipulating large datasets; Expertise in advanced predictive analytic techniques; Strong experience working with Python, or R; working knowledge of SQL (familiarity with multiple languages considered an asset); Demonstrated experience working with analytics through the modeling lifecycle including gathering data, design, model building, testing, implementation, communication, and monitoring; Excellent communication skills; spoken & written, formal/informal presentation – to effectively interpret and present actionable insights to partners; Resourceful and able to learn quickly; A drive to make a difference; Proven ability to thrive in a dynamic environment. Familiarity with cloud computing platforms (ex. AWS, Microsoft Azure); Familiarity with big data technologies (ex. Apache Spark, Hadoop, etc), natural language processing and deep learning frameworks (ex. Tensorflow, Pytorch); Previous exposure to insurance or financial services environment, or Actuarial examinations/designation. 
ScrapedJobID86:
Analyze high-throughput experiments to assess data quality and identify hits. Build tools to streamline design of antisense oligonucleotide compounds. Support pre-clinical development programs with computational analyses BSc in Computer Science, Statistics, Bioinformatics, or related fields and two years post-graduate experience, or MSc in the related fields. Solid knowledge of Python, and some knowledge of R is desirable. Solid statistics knowledge with ability to perform various statistical analyses independently. Understanding of basic concepts in molecular biology and human genetics. Comfort working in a fast-paced and rapidly growing work environment A highly competitive salary and meaningful equity compensation (ESOPs). A wide array of company-paid benefits. Exceptional opportunities for learning and growth working alongside the world’s best team. An opportunity to work alongside a bright, collegial, highly motivated team working at the intersection of the most exciting areas of science and technology. 
ScrapedJobID87:
Build agent-based simulations of smart contracts and blockchain networks using our Python SDK Design and optimize incentive models for blockchain protocols and help discover potential attack vectors Contribute to making our simulation model and platform world-class Build data models and visualizations of public blockchain data and simulation results that provide intuitive analytics to customers Proficient at writing code in Python or similar languages Smart contract development experience (e.g. Solidity) Experience with building machine learning models at scale 
ScrapedJobID88:
Organize and analyze large scale mutation data from tumor genome sequencing in a clinical setting Work closely with the lab and software teams to maintain data integrity Perform analysis of mutations across patient cohorts for quality control and to identify population-level patterns Use standard tools and computational frameworks to visualize, browse and statistically analyze distributions of mutations and clinical covariates Prepare statistically motivated plots of mutation data for presentation Develop approaches to identify anomalous distributions that can be leveraged in quality control processes Compile reports for partners and collaborators. Education: You hold a Master’s degree in bioinformatics, data science, biostatistics or equivalent Industry experience: 3+ years experience working in a clinical or research setting related to cancer genomics applied to tumor tissue analysis and/or cell-free DNA/liquid biopsy. Linux/UNIX: Experienced in working with command-line interfaces. Coding: Proficient with Python (desirable) or other statistical languages such as R. Databases: 1+ years experience in SQL databases, with experience aggregating data within and across patient cohorts. NGS: Experienced handling NGS data including the quality control/quality assurance. Cancer genomics: Facility with cBioPortal interfaces and tools and relevant API-level packages in R or Python to analyse and interpret somatic mutations in cancer. Tech-savvy: Experienced with standard NGS analysis tools such as samtools, alignment software (e.g. BWA or bowtie), and variant detection (e.g. GATK, samtools). Added bonus if you have experience with GitHub and cloud-based computing such as AWS. Attention to detail: Uncompromisingly meticulous with the execution of analysis. Interpersonal skills: Excellent communication skills– written, verbal and non-verbal. You’re considerate and have the ability to develop cooperative relationships with your team members. Organized: Have the ability to organize yourself and set priorities. 
ScrapedJobID89:

ScrapedJobID90:
Competitive salary Employee share plan A flexible office/work-from-home environment Unlimited vacation time Weekly team bonding events (that aren’t lame) And so much more! Build data architecture for sustainability, company, and product data Build scripts to ingest data from various sources Combine data sources to create meaningful insights Assist in forming ML/AI strategy Clean and prepare data for ML/AI Strong data analysis background Strong data cleaning abilities Preferred history working with ML/AI Preferred history working with sustainability, company and product data Preferred Dev-ops/Data-ops experience 
ScrapedJobID91:
Artificial Intelligence / Machine Learning Data Science Cognitive Computing Computational Linguistics Computer Science 0-3 years of experience with general purpose programming languages e.g., Python, C/C++, Java 0-3 years of hands-on experience in machine learning Experience in various deep learning models, e.g., transformers, LSTMs, RNNs Experience in reinforcement learning and the multi-arm bandit class of problems Experience with machine learning platforms such as TensorFlow, TensorFlow Extended, PyTorch Good to have exposure to conversational AI, AI-based question-answering systems, AI-based compliance and monitoring systems, and ad personalization Good to have exposure to MLOps pipelines and Kubeflow Excellent communication skills Ability to collaborate cross-functionally Good presentation skills Attention to detail Collaborate with the Engineering and Product teams to implement machine learning models into the products and offerings of [24]7.ai Collaborate with your team members. Be responsible for implementing the machine learning models, testing them, refining them, and taking them to production Collaborate within the Data Science Group to review and refine your work to ensure the highest quality 
ScrapedJobID92:
We offer excellent compensation packages with market competitive pay, comprehensive healthcare packages, schedule flexibility, work from home opportunities, paid time off, and organizational growth potential. Grow at your own pace through online courses at Learning @ Equifax. Build and create advanced machine learning algorithms such as regression, simulation, scenario analysis, modeling, clustering, decision trees and neural network Develop new tools, advanced analytical techniques and products as part of the innovation team Project management including defining business and technical requirements, resource planning and analytic solution design Working alongside key clients as part of co-innovation projects and effectively communicate analytical results to key stakeholders using strong data visualizations, superior presentation skills and business language to emphasize the so what of the analysis Creation of recommendations, market insights and dashboards following completed analysis and Quality control of all analytical output Bachelor’s or advanced degree in a quantitative discipline such as Engineering, Economics, Mathematics, Statistics, or Physics 3+ years’ Data Science experience with expert knowledge of R, Python, SAS or SQL in a large data environment 3+ years’ experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks Proven hands-on experience designing and building analytical solutions to solve real world problems, with limited direct supervision required Creativity & idea generation and the ability to extract business insights from analysis & transform this into an easy to understand story Master’s level degree in a business-related field/MBA Experience working in a cloud environment such as GCP an asset Experience in working with Credit Data Background in financial services, telecommunications or utilities favorable Accountability Curiosity Collaboration Think and act differently Trust Ownership Decide-Execute-Ship 
ScrapedJobID93:
Is a cross-functional Data team made up of data scientists, data and software architects, software engineers and business reporting analysts spanning the globe Works on analytics project based on the company's business requirements on different domain such as NLP and time series prediction and analysis Has ownership over data company-wide, from analytics to global business reporting Manages the entire data lifecycle from extraction to visualization Works in SQL, Python, R, scikit-learn, Google Cloud BigQuery, Java and C++ and are always prototyping new technologies Build statistical, predictive, and machine learning models Collection, review, perform cleansing and reporting of data Help our Marketing, Strategy, Product, Sales, Customer Service, and Trading teams drive growth in the business Develop data-oriented solutions to help solve complex business problems Create reporting and visualizations and educate the company on your findings Take part in planning sessions, where we develop use cases and requirements for analytical solutions based on data Bachelor, Master’s or Ph.D. degree (Statistics, Computer Engineering, Computer Science, Applied Math, or a related field preferred) Experience using Python, SQL, databases, and visualization tools Experience in data modeling, ETL development, and data warehousing Experience in time series modeling, developing custom algorithms, and Machine Learning Familiarity with GCP, AWS, Azure, Docker, or Kubernetes Strong verbal/written communication and data presentation skills in English Experience with Big Data technologies (such as Spark), and unstructured data Proficient with data analysis and modeling software such as R 
ScrapedJobID94:
Assemble and analyze data to understand customer behavior from existing 407 ETR data, external data sources and emerging sources. Undertake analysis of target customer groups (segments) for specific marketing and pricing programs and assess opportunities and strategies for marketing. Ad hoc analysis and modeling of data. Ability to understand business stakeholder’s issues and create valuable insight. Raise awareness and action of data science within the company to help focus on fact based decisions. Support the Department along with the Information Technology Management Department in planning the structure and storage of new customer related data fields. Represent the department in committees within the organization. A University degree in Engineering, Statistics, Mathematics, or Computer Science. Minimum 5 years working experience with data science techniques: clustering, regression models, classification, anomaly detection and other machine learning techniques. Minimum 5 years of experience with data analysis tools (eg. SAS, R or Python) and BI visualization for reporting. Well-developed business analysis, research and creative problem solving skills. Organizational skills and time management skills; planning and project management, and ability to meet multiple deadlines. Strong communication skills and work ethic. Highly collaborative team player with an entrepreneurial spirit. Familiarity with MicroStrategy is an asset. 
ScrapedJobID95:
Prototype, develop and test new detection and calling algorithms for Genomadix’s rapid DNA tests Assisting the assay development team in interpreting the data it gathers, and participating in Genomadix’s assay development process Ideally, you will be able to assist software team members in taking your algorithms all the way into production You will be working within a medical device software life cycle process (example: IEC 62304) Assist in developing, maintaining and deploying data analysis tools Work collaboratively with cross-functional teams including product managers, other software developers and testers, and other scientists 1+ years of experience with Python scientific programming (numpy, scipy, jupyter notebooks/lab, pandas) Prior experience working in multi-disciplinary teams (Optional) Experience with formal software life cycle processes such as IEC 62304 (Optional) Prior experience or knowledge of PCR Casual dress Company events Dental care Disability insurance Employee assistance program Extended health care Flexible schedule On-site parking Paid time off Vision care Work from home Monday to Friday Yes 
ScrapedJobID96:
Minimum of 3 - 5 years of data science experience using python Strong ML and statistics background 2+ years of software development experience Experience with keras, tensorflow, and sklearn. Experience with time-series and operations data is an asset Previous Kaggle experience or similar is a plus Ability to work in a fast-paced agile environment Experience using Git in a team environment Flexibility to adjust to changing priorities, requirements, and schedules Familiarity with working on remote linux instances Own significant product requirements and drive them from development to deployment Tune and monitor machine learning models deployed for customers. Research and apply state of the art in model interpretation and explainability Package development in Acerta’s Codebase 
ScrapedJobID97:
Degree or Diploma in Computer Science, Software Engineering, Statistics, Economics or equivalent degree or experience Expertise in R and other statistical programming languages (3+ years) Experience in Frequentist and Bayesian Statistical methods (2+ years) Experience working with Machine Learning algorithms, Probabilistic Models, and/or other statistical modelling approaches (2+ years) Experience with modern R packages such as dplyr, ggplot2, data table Experience in front-end R technologies for data products such as ShinyR, Flexdashboard Ability to write complex SQL queries Working knowledge of software engineering fundamentals and workflows Experience working with container orchestration platforms such as Kubernetes or Docker Swarm Cloud Computing Experience Interest in sports or betting data Authority to legally work in Canada An environment passionate about growth and learning Competitive salary with bonus Fitness subsidy program Free beverages in the office Workplace that is conveniently located along the Yonge/Sheppard line 
ScrapedJobID98:
2+ year's experience using and developing machine learning models in a production setting Master's or Graduate Degree in Mathematics, Statistics or Computer Science Knowledge of Python programming; Revision control software (e.g. Git); Understanding of best practices in data science Previous experience in computer vision and image processing; Experience with Django, Pandas, and Scikit libraries. 
ScrapedJobID99:
Understand the client’s business including nuances of the products, sales channels, business cycles and levers like promotions, advertising etc. Ensure completeness, accuracy and quality of data received Identify anomalies in the data and work with the client to resolve the anomalies Design, configure, and tune the AI product model to generate the necessary model outputs Apply domain knowledge of CPG/retail, planning to extract features from the input data Evaluate the accuracy of the model outputs and analyze the output to identify issues in the model Create and present reports showing model performance, and have an engaging conversation with business stakeholders Analyze and resolve any ongoing issues with model performance Bachelor’s or Master’s degree 3+ years of Data Science experience 1+ years working with retail or CPG preferred Good understanding of CPG or retail planning process. Understanding of Retail/CPG data model is a plus. 2+ years of hands-on experience in python, pyspark and SQL Good understanding of regression and/or time series models Expertise in evaluating model output and identifying model improvement opportunities. Excellent problem-solving skills and natural ability to think analytically Understand and adhere to Information Security policies, guidelines and procedure, practice them for protection of organizational data and Information System. Take part in Information Security training and act accordingly while handling information. Report all suspected security and policy breach to Infosec team or appropriate authority (CISO). 
ScrapedJobID100:
Lead data science projects from start to finish, identifying opportunities, defining the problem, building a proof of concept, and deploying a data product. Collaborate with business partners to understand the go-to market process, product lifecycle, and product strategy, and how data science products can enable excellence. Enrich product data through machine learning. Connect with business partners to understand the go-to market process, product lifecycle, and product strategy. Collaborate with data engineering teams to improve data quality and availability. Visualize and communicate results to senior leadership in Product organization. 5+ years of work experience in data analytics, preferably in the retail or apparel industries. Expert in R and/or Python for data analysis. Expert in SQL Demonstrated experience applying machine learning and data mining techniques. Previous work experience with data visualization tools such as Power BI, Tableau and/or Shiny. Acknowledges the presence of choice in every moment and takes personal responsibility for their life. Possesses an entrepreneurial spirit and continuously innovates to achieve great results. Communicates with honesty and kindness and creates the space for others to do the same. Leads with courage, knowing the possibility of greatness is bigger than the fear of failure. Fosters connection by putting people first and building trusting relationships. Integrates fun and joy as a way of being and working, aka doesn’t take themselves too seriously. 
ScrapedJobID101:
Apply advanced analytics to large data sets to drive the development of use cases that meet customer needs Work with subject matter experts to determine relevant use cases Collaborate with Data Engineers to develop use cases into deployable models Develop tools to monitor and analyze the effectiveness of use cases and new data sources Remain current with cyber threat trends to enhance use cases Other related data analytics support as may be required Master’s degree in Computer Science, Mathematics, Machine Learning or similar 5+ years related work experience with advanced analytics and machine learning Experience with Spark, R, Python, Java, SQL, Hadoop Knowledge of advanced statistical and machine learning techniques General knowledge of enterprise data security Working knowledge of Unix/Linux command line tools Excellent written and verbal communication skills and experience presenting Experience in GCP machine learning and big data tools is an asset Dental care Extended health care Vision care Master's Degree (preferred) Data Science: 3 years (required) Yes 
ScrapedJobID102:
Visualisation, Data Analytics or related fields. Typescript, Modern javascript frameworks Significant data science background, including programming, statistical inference, and data structure competencies Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics. Apple is committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. Apple is a drug-free workplace 
ScrapedJobID103:

ScrapedJobID104:
Understands the decision-making process, workflows, and business and information needs of business unit heads and service manager/owners Translates business needs into analytics/reporting requirements to support executive decisions and workflows with required information Proactively mines data warehouses to identify trends and patterns and generates insights for business units and senior leadership Performs large-scale experimentation to identify hidden relationships between variables in large datasets Researches and implements cutting-edge techniques and tools in machine learning/deep learning/artificial intelligence to make data analysis more efficient Determines requirements that will be used to train and evolve deep learning models and algorithms Visualizes information and develops engaging reports on the results of data analysis using data visualization tools Advises product teams on new products, features or updates through data-based recommendations Develops frameworks and processes to analyze unstructured information collected through social media platforms i.e., wikis, blogs, instant messaging, etc. and traditional sources such as e-mail and SharePoint Supports user experience specialists and information architects to enhance information visualization through development of dashboards and user interfaces Distributes best practices to analytics and product teams and provides consultations for their data-based experimentations Up-to-date knowledge of machine learning and data analytics tools and techniques Strong knowledge in predictive modeling methodology Experienced at leveraging both structured and unstructured data sources Willingness and ability to learn new technologies on the job Demonstrated ability to communicate complex results to technical and non-technical audiences Demonstrated ability to work with minimal supervision Strong Background in ML and statistics either through projects or prior work experience Excellent programming skills in python and SQL Experience working with cloud platforms such as Azure, GCP, AWS is a plus Strong foundation in data pipelining, streaming Strong communication, problem-solving skills and a strong team player Basic understanding of libraries like PyTorch, scikit-learn, numpy etc. Bachelors or Master’s degree in Computer Science, Statistics, Mathematics or related fields 
ScrapedJobID105:
Lead data-driven and evidence-based research to support delivery of people metrics, reporting, and advanced and predictive analytics to support Rizing’s customers and Leadership Team Use platforms, programs and programming to develop key algorithms around attrition, diversity, recruitment, learning, engagement, skills, culture, workforce planning, and other important people metrics. Use platforms, programs and programming to develop key algorithms around business analytics, including customer, marketing, sales, productivity, and operations. Translate data sets and insights into graphical visualisations and stories on key metrics. Contribute and lead on designing academically rigorous research studies, defining hypotheses, data collection and running multiple different statistical models. Collaborate with and communicate broadly with Rizing’s analytics, professional services, product and business teams. Support sales pursuits as a subject matter expert to help demonstrate how Rizing’s services and solutions can help solve customers’ business challenges. Establish strong credibility as a trusted advisor through publishing of thought leadership and research studies on analytics. Use machine learning to create predictive and prescriptive models and gather and assimilate multiple data sources, including big data. Act as product owner for Rizing’s analytics solutions, defining requirements. Acts as owner for Rizing’s analytics demo environments, ensuring they are clean, updated, and maintained from a data and configuration perspective. Performs other duties as assigned. Master's or PhD in Statistics, Applied Maths, Operations Research, Economics, Data Science, or a related quantitative field with at least three years of working experience as a Data or Research Scientist. Experience in research design, visualization techniques, and analysis approaches in which you manage and analyze both structured and unstructured data. Experience in advanced statistical methods around hypothesis testing, clustering, machine learning predictions, and text mining. Experience modeling high-dimensional data. Experience in writing academic-style papers for presenting both the methodologies used and results for data science projects. Experience with tools and languages including R, Python, SQL, R, Power BI, Tableau, and in the design and implementation of data pipelines that support the continuous delivery of insights. Understanding of the external people analytics landscape and trends. Experience with data warehouses and BI middleware Fluency in English, with professional communication skills. People analytics experience Ideally experience with people research, the human capital domain, user interface, consulting, and our industry SAP Analytics Cloud certification Experience using SAP platforms, including SuccessFactors, S/4 Hana and C/4 Engagement with Data Science Blogs / Kaggle contributor would be a bonus Advanced knowledge of MS Office programs including Word, Excel, and PowerPoint. Advanced knowledge of R and Python Demonstrable track record of dealing well with ambiguity, ability to self-motivate, prioritizing needs, and delivering results in a dynamic environment. Combination of deep technical skills and business savvy to interface with all levels and disciplines within our and our customer’s organizations Ability to extract, manipulate, transform and analyze large volumes of data with a high level of accuracy Excellent at presenting data visually Excellent attention to detail - you value getting things right Ownership mentality: don't just execute what's asked, consider whether it could be done a better way Conflict resolution skills, with the ability to influence decisions and manage relationships Ability to meet a deadline and manage priorities Work is home-based as part of a global organization. Some travel to office or customer site and working outside of core hours may be required. Routinely uses standard office equipment such as computers, keyboards, printers/scanners, and telephone applications. 
ScrapedJobID106:
Build and maintain efficient Tableau dashboards and reports for a variety of Wysdom customers Maintain and help optimize Tableau Server instances for our clients Conduct an ad-hoc analysis as requested to dig into product performance Assist in building out automated processes using Python to enhance analytics at Wysdom.AI Continually improve our insights products through performance improvements, new metrics, and visualizations Beyond theses day-to-day responsibilities, your sense of curiosity and analytical mindset, will challenge you to dig deeper into the ways in which we can continually improve our solution, our success rate, and the customer experience. Degree in Computer or Data Science, Statistical Analysis, Math and Engineering 2-3 years of experience with data visualization tools, specifically Tableau and experience setting up and managing Tableau Server Experience programming with Python and with Machine Learning frameworks/libraries e.g., Scikit-learn, Pandas, Matplotlib, Seaborn, Tensor flow, or Pytorch would be an asset Experience with ETL tools: Tableau ETL, Airflow Advanced SQL querying skills (Experience with NoSQL, specifically MongoDB is an asset) Experience using Excel/Google Sheets Source Control: Git Strong problem solving, quantitative and analytical abilities Knowledge of API’s/ Web Services Integration 
ScrapedJobID107:
MSc (Junior Scientist) or PhD (Senior Scientist) trained in machine learning. Extensive practical experience at systematically designing, training, debugging, and evaluating neural networks using modern frameworks such as Tensorflow, PyTorch, or Theano. Excellent scientific writing and presentation skills. Senior Scientists must demonstrate leadership and ability to introduce new machine learning techniques. A chance to develop machine learning techniques that will save human lives. Inspiring, creative, and fast-moving startup work environment in downtown Toronto Competitive compensation package including stock options 
ScrapedJobID108:
Bachelor’s Degree in Statistics, Mathematics, Computer Science of another quantitative field required Master’s Degree preferred 5+ years of progressive experience in using advanced analytics and statistical modeling Experience using advanced machine learning algorithms and statistics to provide practical solutions to business problems preferred. Experience using statistical and computer languages (R, Python, SQL, etc.) to query and manipulate data and draw insights from large data sets preferred. Experience communicating complex technical solutions to business clients preferred. Knowledge of advanced statistical techniques, concepts and applications preferred. Expert level analytical and statistics skills, combined with strong business acumen that can transform insights into action Expertise framing client business problems in a way that can be informed through data and analytics – architecting and implementing the solution Advanced written, oral and presentation skills Proven ability to drive organizational change through the applications of data driven insights Leadership (confidence, expertise and communication) skills to influence others to do things differently Expert level ability to transform data into actionable insights Self-starter and intellectually curious Ability to collaborate with variety of stakeholders A competitive base salary plus performance-based incentive compensation Annual merit pay increases Flexible benefits as well as support for retirement benefits Vacation time, a flexible “Day4U” and the option to purchase up to five additional vacation days Other financial perks such as our Employee Banking Advantages which includes waived or reduced financial service fees, reduced rates on personal loans, mortgages and no-interest loans on lifestyle-related items that promote health, wellness, learning and business aptitude 
ScrapedJobID109:

ScrapedJobID110:
Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches. | Travailler avec des ensembles de données vastes et complexes pour résoudre un large éventail de problèmes difficiles en utilisant différentes approches analytiques et statistiques. Apply technical expertise with quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products that serve billions of people and hundreds of millions of businesses. | Appliquer une expertise technique en matière d'analyse quantitative, d'expérimentation, d'exploration de données et de présentation des données afin de développer des stratégies pour nos produits qui servent des milliards de personnes et des centaines de millions d'entreprises. Identify and measure success of product efforts through goal setting, forecasting, and monitoring of key product metrics to understand trends. | Identifier et mesurer le succès des efforts en matière de produits en fixant des objectifs, en établissant des prévisions et en surveillant les paramètres clés des produits pour comprendre les tendances. Define, understand, and test opportunities and levers to improve the product, and drive roadmaps through your insights and recommendations. | Définir, comprendre et tester les opportunités et les leviers d'amélioration du produit, et piloter les feuilles de route grâce à vos idées et recommandations. Partner with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions. | Collaborer avec le produit, l'ingénierie et les équipes interfonctionnelles pour informer, influencer, soutenir et exécuter la stratégie du produit et les décisions d'investissement. A Bachelor’s degree (BA or BS) | Une licence (BA ou BS) A minimum of 2 years of work experience in analytics (minimum of 1 years with a Ph.D.) | Un minimum de 2 ans d'expérience professionnelle dans le domaine de l'analyse (minimum de 1 ans avec un doctorat). Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R) | Expérience des langages d'interrogation de données (par exemple, SQL), des langages de script (par exemple, Python) et/ou des logiciels statistiques/mathématiques (par exemple, R). Masters or Ph.D. Degree in a quantitative field. | Maîtrise ou doctorat dans un domaine quantitatif. 
ScrapedJobID111:

ScrapedJobID112:
Combine rigorous statistical analysis with first-principles insights from physics and chemistry to improve the accuracy and efficiency of customers’ instrumentation and measurement practices Build algorithms and data infrastructure to optimize clients’ operations Build visualization tools to explain insights to the stakeholders (field technicians, traders and executives) Advanced degree (MSc) in computer science, data science, software engineering and 5 years of industry experience First-principles thinking – you have the strong desire to understand any topic at a deeper level than most, and are unsatisfied with decisions based on convention or unjustified assumptions Proficiency with Python and version control (Git) Ability to leverage disparate data sources (i.e SQL, CSV, APIs ) Proficiency with Unix-like operating systems (Linux, MacOS X) and command line interface Proficiency with classical and deep learning methods and Big Data Frameworks Ability to keep high level of alignment with the internal and external stakeholders Ability to effectively plan the work and manage time Competitive compensation Comprehensive health benefits Stock options (at Validere, we're all owners) RRSP/401(k) matching programs Flexible working arrangements Professional development budget to master your craft Generous time-off with parental/family leave Quarterly Employee Wellbeing Days and No Meeting Friday Afternoons An inclusive, ego-free environment where diversity of people and thought is valued Opportunity to impact the trajectory of a fast growing tech company Deliver (the highest) value Remove friction Everyday is more scalable Be well, fair & transparent 
ScrapedJobID113:
Develop and document credit origination and monitoring models/strategies for the Personal Banking, Credit Card and SME business lines Frequently assess the performance of the models/strategies in place and present recommendations for better risk optimization Suggest improvements to existing methodologies and processes Carry out analyses that will guide risk management decisions and strategies at the Bank Establish and maintain effective communication with internal and external stakeholders Use various statistical techniques to model ratings (e.g., scorecards) and decisioning strategies Work in SAS and coordinate data analytics and exploration, including the data transformation and visualization steps (reporting) Organize and conduct meetings with partners from the business lines and risk management to get approval for the models and strategies being developed. Demonstrate acute understanding of partners’ business needs by making recommendations on their actions and strategic orientations Identify irregularities that may pose a risk to the Bank and recommend the necessary corrective measures Act as an expert and advisor for various stakeholders and committees in their decisions related to managing credit risks. Demonstrate leadership in adopting innovative analytical approaches, including artificial intelligence, to solve risk management issues Bachelor’s degree in a related field and 5 years of experience in credit risk, OR master’s degree in a related field and 3 years of experience in credit risk, OR university certificate/undergraduate diploma from the National Bank University Program and 7 years of experience in credit risk Excellent knowledge of quantitative methods Advanced proficiency in SAS and SQL Proficiency in R and/or Python, an asset Experience in applying machine learning, an asset Experience in the banking industry, an asset Excellent analytical and summarizing skills Proven ability to influence and innovate Strong interpersonal and collaboration skills, advisory and communication experience, as well as good ability to explain analytical concepts. Comfortable applying expertise in an ever-changing multidisciplinary environment Fluency in French (required) and a working knowledge of English. Health and wellness program, including many benefits Flexible group insurance Defined benefit pension plan Employee Share Ownership Plan Employee and Family Assistance Program Preferential banking services Community involvement program Telemedicine Virtual sleep clinic 
ScrapedJobID114:
Diplômé(e) en informatique Maîtrise du français Au moins une expérience Data réussie Dynamique et rigoureux(se), tu as un bon relationnel. Tu es à la fois autonome et à l’écoute des autres Tu es passionné(e) de technologie et curieux(se) au sujet de l’évolution des pratiques d’ingénierie logicielle (Continuous Delivery, DevOps, …) Data engineering : Spark (python, scala et/ou java), Impala, Kafka, Hadoop Cloud : GCP, AWS, Azure Machine Learning (en bonus) : Python (scikit learn, numpy, keras, tensorflow), R 
ScrapedJobID115:
Leverage data to identify, quantify and influence tangible business gain. Design and interpret quantitative experiments to objectively guide key business decision making Uplift modeling to identify what audiences we should or should not target with our different marketing tools Perform advanced analysis to guide the company in its strategic choices Oversee the day-to-day operations including the testing and maintenance of data science solutions Set up experimentation to measure the incremental impact of our marketing actions to different audiences. Have the capacity to thrive in our fast-paced environment, adapt quickly and take ownership of your work Experience solving real problems using data mining techniques and with statistical rigor and translating business problems into data problems Strong programming skills (Python) specifically with packages like TensorFlow, Pytorch, SkLearn, Numpy and Pandas Working knowledge of MySql, Clickhouse Strong knowledge of data management (schema design, data pipelines, workflows) Deep understanding of modern machine learning classification/regression techniques such as ANNs, SVMs, Naive Bayes and Decision Trees, as well as various ensemble methods such as boosting and bagging Strong knowledge of the possibilities and limitations of different types of data analysis and/or data science modelling Experience productionizing real-time machine learning models is a plus Please note this position is in Montreal, Quebec. Exploiter les données pour identifier, quantifier et influencer un gain commercial tangible. Concevoir et interpréter des expériences quantitatives pour guider objectivement la prise de décisions commerciales clés. Modélisation de l'uplift pour identifier les audiences que nous devons ou non cibler avec nos différents outils marketing. Réaliser des analyses avancées pour guider l'entreprise dans ses choix stratégiques Superviser les opérations quotidiennes, notamment les tests et la maintenance des solutions de science des données. Mettre en place des expérimentations pour mesurer l'impact incrémental de nos actions marketing auprès de différentes audiences. Avoir la capacité de s'épanouir dans notre environnement au rythme rapide, de s'adapter rapidement et de s'approprier son travail. Expérience de la résolution de problèmes réels à l'aide de techniques d'exploration de données et avec une rigueur statistique et traduction de problèmes commerciaux en problèmes de données. Solides compétences en programmation (Python), en particulier avec des progiciels tels que TensorFlow, Pytorch, SkLearn, Numpy et Pandas. Connaissance pratique de MySQL, Clickhouse Connaissance approfondie de la gestion des données (conception de schémas, pipelines de données, flux de travail) Connaissance approfondie des techniques modernes de classification/régression par apprentissage automatique, telles que les ANN, SVM, Naive Bayes et les arbres décisionnels, ainsi que de diverses méthodes d'ensemble telles que le boosting et le bagging. Connaissance approfondie des possibilités et des limites des différents types d'analyse de données et/ou de modélisation de la science des données. Une expérience de la production de modèles d'apprentissage automatique en temps réel est un atout. 
ScrapedJobID116:
Assist the Data Science team in building and developing solutions on White Whale’s AI platform, DeepSea. Support Data Science team in completing and maintaining client dashboards and deliverables. Search for and expand on DeepSea’s catalog of publicly available datasets. Work on an agile team and participate in sprint planning and daily team stand up. 2+ Years of previous work experience in a Data Science related role Completed a Bachelor's degree in Math, Statistics, Business Analytics, Computer Science or other related fields. Data Science certifications or courses will also be considered. Strong Knowledge of modern data architecture, data mining, data structures and data cleansing. Expertise in coding with Python/R, Pandas, SQL and working knowledge of APIs Experience creating and using advanced machine learning algorithms and models Excellent communication and interpersonal skills Ability to solve problems on your own Resourcefulness in the face of hard challenges A sense of purpose and delightfulness when you go into work everyday Learn, grow and shape your skills in an encouraging and productive environment Be part of a close-knit astronaut team on a critical mission to explore the world of data 
ScrapedJobID117:

ScrapedJobID118:
Develop a strong understanding of the Smartsheet database, how it is used to support operations and reporting, process integration, and the roles that are required to maintain the data. Maintain system’s integrity via strong understanding of system input, output, and interdependencies and provide guidance and training to end-users responsible for inputs. Assess and fulfill system change requests, notification needs, or automation requirements. Ensure system and data integrity. Build reporting tools and dashboards both in Smartsheet and Power BI to support internal and external reporting requirements. Conduct regular auditing of data to ensure that key information is populated and follows up with users where information is missing/inaccurate. Conduct research and keep up-to date on best practices for PS technologies, data analysis and analytics. Basic technical troubleshooting and escalate as required. Maintain effective working relationships, fostering a client driven, continuous improvement culture. Bachelor’s degree or diploma in Information Technology, Computer Data Science, Information Management, Business Administration, or equivalent experience (minimum 3 years). Strong familiarity with the use of Smartsheet for data management and reporting, Smartsheet certified or willingness to attain certification within first three months. Expertise in data models, database design development, data mining and segmentation techniques an asset. Expertise in Excel (macros, pivot and VLOOKUP tables, advanced formulas, charts) is mandatory. Knowledge of SQL databases and programming (ETL frameworks) and data visualization tools: PowerBI, Tableau and Bi360 is an asset. Knowledge of Taleo Business Edition, MS Dynamics AX, Kronos Time & Attendance, Moodle, Video Capture Utilities, SharePoint, survey applications, Raiser’s Edge is an asset. Organizational, time management, information management, technical and numeracy skills. Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. Requires meticulous attention to detail and a high level of sustained concentration over several hours. Non-traditional hours may be required on short notice, particularly during periods of emergency response. The majority of the work is performed remotely. Full vaccination against COVID-19 is mandatory for this position and operation (the CRC will however adhere to its duty to accommodate those who are unable to be fully vaccinated for a reason related to a human right protected ground). 
ScrapedJobID119:
Understands the decision-making process, workflows, and business and information needs of business unit heads and service manager/owners Translates business needs into analytics/reporting requirements to support executive decisions and workflows with required information Proactively mines data warehouses to identify trends and patterns and generates insights for business units and senior leadership Performs large-scale experimentation to identify hidden relationships between variables in large datasets Researches and implements cutting-edge techniques and tools in machine learning/deep learning/artificial intelligence to make data analysis more efficient Determines requirements that will be used to train and evolve deep learning models and algorithms Visualizes information and develops engaging reports on the results of data analysis using data visualization tools Advises product teams on new products, features or updates through data-based recommendations Develops frameworks and processes to analyze unstructured information collected through social media platforms i.e., wikis, blogs, instant messaging, etc. and traditional sources such as e-mail and SharePoint Supports user experience specialists and information architects to enhance information visualization through development of dashboards and user interfaces Distributes best practices to analytics and product teams and provides consultations for their data-based experimentations Up-to-date knowledge of machine learning and data analytics tools and techniques Strong knowledge in predictive modeling methodology Experienced at leveraging both structured and unstructured data sources Willingness and ability to learn new technologies on the job Demonstrated ability to communicate complex results to technical and non-technical audiences Demonstrated ability to work with minimal supervision Strong Background in ML and statistics either through projects or prior work experience Excellent programming skills in python and SQL Experience working with cloud platforms such as Azure, GCP, AWS is a plus Strong foundation in data pipelining, streaming Strong communication, problem-solving skills and a strong team player Basic understanding of libraries like PyTorch, scikit-learn, numpy etc. Bachelors or Master’s degree in Computer Science, Statistics, Mathematics or related fields 
ScrapedJobID120:
Bachelor's Degree 3+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g. R, SAS, or Matlab) 2 years working as a Data Scientist Experience in as many of the following areas: measurement problems, causal inferencing, multi-variate testing & design, A/B testing & design, descriptive analytics, and regression analysis. Good understanding of supervised and unsupervised learning models Solve real world problems by analyzing large amounts of business data, diving deep to identify business insights and opportunities, designing simulations and experiments, developing statistical and ML models by tailoring to business needs, and collaborating with Scientists, Engineers, BIE's, and Product Managers. Translate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies. In cases where questions cannot be answered with available data, work with engineers to produce the required data. Deliver with independence on challenging large scale problems with ambiguity. Manage and drive the technical and analytical aspects of Advertiser segmentation; continually advance approach and methods. Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance. Analyze historical data to identify trends and support decision making. Improve upon existing methodologies by developing new data sources, testing model enhancements, and fine-tuning model parameters. Provide requirements to develop analytic capabilities, platforms, and pipelines. Apply statistical or machine learning knowledge to specific business problems and data. Formalize assumptions about how our systems are expected to work, create statistical definition of the outlier, and develop methods to systematically identify these outliers. Work out why such examples are outliers and define if any actions needed. Given anecdotes about anomalies or generate automatic scripts to define anomalies, deep dive to explain why they happen, and identify fixes. Build decision-making models and propose solution for the business problem you defined Conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication. Utilize code (python or another object oriented language) for data analyzing and modeling algorithms. PhD in Statistics, Economics or related quantitative field. Experience in measurement problems, causal inferencing, multi-variate testing & design, A/B testing & design, manipulating data & analyzing very large data sets, descriptive analytics, and regression analysis. Excellent quantitative modeling, good knowledge of ML methods, statistical analysis, and problem-solving skills. Experience processing, filtering, and presenting large quantities (Millions to billions of rows) of data. Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization. Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment. Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to scientists, engineering, and business audiences. Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations. Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment. Experience in advertising is a plus. 
ScrapedJobID121:
Produce ‘deep-dive’ analysis of our unique data and communicate effective, actionable narratives Validate and manipulate high volume of web, email and physician level data Assist with processing and delivery of contracted client facing reports and analysis Improve existing client facing data visualizations and reports Work with Sales and Account Management teams to support their new client and upsell opportunities Contribute to ongoing product support and facilitate the development new customer support applications. Build a solid working knowledge of DMD’s data sources, their relationships and value to internal and external client’s business challenges and requirements. Efficiently respond to client issues and needs. Generate solution options while balancing the client’s demands with other reporting priorities. BS degree with a specialty in data science, data analytics or related 4+ years of relevant experience in data analytics and marketing support Experience with relational-style query languages is required (T-SQL, AWS Athena or SQL Server) Understanding of data pipelining and ETL, solid R knowledge Understanding of Tableau, and AWS Knowledge of Agile software development and project management processes Understanding of Medical / Pharmaceutical digital marketing industry and the related data and regulations is desired, but not mandatory Unparalleled attention to detail, multitasking and organizational capacity Strong technical, process and problem-solving proficiency Experience with JIRA and Confluence Ability to set and deliver on priorities and deal with a degree of ambiguity Exceptional interpersonal and communications capabilities Display organizational and emotional intelligence A desire to learn, adapt and perfect your work 
ScrapedJobID122:
Advanced Degree (MS or Ph.D.) in Statistics, Computer Science, Operations Research, Applied Mathematics, Physics, Engineering, Economics, or related technical field 5+ years of quantitative experience (industry, consulting, government, academics, or post-doc work) Ability to apply insights to high impact questions with immediate and long-term relevance Build predictive models to forecast upstream and downstream market activities Expertise in Machine Learning algorithms Experience with optimization techniques Work on developing and implementing supply and demand-side models Design and execute field experiments to draw insights from market behaviour Expertise with supervised and unsupervised techniques Ability to work independently and in a highly engaged team environment Develop and deliver machine learning algorithms at scale to solve business-specific problems mapped to use cases Experience cleaning, aggregating, and pre-processing large granular data from varied sources, including complex relational databases Perform econometric and statistical analysis on large granular transaction-level data sets Develop causal models to derive insights about market behaviour Proficient in tools such as Python, Jupyter Notebook, SQL, R, Airflow, Cloud-based services, STATA, SAS, MATLAB Effective verbal and written communication skills; the ability to collaborate with internal and external partners 
ScrapedJobID123:
Apply statistical modelling to optimization tests Develop machine learning systems to mine our data warehouse Develop costing models for risk and value for our transaction processor Run statistical analyses to discover insights about our customers and leads Provide training as our in-house statistics professor Generate ideas as we brainstorm new ways to leverage our existing data Master’s Degree, PhD or equivalent education At least 5 years working experience using Machine Learning Extensive experience performing in depth analytics and testing Experience in Azure ML and R an asset, but not required Strong multi-tasking, organizational and time management skills Keen attention to detail and ability to work independently Outside of the box thinking, someone who is not afraid to ask questions and look for new/different solutions. Unlimited paid vacations Liberal Work-from-Home policy Flexible hours Group RRSP program Regular in-person company events Support for continuous learning and development 
ScrapedJobID124:
Implement new statistical or mathematical methodologies for specific models of data analysis. Research the feasibility of potential predictive maintenance opportunities. Provide expert project leadership as a SME: guidance to team members and participate in cross-departmental projects establishing Geotab as a leader in data science. Create algorithms and predictive models to extract information required to solve complex business problems. Conduct causality experiments by applying A/B experiments or epidemiological approach to identify the root issues of an observed result. Identify new, complex queries from Big Data infrastructure from data warehousing database (i.e. Google BigQuery) to add value to the organization. Use machine learning (ML) packages (e.g. Scikit-learn and Tensorflow) to develop ML models and features. Test the performance of data-driven products and make recommendations for improving Geotab’s product suite. Collaborate with internal technical teams and external stakeholders to gather requirements. Responsible for the design, development, and maintenance of ongoing metrics, reports, analyses, and dashboards to drive key business decisions. Support a platform providing ad-hoc and automated access to large datasets. Post-secondary Diploma/Degree specialization in Data Science, Mathematics, Computer Science, Statistics, or related field. Graduate or post-graduate Degree in Data Science, Mathematics, Computer Science, Statistics, or a related field is highly valued. 5-8 years of experience as a Data Scientist or similar role. 5-8 years experience in writing SQL queries. 5-8 years experience in programming in Python. Solid understanding of machine learning and operations research. Knowledge of data management and visualization techniques. Affinity for statistical analysis and predictive modeling. Possess strong business acumen and link marketing initiatives to streamline operations. High accuracy and meticulous attention to detail. Strong project management skills; able to identify needs, develop effective solutions, and manage projects through to completion. Must stay relevant to technology and should have the flexibility to adapt to the growing technology and market demands. Strong analytical skills with the ability to problem solve to well-judged decisions. Strong team-player with the ability to engage with all levels of the organization. Technical competence using software programs, including but not limited to, Google Suite for business (Sheets, Docs, Slides). Entrepreneurial mindset and comfortable in a flat organization. 
ScrapedJobID125:
Work with a team of ambitious and passionate data scientists on a variety of projects. Use both your IQ and EQ to support yourself, your team, and your company in achieving more inside and outside the office. Work with Product Managers and Development teams to develop Machine Learning Solutions and scripts that will be built into software products. Work with the Workforce Science team to push the boundaries on what is known about the “how” and “why” of the ways people work and interact with their peers. Work with the Product team or other internal teams to analyze data such as feature usage and adoption and uncover insights to guide future product investments or business directions. Work with the Client Success team to explore how recognition/engagement data relates to customer data and business metrics. Bring an “A-Player” attitude: aiming for the happiness of your stakeholders; erring on the side of quick communication and deep collaboration; strong sense of integrity and respect toward your colleagues (and everyone) that you express with helpfulness – you’re a team-player Advanced degree in Statistics, Computer science, Behavioural Science or Mathematics preferred 3+ years of experience analyzing product’s data, building ML algorithms or making product focused impact with Data Science. Demonstrated experience in leveraging data for actionable insights using different techniques including AI and ML. Demonstrated experience working with both structured and unstructured data and a deep understanding of ML algorithms and statistical modeling. Have software engineering skills (scripting is important for quick prototyping, but knowledge in OOP is crucial for the long run), fluency in Python, experience in deep learning libraries such as PyTorch / Tensorflow / Keras – Bonus if you are proficient in Spark Experience working with Google Cloud Platform (GCP) Experience working in social networks, recommender systems and/or NLP applications Have deployed models to production with an engineering team Excellent communication – written, conversational, presentation, and data-visualization. Experience with both software engineering (ideally in an agile environment and with programming best practices) and empirical science. Experience in an HR space (e.g. People Analytics) or knowledge of Organizational Psychology is highly desirable. PhD in Machine Learning, Mathematics, Statistics, Computer Science or in another highly quantitative field Expertise in machine learning methods including Time series analysis, State-space models, Mixed-effect models, Longitudinal data analysis, Hierarchical Bayes; and Learning techniques such as Decision Trees, Boosting, Random Forests, Deep Learning, Neural Networks 
ScrapedJobID126:
Management Finances and Administration Natural and Applied Science + Related Fields Health Sales & Services Supply chain, Transportation, and Related Fields Natural Resources, Agriculture Public Utilities – Fabrication & Services PhD/Master’s degree in computer science, engineering, or mathematics fields Prior experience in artificial intelligence, machine learning Minimum 3 years of machine learning experience in Python with interest in Deep Learning A track record of outstanding AI (Deep Learning focus) software development with Github (or similar) evidence Demonstrated abilities in designing AI systems Demonstrated interest in applied Deep Learning, including early stage of data preparation, augmentation, generation, systematic Deep Learning model tuning, replicable Machine Learning experiments modeling, Deep Learning pipeline for ML model selection and validation Expert-level knowledge and experience working with at least one data science programming language (e.g. Python, R, Scala) to explore, understand, and build analytic models from data assets of varying size, type, and quality Expertise in Embedded Machine Learning (e.g. Deep Learning quantization) is a strong plus Good foundation in mathematics, statistics, and probability Strong knowledge of Machine Learning foundations with one or more of the following: Computer Vision applications Natural human interaction Predictive analytics Knowledge of mainstream Deep Learning architectures (MLP, CNN, UNET, etc) and Deep Generative Learning architectures (GAN, VAE) for computer vision tasks Strong Python programming skills Working knowledge of Linux OS Eagerness to contribute in a goal-oriented environment Ability to work creatively and analytically in a problem-solving environment Proven verbal and written communication skills in English (talks, presentations, publications, etc.) Great communicator Team player Critical thinker Avid learner Focus driven Transformational agent High School Professional Training Bachelor’s degree Master PhD Required / Privileged Bilingual Fluent Good Average School level Required / Privileged Bilingual Fluent Good Average School level Required/ Privileged Requited / Privileged Fixed Duration (temporary) Undetermined Duration (permanent) Annual Monthly Weekly Hourly Confidential Public Stimulating work environment and state-of-the-art projects, Professional development and continuing education with access to international conferences, Benefits after 3 months in position providing excellent coverage, Open work environment and sophisticated work equipment. 
ScrapedJobID127:
Apply advanced statistical and machine learning techniques to build models for underwriting, experience studies, assumption development, pricing, and claims management. Help us drive innovation by enabling new underwriting paradigms, distribution models, and data management. Build and implement solutions that enable operational units to improve quality and speed of core processes in order to generate incremental revenue or reduce expense. Proactively research new ways of modeling data to unlock actionable insights or improve processes. Collaborate across Munich Re functions and with clients to use analytics to influence business decisions. Work with existing data science groups at Munich Re and collaborate with internal partners to leverage capabilities in big data technology. Undergraduate Degree in Computer Science, Engineering, Statistics, or Applied Mathematics, plus 3 years’ experience OR Graduate Degree in Computer Science, Engineering, Statistics, or Applied Mathematics, plus 1 years’ experience. Insurance or financial services background is preferred but not required. Actuarial examinations or designation is an asset but not required. Expertise in advanced predictive analytic techniques. Strong experience working with Python, or R; working knowledge of SQL (familiarity with multiple languages considered an asset). Experience working with analytics through the modeling lifecycle including gathering data, design, recommendations, testing, implementation, communication, and retraining. Familiarity with cloud computing platforms (ex. AWS, Microsoft Azure). Familiarity with big data technologies (ex. Apache Spark, Hadoop, etc.), natural language processing and deep learning frameworks (ex. Tensorflow, Pytorch) is an asset but not required. Excellent communication skills, effectively interpreting modeling results, distilling actionable insights and presenting them to partners. The ability to learn quickly. A drive to make a difference. Thrive in a dynamic environment and successfully deliver on multiple assignments under deadlines. 
ScrapedJobID128:
Create summaries from large datasets coming from multiple data sources Connect the dots and identify trends within the data Look at past policyholder behaviour and predict how policyholders may react to various initiatives / offers Collaborate well with cross-functional teams across Canadian segment, both technical and non-technical Have good communication skills and able to explain findings Have good time management skills Have good negotiation skills (e.g. getting information from other teams that have competing priorities) 
ScrapedJobID129:
Exposure to business operations within a rapidly growing startup: you will have an opportunity to meet and collaborate with department leaders across the business High growth - we achieved 10x growth in Q1 and are determined to triple our success by year end Opportunity to grow and expand within VendorPM. You will wear many hats, be a crucial part of company growth, opportunity to own projects from start to finish, have access to mentorship, and take on new initiatives Hybrid work model - we have recently acquired a beautiful office space downtown for those who are looking for nice scenery but will continue flexibility for working at home. Ideally, teams are meeting in person once a week We have a leadership team that is committed to building the best place for top talent to work and take an invested interest in the success of our team members Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches. Apply technical expertise with quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products that process millions of dollars of business transactions. Identify and measure success of product efforts through goal setting, forecasting, and monitoring of key product metrics to understand trends. Define, understand, and test opportunities and levers to improve the product, and drive roadmaps through your insights and recommendations. Partner with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions. Segment MixPanel Heap Metabase A Bachelor’s degree (BA or BS) and/or minimum of 4 years of work experience in analytics Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R) Masters Degree in a quantitative field is an asset Emiel Bril , CEO : https://www.linkedin.com/in/emiel-b-a1a4a187/ Dylan Sher, VP of Product and Ops: https://www.linkedin.com/in/dylan-sher-911a7362/ Connor Wiebe, Software Developer: https://www.linkedin.com/in/connorwiebe/ Interview process step 1: Phone screen with Recruiter Interview process step 2: Technical Interview with VP of Product Optional equity in a quickly growing, venture-funded startup, benefits, 3 weeks vacation + competitive base salary 
ScrapedJobID130:
Validate (review and provide effective challenge) Machine Learning models and AI applications. Develop/implement Machine Learning model validation methodologies and standards. Ensure that the validation methodologies and standards are in line with industry best practice. Develop codes/dashboards to contribute to the automation of the validation procedures. Develop and apply a variety of statistical tests and modeling techniques to identify/recommend improvements to models and undertake related initiatives. Ensure extensive testing of model sensitivity and stability that help assessing model behavior and risk. Implement and evaluate external models used for benchmarking internal model performance. Participate in model selection and related due diligence activity. Ensure data integrity and completeness/representativeness of data captured for development and validation purpose. Maintain full professional knowledge of techniques and developments in the field of Machine Learning and share knowledge with business partners and senior management. Strong quantitative skills with an advanced degree in one or more of the following areas: computer science, mathematics, physics, statistics, machine learning, economics, finance, engineering, and/or actuarial science. Up to 3 years' experience of working in analytical environments. Experience with and strong knowledge of Machine Learning theory and predictive algorithms: Bagging and Gradient Boosting methods, Neural Networks/Deep Learning, NLP, Generalized Additive Models, Graphical Models, Bayesian/probabilistic methods and etc. Experience or knowledge of Machine Learning Model Interpretation/Explanation, as well as Bias/Fairness assessment, tools and algorithms. Experience with Big Data analytics tools and environments, such as, Hadoop/Hive, Spark, and H2O. Ability to research and implement Machine Learning algorithms from academic research papers is a plus. Object Oriented programming skills. Proficient in one or more programming languages such as Java, Scala, Python and/or R. Knowledge of neural network tools such as Tensorflow/Keras, PyTorch and/or MXNet. Excellent verbal and written communication skills (position requires writing reports). Quick learner who constantly works on improving their skills and expertise. Good time management and multitasking skills with minimal supervision. Continuously enhance knowledge / expertise in own area and keep current on emerging trends /developments and grow knowledge of the business, analytical tools and techniques Prioritize and manage own workload to deliver quality results and meet assigned timelines Support a positive work environment that promotes service to the business, quality, innovation ,and teamwork; ensure timely communication of issues/ points of Identify opportunities and recommend data related solutions to enhance productivity, effectiveness and operational efficiency Establish effective relationships across multiple business and technology partners, program and project managers Participate in knowledge transfer within the team and business units Work autonomously and accountable for acting as a lead within a specialized business management function and may provide work direction to others Provide seasoned specialized knowledge, advice and/or guidance to various stakeholders and team members Scope of role may have enterprise impact Focus on short to medium - term issues (e.g. 6-12 months) Undertake and complete a variety of complex projects and initiatives requiring specialist knowledge and/or the integration of cross functional processes within own area of expertise Oversee and/or independently perform tasks from end to end Generally reports to a Senior Manager or executive role 
ScrapedJobID131:
Define, develop and lead a data science program which identifies exploitation opportunities, and provides solutions and capabilities to address them. Conduct research and recommend potential initiatives to analysts, and branch management and senior executive staff. Autonomously find, enrich, transform, interpret, and exploit data to create intelligence products. Act as a Service representative on joint projects related to data science and participate in collaborative efforts where applicable. Provide mentorship and guidance to fellow Data Scientists and Data Exploitation Analysts, regarding intelligence analysis and associated activities pursued in response to the mandate. Recommend new data exploitation projects in annual work plans by identifying analytical gaps and suitable solutions. Regularly update knowledge of academic and industry data science practices and standards. Effectively communicate and present findings to specialists, management and non-technical audiences. Clearly document methodologies employed in research and data exploitation solutions. Mathematics Statistics Computer Science Computer Engineering Field of study related to data analytics Undergraduate degree and seven (7) years of experience Experience performing complex data exploitation on large volumes of data to provide tactical and strategic insights directly to analysts, business owners, and decision makers. Experience gathering requirements and identifying opportunities to apply data science towards business objectives. Experience prototyping and developing data exploitation capabilities using Python, in a Jupyter environment. Experience visualizing analytics, writing reports, producing functional notebooks, and designing and delivering presentations. Experience working with one or more of the following technologies: TensorFlow, PyTorch, Spark, Scala. Experience with supervised and unsupervised machine learning. Experience in the creation and implementation of algorithms and statistical techniques to resolve data science problems. Experience with text analytics and natural language processing (NLP). Experience in the design, creation, and implementation of graph analytics. Experience with complex data processing for time series and patterns of life analyses. Communication Initiative Innovation Creativity Ingenuity Analytical skills Coaching Salary Grade Breakdown 
ScrapedJobID132:
Develop, train, tune and integrate Machine Learning models Test and implement different A.I. technologies to address business needs Lead MLOps design and development Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions. Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies. Assess the effectiveness and accuracy of new data sources and data gathering techniques. Develop custom data models and algorithms to apply to data sets. Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes. Develop company A/B testing framework and test model quality. Coordinate with different functional teams to implement models and monitor outcomes. Develop processes and tools to monitor and analyze model performance and data accuracy. Masters in Statistics, Mathematics, Computer Science or another quantitative field Experience querying databases and using statistical computer languages: R, Python, SLQ, etc. Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc. Excellent communication skills, both written and verbal Experience in project management methodologies Work independently as well as in a team-oriented environment Strong analytical skills to solve and model complex business requirements Places emphasis on client satisfaction and clearly communicate solutions to both technical and non-technical team members and other staffs Demonstrated ability for creativity and innovative problem solving Able to multi-task in a dynamic environment, think clearly and calmly under pressure Ability to work in a fast-paced, dynamic environment that requires flexibility and balancing of competing priorities Ability to deal with situations, people and problems ethically, with honesty and integrity Experience using Informatica ETL is an asset Must complete & pass a criminal record check We live and breathe our core values. We go the extra mile. We’re honest. We always have each other's back. We have tons of integrity. And we always own it and adapt – no matter the challenge. With the support to do things differently, grow personally and professionally and bring your whole self to work, there's no limit to the impact you can make. We provide a competitive compensation package composed of a group benefits plan, rent subsidy and discretionary profit-sharing program. We are committed to a strong safety work environment. 
ScrapedJobID133:
Work with data engineers, data scientists and domain experts to build, evaluate, deploy and maintain high-performance machine-learning models Work with domain experts to manipulate, analyze and manage high dimensional time-series data from global utility/industrial customers (i.e. vibration, flow, temperature, pressure) Develop testable, readable, and effective production quality code Bachelor's Degree/Master’s Degree (or pursuing one) in Data Science, Statistics/Mathematics or related field Experience with Python Data science libraries (NumPy, Pandas, Scipy, Scikit-learn, TensorFlow/Py torc, etc) Previous intern/FTE experience, building regression, classifier and cluster models using ML/statistical algorithms Advanced understanding of Classic Machine learning, statistical learning and deep learning algorithms Advanced understanding of Python for data science Knowledge of cloud services in AWS like SageMaker, S3, Lambda, etc. Experience using swarm intelligence or equivalent optimization methods Experience with the modelling building lifecycle (data discovery/cleaning, feature engineering, modelling, testing/validation) Experience supporting and working with cross-functional teams in a dynamic environment 
ScrapedJobID134:
Data scientists work on a broad range of subjects, acquiring a lot of technical and professional experience in data science, data engineering, coding, business understanding and client interactions; skills invaluable in any career. Our company is small enough that each person's achievements have an impact on overall performance, yet big enough to be a world leader in our domain. We are a fast growing company, the best contributors will grow to managerial or product tech lead positions much more rapidly than in bigger companies Implementation of the data engineering, usually from client extracts to the insertion of the data in our data stores (SQL, ElasticSearch) Developing, testing, tuning models and putting them in production for tasks such as fraud detection and automation detection in complex environments. Automate key business tasks by implementing them in our production process framework in C# Conduct meetings with clients and interact with external stakeholders, whether it is direct user feedback, presenting business cases or defining the roadmap of evolutions for that client Code-savvy, either by having a degree in computer science and/or having developed some apps with actual users, or by willing to spend a lot of time practicing. Writing scripts for models and notebooks is not enough at Shift, we thrive on people who can write maintainable, production-quality code that will run everyday without breaking. AI-savvy, either by having a degree in machine learning and/or statistics or be looking to work on those subjects. Having a clear understanding of statistics and machine learning problems, tasks and common resolutions is important to communicate internally and explain to the client how the product is working. Client facing. You will need to be comfortable, clear and professional when talking to clients during meetings and by email. Expect to talk with a client every other day and grow your communicational and presentational skills! Business smart. We don't expect candidates to know the insurance sector, but we want people who can learn and master the business aspects of our products English speakers. We are an international company with offices in many countries and 40+ nationalities, the Shift working language is English. 
ScrapedJobID135:
End-to-end implementation and iterative enhancement of complex models to various lines of business Research and development of models using state-of-the-art artificial intelligence in a diverse and established finance data Exploratory data analysis and feature engineering on original data Structure and organize big data sets from a variety of noisy sources with the goal of discovering valuable and actionable insights Think strategically to architect new modeling approaches to complex problems 2-5 Years of experience with research, building and implementing machine learning models 2+ years of experience with Python In-depth knowledge of deep learning, convolutional neural networks, natural language processing, and recurrent neural networks. Strong mathematics and statistical analysis background A keen interest in technology and continuous learning about emerging technologies Background experience in financial markets with experience in Risk, Finance, Planning and forecasting or other relevant fields is preferred Ability to work as part of a team, as well as work independently or with minimal direction. Excellent presentation and data visualization skills Master's in a technical discipline such as Engineering, Mathematics, Econometrics, Computers Science or Statistics. Relevant PhD preferred but not required Monday to Friday Temporarily due to COVID-19 
ScrapedJobID136:
Supervise and support our team of Research Interns. Develop tools, algorithms, machine learning models and automated systems that help identify high risk user generated content on social networks. Work closely with our Product and Engineering Team to turn models into products. Perform data exploration, statistical analysis, and model the ways that social networks can use our tools. Use insights to identify meaningful features and patterns. Create prototypes and experiments to test the viability of insights and demonstrate results to the Product Team. Partner with high profile clients to understand their data science needs Present and visualize data to communicate findings to non-data science team members and Executive Team Working with related deep-learning technologies (Python, TensorFlow, PyTorch) Working with cloud platforms (AWS/Sagemaker, Snowflake) Experience with Tableau is an asset Experience with Golang is an asset Permanent position, 40 hours/week Remote applicants are welcome 
ScrapedJobID137:

ScrapedJobID138:
This is a full-time position. In terms of remote work, we are flexible. You must live close enough to either our Toronto or Boston office that you can come in as needed, but you won’t be required to come in every day. If U.S-based, you must be legally authorized to work in the U.S. Work hours are flexible, but meetings are likely to fall within the traditional 8-5 (EST) workday. The salary range for this role varies depending on your location (Canada or the US). We'll share that during the intro call. Post-processing and analyzing NMR spectra using an in-house developed platform Improving and expanding our data analysis and visualization platform Identifying and developing advanced algorithms to tackle unique low-field MRS challenges including denoising, spectral deconvolution, and post-processing corrections Leveraging SOTA machine learning methods to improve processing and analysis of in vivo magnetic resonance spectra. Developing robust approaches for the accurate quantification of in vivo metabolite concentrations Thorough understanding of and experience with signal processing for NMR Programming skills, particularly in Python, with experience using Python scientific libraries like NumPy and SciPy Familiarity with Git for version control Thorough understanding of machine learning and statistics 
ScrapedJobID139:
Management Finances and Administration Natural and Applied Science + Related Fields Health Sales & Services Supply chain, Transportation, and Related Fields Natural Resources, Agriculture Public Utilities – Fabrication & Services Works with stakeholders to identify the business requirements, understand distinct problems and expected outcomes, and models and frames business scenarios which impact critical business decisions. Applies scripting and programming skills to assemble various types of source data (unstructured, semi-structured, and structured) into well-prepared datasets with multiple levels of granularities (e.g., demographics, customers, products, transactions). Summarizes statistical findings and draws conclusions, presents actionable business recommendations. Presents findings and recommendations in a simple, clear way to drive action. Makes strategic recommendations on data collection, integration and retention requirements incorporating business requirements and knowledge of best practices. Helps define the strategic direction that Nuvoola AI should take with respect to AI. Influences stakeholders on the best approaches to use for deep learning. Identifies cloud infrastructure needs for deep learning. Evaluates and makes recommendations for new tools, techniques, and technologies to develop and support evolving operational needs in the AI space. Designs and develops custom data models and algorithms for the Nuvoola AI product line. Institutionalizes and develops the practice of data scientist within Nuvoola AI. Popularize complex solutions so that they are clear and understandable for non-experts. Promotes data science at Nuvoola AI, its customers and to the external community. Acts as a liaison between our University partners and Nuvoola AI (University of Moncton & ETS). Works closely and supervises the future holders of a doctorate working on our innovating projects with such key partners. Will physically work at those facilities when required. University Degree in Computer Science, Math, or related field or equivalent. Masters or PhD preferred. 5+ years of work experience directly related to quantitative analysis with proven results. 3+ years of work experience across a broad set of data science skills, including traditional statistical methods, machine learning and Natural Language Processing. 3+ years of experience with time-series analysis, forecasting, and anomaly detection Strong knowledge and hands-on experience with R, Python, SQL and C. Excellent oral and written communication skills (English and French) Excellent analytical, interpersonal and communication skills, including strong presentation skills. Dynamic, positive attitude, practical, takes initiative to solve problems. Excellent time management, organizational and collaborative skills. High School Professional Training Bachelor’s degree Master PhD Required / Privileged Bilingual Fluent Good Average School level Required / Privileged Bilingual Fluent Good Average School level Required/ Privileged Requited / Privileged Fixed Duration (temporary) Undetermined Duration (permanent) Annual Monthly Weekly Hourly Confidential Public Stimulating work environment and state-of-the-art projects, Professional development and continuing education with access to international conferences, Benefits after 3 months in position providing excellent coverage, Open work environment and sophisticated work equipment. 
ScrapedJobID140:
Provide insight into leading analytic practices, designs and leads iterative learning and development cycles, and ultimately produce new and creative geospatial analytic solutions that will become core deliverables Work closely with business owners to identify opportunities and serve as an ambassador for geospatial data science Design and deliver enterprise analytic geospatial solutions for customers Develop powerful business insights from social, marketing and industrial data using advanced machine learning techniques Work in a highly interactive, team-oriented environment with Big Data developers, engineers, modelers and Visualization experts Build complex statistical models that learn from and scale to petabytes of data. Analytical thought leadership and stay current on developments in data mining and the application of data science Work independently as a senior lead and may manage and direct activities related to analysis, design and support of technical data management solutions on various projects ranging in complexity and size Act as a technical working lead/resource to others. Work closely with senior leadership on significant projects using GIS tools, technology and techniques Provide thought leadership and/or industry knowledge for area of expertise: Geospatial Analytics Support a positive work environment that promotes service to the business, quality, innovation, and teamwork; ensure timely communication of issues/ points of interest Identify opportunities, leverage data related solutions to drive business productivity, and implement measures to enhance effectiveness and operational efficiency Work effectively as a team, supporting other members of the team in achieving business objectives and providing client services Participate in knowledge transfer within the team and other business units, including participation in cross-functional groups or committees (e.g., Data Councils) Generally accountable for a significant business management area that typically has enterprise wide impact or accountability Enterprise or functional expert, requiring broad managerial and deep specialized knowledge at the enterprise, business, regulatory and industry levels Undertake and complete a variety of complex initiatives requiring seasoned specialist knowledge and/or the integration of cross functional processes Position typically deals with senior/executive management Focus on longer-range planning for functional area (e.g. 12 months or greater) Undergraduate degree in Geomatics, GIS, Geography, Urban Planning, or Retail Planning 
ScrapedJobID141:
Research and development institution Computer hardware or software retailer/wholesaler Research and document data requirements, data collection and administration policy, and data access rules Data Science C C++ Python Go Linux Software development Dental Benefits Group Insurance Benefits Vision Care Benefits 
ScrapedJobID142:

ScrapedJobID143:
Influences the strategic direction of the brand by communicating data-derived insights and recommendations aligned to the needs of the business Builds and maintains patient flow and trend-based forecast models
Manages the forecasting process and gains alignment on forecast assumptions and scenarios with cross-functional partners
Work with global Takeda partners to design and refresh forecast models Manages the forecasting process and gains alignment on forecast assumptions and scenarios with cross-functional partners Work with global Takeda partners to design and refresh forecast models Creates and maintains dashboards and scorecards, primarily in Power BI, as well as insights presentations in PowerPoint
Defines key performance indicators in consultation with cross-functional partners to deliver meaningful and actionable findings
Creates Power BI dashboards both self-sufficiently and, where required, in partnership with vendors and commercial IT
Drives business unit adoption of insights and self-serve analytics Defines key performance indicators in consultation with cross-functional partners to deliver meaningful and actionable findings Creates Power BI dashboards both self-sufficiently and, where required, in partnership with vendors and commercial IT Drives business unit adoption of insights and self-serve analytics Support omni-channel analytics through delivery of reporting, insights and measurement Analyzes data to answer brand team questions and conducts self-driven exploratory analysis Effectively collaborates with Customer Excellence team members to deliver on salesforce effectiveness requirements including: territory design, targeting/call planning, resource allocation, incentive compensation and segmentation Develops and maintains a thorough understanding of the therapeutic area Partner with vendors on primary and secondary market research to understand customer journeys and current brand utilization as well as to guide future strategy Degree in applied sciences, statistics, mathematics, data science or medical sciences an asset High level of analytical skill and problem solving ability Proven ability to work both self-directed in a fast-paced, complex environment as well as collaboratively with both internal and external partners Demonstrated strategic and critical thinking Experience with quantitative reasoning and making evidence-based recommendations Experience in business intelligence and analytics, including:
Forecasting model development, execution and communication of outputs
Market insights synthesis, KPI creation and dashboard design
Sales force effectiveness (territory design, segmentation, salesforce sizing, incentive compensation) Forecasting model development, execution and communication of outputs Market insights synthesis, KPI creation and dashboard design Sales force effectiveness (territory design, segmentation, salesforce sizing, incentive compensation) Excellent Excel and Power BI capabilities
Python, SQL, R, language proficiency and experience with Databricks an asset Python, SQL, R, language proficiency and experience with Databricks an asset Strong communication and presentation skills, have the ability to communicate with impact the ‘so-what’ of complex analytics to non-technical audiences Excellent interpersonal skills, ability to build relationships across departments Ability to understand complex therapeutic areas and clinical/scientific data an asset Basic project management and ability to lead productive meetings with large groups Proficiency with Canadian pharmaceutical data sources such as IQVIA (previously IMS) and knowledge of Canadian pharmaceutical industry an asset Willingness to travel to occasional company meetings, including overnight trips in Canada, US, and Europe (<10%). Note for COVID-19: subject to company travel policies, currently all non-essential international and domestic travel is suspended until the end of 2021. 
ScrapedJobID144:
has a history of driving insights that have a profound impact on the business or customers is resilient and can lead others through high pressure, ambiguous and challenging environments has the “know how” in leveraging rigorous and structured approach to solve complex problems Entrepreneurial: embrace the art of the possible and take initiative in driving change Strong communicator: tell the story and get to the point in a clear and concise manner Curious and inquisitive: are passionate about learning and continuously drill down into a problem to uncover the root cause Courageous: are prepared to go to a place of discomfort and thrive in ambiguity Inclusive: collaborate with multidisciplinary teams and individuals with diverse backgrounds, and value different perspectives Technology advocate: leverage tools and capabilities to drive insights and efficiencies Action oriented: turn strategic visions into solution designs and execution plans Customer-centric: always look through the lens of the customer Advanced proficiency in database querying, data extraction frameworks, data mining, machine learning, artificial intelligence and relational database design Fluency in programming languages: SQL, R, Python, Java, SASS. Data visualization experience with platforms such as Tableau Degree in science, math, engineering, computer science, or other technology related discipline 
ScrapedJobID145:
Lead business strategy conversations to understand business needs Lead long term capability roadmap development with business leads Evaluate business processes and uncovering areas for improvement Translate Business needs into technical requirements Collaborating with business stakeholders and technical teams to deliver a variety of projects Lead solution planning, development, and implementation Deliver advanced analytics and data science projects from end-to-end Effectively communicating insights to project stakeholders Complete proof of concepts Lead the adoption of solutions into the business process Providing training, coaching and guidance on advanced analytical tools and data storage structures Identify best practices in the advanced analytics space by tracking technology and industry trends Graduating with a Bachelor's Degree in Data/Computer Science, Mathematics/Statistics, an engineering discipline, or equivalent On the job experience with statistical modeling, machine learning and/or deep learning modeling Expertise in statistical analysis tools like R or Python Comprehensive knowledge of Databases and strong SQL programming skills Proficiency in data blending tools like Trifacta, Knime or Alteryx is an asset Demonstrated experience in handling large data sets and relational databases Experience with visualization tools like Tableau, Power BI or Matplot Ability to translate business and technical requirements into non-technical terms Strong communication and collaboration skills Exceptional analytical and conceptual thinking skills Demonstrated ability to thrive in fast paced environment Ability to work independently with minimal supervision Experience with Scrum/Agile Methodology is an asset Experience using Hadoop/Hive, Teradata is an asset Competitive compensation, benefits, pension, RRSP contribution and vacation time A flexible working environment that promotes a healthy work-life balance A dynamic and inclusive culture that promotes you to bring your whole-self to work A supportive team that will encourage your professional growth and development An opportunity to be meaningful and impactful within your work and projects An opportunity to give back to the community with our Always on Volunteer 360 Program An organization that aims to use their scale, reach and expertise to build a more sustainable world 
ScrapedJobID146:
Working with our ML scientists to develop highly scalable models and algorithms for predicting molecular phenotypes using state-of-the-art neural network methodologies. Developing evaluation, visualization, and productivity tools for streamlining machine learning research Adapting our algorithms and architectures to best exploit modern cloud computing environments Working with our software engineers, biologists and geneticists to operationalize and deploy research output to match the needs of stakeholders. Solid Engineering and Computer Science fundamentals, ideally with a degree in CS, Math, or equivalent experience. Senior candidates should have experience in architecting, developing, and deploying large software systems in a leading position Experience in building, testing, training, and deploying production-ready ML workflows. Experience developing machine learning algorithms or machine learning infrastructure in Python or C/C++. Experience with frameworks like PyTorch, Caffe2, Tensorflow, Keras, JAX, Chainer, etc. Experience in the operationalization of Machine Learning projects (MLOps) using at least one of the popular frameworks or platforms (e.g. Kubeflow, AWS Sagemaker, Google AI Platform, Azure Machine Learning). Leading role in developing the future of drug development to cure genetically defined diseases. A highly competitive salary and meaningful equity compensation. Exceptional opportunities for learning and growth. A bright, collegial, highly motivated team working at the intersection of the most exciting areas of science and technology. 
ScrapedJobID147:
Statistical analysis: Identify patterns in data. This includes having a keen sense of pattern detection and anomaly detection. Machine learning: Implement algorithms and statistical models to enable a computer to automatically learn from data. Business intuition: Connect with stakeholders to gain a full understanding of the problems they’re looking to solve. Analytical thinking. Find analytical solutions to abstract business issues. Inquisitiveness: Look beyond what’s on the surface to discover patterns and solutions within the data. Degree in a STEM discipline (applied mathematics, computer science, statistics, engineering, machine learning, econometrics etc.) 8 hour shift Monday to Friday Master's Degree (preferred) machine learning: 1 year (preferred) Machine: 4 years (preferred) Process and clean the data: 3 years (preferred) Statistical modeling: 3 years (preferred) Artificial Intelligence: 2 years (preferred) 
ScrapedJobID148:
Organize and analyze large scale mutation data from tumor genome sequencing in a clinical setting Work closely with the lab and software teams to maintain data integrity Perform analysis of mutations across patient cohorts for quality control and to identify population-level patterns Use standard tools and computational frameworks to visualize, browse and statistically analyze distributions of mutations and clinical covariates Prepare statistically motivated plots of mutation data for presentation Develop approaches to identify anomalous distributions that can be leveraged in quality control processes Compile reports for partners and collaborators. Education: You hold a Master’s degree in bioinformatics, data science, biostatistics or equivalent Industry experience: 3+ years experience working in a clinical or research setting related to cancer genomics applied to tumor tissue analysis and/or cell-free DNA/liquid biopsy. Linux/UNIX: Experienced in working with command-line interfaces. Coding: Proficient with Python (desirable) or other statistical languages such as R. Databases: 1+ years experience in SQL databases, with experience aggregating data within and across patient cohorts. NGS: Experienced handling NGS data including the quality control/quality assurance. Cancer genomics: Facility with cBioPortal interfaces and tools and relevant API-level packages in R or Python to analyse and interpret somatic mutations in cancer. Tech-savvy: Experienced with standard NGS analysis tools such as samtools, alignment software (e.g. BWA or bowtie), and variant detection (e.g. GATK, samtools). Added bonus if you have experience with GitHub and cloud-based computing such as AWS. Attention to detail: Uncompromisingly meticulous with the execution of analysis. Interpersonal skills: Excellent communication skills– written, verbal and non-verbal. You’re considerate and have the ability to develop cooperative relationships with your team members. Organized: Have the ability to organize yourself and set priorities. 
ScrapedJobID149:
Develop models and algorithms to maximize ROI and advertising performance Implement machine learning models in production, sometimes with the assistance of Data Engineers Implement a data analysis framework to analyze and test models effectively Generate insights on user behaviour and implement necessary solutions Be able to test results using historical data and optimize efficiently in production Have a Masters degree or PhD in Computer Science, Statistics, Operations Research, or a related field, with dual degrees preferred. Have relevant experience as a Data Scientist Have the ability to take an ambiguously defined task, and break it down into an insightful analysis Are proficient with relevant data science tools such as Spark, Python (scipy, sk-learn) etc. Have a comprehensive understanding Bayesian modeling, machine learning techniques, and optimization Have the ability to innovate custom algorithmic solutions to machine learning problems Have worked with large datasets Understand multivariate regression, and classification Background in advertising technology or a related field is a plus Work alongside some of the smartest people in the industry Highly competitive salary with RRSP Matching Bright office in the heart of Toronto's tech center (currently we are remote due to COVID) Full benefits from League on day one of employment 3 weeks vacation + 3 personal care days + 1 volunteer day + birthdays off Home office and Internet reimbursements Coverage and support of personal development initiatives (conferences, courses, etc) An awesome parental leave policy A weekly $15 lunch credit via Ritual 
ScrapedJobID150:
Collect, parse, analyze and visualize large sets of data using multiple database and parallel data processing technologies Develop sophisticated Machine Learning and Advanced Analytics solutions that deliver business value Cooperate with Data Engineers and Data Developers to build robust software and productionize solutions Prepare documentation of models and design decisions for data and product development teams Communicate insights and propose solutions to internal clients and partners and provide reports and guidelines for improving operations Expertise in Machine Learning and applied statistics A demonstrated ability in Data Science, derived from hands-on experience working on multiple projects that went into production in an industry setting Demonstrated expertise with Python/ R, Scikit learn, Pandas, NumPy Proficiency in Python for data processing, statistical analysis, visualizations, and Machine Learning Practical experience in writing SQL queries Experience working in Agile or using other rapid development methods and environments Excellent problem solving, critical thinking, and communication skills Experience in developing presentations and communications to be shared internally and externally Experience with Time Series Analysis and/or Network and Graph Analytics Experience with Dataiku 
ScrapedJobID151:
Provide insight into leading analytic practices, designs and leads iterative learning and development cycles, and ultimately produce new and creative geospatial analytic solutions that will become core deliverables Work closely with business owners to identify opportunities and serve as an ambassador for geospatial data science Design and deliver enterprise analytic geospatial solutions for customers Develop powerful business insights from social, marketing and industrial data using advanced machine learning techniques Work in a highly interactive, team-oriented environment with Big Data developers, engineers, modelers and Visualization experts Build complex statistical models that learn from and scale to petabytes of data. Analytical thought leadership and stay current on developments in data mining and the application of data science Work independently as a senior lead and may manage and direct activities related to analysis, design and support of technical data management solutions on various projects ranging in complexity and size Act as a technical working lead/resource to others. Work closely with senior leadership on significant projects using GIS tools, technology and techniques Provide thought leadership and/or industry knowledge for area of expertise: Geospatial Analytics Support a positive work environment that promotes service to the business, quality, innovation, and teamwork; ensure timely communication of issues/ points of interest Identify opportunities, leverage data related solutions to drive business productivity, and implement measures to enhance effectiveness and operational efficiency Work effectively as a team, supporting other members of the team in achieving business objectives and providing client services Participate in knowledge transfer within the team and other business units, including participation in cross-functional groups or committees (e.g., Data Councils) Generally accountable for a significant business management area that typically has enterprise wide impact or accountability Enterprise or functional expert, requiring broad managerial and deep specialized knowledge at the enterprise, business, regulatory and industry levels Undertake and complete a variety of complex initiatives requiring seasoned specialist knowledge and/or the integration of cross functional processes Position typically deals with senior/executive management Focus on longer-range planning for functional area (e.g. 12 months or greater) Undergraduate degree in Geomatics, GIS, Geography, Urban Planning, or Retail Planning 
ScrapedJobID152:
Work on challenging and research-based initiatives using advanced machine learning and other statistical methods focused on tangible value added outcomes Collaborate effectively with colleagues to identify business opportunities and designing innovative solutions to optimize processes and promote informed decision-making Prepare and integrate large and varied types of data (structured/non-structured, text/financial) from source systems to generate value for downstream analytics Implement machine learning models, data mining methods, and statistical analysis Leverage visualization tools/packages to create powerful representations of results Produce data-driven insights to help in informed decisions and actions by telling a convincing story and effectively communicate findings to business partners and executives as well as collaborate with the IT development team to deploy production-scale solutions Quickly learn new methods, tools and technologies presented in research communities to implement and adapt within the daily analytics exercises Contribute to the development of a data strategy that will effectively articulate the RRP program’s data needs while streamlining process and providing a platform for future analytics Undergraduate degree in computer science, statistics, quantitative finance or other science, technology, engineering and mathematics (STEM) fields Expert in Python programming to write production-ready codes and software packages in addition to experience with Natural Language Processing (NLP) and text analytics methods and packages, particularly BERT-based models Strong data profiling, cleaning, mining and technical documentation skills as well as strong communication and presentation skills Experience developing machine learning models and other data analytics for real business problems, and big data technologies and parallel processing techniques (e.g. Hadoop, Spark) Sound knowledge and experience of different deep neural networks architectures and transfer learning Graduate degree in computer science, statistics, quantitative finance or other STEM fields Solid understanding of how to deploy container-based virtualization e.g. kubernetes or docker Experience with machine learning operations (MLOps) to build end-to-end pipeline and deploying models in production, and creation of graphical user interfaces (GUIs) using python packages Business intelligence (BI) reporting using Tableau Proficient in Linux environment, shell scripting, and Git A comprehensive Total Rewards Program including bonuses and flexible benefits, competitive compensation, commissions, and stock where applicable Leaders who support your development through coaching and managing opportunities Ability to make a difference and lasting impact Work in a dynamic, collaborative, progressive, and high-performing team Opportunities to take on progressively greater accountabilities 
ScrapedJobID153:
Applying climate and data science skills to advise teams on how best to approach their climate science-related projects. Working closely with international teams on project goals and timelines. Providing climate science expertise and strategic insight both internally and with external partners. Collaborate with fellow researchers to manage, plan, and conduct research related to climate change and climate change communication. Design and conduct quantitative analysis of data with respect to specific research questions, in collaboration with the project team. Collaborate with fellow researchers and staff in data processing, analysis, validation, and interpretation. Interpret results and write up academic publications. Other duties and roles as agreed upon with supervisor. Strong research skills, including designing research questions, literature review, writing up scientific findings. Excellent understanding of environmental science concepts. Prior quantitative research experience applying advanced statistical techniques. Understanding and experience with challenges of data collection and analysis. Previous research and interest in the areas of climate change research, climate change communication, and/or health communication considered an asset. Extensive knowledge of statistical software such as Stata, SAS, or SPSS. Proficiency with Microsoft Office Suite. Excellent interpersonal, communication (oral and written) and organizational skills. Detail-oriented, with excellent analytical thinking skills, a propensity to take initiative and a demonstrated ability to exercise good judgment. The ability to produce high-quality, accurate work in a timely way, and in accordance with project deadlines. Excellent teamwork skills and a demonstrated ability to collaborate effectively with team members and liaise with study investigators. Work from home Monday to Friday Master's Degree (preferred) data analsis: 2 years (preferred) Yes 
ScrapedJobID154:
Working with project teams to address data science/computing challenges Identifying opportunities for technology to enhance service offerings Acting as a resource and participating in client engagements and research as part of the project team Maintaining up-to-date knowledge of computing tools, providing technical training and helping to grow the in- house knowledge base, specifically in a Linux environment Presenting research at selected conferences Developing data engineering and machine learning production systems for full stack data science projects Using natural language processing methodologies to work with EMR data, social media data and other unstructured data Optimizing procedures for managing and accessing large databases (e.g., insurance claims, electronic health records, financial transactions) Developing and reviewing software and packages in R, Python, C# and other Object Oriented Languages Significant experience working within a Linux environment required, experience with Docker and front-end development using a Javascript framework (e.g., Vue.js, Angular) is highly preferred. Strong credentials and experience working with document and relational databases (MongoDB, SQL Server, etc.). Bachelor’s degree required. Advanced degree, ideally PhD in Computer Science, Mathematics, Statistics, Economics or other relevant scientific degree with relevant experience, is preferred. Other candidates with at least one year of experience in the field may also be considered. Demonstrates strong interpersonal, written, and oral communication skills. Project experience with Python and/or R is preferred. Demonstrated experience working on project teams and collaborating with others. Le masculin est utilisé ici en tant que genre neutre et sert uniquement à alléger le texte. Collaborer avec les équipes de projet pour relever les défis informatiques et liés à la science des données Identifier des façons dont la technologie peut améliorer l’offre de services Contribuer à l’activité et à la recherche du client en tant que spécialiste et membre de l'équipe de projet Maintenir les connaissances sur les outils informatiques à jour, former le personnel sur des points techniques et aider à développer la base de connaissances interne, en particulier dans un environnement Linux Présenter les recherches lors de certaines conférences Développer des systèmes de production en ingénierie des données et apprentissage automatique pour des projets de science des données full-stack Utiliser des méthodologies de traitement automatique du langage pour travailler avec les données des DME et des médias sociaux et d’autres données non structurées Optimiser les procédures de gestion et d'accès aux grandes bases de données (déclarations de sinistre, dossiers de santé électroniques, transactions financières, etc.) Développer et réviser des logiciels codés en R, Python et autres langages orientés objet Une expérience de travail significative au sein d'un environnement Linux est requise, une expérience avec Docker et de développement front-end à l'aide d'un framework JavaScript (par exemple, Vue.js, Angular) est hautement préférée. Compétences avancées et expérience de travail avec des bases de données orientée documents et base de données relationnelle (MongoDB, SQL Server, etc.) Diplôme de niveau licence exigé. Dans l’idéal, le candidat possède un doctorat en informatique, mathématiques, statistiques, économie ou un autre diplôme scientifique pertinent accompagné d’une expérience professionnelle concordante. La candidature d’autres personnes possédant au moins un an d'expérience dans le domaine sera éventuellement étudiée. Excellentes aptitudes pour les relations interpersonnelles, la communication orale et écrite. Expérience de projets utilisant Python et/ou R souhaitée. Expérience avérée de travail au sein d'équipes de projet et de collaboration avec des tiers. 
ScrapedJobID155:
You will build pipelines to bring data required to support the use case You will develop new machine learning models to enable intelligent campaigns You will productionalize machine learning models and automate processes Collaborate with business stakeholders to enable new use cases for TELUS Business Effectively communicate with leadership and stakeholders in explaining the model and outcomes You have experience leading large scale projects and partnering with multiple stakeholders You can manage ambiguity and change with a learning and growth mindset You love digging into quantitative and qualitative data You have experience working with customer data, building recommendation engines, personalized offer management, lifetime value and propensity modeling You have experience in building machine learning algorithms You have worked with R/Python, SQL, spark, big data technologies or cloud You have data engineering experience and ability to extract data from various sources You have 5+ years of experience in a similar role and/or related education with demonstrated performance Prior telecommunications or B2B marketing experience Experience with Cloud / Salesforce technologies 
ScrapedJobID156:
Assemble and analyze data to understand customer behavior of existing 407 ETR data, external data sources and emerging sources to make recommendations on future state of loyalty program and bring awareness of usage behavior Generate dashboards and automate reports that empower teams across the organization to make data-driven decisions Break down strategic problems, and analyze data and information to provide insights and recommendations Assist in identifying new data sources or analytic approaches to current business problems Develop data solutions to support the business strategy and stakeholder needs Build and maintain analytical models to identify revenue opportunities Think critically about experimental design and advocate for thoughtful experimentation Challenge assumptions and ways of working Collaborate with business partners to implement change to business processes and workflows A University degree in Engineering, Statistics, Mathematics, or Computer Science Exceptional business analysis and creative problem-solving skills Highly collaborative team player with an entrepreneurial attitude Strong communication and presentation skills Exceptional work ethic and desire to learn and continue learning. Proficiency with Python, SQL, and Tableau is an asset 
ScrapedJobID157:
Organize and analyze large scale mutation data from tumor genome sequencing in a clinical setting Work closely with the lab and software teams to maintain data integrity Perform analysis of mutations across patient cohorts for quality control and to identify population-level patterns Use standard tools and computational frameworks to visualize, browse and statistically analyze distributions of mutations and clinical covariates Prepare statistically motivated plots of mutation data for presentation Develop approaches to identify anomalous distributions that can be leveraged in quality control processes Compile reports for partners and collaborators. Education: You hold a Master’s degree in bioinformatics, data science, biostatistics or equivalent Industry experience: 3+ years experience working in a clinical or research setting related to cancer genomics applied to tumor tissue analysis and/or cell-free DNA/liquid biopsy. Linux/UNIX: Experienced in working with command-line interfaces. Coding: Proficient with Python (desirable) or other statistical languages such as R. Databases: 1+ years experience in SQL databases, with experience aggregating data within and across patient cohorts. NGS: Experienced handling NGS data including the quality control/quality assurance. Cancer genomics: Facility with cBioPortal interfaces and tools and relevant API-level packages in R or Python to analyse and interpret somatic mutations in cancer. Tech-savvy: Experienced with standard NGS analysis tools such as samtools, alignment software (e.g. BWA or bowtie), and variant detection (e.g. GATK, samtools). Added bonus if you have experience with GitHub and cloud-based computing such as AWS. Attention to detail: Uncompromisingly meticulous with the execution of analysis. Interpersonal skills: Excellent communication skills– written, verbal and non-verbal. You’re considerate and have the ability to develop cooperative relationships with your team members. Organized: Have the ability to organize yourself and set priorities. 
ScrapedJobID158:
Statistical analysis: Identify patterns in data. This includes having a keen sense of pattern detection and anomaly detection. Machine learning: Implement algorithms and statistical models to enable a computer to automatically learn from data. Business intuition: Connect with stakeholders to gain a full understanding of the problems they’re looking to solve. Analytical thinking. Find analytical solutions to abstract business issues. Inquisitiveness: Look beyond what’s on the surface to discover patterns and solutions within the data. Degree in a STEM discipline (applied mathematics, computer science, statistics, engineering, machine learning, econometrics etc.) 8 hour shift Bachelor's Degree (preferred) Machine Learning: 1 year (preferred) Process and clean the data: 2 years (preferred) statistical modeling: 2 years (preferred) Artificial Intelligence: 2 years (preferred) 
ScrapedJobID159:
Apply data science expertise to multiple commercial and customer analytics projects Use data analysis, visualization, storytelling, and data technologies to scope, define and deliver AI-based data products Apply analytics to individual-level data and/or marketing data sources, including data regarding media and digital audiences, ad-tech and digital clickstream to attribute sales and operations impact Build models, algorithms, simulations, and performance evaluation by writing highly optimized, deployable code and using state-of-the art machine learning technologies Work on full spectrum of activities from conducting experiments to delivering production-ready models Work with developers, engineers, and MLOps to deliver AI / ML solutions. Degree in mathematics, computer science, engineering, physics, statistics, economics, computational sciences or a related quantitative discipline and 2+ years of analytical experience, or PhD in relevant domain. Experience AI / ML modeling of complex datasets, preferably commercial or customer analytics An aptitude and skills for data visualization Expertise with the core data science languages (such as Python, R, Scala), and familiarity & flexibility with database systems (e.g. SQL, NoSQL) Comfortable working in cloud and high-performance computational environments (e.g. AWS, Apache Spark, Databricks) Excellent written and verbal communication, business analysis, and consultancy skills Knowledge of some customer-focused modeling approaches (Market Mix Models, demand forecasting, elasticity modeling, mixed effects modeling, reinforcement modeling, markov simulations) Tableau, Power BI, Plotly or similar Disciplined AI / ML development (CI / CD, Orchestration) Experience using optimization solvers (LP, QP, MILP…) 
ScrapedJobID160:
8 hour shift Monday to Friday Fort McMurray, AB: reliably commute or plan to relocate before starting work (required) Data Visualization: 3 years (preferred) SQL Programming: 3 years (preferred) VBA Programming: 3 years (preferred) Tableau: 1 year (preferred) Power BI: 1 year (preferred) Database Management: 3 years (preferred) Ability to analyze large datasets: 1 year (preferred) Oil and Gas: 1 year (preferred) Oil Sands turnaround operations: 1 year (preferred) No 
ScrapedJobID161:
Develop models and algorithms to maximize ROI and advertising performance Implement machine learning models in production, sometimes with the assistance of Data Engineers Implement a data analysis framework to analyze and test models effectively Generate insights on user behaviour and implement necessary solutions Be able to test results using historical data and optimize efficiently in production Have a Masters degree or PhD in Computer Science, Statistics, Operations Research, or a related field, with dual degrees preferred. Have relevant experience as a Data Scientist Have the ability to take an ambiguously defined task, and break it down into an insightful analysis Are proficient with relevant data science tools such as Spark, Python (scipy, sk-learn) etc. Have a comprehensive understanding Bayesian modeling, machine learning techniques, and optimization Have the ability to innovate custom algorithmic solutions to machine learning problems Have worked with large datasets Understand multivariate regression, and classification Background in advertising technology or a related field is a plus Work alongside some of the smartest people in the industry Highly competitive salary with RRSP Matching Bright office in the heart of Toronto's tech center (currently we are remote due to COVID) Full benefits from League on day one of employment 3 weeks vacation + 3 personal care days + 1 volunteer day + birthdays off Home office and Internet reimbursements Coverage and support of personal development initiatives (conferences, courses, etc) An awesome parental leave policy A weekly $15 lunch credit via Ritual 
ScrapedJobID162:
Prepare analysis datasets from raw / precursor datasets for use in statistical analyses of clinical trial and observational clinical data. Independently lead and manage projects related to but not limited to analysis of clinical trials, synthetic control analyses, and etc. Participate in code development, cleaning and quality control exercises. Lead writing and submissions of manuscripts sections to be published in peer-reviewed journals; prepare technical reports for stakeholders as well as abstracts, posters, and other materials to be presented at research conferences and workshops Assist in the development of grant applications and proposals. Contribute to the development and maintenance of a positive team-focused company culture Master’s degree in a quantitative field or bachelor’s degree with 1-2 years of relevant experience (e.g. epidemiology, economics, data science, statistics) Demonstrated proficiency in the R programming language (e.g. research or industry experience, thesis or capstone project) Demonstrated experience with data exploration / management / preparation / wrangling Attention to detail/experience with reproducible research practices Some knowledge of applied statistics SAS experience is a plus Experience working with health/biomedical data Knowledge of ADaM, SDTM or OMOP standards is a plus Experience with version control a plus 
ScrapedJobID163:
Develop and maintain attribution models to help customers understand marketing campaign performance and return on investment from their marketing investments across online and offline channels. Work with internal stakeholders in Marketing, Product and Sales to implement and continually back test and refine models as necessary Work with large data sets from different source systems, transforming and cleaning online and offline data to discover actionable insights Develop easy to understand visualizations to convey insights to customers and present clear calls to action Extract, clean and transform customer data from across Trader’s business for the purposes of analysis, modeling, and prediction Use predictive modeling to increase and optimize customer experiences on the autoTRADER marketplace, drive revenue generation, and improve ad targeting Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies. Work with stakeholders throughout the organization to identify opportunities to leverage company and consumer data to drive business solutions and capitalize on opportunities Work cross functionally to integrate predictive models within Trader systems as needed Work closely with Analytics teams across the organization to develop best practices and standards for advanced data analytics and data science that improve the quality of Trader's data product deliverables Develop comprehensive testing and measurement programs that quantify and optimize models developed with each successive execution Collaborate with Analytics, Marketing, Engineering and Sales to identify and secure data needed to increase the effectiveness of Trader’s predictive models Identify internal and 3rd party data required to enhance and improve model accuracy Strong communication and presentation skills (verbal and written), combined with the ability to effectively coordinate multiple competing priorities to meet deadlines. High degree of autonomy – ability to work with product teams to identify requirements and communicate them effectively Strong business perspective – ability to understand medium-term (9-12m) implications of business decisions and react accordingly A sense of curiosity – ability to ask the right questions and really get data talking Strong communication skills – ability to work in both technical and business environments, and can communicate key findings and implications to business leaders Creative and innovative thinker with strong problem solving skills Ability to interact professionally with all levels within and external to the organization Minimum 5 years of work experience in advanced data analytics, data science, machine learning, model development, quantitative analysis, interpretation and communication to internal and external stakeholders. Experience in online businesses and with online advertising is strongly preferred 5 or more years of experience in an analytical role; knowledge of, and hands-on experience, working with Google Marketing Platform tools such as GTM and GAM Bachelors/Masters/Advanced Degree in Mathematics/Statistics, Quantitative Science or Computer Science. Master’s degrees and higher preferred Development of models include innovative solutions that leverage large data sets focused on customer attributes, business attributes and transactional data. Experience creating and using advanced machine learning algorithms and statistics (ie regression, simulation, clustering, decision trees, neural networks, etc) Expert level SQL querying skills; fluent in programs for large scale data analysis (i.e. R, Python) Experience working and combining data from multiple source systems (ie Google Analytics, AdWords, Facebook Insights, Adobe Audience Manager, etc)High level of competency in MS Office Applications (Excel, PowerPoint, Word, Access, Outlook) An environment built to help you be your creative best Competitive employee benefits program (medical, dental, vision and extended health care) Paid time off Professional Development dollars Retirement benefits Company Incentive plans Flexible work environment Team-building and Employee Appreciation events Employee and Family Assistance and Wellness Programs Gym membership discounts 
ScrapedJobID164:
Be involved in sales discussions, potentially fueling the conversation about what AI can do and bringing clarity to the discussion Work with customers and implementation teams to build out custom solutions Build POCs with AWS assistance and consulting PMs on opportunities Be hands-on. Design, Prototype, Configure - validate solutions rapidly to ensure we solve the right problems, in the right order Be a storyteller. Author & design high-quality specifications and communicate specific, actionable requirements to your engineering teammates Be a leader. Look for opportunities to innovate, keep up with the latest software, machine learning, manufacturing industries trends, and distill them into product requirements Be agile. Design, implement, iterate Take pride in your work 2+ years of software development/architect, product management, or technical consulting role in AI 5+ years of professional work experience in agile software development environments Demonstrated skills in design, product development, and planning Ability to work independently in a fast-paced environment, with little direct supervision Excellent oral and written communication skills with the ability to effectively explain complex problems and advocate technical solutions to Engineering and customers Degree in computer science or engineering Experience with AI and Machine Learning Models Experience with Natural Language Processing Experience working in the following industries: Consumer Packaged Goods, Chemical and Cosmetics Experience working on SaaS enterprise applications or content management systems Experience with API and data exchange schemas Experience with data migration Experience with Search matching algorithms and heuristics Experience with Python, SQL, XML, and JSON Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID165:
Effective October 26th, all new hires to Fraser Health will need to have full COVID 19 vaccination (have received a full series of a World Health Organization “WHO” approved vaccine against infection by SARS-COV-2, or a combination of approved WHO vaccines). Please note this applies to all postings, and individual medical exemptions must be approved by the Provincial Health Officer. Working as the lead Data Scientist and strategist for the System Optimization department, cultivating and developing a proven and sustainable machine learning foundation and competency for Fraser Health. Working closely with clinical and leadership teams across the health authority to strategize and develop artificial intelligence (AI) products. Identifying, cleaning, and integrating large sets of structured and unstructured datasets from disparate sources for use in ML models and products. Enhancing data collection procedures to include information that is meaningful for building a ML models. Using advanced ML processes to convert data from non-functional forms, such as scanned image text, to functional forms ready for use in further ML models. Using advanced ML models to identify patterns, trends, and opportunities that can make predictions or reduce workload across various clinical domains within Fraser Health. Implementing ML models into production by collaborating and guiding developers. Identifying, engaging, and collaborating with specific partners as required for the development of AI products. Communicating analytic solutions to leadership and making recommendations regarding strategic actions to maintain the ML development pipeline, analytic architectures, and life cycle to avoid potential negative consequences and system failures. PhD in Statistics, Mathematics, Computer Science or another quantitative field Five (5) to seven (7) years of experience working with large datasets and machine learning models 
ScrapedJobID166:
Effective October 26th, all new hires to Fraser Health will need to have full COVID 19 vaccination (have received a full series of a World Health Organization “WHO” approved vaccine against infection by SARS-COV-2, or a combination of approved WHO vaccines). Please note this applies to all postings, and individual medical exemptions must be approved by the Provincial Health Officer. Working as the lead Data Scientist and strategist for the System Optimization department, cultivating and developing a proven and sustainable machine learning foundation and competency for Fraser Health. Working closely with clinical and leadership teams across the health authority to strategize and develop artificial intelligence (AI) products. Identifying, cleaning, and integrating large sets of structured and unstructured datasets from disparate sources for use in ML models and products. Enhancing data collection procedures to include information that is meaningful for building a ML models. Using advanced ML processes to convert data from non-functional forms, such as scanned image text, to functional forms ready for use in further ML models. Using advanced ML models to identify patterns, trends, and opportunities that can make predictions or reduce workload across various clinical domains within Fraser Health. Implementing ML models into production by collaborating and guiding developers. Identifying, engaging, and collaborating with specific partners as required for the development of AI products. Communicating analytic solutions to leadership and making recommendations regarding strategic actions to maintain the ML development pipeline, analytic architectures, and life cycle to avoid potential negative consequences and system failures. PhD in Statistics, Mathematics, Computer Science or another quantitative field Five (5) to seven (7) years of experience working with large datasets and machine learning models 
ScrapedJobID167:
Build agent-based simulations of smart contracts and blockchain networks using our Python SDK Design and optimize incentive models for blockchain protocols and help discover potential attack vectors Contribute to making our simulation model and platform world-class Build data models and visualizations of public blockchain data and simulation results that provide intuitive analytics to customers Proficient at writing code in Python or similar languages Smart contract development experience (e.g. Solidity) Experience with building machine learning models at scale 
ScrapedJobID168:
Collect, parse, analyze and visualize large sets of data using multiple database and parallel data processing technologies Develop sophisticated Machine Learning and Advanced Analytics solutions that deliver business value Cooperate with Data Engineers and Data Developers to build robust software and productionize solutions Prepare documentation of models and design decisions for data and product development teams Communicate insights and propose solutions to internal clients and partners and provide reports and guidelines for improving operations Expertise in Machine Learning and applied statistics A demonstrated ability in Data Science, derived from hands-on experience working on multiple projects that went into production in an industry setting Demonstrated expertise with Python/ R, Scikit learn, Pandas, NumPy Proficiency in Python for data processing, statistical analysis, visualizations, and Machine Learning Practical experience in writing SQL queries Experience working in Agile or using other rapid development methods and environments Excellent problem solving, critical thinking, and communication skills Experience in developing presentations and communications to be shared internally and externally Experience with Time Series Analysis and/or Network and Graph Analytics Experience with Dataiku 
ScrapedJobID169:
Analyzing data using statistical techniques and providing reports Identifying, analyzing, and interpreting complex data sets using SQL, Excel, and visualization tools.Designing custom data extracts. Migrating data to enterprise applications. Identifying process improvement opportunities Advanced skills in Microsoft Excel Practical experience using data visualization tools Ability to write, analyze, and debug complex SQL queries B.S. degree in Computer Science, Business, or similar. M.S. in Computer Science or similar 2+ years of experience working in a data science or data analyst role 
ScrapedJobID170:
Convert the business opportunity into an analytical problem. Measure the size of the opportunity. Determine key performance measures (KPIs) to track success. Use a variety of statistical and machine learning techniques to solve the problem. Demonstrate shared value through the conversion of algorithms into a business process. Candidates are expected to hold a Masters or PhD in Computer Science, Computer Engineering, Statistics, Data Science or a related quantitative field. Must be proficient in programming (Python), algorithms and data structures. Must be familiar with Machine Learning, Natural Language Processing and Deep Learning, and should demonstrate their knowledge through the past projects (academic or industrial). Should demonstrate the knowledge of applied statistics and its usage in data analysis and feature engineering. Good to have knowledge of big data technologies such as Spark, Hadoop and cloud platforms like Azure Machine Learning. Good to have the knowledge of Reinforcement Learning or Graph Analytics. In-house Kaggle-style data science competitions Team and networking events Monthly Global Best Practice meetings Conferences/Training courses Presentations to Executives 
ScrapedJobID171:
Lead data science modelling and digital twin technology projects and initiatives Collaborate with software teams to integrate and maintain data-driven models Collaborate with domain experts to build data-driven solutions Collaborate with the product team to gather modelling requirements and build proof-of-concept algorithms Conceptualize solutions using sketches, mock-ups, or simple applications. Contribute to maintaining a production-level codebase of models and modelling tools Test and validate models, algorithms, and tooling against real-time client data to ship code at the global scale with confidence Review the work of data science colleagues and provide feedback in a professional matter 2+ years of professional experience working in data science, machine learning, or similar 2+ years of development experience in Python Proven experience working on different processes of the data science lifecycle: pre-processing, modeling, validation, deployment, and others. Experience working with Python libraries (numpy, scikit-learn, pandas) Proven ability for writing code that is maintainable and scalable Working knowledge of version control systems such as Git Post-graduate degree in engineering, physics, computer science, applied mathematics, or related field A link to your Github or portfolio of projects Personal or professional experience working with time-series data Knowledge of forecasting or anomaly detection algorithms applied to time-series data Experience with deep learning and Python libraries for deep learning (tensorflow, keras, pytorch) 
ScrapedJobID172:
Experience in Python – Advance Python Skills, Pam, Reduce, Filter, Zip, Lambda Functions, List, Dictionary Experience in Data Science Libraries – NUMPY, Pandas, RE and Datetime Experience working with Google Cloud, GCP, Parsers, Doc AI etc. Experience in using machine learning tools to train and evaluate natural language processing models Experience working with dataset labelers to prepare labeled datasets for model training and testing Familiarity with AutoML-like tools for model development Familiarity with OCR and NLP Entity Extraction technologies to process Familiarity with ML metrics (F1 score, precision, recall, etc) to evaluate model performance Experience in Evaluation Metrices like R squared, Classification – Confusion matrix, Accuracy, Precision Familiarity with Statistics Techniques like Hypothesis Testing He or she should be able to Collect training datasets from customers Should be able to create document labeling instructions for labelers to label documents / templates for each document type Monitor quality of labeled datasets and resend if required for corrections Run model training and eval runs iteratively, to improve the accuracy of extraction models. Monday to Friday Temporarily due to COVID-19 
ScrapedJobID173:
Collaborate with autonomy teams to understand their pain points and priorities. Research new machine learning problems and models. Derive practical solutions and deploy them on the NuroBot. Have the potential to lead a team on increasingly ambitious new projects. Ph.D. in Computer Science or related fields, or B.S./M.S. in computer science or related fields with 5+ years of relevant experience. Deep understanding of many advanced machine learning techniques and hands-on experience of training deep models. Passionate for researching and solving near-impossible research problems. Strong desire to deploy the solutions into the product. Outstanding communication skills to lead projects with multi-team collaboration. Strong programming skills in C++ or Python. Enthusiastic about self-driving technology and its potential impact on society. Highly cited publications in top conferences in machine learning or related fields. Experience of using large scale machine learning systems in production. Experience of leading a project from conception and experimentation to product-ionization. 
ScrapedJobID174:
Perform descriptive statistical analysis in R, including but not limited to: variability, z-scores, skewness, kurtosis, confidence intervals, coefficients of variation Perform inferential statistical analysis in R, including statistical tests for significance, such as null-hypothesis testing Manipulate, transform, and combine data from multiple R data sets to prepare for multiple study design formats, including cross-sectional, cohort, and case-control studies, and randomized trials Follow detailed study protocols and analysis plans to perform a wide variety of statistical analyses, including: multivariable modeling, multilevel hierarchical analysis, longitudinal designs (including repeated measures), propensity score analysis, prediction modeling, multiple imputation Conducting analysis with basic supervised and unsupervised machine learning methods Prepare tables and patient lists to help research assistants perform manual chart review Produce high quality ad hoc and standardized reports customized per study, using R procedures Prepare reports for end-users, including clinicians, researchers, senior management, and hospital executives Prepare appropriate data visualizations to communicate results Contribute to writing and reviewing manuscripts, especially methods sections Provide support for all data operations including formatting, validating, standardization Perform analyses to ensure the accuracy and completeness of data Validate any output tables, listings or figures generated to ensure accuracy and reliability of analyses Follow and update Standard Operating Procedures to ensure data consistency prior to analyses Maintain high quality coding practices and documentation of coding Efficiently identify and correct syntax and programming logic errors in R code A Master's in Clinical Epidemiology, Biostatistics, Public Health or related discipline At least 3 years of relevant experience Advanced knowledge in inferential statistics and data science, knowledge in clinical research/internal medicine is a plus but not necessary Fully proficient in the use of R and MS Office software (Word, Excel, PowerPoint, Outlook, Internet Explorer, etc.) Experience preparing data for varied statistical methods preferred Demonstrated ability to develop software tools and support analytic operations Experience with multiple study design formats preferred Knowledge of Python and Perl is a plus Expertise using key databases such as SQL is a plus Knowledge in data science in a clinical research setting is a plus Experience with working with large datasets using high-performance clusters is a plus Basic knowledge of HTML, CSS and JavaScript is a plus Excellent attention to detail and proven ability to learn new skills Experience working independently and as part of a team Excellent organizational skills to manage multiple tasks in a timely manner Demonstrated the ability to adapt and manage changing priorities 
ScrapedJobID175:
Maintain an acute awareness of the industry and what the competitors are putting out. Investigate new options for the system from code to core. Coordinate with Senior Technical Leads regarding AI tech. Coordinate with team members to discover the best solution for the clients. Conceptualize new features that we could offer exclusively. Manage R&D Data Science Developers. 2+ years of Experience in Software Development Education: M.tech or Ph.D. in Computer Science/Engineering preferably with a focus on AI. Strong hold on Data structures and Algorithms. Experience with Anaconda/Python/Tensorflow. French Language skills. Hours: 30-40 hours/week. Wage: $85,000 - $100,000/year. 3 Weeks of Vacation. A great environment and the right tools to do great work. 
ScrapedJobID176:
Working with our Product team, educating clients on Wicket’s data architectures, processes, and practices, including data quality, privacy, and security Working with clients to establish custom data architectures and data flows Consult and build reports and dashboards with tools like Elasticsearch and Tableau Our data onboarding process using Python and PostgreSQL Support clients with data management and troubleshooting issues. AWS data architecture design and implementation A strong communicator, who can take on data challenges with enthusiasm. Someone who can engage both technical and non-technical clients Client-facing experience in gathering requirements and presenting data Experience with Python (including Pandas), Javascript, etc. Experience with ETL tools and processes Experience with client data management, including data quality A self-starter who is hungry to learn new technologies and improve your skills Worked on an Agile team Previous knowledge of JSON API (jsonapi.org) and/or JSON Schema (json-schema.org) specifications Experience with data presentation Familiarity with data lakes / unstructured data environments A diploma, certificate, or training program in data science / data management or a degree in computer science or mathematics The opportunity to work remotely from anywhere in Canada Stock options Competitive health benefits (dental, vision, paramedical, prescriptions, out-of-country care) that extend to programs including mental health, employee family assistance, virtual health care services, and Best Doctors An annual professional development stipend and dedicated time for professional development, including quarterly Hack Weeks Life Days for anything requiring time away from work outside of vacation time Company-wide office closures so our team can collectively take time to recharge Highly intentional, progressive practices around feedback, team-building, skills and career development, and peer-to-peer recognition 
ScrapedJobID177:
Transform ML Prototypes into working products that can be used by business units seamlessly. Work with business units to understand integration requirements to ensure models are delivered to meet business needs Productionalize models in our Azure cloud environment, while also maintaining high quality, reusable code Optimize ML models/code developed by Data scientists - for performance and scalability Ensure that all production models and jobs related to the model are working properly in terms of actual execution and scheduling Automate and abstract different repeatable routines that are present in most machine learning tasks Constantly seek performance improvements and decide which ML technologies will be used in production environment Provide support to Data Scientists to design, build, implement, and optimize ML solutions Bachelor’s in computer science, Software Engineering, Statistics, Informatics, Information Systems or another quantitative field Master’s in Computer Science, Software Engineering, Statistics, Informatics, Information Systems or another quantitative field Azure Data science and ML certifications 1 or more years of experience with ML model operationalization 1 years of Machine learning experience, mathematical and statistical knowledge, Python, R, Spark 1 or more years of experience with Azure or any other cloud ML build and implementation Proficiency in R, Python, Spark ML Model building and deployment experience in Cloud Knowledge of scalable, distributed systems using Cloud Providers such as Microsoft Azure will be preferred Experience with using Dockers effectively Experience with Data Bricks and Kubernetes will be an asset Mathematical and statistical knowledge MLOps Experience preferred Familiarity with Tensorflow or Pytorch will be an asset 
ScrapedJobID178:
MobSquad solves the significant and growing technology talent shortage faced by US-based start-ups and scale-ups by enabling its clients to quickly have a turnkey "virtual" Canadian subsidiary. MobSquad ensures technology professionals with US work visa challenges remain working with their current company, but nearshore from Canada. This is accomplished via MobSquad's unique partnership with the Canadian Government, enabling work visas to be issued for technology professionals and their respective families within four to six weeks, and Canadian permanent residency within six to eight months. Additionally, MobSquad has unfettered access to top-tier global technology talent which it relocates to Canada and pairs with American as well as Canadian clients on an exclusive, long-term basis, helping firms not only retain their existing world-class technology talent base, but grow it substantially. We're a Certified B corporation, and have made numerous contributions to charitable organizations, as well as a financial commitment to the Upside Foundation. We believe we are playing a key role in enhancing Canada's innovation economy, and have received financial support from the Government of Canada, Province of Alberta, Province of Nova Scotia, and City of Calgary, to support this ambition. For our workplace culture, we were recognized as the 3rd best place to work in Canada (for a small company) in 2020, as well as recognized specifically for being one of the best workplaces nationally for: inclusion; mental wellness; giving back; youth; and technology. We were also recognized as one of the best start-ups to work for across Canada. For our innovative business model, we have been featured in numerous media outlets including: Asian Pacific Post; BetaKit; Bloomberg; CBC; Global News; Gothamist; International Business Times; MIT Technology Review; Nearshore Americas; Nikkei Asian Review; NPR; The Economic Times of India; The Financial Times; The Globe and Mail; The Information; The New York Times; and The Washington Post. Harvard Business School published a case study on MobSquad last fall, and Harvard Business Review featured us multiple times in an article that appeared on the cover of their November/December 2020 edition. You can learn more about us on our website. You have an advanced degree (M.S. or PhD) in Data Science, Computer Science, Engineering, or a comparable analytical field from an accredited institution You are expert in data mining, machine learning, deep learning, statistical modeling, and data visualization techniques using data-oriented tools and languages such as Python, R, and MATLAB You have over three years of experience or demonstrated fluency in relevant programming languages (Python, R, Scala, Java, C/C++, C#) You have over three years of experience working with SQL (MySQL, SQL Server) as well as NoSQL (Cassandra, Hbase) databases You have experience setting up and using large-scale distributed data-processing frameworks such as Apache Spark and Hadoop MapReduce You have experience working with enterprise-grade cloud computing platforms such as Microsoft Azure, Amazon Web Services, or Google Cloud You have demonstrated ability to develop high-quality code adhering to industry best practices (e.g., code review, unit testing, revision control) You are familiar with designing experiments and collecting data for the purpose of deriving data analytics insights and solutions You have experiencing creating and deploying recommendation and/or predictive models You have work/project history reflective of a self-motivated professional who excels when given open-ended problems and broadly-defined goals, having an innate desire to discover the patterns and relationships in data that can be leveraged to provide business value A full-time position that offers competitive compensation A benefits program delivered through our bespoke digital platform, giving you control, choice, and flexibility. We give you the ability to build your package of benefits covering health (e.g., medical, dental, vision), wellness (e.g., gym, workout gear, massage, transit), and RRSP (retirement savings) A downtown office location with first-rate amenities, surrounded by great restaurants and easily-accessible transit For international candidates, sponsorship for an immediate work permit, expedited permanent residency, and Canadian citizenship within four years 
ScrapedJobID179:
Participate in building models that will scale products with millions of users globally Partner with cross-functional teams including engineering, UX/UI, sales, marketing, and customer success to build growth strategies and manage complex, cross-functional projects Analyze diverse sources of data to devise actionable insights Deep understanding of the B2C consumer markets and core metrics in the markets Work with Product Managers to develop, execute, and test different growth experiments that have a significant impact on conversion across all funnels (acquisition, retention, engagement, and monetization) Undergraduate degree in quantitative fields including Engineering, Math, Statistics from top tier institute or relevant field Candidate must have the ability to independently build data pipelines, develop data models, and recommend growth strategies to product and executive teams 1 - 5 years of previous experience in building ETLs, analyzing consumer insights, creating metrics Experience with SQL and/or NoSQL database Experience with data visualization, dashboards, and reports Experience with scripting languages such as Python Eager to learn new programming languages and tools when needed Strong desire to work in a fast-paced startup environment Obsessive around moving critical business metrics and products Strong communication skills, attention to detail, and ability to manage multiple projects and stakeholders 
ScrapedJobID180:
Design and code highly scalable, machine learning applications processing large volumes of image and video data. Develop and implement state of the art algorithms for face detection, face recognition, face clustering and liveness. Measure progress against industry standard benchmarks such as WiderFace, COCO, NIST-FRVT. Collaborate with others in crafting and implementing your technical vision. Follow agile processes with a focus on delivering production-ready testable code in small iterations. Participate in the entire development lifecycle, from concept to release. Participate in all phases of quality assurance and defect resolution. PhD in Computer Science or related field with research in machine learning. 3+ years of experience building machine learning or AI systems. OR MSc in Computer Science or related field and 10 years software engineering experience in a related advanced technology environment. Expert skills with machine learning software packages (e.g., PyTorch, MXNet, Caffe, scikit-learn, TensorFlow). Deep understanding of mathematical foundations of Machine Learning algorithms. Experience working with large datasets. Excellent problem-solving, analytical and interpersonal skills. Ability to work autonomously and willingness to roll up one’s sleeves to get the job done. Polished communication style, both oral and written, and a comfort interfacing with various levels across the organization, with both technical and non-technical audiences. Ability to manage multiple, competing priorities simultaneously. A true passion for technology and thoughtful delivery of next-generation capabilities. Solid knowledge in state-of-art deep learning models and optimization methods. Experience working with different types of Generative Adversarial Networks (Style, Cycle, etc.). Experience working with one of the major cloud services: AWS, GCP or Azure. Prior computer vision or image processing experience. Ability to independently conduct literature survey, find cutting edge heuristics or algorithms, and implement them in an engineering environment. Experience with building Operations Research/Machine Learning algorithms and productionizing them at scale in a distributed computation environment. Publication in peer-reviewed journals or conferences is a plus. Competitive salary with meaningful equity compensation and excellent benefits. The opportunity to work with a group of highly talented and equally nice people while making a huge impact. Work-life flexibility - we value your contributions above all. A professional environment with a focus on teamwork. 
ScrapedJobID181:
Utilizes programming and analytical tools, including programs like Tableau, Microsoft Power BI, VBA or similar relational database tools to formulate models and/or extract insights. Well versed in knowledge of creating algorithms, identifying patterns and insights from structured and unstructured data sets utilizing graphs, trees and/or other data representation techniques as required Performs trend analysis, insights, and outlier identification of energy-related data Supports ongoing data review of data from multiple energy, project, suitability, operations, and environment team sources to ensure ongoing data integrity Develops data structures and pipelines to organize, collect, cleanse, and standardize data in order to generate insights and addresses reporting needs Coordinates the delivery of energy-related client deliverables, generate data upon request and prepare various reports Defines data requirements and gathers and validates information, using judgment and statistical tests Identifies and troubleshoots data integration and integrity issues in cooperation with the appropriate business units Performs ad-hoc, strategic analysis of structured and unstructured data across multiple data sources, reflecting project costs, greenhouse gas savings and utility related data Organizes data and ongoing preparation and development of various sustainability focused reports as needed including but not limited to water, materials and energy metrics Works with internal BGIS team members & PSPC key contacts to coordinate data management, sharing and integration Supports energy team members in the development and design of new tools, databases and process for energy and project management Supports operation teams in providing reports to fulfill project, compliance, and contractual requirements Other Duties as Required Bachelor degree in computer science, math, engineering, data science, or related Equivalent or similar college diploma with significant job experience will also be considered More than one year, up to 3 years of job related experience Management and organization of large data sets using MS Excel based software Ability to identify and troubleshoots data integration and integrity issues in cooperation with the appropriate business units Proficiency in MS Office applications with strong Excel skills. VBA knowledge, database and programming knowledge Experience with visualization software (Microsoft PowerBI, Tableau) and use of DAX (Data Analysis Expressions). Ability to define work flows & data requirements, gather, validate and present information; using judgment and statistical tests. Understanding of mathematical trend analysis such as regression models and cumulative sum Identifies opportunities to maximize data usage, applying modeling and optimization methods to develop new strategies and improve business performance. Problem solving and solution identification and development abilities Strong administrative, organizational and multi-tasking abilities with a strong attention to detail Creative, innovative, out-of-the-box thinker Effective verbal and written communication and interpersonal skills with proven ability to work collaboratively with others with a proven ability to influence and persuade others Would be considered an asset:
Technical experience in software development, statistical analysis, data engineering and data visualization related work.
Experience related to building operation and utility management experience
Ability to develop data structures and pipelines to organize, collect, cleanse, and standardize data in order to generate insights and addresses reporting needs.
A passion for Energy and GHG reducing initiatives
A history of analytical rigor, judgment, and ability to present a comprehensive 'data story' to multiple levels of project investments and GHG savings
A history of establishing protocols and standards for user input data and working with teams to improve consistency of data quality
Experience in justification of sustainability investments through financial metrics e.g. NPV, ROI, SPB, Financial background
Experience of Python, R, SAS, SQL, Oracle software
Bilingual: French and English, Written and spoken Technical experience in software development, statistical analysis, data engineering and data visualization related work. Experience related to building operation and utility management experience Ability to develop data structures and pipelines to organize, collect, cleanse, and standardize data in order to generate insights and addresses reporting needs. A passion for Energy and GHG reducing initiatives A history of analytical rigor, judgment, and ability to present a comprehensive 'data story' to multiple levels of project investments and GHG savings A history of establishing protocols and standards for user input data and working with teams to improve consistency of data quality Experience in justification of sustainability investments through financial metrics e.g. NPV, ROI, SPB, Financial background Experience of Python, R, SAS, SQL, Oracle software Bilingual: French and English, Written and spoken None required 
ScrapedJobID182:
MS degree / PhD degree in a quantitative discipline (eg. Computer Eng., Computer Science, Stats, Physics). Undergraduate, if has taken courses related to the field. Applied experience with machine learning, data science and solving problems at scale Ability to communicate business outcomes and recommendations from analysis verbally and written, ability to present results coherently Ability to develop confidently in Python as the majority of our team is using it. We need people with a passion for software, who can read and understand complicated codebases. Confident in extracting and manipulating data from our various SQL and NoSQL data stores and storage frameworks. Practical experience with Multivariate forecasting, optimization, online training. Experience working on a Logistics project Experience working with pricing algorithms Experience in retail in similar markets to Just-Eat takeaway Experience working in agile teams, with code reviews and source control Comfortable with big data stores (Google BigQuery, Amazon Datastores) and tools (including dynamoDB, elasticsearch, S3, SQS, Kinesis) or Spark / Hadoop / Kafka. 
ScrapedJobID183:
Working with computer vision or natural language processing problems including image classification, object segmentation, image registration, text classification, named entity recognition. Demonstrating an in-depth understanding of standard supervised and unsupervised machine learning methods. Researching state-of-the-art methods for a given task. Implementing and improving upon these techniques to provide the best possible solution. Working with medical image or text data including X-ray, CT, MRI, Ultrasound or HL7 reports. A passion for the healthcare industry as well as novel technologies such as AI and advanced computing. Minimum Master’s degree in Computer Science, Biomedical Engineering, Electrical Engineering, Engineering Physics, Mathematics, Statistics, or another technical discipline. Strong background in fundamental machine learning including classification, regression, clustering etc. In addition, a good background with probability and statistics is required. Experience working with computer vision or natural language processing projects. Strong programming skills with Python. Experience of machine learning, scientific computing, and data analysis Python packages (e.g., Tensorflow, PyTorch, Numpy, Scipy, Scikit-learn, Pandas). Experience with data exploration, data cleaning and data processing techniques. Experience with state-of-the-art deep neural network-based techniques. Demonstrated strong analytical and decision-making skills. Excellent project management skills and the ability to adapt to a fast-paced, Agile environment with changing priorities. Strong communication and critical thinking skills. Excellent people and management skills in interacting with staff, colleagues, cross-functional teams and third parties. An eagerness to learn about new trends, tools, and technologies, and to continually consider how they will influence our products. Openness to receiving and giving feedback to elevate team performance. 
ScrapedJobID184:
Ideate, prototype, and productionize the machine learning algorithms that power Coursera’s products, especially our recommendation engine for online degree programs (e.g., degree recruitment engine, cohort forecasting, real-time recommendation, email bandits ) Design, deploy and scale end-to-end machine learning / deep learning pipelines and models with AWS cloud services Distill insights from complex data and/or data product results; communicate findings clearly to both technical and non-technical audiences Partner with Product Managers and Engineers to identify and articulate opportunities, build efficient and scalable ML solutions, and proactively drive data product adoption Extend existing ML libraries and frameworks 2+ years of research and/or industry experience Solid background in applied math, computer science, statistics, or related technical field Deep skills in two or more of: applied statistics, optimization, NLP, predictive modeling, recommender systems, ranking systems, reinforcement learning Strong computational skills; ability to implement data science pipelines and applications at scale using a general programming language (e.g, Python, Java, Scala) Proficient with relational databases and SQL Strong project management and cross-functional collaboration skills Excellent problem solving, critical thinking, analytical and interpersonal skills Passion for Coursera’s mission 2+ years of work experience in deployment and scaling of Machine Learning and Deep Learning algorithms on AWS cloud services (Sagemaker, Lambda, Cloudwatch, etc.) Experience with model lifecycle management, testable code and shipping code into production Proficient with large-scale distributed databases (e.g., Spark) Experience with online controlled experimentation MS or above Recommender Systems Machine Learning Sentiment Analysis with Deep Learning Using BERT 
ScrapedJobID185:
Analyze Sharethrough data to discover patterns, abnormalities, and increased revenue opportunities Present findings to key leadership to influence product roadmaps Designing and developing algorithms to track important metrics in real time to feed into ML models that power our platform Designing and developing machine learning models that classify content, predict behavior, and forecast supply and demand equilibriums Work closely with business leadership to integrate data into every part of the product 5+ years of experience working in an analytics organization Degree in Statistics, Computer Science, Econometrics, or similar domain Competent performing statistical analysis using a scripting language (Python, R, Julia) Proficient with SQL Able to create intuitive and readable dashboards using visualization tools (Tableau, Looker, etc.) Strong familiarity with experimental design Comfortable pairing with product Experience or familiarity with the adtech ecosystem Experience working closely with Product teams Comfortable collaborating with leadership to distill down high level business goals and provide data driven recommendations Experience with machine learning techniques and how they are applied in production systems Competitive compensation packages Generous group health insurance plan Access to the virtual healthcare platform Dialogue Access to the company's stock option plan 16 days of vacation per year, which increases with seniority at the company 3 paid Caring days 1 paid volunteer day Offices closed during the holidays Wellness allocation of $840 per year (for gym memberships, sportswear, etc.). In-house training programs on our company and industry Encouragement and funding of continuing education and training Very active social committee and free online sports classes Access to a tool that measures your engagement and job satisfaction anonymously Pairing with a buddy for your first 6 months Advantageous referral program Inclusive, inspiring, and dynamic work environment Casual dress code Work from home and flexible hours And more! 
ScrapedJobID186:
Monitor and deploy within the production data science environment using best practices, pipeline controls, and clear documentation around intent and usage of model or algorithm. Research, design, and construct predictive models to enhance understanding of Moneris core business and adjacent opportunities. Design and implement solutions that can measurably improve business performance in the business context. Partner with data engineering and data analytics teams to ensure that data structures and data pipeline enhances data science applications and shortens development cycle. Use robust statistical techniques to increase accuracy for existing projects and create solutions for adoption in business context knowingly increase performance. Lead in tuning and refining the deployment of models in a variety of environments ensuring that the business context matches the performance of the model and that the cost of running aligns with the need. Collaborate with different functional teams to promote structured pipeline deployment of data science to ensure consistency, security, resiliency of the system. Collaborate with business teams in the centre of excellence on data science sharing best practice, new approaches, and successes Actively build business and technical understanding to enhance solution development and create opportunities to enhance business processes and overall performance. Masters degree in in a quantitative field required, or equivalent work experience. PhD considered an asset Experience in Databricks Experience in Spark, Pyspark, SQL, Python Experience in Azure Experience in Power BI, Tableau Experience in Machine Learning methodologies and has experience building production grade solutions Minimum 5 years experience in analytics, data science, computer engineering, database management Proficient in multiple programming languages and can code with no oversight. Experience in production data science pipeline management and deployment of models in a production environment. Highly proficient in leading large scale projects or significant project steps and communicating progress/approach with technical/non-technical peers/clients and leaders. 
ScrapedJobID187:
Designing machine learning models for analyzing unstructured medical data including image and text. In addition to machine learning model development, perform bench testing on the model, analyzing and reporting on the results. Demonstrating a fair understanding of standard supervised and unsupervised machine learning methods. Researching state-of-the-art methods for a given task. Implementing and improving upon these techniques to provide the best possible solution. A passion for the healthcare industry as well as novel technologies such as AI and advanced computing. MS/PhD student in Computer Science, Electrical Engineering, Biomedical Engineering, Engineering Physics, Mathematics, or other related discipline. You should be eligible for the MITACS program. Strong knowledge with basic machine learning techniques including classification, regression, clustering etc. Hands-on experience with state-of-the-art deep neural network-based techniques in computer vision or natural language processing problem Experience of machine learning, scientific computing, and data analysis Python packages (e.g., Tensorflow, PyTorch, Numpy, Scipy, Scikit-learn, Pandas) Excellent project management skills and the ability to adapt to a fast-paced, Agile environment with changing priorities. Strong communication and critical thinking skills. Excellent people and management skills in interacting with staff, colleagues, cross-functional teams and third parties. An eagerness to learn about new trends, tools, and technologies, and to continually consider how they will influence our products. Openness to receiving and giving feedback to elevate team performance. 
ScrapedJobID188:
Help to identify opportunities for machine learning in our products Own a machine learning system Query our petabyte-scale database to extract game data Conduct exploratory data analysis, hypothesis testing, and feature engineering Build and evaluate machine learning models to improve in-game features and boost product metrics Communicate project goals, progress, and outcomes with production, design, and engineering teams Perform tests to evaluate the ROI/lift of machine learning models Work with engineers to deploy models (batch predictions, microservices, and monitoring) Master’s Degree in a STEM discipline, preferably thesis-based 2+ years of industry experience in data science, preferably in large scale client-facing software/web/application companies Professional level Python programming skills (NumPy, pandas) Experience deploying machine learning models into production Proficient with machine learning libraries: eg. sci-kit-learn, TensorFlow, PyTorch Strong SQL skills (joins, subqueries, analytic functions) Can drive projects independently, maneuver through imperfect data or experimentation, and pivot goals or targets with ease Communicates in a clear, concise, and professional manner with staff at all levels; justifies decisions, and achieves peer consent Software/ML or data engineering experience PhD in a STEM discipline Proficient in Docker, Airflow, Bigquery, Tableau, Github Game industry experience Experience with Pytorch, Tensorflow, Other Deep Learning Libraries Experience with recommendation systems Background in advanced statistics Experience working with Google Cloud Platform, or other cloud-based machine learning platform Evidence of continued learning Active Github or Kaggle Profile 
ScrapedJobID189:
Own analytical frameworks that guide the product roadmap Design rigorous experiments and interpret results to draw detailed and actionable conclusions Develop statistical models to extract trends, measure results, and predict future performance of our product Build simulations to project impact of various product and policy interventions Enable objective decision making across the company by democratizing data through dashboards and other analytical tools Use expertise in causal inference, machine learning, complex systems modeling, behavioral decision theory etc. to shape the future of Instacart Present findings in a compelling way to influence Instacart's leadership 5+ years experience working in a quantitative role at a product company or a research organization Ability to run rigorous experiments and come up with scientifically sound recommendations Ability to write complex, efficient, and eloquent SQL queries to extract data Ability to write efficient and eloquent code in Python or R A desire to build and improve consumer software products Ability to translate business needs into analytical frameworks Eagerness to learn, flexibility to pivot when needed, savviness to navigate and thrive in a dynamic environment, and a growth mindset needed to build a successful team and company 
ScrapedJobID190:
Answering business-related questions through exploratory data analyses and ad-hoc reporting that drives engagement, retention, and monetization Building data visualizations used by the Product and Leadership teams Developing new metrics and player cohorts to unlock insights into player behavior Continually trying to improve our A/B test analysis process through new tooling and automation Deep diving into user behavior to unlock value for the product team Collaborating across data teams in the organization to improve data-driven decision-making and elevate Uken’s use of data science. 2 years writing complex queries in SQL preferably Redshift Attention to detail and proven organization and analytical skills Ability to communicate and present information clearly Proficiency in Python and/or statistical modeling An appetite to learn, grow and take on increasingly more responsibility A desire to answer questions that drive business outcomes Passion/knowledge of the mobile gaming industry Previous experience at a startup or mobile game/app company Degree in statistics, economics, math, or a related field Experience in a Product Management / Data Analyst role Proficiency in Scala Work from anywhere - remote and in-office options Join a world class team eager to learn something new everyday You’ll be equipped with high-end equipment Competitive compensation and benefits Stock Options, Group RRSP and employer matching Generous allowances and perks Uken social nights including mixers, game night, and more - we take entertainment seriously! Convenient location in the heart of downtown Toronto at Front & John St. 
ScrapedJobID191:
Implement currently available time series forecasting models Develop customized forecasting algorithms required by specifications of each project Prototype, simulate and benchmark accuracy of algorithms Develops production-ready codes in R Works with main stakeholders including but not limited to: Account Executives, Management, Project Managers and Consulting Teams Performs various other duties as delegated or assigned. Graduate degree in a Statistics, Math Computer Science or Engineering program; Proficient in time series analysis and forecasting Fundamental knowledge of supervised and unsupervised Machine Learning Experience with data preprocessing, anomaly/outlier detection Advanced programming skills in R language is mandatory; Knowledge of pharmaceutical industry is an asset; Capability to adapt in fast changing environment and eager to learn The ability to travel and work outside regular business hours as required; Proven, motivated self-starter with the ability to lead by example and approach and solve business problems; Experience working in cross-functional teams with the agility to learn new software applications and technologies; Demonstrated time management, problem solving and decision making competencies; Ability to work autonomously and in teams to effectively prioritize multiple projects and associated deliverables; Proven excellent communication, including presentation, hands on analytical with business savviness and customer relationship abilities; Proven ability to comprehend, analyze and research problems of a complex nature, make decisions and/or present recommendations; 
ScrapedJobID192:
Building, implementing and supporting Microsoft Power BI solutions Assist in the creation of a framework for how data, reports and dashboards are managed and delivered Create data visualizations, dashboards, and reports to present using Microsoft Power BI Convert existing datasets/reports into SQL Server/Analysis Services/Power BI Solutions Contribute reporting and business intelligence expertise to special projects as required Create and maintain business intelligence tools and reports, including physical data models and dimensional analysis Build a data pipeline to automate business processes and synchronize data between applications Assist stakeholders to determine business needs and requirements for BI, including the development of performance metrics and KPIs Design, code, test and aggregate results from SQL queries to provide information to stakeholders Analyze data to provide recommendations for future actions to business stakeholders Foster a data-driven culture through the adoption of data management best practices Partner with design, engineering and construction teams to gain cost and schedule efficiencies Leverage technology to enhance operational performance and productivity 2+ years hands on experience with Microsoft Power BI and Data Analysis 2+ years of technical experience with SQL Server is preferred Undergraduate degree in related field (computer science, engineering, mathematics, or equivalent) Microsoft Power BI certification is an asset Microsoft Azure Data Scientist associate is an asset Detailed knowledge of BI Best Practices/Methodologies, relational structures, dimensional data modeling, structured query language (SQL) skills, data warehouse and reporting techniques Working knowledge of coding languages, including C+, VBA, R and Python Familiarity with Workato Ability to understand and create complicated Data Analysis Expressions (DAX) language expressions and familiarity with Power Query Proven experience with using data visualization techniques to create meaningful reports and dashboards Interest in the Architecture, Engineering and Construction industries Working knowledge of Power Apps 
ScrapedJobID193:
Maintain an acute awareness of the industry and what the competitors are putting out. Investigate new options for the system. Coordinate with Senior R&D R&D regarding tech. Coordinate with team members to discover the best solution for the clients. Conceptualize new features that we could offer exclusively. 1+ years of Experience in Software Development Education: BSc or M.tech in Computer Science/Engineering preferably with a focus on AI. Strong hold on Data structures and Algorithms. Experience with Anaconda/Python/Tensorflow. French Language skills. Hours: 30-40 hours/week. Wage: $70,000 - $80,000/year. 2 Weeks of Vacation. A great environment and the right tools to do great work. 
ScrapedJobID194:
Lead broad analytics projects core to Yelp’s business, communicate key insights to decision makers, and help product leaders uncover new opportunities. Manage tight deadlines and quickly iterate analyses to answer unstructured business questions, deliver actionable learnings, and make strategic recommendations. Work cross-functionally with product and engineering to define, log, and track Yelp’s key product metrics and opportunity size new initiatives. Generate dashboards and automate reports that empower teams across the organization to make data-driven decisions. Grow and maintain impactful relationships with stakeholders of both technical and non technical backgrounds with clear and frequent communication. Think critically about experimental design and advocate for thoughtful experimentation. BA/BS or graduate degree in a quantitative field (mathematics, statistics, economics etc.) Ideally 3+ years of quantitative industry experience, ideally within the consumer product space Excellent SQL skills, fluency in Python, and experience with at least one statistical package (R, Pandas/NumPy/SciPy/matplotlib, Stata, Matlab). An eye for compelling data visualization and extensive experience with related tools (Tableau, Mode, Looker). Solid understanding of statistical inference, experimental design and analytic bias. Familiarity with financial modeling and advanced statistics (regression, non parametrics, predictive modeling) a plus. 
ScrapedJobID195:
Post-secondary education in a related field. Must have at least 1 year of experience with Deep Learning frameworks like PyTorch or TensorFlow. Must have at least 1-3 years of experience with C/C++, Python coding or other high-level languages. A strong publication record or alternative relevant innovation experience. 
ScrapedJobID196:
Provide the Data Intelligence and Governance team with data analyses from researching systems and processes, profiling data via SQL queries, and validating data quality requirements. Identify and partner with data stewardship across the organization to operationalize the Data Governance framework. Champion data governance initiatives by promoting ideas into action; including developing and implementing data quality rules, communication, and adoption strategy. Oversee data quality management and data quality issue prioritization. Assist in developing data governance policies, processes, and documentation. Support corporate data quality initiatives through recommendation for solutions and leadership around data validation. Analyze and understand corporate data across data domains, on both source and target levels. Collaborate with other data analysts from cross-functional teams to address data quality issues and educate data stewardship on data governance principles. Identify new opportunities for data governance continually. You are proficient in data analysis (preferably within software development, data delivery, and data analytics settings). Have a post-secondary degree in Data Science, Computing, Mathematics or Healthcare Informatics (preferably master’s level). Have 5+ years of data analysis experience with increasing responsibility. Are highly knowledgeable in databases and adept in SQL. Have hands-on experience in data visualization tools such as PowerBI. Are experienced with CRM tools such as SalesForce and NetSuite. Are exceptional at rapport building and creative problem solving. Have strong organizational, planning, and prioritization skills. Are goal-oriented, positive, a self-starter, with strong analytical skills. Are a data detective with excellent communication, known for collaborating and your ability to communicate complex data findings to various audiences. Demonstrate a proven track record of delivering results while guiding and facilitating business partners in solving data quality issues. Able to work independently. 
ScrapedJobID197:

ScrapedJobID198:
Write SQL queries to gather real-time data on our recruiting pipeline, so that we can provide our data science, marketing, finance, and people teams with evidence to support key decisions and major company-wide initiatives Lead data quality and issue investigations for HR/recruiting data, and collaborate with stakeholders across the company to fix them Assist with the automation of the creation, data validation, and distribution of mission critical reports across the company Work with data science team to build data models within our business intelligence tools (Looker and Tableau) 0-2 years of experience working at a finance or technology company in an analytical function. Proficiency in writing SQL Prior experience in working with Python a plus. Strong Excel skills, prior experience working with VBA a plus Familiarity with some kind of business intelligence or data visualization tool (Looker, Tableau, DOMO, PowerBI, etc.) You have the ability to recognize data patterns and understand when a particular field or table is not in line with business expectations. 
ScrapedJobID199:
Conducting research to identify data sources and data products for specific client requirements Building connectors to data sources, QA-ing and wrangling datasets to conform to ThinkData standards Managing our large open and public data catalog by connecting to new sources as they become available and monitoring existing connections. 
ScrapedJobID200:
Collaborate with business partners to develop innovative solutions to meet objectives utilizing cutting edge techniques and tools. Effectively communicate the analytics approach and how it will meet and address objectives to business partners. Advocate and educate on the value of data-driven decision making; focus on the “how and why” of solutioning. Lead analytic approaches; integrate solutions collaboratively into applications and tools with data engineers, business leads, analysts and developers. Create repeatable, interpretable, dynamic and scalable models that are seamlessly incorporated into analytic data products. Engineer features by using your business acumen to find new ways to combine disparate internal and external data sources. Share your passion for Data Science with the broader enterprise community; identify and develop long-term processes, frameworks, tools, methods and standards. Collaborate, coach, and learn with a growing team of experienced Data Scientists. Stay connected with external sources of ideas through conferences and community engagements Bachelors Degree in Data Science, Computer Science, or related field 4+ years of Data Science and Machine Learning experience required Proficiency in Python or R. Ability to write complex SQL queries Proficiency with Machine Learning concepts and modeling techniques to solve problems such as clustering, classification, regression, anomaly detection, simulation and optimization problems on large scale data sets. Ability to implement ML best practices for the entire Data Science lifecycle Ability to apply various analytical models to business use cases (NLP, Supervised, Un-Supervised, Neural Nets, etc.) Exceptional communication and collaboration skills to understand business partner needs and deliver solutions Bias for action, with the ability to deliver outstanding results through task prioritization and time management Experience with data visualization tools — Tableau, Power BI, etc. preferred 
ScrapedJobID201:
Research, analyze, and evaluate a wide variety of issues in occupational health and safety, management oversight, internal operations and disability management Extract and transform data from a variety of databases using tools such as SQL, Python, PowerBI, and Tableau Identify industry trends, emerging issues, and opportunities of business significance to WorkSafeBC Develop and improve complex analytical models (e.g. for evaluation, prediction, classification, prescription) Provide ongoing consultation, decision support, analytics, and business intelligence to various WorkSafeBC department leads Present research information to audiences of varying levels of expertise that include detailed findings, implications, and recommendations Independently plan, prioritize, schedule, monitor, and complete complex multi-task workload projects and activities to consistently meet deadlines Clearly and concisely present analysis results and recommendations both in written reports and verbally to individuals and groups of varying levels of expertise Identify significant information from a variety of sources, collect and analyze data to develop, assess, and establish meaningful ways of grouping and transforming data to draw conclusions Interpret, evaluate, infer, and explain business data or concepts and develop alternatives and recommendations appropriate for the business Apply quantitative and qualitative research methods (e.g. statistical analyses, data modeling, text mining, machine learning, predictive analytics, sampling, survey and questionnaire design). Write scripts and formulas for extracting, compiling and, displaying information A master’s degree in a quantitative-related discipline such as statistics/mathematics, operations research, big data, data science, computer science, information technology, finance, business, management information systems, or engineering. A minimum of 12 months of recent directly related experience within five years in business intelligence, statistical analysis, strategic analysis, and/or advanced analytics. 
ScrapedJobID202:
Work cross functionally to translate business problems into ones that can be solved and informed by data analysis Have curiosity and apply analytical skills to dive deep into data to find key insights that impact the business. Develop models of usage, user behavior & business behavior to make recommendations and influence the product road map. Work with other teams across Microsoft to develop key metrics to achieve business outcomes. Be a champion of AB testing. Design, execute and analyze experiments to prove product change attribution. Utilize tools like Data Bricks, R, Python, SQL to execute analyses One plus year exhibiting a strong passion & understanding for the need to deliver the right business impact by working with stakeholders to turn business problems into data analysis questions and unearthing deep insights from data. Have a track record of innovative thinking and problem-solving skills using Big Data. Be self-driven and show the ability to deliver on ambiguous projects with incomplete data. Understanding of the practical uses of statistics (i.e. experimentation, sampling) Professional experience with large-scale computing systems like Hadoop, MapReduce, and/or similar systems. Strong skills in SQL, R, Python, Databricks, or related tools for large-scale analysis. Excellent communications & interpersonal skills. Ability to convince other strong personalities of their ideas and communicate complex analysis & insights to a non-technical audience. 
ScrapedJobID203:
Recognized as a technical leader with an innate ability to develop and motivate team members, as well as positively influence change Passion for data and new technologies Acknowledged for your strong general knowledge of the overall data analysis technology ecosystem Known for your deep specific knowledge in one or two specific data analysis technology stacks Confident in the use of Agile, iterative, Lean product lifecycles Commended for your ability to communicate clearly and collaborate with a broad array of stakeholders at all levels Knack for collaboration, openly contributing ideas within a highly cross-functional team Willingness to do both Development and Operations Confident with your ability to articulate an end-to-end customer experience Skilled in assessing and articulating the financial impact of a customer experience Senior level experience of 5+ years within the industry Have a Bachelor's degree in Engineering or Computer Science Database bingo: SQL; noSQL; Hadoop; Oracle; MongoDB; ETL bingo: ELK; DOMO; Tableau; Splunk; Programming bingo: JAVA; Python; UNIX; Selenium; Cucumber; Process bingo: Agile; Scrum; Kanban Other tools: Slack; Assembla; Google Suite; Telecom knowledge 
ScrapedJobID204:
Analyzing data using statistical techniques and providing reports Identifying, analyzing, and interpreting complex data sets using SQL, Excel, and visualization tools.Designing custom data extracts. Migrating data to enterprise applications. Identifying process improvement opportunities Advanced skills in Microsoft Excel Practical experience using data visualization tools Ability to write, analyze, and debug complex SQL queries B.S. degree in Computer Science, Business, or similar. M.S. in Computer Science or similar 2+ years of experience working in a data science or data analyst role 
ScrapedJobID205:
Conducting research to identify data sources and data products for specific client requirements Ingesting and enriching the data on the platform Building connectors to data sources, QA-ing and wrangling datasets to conform to ThinkData standards Design and build data products. You are currently enrolled in or have a relevant degree such as Statistics or Mathematics or Data Science, and have working knowledge of Python and/or Ruby. Wrangle data. You are familiar with data wrangling using scripts and a variety of tools, such as Pandas, OpenRefine or similar. Collaborate. You can work as part of the team, or work autonomously. You are adaptable, flexible, and able to adjust to a dynamic startup environment. Previous experience working at a startup environment is an asset Evolve with us. The landscape is being built under our feet as we move forward, so we need people who can channel their passion, learn quickly, and navigate the unknown at top speed. Must be eligible to work in Canada Competitive compensation. You will earn a salary commensurate with your experience. Career development. We believe in informal mentorship and formal training. You will work closely with our VP of Data, and have the opportunity to participate in lunch-and-learn workshops. The opportunity to make a mark. We are growing. And with that growth comes the need for people with insights to help us scale. You will have the opportunity to apply your insights, try different methods and introduce best practices, building out a framework for our Data Team. An amazing team. Collaboration across teams is paramount to our success and our culture as we scale. At ThinkData Works, we prioritize mental and physical wellness. We believe in balance as we grow. We play Smash Bros, pool, and board games. We know how to have fun and enjoy spending some extra time together. 
ScrapedJobID206:
As a Transformation Office leader, own and communicate the Data Modernization program’s vision and roadmap. Accountable to establish and nurture the leadership structure to execute and deliver value towards the associated benefits and KPIs. In close collaboration with IT and Business leaders, enable a culture that manages data as an enterprise asset. Standardize the use and governance of data and analytics in support of the enterprise's business strategy in collaboration with key internal stakeholders (marketing, risk, etc.). This includes the governance of data and algorithms used for analysis, analytical applications and automated decision making. Bring thought leadership throughout the execution of the Digital Transformation, advising BDC on how to maximize the value of data (internal and external, structured, and unstructured) to better understand and service the Canadian entrepreneurs, make better decisions (risk, marketing, finance, etc.) and improve efficiency (through the eventual leverage of data with AA/AI). Establish AA/AI capabilities for better business decisions, enhance client insights, engagement and increase data reliability with single source of truth. Enhance BI Reporting & Visualization capabilities and enable users to efficiently and reliably perform analytics and reporting. Organize and lead a data and analytics governance council to provide executive sponsorship and oversight. With the IT team, oversee the integration and staging of data, the development and maintenance of the data lakes, data warehouse and data marts, for use by analysts throughout the organization. Identify new kinds, types and sources of data to drive business innovation throughout the organization. Define processes for the effective, integrated introduction of new data. Bachelor's or master's degree in business administration or systems, computer science/engineering, data science, information science or related field, or equivalent work experience Extensive management experience in a senior leadership role related to Data, Analytics and Enterprise Architecture and Business Strategy Strong stakeholder’s management capability Led major data and/or BI related migration project(s)/program(s) will be considered an asset Five or more years of leadership experience in leading cross-functional teams and large enterprise programs, operating and influencing effectively across the organization and within complex contexts Agile delivery and coaching experience, a strong asset Excellent business acumen, interpersonal and stakeholder management skills Proven data literacy — the ability to describe business use cases/outcomes, data sources and management concepts, and analytical approaches/options Outstanding problem-solving abilities Team player Broad experience in multiple domain areas, such as data warehousing, business intelligence (BI), data governance, data architecture, etc. Banking and Financial Services experience is a strong asset Bilingualism in French and English is a strong asset 
ScrapedJobID207:
Research: Discover solutions to unique data science challenges while satisfying business needs Develop and Implement full solutions
Load and clean the data
Prepare and train the model
Deploy, monitor and maintain the solution Load and clean the data Prepare and train the model Deploy, monitor and maintain the solution PhD in a quantitative STEM field with an important data analysis component OR Msc. in a quantitative STEM field with 3+ years of experience as a Data Scientist Strong programming skills in Python and experience with Machine Learning tools (numpy, scipy,scikit-learn, pandas, pytorch/ tensorflow, ...) Strong knowledge of data science algorithms and their limitations (execution speed, memory considerations, etc) Experience dealing with very large datasets Familiarity with database environments (including distributed big data solutions) and functional SQL knowledge Experience with UNIX/Linux environments Good team player and open to give and receive constructive feedback Ability to communicate clearly to non-experts Understanding and/or familiarity with non-interpreted (compiled) programming languages Experience with cloud providers (AWS, GCP, Azure) Data science side projects or Kaggle competitions 
ScrapedJobID208:
Working closely with other data scientists and developers in building and deploying various machine learning models for Global Relay's customers Being a subject matter expert on current machine translation (MT) techniques Interacting with product managers on enhancements to our core products Executing all steps in the data science process from understanding business requirements to deploying models Producing reports detailing model performance 5+ years of experience with solving machine learning problems Experience working with very large data sets in an enterprise-wide application environment Python and Bash experience Knowledge of common machine learning libraries such as: Scikit-learn, TensorFlow, PyTorch, NLTK, SpaCy Understand and appreciate tradeoffs of different methods for MT An understanding of different neural network architectures as applied to MT such as: Transformers, LSTMs, RNNs and CNNs Strong organizational and communication skills MSc or PhD in a STEM or Linguistics subject Data collection and cleaning experience Data engineering skills Machine learning experience in different modalities Experience working with explainable and interpretable models Experience with:
Specialized machine learning libraries like: Seq2Seq, Nemo, Fairseq
Many-to-Many multilingual translation
Multi-task / Transfer-learning
Model optimization: pruning, distillation, quantization
Kubernetes and micro services
Working in an agile development environment Specialized machine learning libraries like: Seq2Seq, Nemo, Fairseq Many-to-Many multilingual translation Multi-task / Transfer-learning Model optimization: pruning, distillation, quantization Kubernetes and micro services Working in an agile development environment 
ScrapedJobID209:
Develop, train, tune and integrate Machine Learning models Test and implement different A.I. technologies to address business needs Lead MLOps design and development Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions. Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies. Assess the effectiveness and accuracy of new data sources and data gathering techniques. Develop custom data models and algorithms to apply to data sets. Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes. Develop company A/B testing framework and test model quality. Coordinate with different functional teams to implement models and monitor outcomes. Develop processes and tools to monitor and analyze model performance and data accuracy. Masters in Statistics, Mathematics, Computer Science or another quantitative field Experience querying databases and using statistical computer languages: R, Python, SLQ, etc. Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc. Excellent communication skills, both written and verbal Experience in project management methodologies Work independently as well as in a team-oriented environment Strong analytical skills to solve and model complex business requirements Places emphasis on client satisfaction and clearly communicate solutions to both technical and non-technical team members and other staffs Demonstrated ability for creativity and innovative problem solving Able to multi-task in a dynamic environment, think clearly and calmly under pressure Ability to work in a fast-paced, dynamic environment that requires flexibility and balancing of competing priorities Ability to deal with situations, people and problems ethically, with honesty and integrity Experience using Informatica ETL is an asset Must complete & pass a criminal record check We live and breathe our core values. We go the extra mile. We’re honest. We always have each other's back. We have tons of integrity. And we always own it and adapt – no matter the challenge. With the support to do things differently, grow personally and professionally and bring your whole self to work, there's no limit to the impact you can make. We provide a competitive compensation package composed of a group benefits plan, rent subsidy and discretionary profit-sharing program. We are committed to a strong safety work environment. 
ScrapedJobID210:
Identify and implement improvements that allow analysts to onboard new clients efficiently and identify any data quality issues. Partner with data analysts to identify how the platform can solve unique emerging client needs, and make necessary adjustments to accommodate, appropriately balancing quality and timeliness Partner with application developers to effectively integrate the analytical backend with new client-facing features on the front-end. Bring one-off analysis / R&D code up to production standards so that another analyst can easily apply the method to another client Simplify, clean up and improve our database and data pipeline to ensure they remain fast, reliable, efficient, and maintainable. Integrate data ingestion tools and automate data quality checks. Develop SQL queries and Python scripts to produce analytics datasets. Maybe even do a little Excel. Yes. There's still a time and place for Excel. Create documentation, training materials and provide support for team members relying on your expertise At least 2-3 years experience as a Data or Analytics Engineer, ideally in a product-minded SaaS or Tech company Proficiency in Python for data processing and SQL for building data transformation. Passion for delivering the foundational work needed to empower our team to deliver greatness to our customers. Ability to handle multiple competing priorities in a small but ambitious, product-led growth SaaS company. Ability to pay a huge amount of attention to nitty-gritty details, yet not lose sight of the big picture Strong cross-functional working and communication skills, and the ability to work with stakeholders who are not engineers. Growth-focused and product-minded attitude. Believe in our values. Experience with different modern approaches to data transformation, management, and data pipeline integrations Experience with orchestration technologies such as Prefect, Airflow or Luigi. Experience with business intelligence tools such as Tableau or PowerBI An understanding of data visualization design theory Experience with creating data visualizations with code in Python, R or Javascript Experience with Node.js and Javascript in general Experience with geospatial datasets and tools. Experience with Jupyter Notebooks, Excel, Tableau, data analytics, data science. Cloud platform experience with Amazon Web Services Competitive salaries within a transparent salary environment Competitive benefits and a profit-sharing program Unlimited vacation plus a summer shut down Flexible working conditions; work from wherever you want, whenever you want The ability to make an impact and do work that matters 
ScrapedJobID211:
Your work background: At least one experience at a Startup 5-10 years' experience of increasing responsibility, autonomy and influence 5+ years of solid data science experience Your technical background Experience developing specialized models and experiments - including data sourcing, intake, feature engineering, model selection, and iteration - across a variety of business-focused use cases Expertise in matching model and experiment outputs to business processes and decision making, as well as fully integrating data outputs with business processes across stakeholder groups Expertise in Python (Pandas/SciPy), R (or similar), strong SQL Educational background: the hiring manager's favorite ex-colleague had a Chemistry degree. We don't care where you went to school. What matters is that you have Science and Systems thinking, what you've learned; when and how. We care that you're curious, open-minded and meticulous. We care that you want to build Your data background Proficiency in sourcing, validating, and cleaning your own data, as well as working across teams to design new data collection structures to fill gaps in current data collection Experience with working on systems that process imperfect data A github/gitlab repo with some of your public work Your public.tableausoftware.com work examples Slides from prior presentations Hobby projects Favorite analytical projects Experiments you've run Projects that have failed Medical, Dental and Vision PPO as well as supplementary secondary benefits Annual HCSA for individuals & families & 100% drug coverage - Canadian employees only 401(k) -US employees only Generous PTO Stock options Growth potential and opportunity to have a significant impact at an early stage of our company's journey Working with a team of rockstars (+ a weekly happy hour with the team!) 
ScrapedJobID212:
Software Development Environments - Experience in either Java, Scala, or Python; Software content management tools such as git (preferred) or SVN; Experience with functional programming. Software Engineering - Understanding of core software design patterns; Practical experience with distributed computing is an asset; Apache Spark is preferred, Apache Hadoop Map/Reduce or experience with other similar distributed compute engines; Automated code deployment to various environments. Machine Learning - Experience with any of the following machine learning toolkits: Weka, Spark, h20.ai, Tensorflow, Keras, Pytorch, R is valued Natural Language Processing - Experience with any of the following toolkits: Gate NLP, Open NLP, Stanford NLP, Python NLTK, Apache UIMA, R We thank you for your interest, however, only those who qualify for an interview will be contacted. 
ScrapedJobID213:
Evaluate and explore opportunities in our games and operations, through detailed querying and analysis of our data. Be a key bridge between data, game design, and the business through the creation of reports and dashboards, helping to illustrate the ongoing story told by our data. Build partnerships with each team member, sharing the tools and insights that improve retention and monetization within our products. Formulate hypotheses and run a variety of A/B tests to determine the best strategies to implement into our products. Continuously improve, maintain, and develop our analytics tools and predictive models for our games. A bachelor's degree in mathematics, statistics, computer science, economics, or a related quantitative field; or a graduate degree in data science or business analytics. Expert level knowledge of SQL (e.g., window functions), Tableau, and proficiency with at least one scripting language (e.g., R, Python). Ambition to own and take ownership of the reporting and analysis functions for our games. The ability to tell a convincing story with data. An innate curiosity and ability to look at large complex data sets and formulate meaningful conclusions. Previous experience A/B testing and calculating statistical significance within a big data context (e.g., bootstrapping, permutation testing). Strong written and oral communication skills. Mobile, F2P, or idle game experience and interest is a HUGE plus! Hungry, humble, and smart and can use these three pillars to impact you and those around you. A mobile game fanatic. You are on top of the latest games, trends, and what’s happening in live events. Entrepreneurial, self-motivated, and have the attitude to get things done. A risk-taker, and gain your biggest learnings through them. Empathic, compassionate, and curious. Solution-oriented and data-driven. Comfortable in an environment where priorities and plans change rapidly. 
ScrapedJobID214:
Comprehensive research on the state-of-the-art algorithms on Computer Vision, Image Processing, OCR and NLP. Compare all the candidates or propose new algorithm that could improve and enhance our current products or create proposals for new products. Design and implement deep learning architectures that learn efficient generalizable representations for several tasks including classification, regression, segmentation and object detection. Deploy ML algorithms in conjunction with other members of the Software Team in the real applications. Bachelor, Master or PhD degrees in Computer Science, Electrical Engineering or equivalent. Experience developing Computer Vision, Image Processing, OCR, or NLP algorithms. Experience developing Deep Learning Models for Computer Vision, OCR, NLP tasks. Experience Implementing deep learning architectures such as CNN, R-CNN, Single Shot Detector, ResNet, etc. Good working knowledge of one or more Machine Learning Frameworks (TensorFlow, PyTorch Keras, Caffe, MXNet, etc.) Experience wtih C++, Python, or other programming languages. First class analytical, diagnostic and problem solving skills. Excellent verbal and written communication skills with an ability to collaborate with other team members. Passion to work in an exciting environment and deliver new technologies and products to the marketplace. Ability to learn quickly. A positive mental attitude and growth mindset. Please advise in your application whether you are eligible to work in Canada. Remote work available Competitive salary with full benefits and vacation package Professional and positive teamwork environment Monday to Friday Temporarily due to COVID-19 
ScrapedJobID215:
You are working in an interdisciplinary team of sales, marketing, finance, and IT experts, willing to share knowledge and expertise with you. You help gather data from multiple sources; document and catalog into a central repository system on AWS. You support the setup of KPI-oriented / data-based reports and analysis for all levels of management and enhance digital transformation of BMW Group Canada. Processing raw data to desired output format and performing analysis on it. Creating data visualizations and establishing data pipelines to Tableau dashboards. Driving automation of reports and ensuring availability of accurate data in dashboards. Collaborating within Agile Working Model and processes such as Scrum, Kanban using JIRA platform. Current student or recent graduate in Data Science, Data Analytics or a comparable course of studies. Minimum one-year experience within Sales, Marketing, Business Development or IT. Relevant analytics and/or BI related working experience is preferred. Strong knowledge in MS Office, especially PowerPoint and Excel. Knowledge in data visualization programs like Tableau, Qlik, or Power BI. Coding experience in data processing, aggregation (R, Python) and database management (SQL) is an asset. Analytical thinking and first knowledge in analyzing and visualizing data. Fast learner and willingness to work with Data Analytics Software. Teamwork and communication skills. Openness, motivation and hands-on mentality. 
ScrapedJobID216:
ProCogia has doubled in size over the last two years & core to ProCogia's culture is ensuring we maintain a balanced male to female ratio. We are proud to share our consulting teams consist of 40-50% females compared to the industry standard of 10-20%. Our diversity, and differences allow us to create innovative and effective solutions for our clients. We work with industry leading clients from various sectors including Pharmaceuticals, Telecommunications, Technology, Financial Services & Retail. Our work environment ensures opportunities to gain valuable experience in various industries enhancing your personal & career development. You're a highly skilled and passionate analytics professional who thrives at the intersection of data, purchase behavior, marketing, product, and engineering. You are a strong communicator and thrive in a collaborative environment, influencing the organization by promoting business outcomes. You've are a passionate leader who can own and drive team success! You will find and manipulate data to build data sets with Adobe. Partnering with marketing, research, and product organizations, you will scope, design, execute, measure, and improve the impact of digital product development and marketing efforts of the business. You are a data insights translator, creating actions and recommendations to drive user growth and engagement. 4+ years of hands-on experience with Adobe Analytics, experience platform, and the suite. 4+ years Data Analysis, Data Science, Decision Science or quantitative fields. Management consulting experience, presenting data-driven insights to business audiences. Master's in economics / mathematics / engineering / psychology 3+ years applying experimentation methods to test various hypotheses for customer segmentation, user growth, and outbound marketing campaign evaluation. We are a people first organization that values it's culture at its core. We operate a flexible hybrid model to allow for the individuals preference. We offer career development, educational budgets, and foster learning through weekly Tech Talks! Our package is competitive in the market. 
ScrapedJobID217:
Be proficient in all stages of model building – data sourcing, exploratory data analysis, data profiling, data cleaning, data preparation, feature engineering, scaling, model development, validation techniques, and model deployment to production Given a problem statement, be able to identify machine learning method (supervised/unsupervised) and categorize the problem into regression/classification/clustering models Ability to explore large datasets, visualize the data, and unearth the hidden data patterns Assess and understand data quality, and prepare quality datasets for training machine learning models Identify suitable machine learning algorithms, derive feature importance, define accuracy metrics to build, and validate models Define validation strategy, rank models, and choose the best model Must be able to explain the model outcome Ability to code in Python, write complex SQL and use AI/ML tools on cloud platforms (Azure, GCP, AWS) Be self-driven and welcome new learning opportunity to grow skills Guide and share knowledge with the team on approaching different data science problems Work in a fast growing and exciting organization with professionals who are eminent in their respective field Have challenging and interesting work in a team environment Continue your development throughout your career to reinforce and expand your chosen career path Minimum of 5 years of relevant experience. Experience as a Data Scientist in end to end machine learning life cycle Experience in Python, NumPy, Pandas, scikit-learn, statsmodels, TensorFlow, PyTorch, and/or predictive/cognitive analytics technologies Experience in R is an asset Working experience with predictive/cognitive modeling Knowledge or experience with AI/ML tools on a cloud platform (e.g. Azure) such as Azure ML, Azure Cognitive Services, etc. is considered a strong asset Experience in SQL queries for data sourcing Experience with one or more database and unified analytics engines: DB2, Azure SQL, Spark, HANA Demonstrated ability to deal with structured, unstructured data and ability to prepare it for analytic operations Demonstrated ability to integrate data from multiple sources with varied formats Exposure to MLOps on any platform is a preferred Knowledge in NLP techniques is nice to have Experience in working with Transformer based models like BERT, RoBERTa, T5 is nice to have Lead the way: Deloitte is not only leading the profession, but reinventing it for the future. We’re also committed to creating opportunity and leading the way to a more sustainable world. Serve with integrity: Deloitte has earned the trust of employees, clients, regulators, and the public for 175 years. Upholding that trust is our single most important responsibility. Take care of each other: We look out for one another and prioritize respect, fairness, development, and well-being. Foster inclusion: We are at our best when we foster an inclusive culture and embrace diversity in all forms. We know this attracts top talent, enables innovation, and helps us deliver well-rounded client solutions. Collaborate for measurable impact: We approach our work with a collaborative mind¬set, teaming across businesses, geographies, and skill sets to deliver tangible, measurable, attributable impact. 
ScrapedJobID218:
Post-secondary education in a related field. Must have at least 1 year of experience with Deep Learning frameworks like PyTorch or TensorFlow. Must have at least 1-3 years of experience with C/C++, Python coding or other high-level languages. A strong publication record or alternative relevant innovation experience. 
ScrapedJobID219:
Assist the Data Science team in building and developing solutions on White Whale’s AI platform, DeepSea. Support Data Science team in completing and maintaining client dashboards and deliverables. Search for and expand on DeepSea’s catalog of publicly available datasets. Work on an agile team and participate in sprint planning and daily team stand up. 2+ Years of previous work experience in a Data Science related role Completed a Bachelor's degree in Math, Statistics, Business Analytics, Computer Science or other related fields. Data Science certifications or courses will also be considered. Strong Knowledge of modern data architecture, data mining, data structures and data cleansing. Expertise in coding with Python/R, Pandas, SQL and working knowledge of APIs Experience creating and using advanced machine learning algorithms and models Excellent communication and interpersonal skills Ability to solve problems on your own Resourcefulness in the face of hard challenges A sense of purpose and delightfulness when you go into work everyday Learn, grow and shape your skills in an encouraging and productive environment Be part of a close-knit astronaut team on a critical mission to explore the world of data 
ScrapedJobID220:
Design, document, develop, test and deploy new ML learning models. Maintain, update pre-built models. Take ownership of the project's data. Build end to end ML pipelines with automation for continuous training and continuous deployments. Excellent communication skills, both verbal and written. Proven record of finishing projects where the work spans several months. Familiar with the entire lifecycle of a data science project from data exploration, modeling and analysis, to model selection, validation, evaluation, and deployment. Experience in cleaning, filtering, and re-factoring complex data from different sources. 3+ years development experience in Python. 3+ years of experience working with data, and modeling. Professional command of ML tool sets in Python (Numpy, Scipy, Pandas, Scikit-learn). Experience with computer vision and deep learning frameworks (tensorflow, pytorch, darknet). BS degree, or College Diploma in Computer Science or related. A link to your Github/Gitlab account Experience with other programming languages. Experience with building and automating end-to-end machine learning pipeline on any of the clouds AWS/GCP/Azure is a strong plus Experience participating and contributing to open source projects. Knowledge of cloud computing. Good understanding of OS concepts, networking and bash scripting. Only resumes in PDF format will be reviewed. 8 hour shift Link to your Github/Gitlab account ML: 3 years (preferred) Object-Oriented Programming: 3 years (preferred) Yes 
ScrapedJobID221:
Provide management with deep-dive quantitative analyses and present them in an immediately usable format, extracting key insights from extensive, complex data sets Collaborate with product management, software and data engineering, data science and other analysts to share and develop knowledge Find opportunities to automate repetitive analyses Quantitatively analyze user behaviour to help determine product strategy and drive business decisions, including driving learning from A/B tests 2-5 years of progressive experience using quantitative analysis to make business-focused recommendations Strong understanding of incrementality and sizing business problems and opportunities Good communication skills at different levels of organizational hierarchy Experience with ambiguous and complex analytical assignments Experience with raw clickstream data (telemetry event data) and datasets of 100 million+ records Experience with web/digital analytics metrics (Daily Active Users, Retention, Churn) Understanding of basic statistical concepts such as confidence, normal distribution, correlation, linear regression, and linear programming Proficiency with SQL or other query languages Experience with data visualization and analytical tools (E.g. Tableau, PowerBI, Looker) A skillset that encompasses problem identification, analysis, solution definition, results, and communication Experience with Python, R, or other programming languages Experience in an internal or external management consulting/advisory role Have held a similar position at an online dating, social networking, gaming or subscription-based business You're a user of Plenty of Fish or other online dating service or familiar with the product! 
ScrapedJobID222:
You will build pipelines to bring data required to support the use case You will develop new machine learning models to enable intelligent campaigns You will productionalize machine learning models and automate processes Collaborate with business stakeholders to enable new use cases for TELUS Business Effectively communicate with leadership and stakeholders in explaining the model and outcomes You have experience leading large scale projects and partnering with multiple stakeholders You can manage ambiguity and change with a learning and growth mindset You love digging into quantitative and qualitative data You have experience working with customer data, building recommendation engines, personalized offer management, lifetime value and propensity modeling You have experience in building machine learning algorithms You have worked with R/Python, SQL, spark, big data technologies or cloud You have data engineering experience and ability to extract data from various sources You have 5+ years of experience in a similar role and/or related education with demonstrated performance Prior telecommunications or B2B marketing experience Experience with Cloud / Salesforce technologies 
ScrapedJobID223:
Ingest and transform large-scale OR datasets to be used for computing key risk indicators (KRIs) and building OR models. Conduct exploratory analysis and interpretation of new and different data sources to find solutions to business problems Develop Tableau dashboards that present OR deliverables to its business partners and stakeholders. Support the development of a proactive approach to Operational Risk Management Participate in Proof of Concept or Proof of Technology projects to evaluate operational risk technologies and platforms Work with Operational Risk subject matter experts to identify key threats to the organization 4+ years of experience performing common ETL operations on structured datasets 2+ years of experience in developing, supporting, and maintaining Tableau dashboards Strong background in programming in Python and/or PySpark with familiarity with common packages; e.g. numpy, scipy, pandas, … Strong critical thinking and creative problem-solving skills Strong communication skills both in written and verbal Solid understanding of data management practices and data pipelines Strong analytical skills and competency in mathematics Experience with source version control such as GitHub. Experience with the Hadoop ecosystem HDFS/Spark/Hive Experience with common DevOps tools; e.g. Jenkins, Artifactory, Experience working with databases Knowledge of Agile methodology Knowledge/interest in UX Design and data visualization Leaders who support your development through coaching and managing opportunities Ability to make a difference and lasting impact Work in a dynamic, collaborative, progressive, and high-performing team Opportunities to do challenging work and make a difference Opportunities to building close relationships 
ScrapedJobID224:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID225:
Develop models and algorithms to maximize ROI and advertising performance Implement machine learning models in production, sometimes with the assistance of Data Engineers Implement a data analysis framework to analyze and test models effectively Generate insights on user behaviour and implement necessary solutions Be able to test results using historical data and optimize efficiently in production Have a Masters degree or PhD in Computer Science, Statistics, Operations Research, or a related field, with dual degrees preferred. Have relevant experience as a Data Scientist Have the ability to take an ambiguously defined task, and break it down into an insightful analysis Are proficient with relevant data science tools such as Spark, Python (scipy, sk-learn) etc. Have a comprehensive understanding Bayesian modeling, machine learning techniques, and optimization Have the ability to innovate custom algorithmic solutions to machine learning problems Have worked with large datasets Understand multivariate regression, and classification Background in advertising technology or a related field is a plus Work alongside some of the smartest people in the industry Highly competitive salary with RRSP Matching Bright office in the heart of Toronto's tech center (currently we are remote due to COVID) Full benefits from League on day one of employment 3 weeks vacation + 3 personal care days + 1 volunteer day + birthdays off Home office and Internet reimbursements Coverage and support of personal development initiatives (conferences, courses, etc) An awesome parental leave policy A weekly $15 lunch credit via Ritual 
ScrapedJobID226:
Provide management with deep-dive quantitative analyses and present them in an immediately usable format, extracting key insights from extensive, complex data sets Collaborate with product management, software and data engineering, data science and other analysts to share and develop knowledge Find opportunities to automate repetitive analyses Quantitatively analyze user behaviour to help determine product strategy and drive business decisions, including driving learning from A/B tests 2-5 years of progressive experience using quantitative analysis to make business-focused recommendations Strong understanding of incrementality and sizing business problems and opportunities Good communication skills at different levels of organizational hierarchy Experience with ambiguous and complex analytical assignments Experience with raw clickstream data (telemetry event data) and datasets of 100 million+ records Experience with web/digital analytics metrics (Daily Active Users, Retention, Churn) Understanding of basic statistical concepts such as confidence, normal distribution, correlation, linear regression, and linear programming Proficiency with SQL or other query languages Experience with data visualization and analytical tools (E.g. Tableau, PowerBI, Looker) A skillset that encompasses problem identification, analysis, solution definition, results, and communication Experience with Python, R, or other programming languages Experience in an internal or external management consulting/advisory role Have held a similar position at an online dating, social networking, gaming or subscription-based business You're a user of Plenty of Fish or other online dating service or familiar with the product! 
ScrapedJobID227:
You will build pipelines to bring data required to support the use case You will develop new machine learning models to enable intelligent campaigns You will productionalize machine learning models and automate processes Collaborate with business stakeholders to enable new use cases for TELUS Business Effectively communicate with leadership and stakeholders in explaining the model and outcomes You have experience leading large scale projects and partnering with multiple stakeholders You can manage ambiguity and change with a learning and growth mindset You love digging into quantitative and qualitative data You have experience working with customer data, building recommendation engines, personalized offer management, lifetime value and propensity modeling You have experience in building machine learning algorithms You have worked with R/Python, SQL, spark, big data technologies or cloud You have data engineering experience and ability to extract data from various sources You have 5+ years of experience in a similar role and/or related education with demonstrated performance Prior telecommunications or B2B marketing experience Experience with Cloud / Salesforce technologies 
ScrapedJobID228:
Ingest and transform large-scale OR datasets to be used for computing key risk indicators (KRIs) and building OR models. Conduct exploratory analysis and interpretation of new and different data sources to find solutions to business problems Develop Tableau dashboards that present OR deliverables to its business partners and stakeholders. Support the development of a proactive approach to Operational Risk Management Participate in Proof of Concept or Proof of Technology projects to evaluate operational risk technologies and platforms Work with Operational Risk subject matter experts to identify key threats to the organization 4+ years of experience performing common ETL operations on structured datasets 2+ years of experience in developing, supporting, and maintaining Tableau dashboards Strong background in programming in Python and/or PySpark with familiarity with common packages; e.g. numpy, scipy, pandas, … Strong critical thinking and creative problem-solving skills Strong communication skills both in written and verbal Solid understanding of data management practices and data pipelines Strong analytical skills and competency in mathematics Experience with source version control such as GitHub. Experience with the Hadoop ecosystem HDFS/Spark/Hive Experience with common DevOps tools; e.g. Jenkins, Artifactory, Experience working with databases Knowledge of Agile methodology Knowledge/interest in UX Design and data visualization Leaders who support your development through coaching and managing opportunities Ability to make a difference and lasting impact Work in a dynamic, collaborative, progressive, and high-performing team Opportunities to do challenging work and make a difference Opportunities to building close relationships 
ScrapedJobID229:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID230:
Develop models and algorithms to maximize ROI and advertising performance Implement machine learning models in production, sometimes with the assistance of Data Engineers Implement a data analysis framework to analyze and test models effectively Generate insights on user behaviour and implement necessary solutions Be able to test results using historical data and optimize efficiently in production Have a Masters degree or PhD in Computer Science, Statistics, Operations Research, or a related field, with dual degrees preferred. Have relevant experience as a Data Scientist Have the ability to take an ambiguously defined task, and break it down into an insightful analysis Are proficient with relevant data science tools such as Spark, Python (scipy, sk-learn) etc. Have a comprehensive understanding Bayesian modeling, machine learning techniques, and optimization Have the ability to innovate custom algorithmic solutions to machine learning problems Have worked with large datasets Understand multivariate regression, and classification Background in advertising technology or a related field is a plus Work alongside some of the smartest people in the industry Highly competitive salary with RRSP Matching Bright office in the heart of Toronto's tech center (currently we are remote due to COVID) Full benefits from League on day one of employment 3 weeks vacation + 3 personal care days + 1 volunteer day + birthdays off Home office and Internet reimbursements Coverage and support of personal development initiatives (conferences, courses, etc) An awesome parental leave policy A weekly $15 lunch credit via Ritual 
ScrapedJobID231:
Explore, design and build AI prototypes capable of significantly altering our users’ experiences Develop detailed data models to explain user behavior and discern complicated patterns Dive into the data to analyze subtle trends in business performance, presenting insights and stories through the data in accessible ways Work alongside our Architects to evaluate and review the algorithms we use to match users Design and building complex predictive models, creating forecasts, and mining deep insights from raw and unstructured data Perform deep dives into unstructured data and build complex models to extract valuable insights into our users and the business Perform time series analysis and forecasting for a variety of important business and operational metrics Coordinate with the Product team to identify and measure key business areas and provide them with actionable insights Evangelize a data-driven culture Participate in a highly collaborative environment, we want you to share your expertise! M.S or PhD in a quantitative field such as physics, mathematics, computer science, statistics, biostats, or economics Minimum of 2+ years post graduation experience as a Data Scientist, Research Scientist or Machine Learning Engineer Familiar with cutting edge deep learning techniques and associated tools (such as PyTorch/Tensorflow) Strong programming skills with history of deployment to production at scale Proven track record of productionizing machine learning solutions for stakeholders at scale Solid understanding of mathematical modeling and statistics: inference, Bayesian methods, graphical models, network theory, likelihood estimation, Monte-Carlo methods and sampling theory Experience working with and deploying recommender systems Understanding of how to optimize machine learning models (parallelization, batching techniques, etc) Ability to rapidly acquire and adopt new knowledge and techniques Ability to think creatively about problems and not afraid to go “outside the box” Proficient with standard SQL and relational databases Familiarity with Python and/or R and their data science/machine learning packages Comfortable working independently on large projects (demonstrated via industry or academic experience) or as part of a diverse team of different skills as necessary Ability to see the “big picture” and how your work relates to POF’s entire business - and the ability prioritize your research work accordingly Experience with GCP/AWS or other cloud providers 
ScrapedJobID232:
Establish data science practices for ZenHub Conduct research and analysis in order to come up with solutions to business problems Evaluate business processes to uncover areas for improvement Identify business challenges and opportunities using data modelling techniques Guide data model and architecture decisions to help support strategic decision making Provide business insights based on comprehensive analysis Identify new opportunities in the conversion funnel Provide data exploration and analysis to various product teams Make data insights accessible via data visualizations Document, present and effectively communicate your insights to cross-functional team members and leadership team Drive initiatives to automate and modernize processes and technologies Oversee the implementation of new technology and systems 5+ years experience in an Applied Data Scientist role 1+ year experience in improving SaaS products by applying data science techniques on large scale datasets Exceptional problem solving, conceptual thinking, analytical skills and experiment design (e.g. AB Testing) Advanced knowledge of statistical machine learning techniques and python programming Experience creating detailed reports and presenting insights from the analysis and research Experience with databases, both relational databases (e.g. PostgreSQL) and non relational databases (e.g. Mongo) Experience with data engineering and data warehouses (e.g. Google BigQuery) Boundaryless working style. We want our team to work from wherever is best for them. Whether you prefer to work from the comfort of your home office or from our bright, spacious, and dog-friendly Zen-den, we support you. For those opting to wfh, we offer a generous monthly stipend to cover ongoing remote work expenses. If you opt to join us in-office, we’ll contribute to your commute expenses or bike maintenance. A flexible vacation policy. We work hard and it’s important we take time to recharge. We have a flexible time off policy with no hard limit and encourage our team members to take a minimum of 3 weeks off per year. A commitment to continued learning and development. We provide an annual professional development budget to use towards conferences, classes, books, and other opportunities to maintain and expand your skill set. Fitness reimbursements. Stay fit with our monthly reimbursements for health-related benefits like gym memberships, fitness apps, and personal training. Top-of-the-line equipment. In addition to receiving a company smartphone of your choice with a paid voice/data plan, every team member receives a generous annual new tech budget to try new gadgets, tools, and platforms. Flexible parental leave policies. We understand the importance and demands of a growing family. In addition to state, provincial, and federal leave allowances, parents on our team have the ability to create flexible schedules or take days off when family needs to come first. Social Connection. When it’s safe to gather again our team will have access to a shared collaboration space in Vancouver, but our team is focused on fostering strong relationships and an equitable experience no matter where in the world you’re working. 
ScrapedJobID233:
Lead business strategy conversations to understand business needs Lead long term capability roadmap development with business leads Evaluate business processes and uncovering areas for improvement Translate Business needs into technical requirements Collaborating with business stakeholders and technical teams to deliver a variety of projects Lead solution planning, development, and implementation Deliver advanced analytics and data science projects from end-to-end Effectively communicating insights to project stakeholders Complete proof of concepts Lead the adoption of solutions into the business process Providing training, coaching and guidance on advanced analytical tools and data storage structures Identify best practices in the advanced analytics space by tracking technology and industry trends Graduating with a Bachelor's Degree in Data/Computer Science, Mathematics/Statistics, an engineering discipline, or equivalent On the job experience with statistical modeling, machine learning and/or deep learning modeling Expertise in statistical analysis tools like R or Python Comprehensive knowledge of Databases and strong SQL programming skills Proficiency in data blending tools like Trifacta, Knime or Alteryx is an asset Demonstrated experience in handling large data sets and relational databases Experience with visualization tools like Tableau, Power BI or Matplot Ability to translate business and technical requirements into non-technical terms Strong communication and collaboration skills Exceptional analytical and conceptual thinking skills Demonstrated ability to thrive in fast paced environment Ability to work independently with minimal supervision Experience with Scrum/Agile Methodology is an asset Experience using Hadoop/Hive, Teradata is an asset Competitive compensation, benefits, pension, RRSP contribution and vacation time A flexible working environment that promotes a healthy work-life balance A dynamic and inclusive culture that promotes you to bring your whole-self to work A supportive team that will encourage your professional growth and development An opportunity to be meaningful and impactful within your work and projects An opportunity to give back to the community with our Always on Volunteer 360 Program An organization that aims to use their scale, reach and expertise to build a more sustainable world 
ScrapedJobID234:
Build production ready data mining and big data analytics algorithms and pipelines; your models will be the engine that powers all online commerce through Bolt Conduct data analysis to determine which policies we adopt and help inform strategic growth Build statistical models, data pipelines, data mining, data analytics, and production ready services to serve offline and live traffic Work with other teams at Bolt to engineer data models and extract data insights that help improve Bolt business Passion to improve e-commerce businesses Strong communication skills in a cross-functional team Unrelenting focus on impact Master's degree in relevant technical discipline Knowledge of data mining, and big data analytics techniques Knowledge of statistical concepts and techniques Mastery in one or more of Python, Java, Scala, SQL AWS Lambda for data ingestion and Kinesis Firehose to transport them into S3 Step functions and Lambdas to coordinate workflows AWS Redshift as the data warehouse + Spark on EMR for doing ETL Terraform for maintaining infra Jenkins & CircleCI for build pipelines Postgres RDS is our application database Our code base is primarily in Golang & Typescript. However, our data bits are mostly in Python. Competitive Pay Flexible PTO Retirement plans Cell phone reimbursement Wifi reimbursement Comprehensive health coverage: Medical, dental and vision Monthly wellness stipend Paid parental leave Monthly (virtual) team events 
ScrapedJobID235:
Post-secondary degree in public health, biostatistics, epidemiology, health promotion or related discipline and/or combined relevant experience Ownership, Control, Access, and Possession (OCAP®) certification Must have working knowledge of determinants and regulatory process impacting First Nations health and First Nations governance Knowledge of the complex health service delivery landscape in northern Ontario and the inter-jurisdictional issues as they relate to the First Nations health Good data scripting and programing skills including proficiency in using query languages, codes statistical testing, regression, etc. Experience with common data science and data visualization tools Ability to extract, analyze and interpret data as well as prepare and deliver high quality written reports and presentations for diverse audiences with the ability to express ideas clearly, concisely, and respectfully Understand and facilitate data gathering, analysis, and interpretation for health program design and the interrelationship of data with health policy and program Experience with excel, SPSS, and other data systems Experience with First Nations community engagement, community-based research and First Nations decision making processes Excellent interpersonal, communication, advocacy and organizational skills As per policy, applicants should note that COVID-19 immunization is a condition of employment within SLFNHA. Create and replicate statistical codes, statistical programs and develop and maintain complex data bases and coding algorithms Collect, create, analyze, and disseminate information and evidence to support health planning and decision making Collect and analyze data—through extracting secondary data, observations, interviews, and surveys to find the causes/associations of diseases or other health problems in First Nations Communities Support the Preventing Infectious Diseases team in data tracking (i.e. line lists) and communicable diseases surveillance. Identify effective methods of knowledge transfer based on specific targeted audiences Facilitate the establishment and strengthening of effective networks and relationships with all levels of leadership/government and other experts as required Participate in the launch and management of Epi briefs, health status reports, and advocacy strategies related to the SLFNHA priorities for its communities based on evidence Provide data to support funding opportunities through proposals and partnerships with other agencies Provide support for the regional strategic health planning function of SLFNHA and facilitate the continued implementation of the Anishinabe Health Plan. Work alongside teams within ACW or the management team to establish program needs Research, review, monitor and analyze provincial and federal government data sources and policies which affect the health and health services for First Nations in the Sioux Lookout area Communicate data findings to health practitioners, policymakers, and Tribal Councils All other duties as assigned 
ScrapedJobID236:
Design, implement, train and optimize deep learning models Analyze and improve models performance and speed Write production-ready Python/c code Strong background in machine learning theory and algorithms 2 Years+ experience in ML models design, train and optimization Familiar with pytorch and tensorflow Familiar with well known deep learning models such as yolo, SSD, faster RCNN and able to adapt it to new applications Highly self-motivated and quick learner Extended health care Flexible schedule 8 hour shift Bachelor's Degree (preferred) machine learning: 2 years (preferred) 
ScrapedJobID237:
Maintain an acute awareness of the industry and what the competitors are putting out. Investigate new options for the system. Coordinate with Senior R&D R&D regarding tech. Coordinate with team members to discover the best solution for the clients. Conceptualize new features that we could offer exclusively. 1+ years of Experience in Software Development Education: BSc or M.tech in Computer Science/Engineering preferably with a focus on AI. Strong hold on Data structures and Algorithms. Experience with Anaconda/Python/Tensorflow. French Language skills. Hours: 30-40 hours/week. Wage: $70,000 - $80,000/year. 2 Weeks of Vacation. A great environment and the right tools to do great work. 
ScrapedJobID238:
Building, implementing and supporting Microsoft Power BI solutions Assist in the creation of a framework for how data, reports and dashboards are managed and delivered Create data visualizations, dashboards, and reports to present using Microsoft Power BI Convert existing datasets/reports into SQL Server/Analysis Services/Power BI Solutions Contribute reporting and business intelligence expertise to special projects as required Create and maintain business intelligence tools and reports, including physical data models and dimensional analysis Build a data pipeline to automate business processes and synchronize data between applications Assist stakeholders to determine business needs and requirements for BI, including the development of performance metrics and KPIs Design, code, test and aggregate results from SQL queries to provide information to stakeholders Analyze data to provide recommendations for future actions to business stakeholders Foster a data-driven culture through the adoption of data management best practices Partner with design, engineering and construction teams to gain cost and schedule efficiencies Leverage technology to enhance operational performance and productivity 2+ years hands on experience with Microsoft Power BI and Data Analysis 2+ years of technical experience with SQL Server is preferred Undergraduate degree in related field (computer science, engineering, mathematics, or equivalent) Microsoft Power BI certification is an asset Microsoft Azure Data Scientist associate is an asset Detailed knowledge of BI Best Practices/Methodologies, relational structures, dimensional data modeling, structured query language (SQL) skills, data warehouse and reporting techniques Working knowledge of coding languages, including C+, VBA, R and Python Familiarity with Workato Ability to understand and create complicated Data Analysis Expressions (DAX) language expressions and familiarity with Power Query Proven experience with using data visualization techniques to create meaningful reports and dashboards Interest in the Architecture, Engineering and Construction industries Working knowledge of Power Apps 
ScrapedJobID239:
Work with Finance Data and Analytics CoE team members, Finance as well as other Bell Businesses to understand and assess business needs and design and develop data solutions by exploring data sources and analytics approaches to be used (e.g. mining, forecasting, visualization, etc.) and execute to address the business needs Explore new sources of information to uncover new business opportunities at all levels of the business (judicious to operational) Exercise leading edge analytics skills in data visualization, mining, forecasting, etc. to address business needs Work with and present to all management levels Maintain and expand your knowledge of data systems and current technology through training opportunities Work in an agile environment and contribute to the improvement of our development processes Implementation of methodologies and processes to organize and aggregate large datasets to expedite actionable insights from all available data sources. Leverage data, machine learning and business principles to identify and solve complex business problems for the wider finance organization. Ensure that the return on investment in advanced financial analytics resources and technology is realised by keeping abreast with strategic requirements from senior management and that these are aligned to internal projects being actioned. Ensure that advanced financial analytics techniques that are relevant within non-traditional divisions are identified and actioned. Degree in Data Science, Computer Science, Information Technology, Economics, Statistics, Information Systems, Applied Math, Business Administration, Finance or any other related field (masters degree considered an asset). CPA or related finance experience considered an asset Demonstrated experience in business process analysis, data architecture design and development, and the implementation of workflow enabled solutions and their intricacies in a finance environment. Minimum 5 years of coding experience 2 years’ experience with Machine Learning and Artificial Intelligence algorithms and approaches Advanced skills with SQL and database systems such as Hive, Impala, MySQL, SQL Server, Teradata Highly analytical skills and ability to work with large and complex technical data sets Ability to leverage insights and opportunities from data and metrics to build strategies and make recommendations Knowledge of, and preferably experience with, Big Data and/or software development, and/or developing visualization tools Ability to work with a team towards common goals Ability to quickly learn new programming languages and frameworks Able to manage multiple projects and priorities Self starter who is comfortable working with and presenting to all management levels Working knowledge of data mining principles: predictive analytics, mapping, clustering, collecting data from multiple data systems on premises and cloud-based data sources. Working knowledge of machine learning techniques, for example: Support Vector Machine, Naïve Bayes, K-Nearest Neighbours, K-Means, Random Forest, Dimensionality Reduction Algorithms, Deep Learning techniques and Gradient Boosting Algorithms. Experience and knowledge of statistical modelling techniques: GLM multiple regression, logistic regression, log-linear regression, variable selection, etc. Understanding of and experience using analytical concepts and statistical techniques: hypothesis development, designing tests/experiments, analyzing data, drawing conclusions, and developing actionable recommendations for business units. Strong SQL and SAS skills, ability to perform effective querying involving multiple tables and subqueries. Experience writing advanced SAS, SQL, Python, R (or similar) code statements, models, and macros. Experience using analytics techniques to contribute to company growth efforts, increasing revenue and other key business outcomes. Strong problem solving, quantitative and analytical abilities. The right candidate will also be proficient and experienced with the following tools/programs: Strong programming skills with querying languages: SQL, SAS, R, Python, etc. Experience with big data tools: Alteryx, Teradata, Aster, Hadoop, etc. Experience with other Analytics/Programming tools will be beneficial: C, C++, JAVA, or other programming languages Experience with Excel (incl. VBA), Word, Access and PowerPoint. Advanced Visualization Development Experience with Tableau, PowerBI, Qlik, Microstrategy, etc. Statistics and math background Experience in Telecom, Finance or IT is a strong asset. 
ScrapedJobID240:
Degree or Diploma in Computer Science, Software Engineering, Statistics, Economics or equivalent degree or experience Expertise in R and other statistical programming languages (3+ years) Experience in Frequentist and Bayesian Statistical methods (2+ years) Experience working with Machine Learning algorithms, Probabilistic Models, and/or other statistical modelling approaches (2+ years) Experience with modern R packages such as dplyr, ggplot2, data table Experience in front-end R technologies for data products such as ShinyR, Flexdashboard Ability to write complex SQL queries Working knowledge of software engineering fundamentals and workflows Experience working with container orchestration platforms such as Kubernetes or Docker Swarm Cloud Computing Experience Interest in sports or betting data Authority to legally work in Canada An environment passionate about growth and learning Competitive salary with bonus Fitness subsidy program Free beverages in the office Workplace that is conveniently located along the Yonge/Sheppard line 
ScrapedJobID241:
Supervise and support our team of Research Interns. Develop tools, algorithms, machine learning models and automated systems that help identify high risk user generated content on social networks. Work closely with our Product and Engineering Team to turn models into products. Perform data exploration, statistical analysis, and model the ways that social networks can use our tools. Use insights to identify meaningful features and patterns. Create prototypes and experiments to test the viability of insights and demonstrate results to the Product Team. Partner with high profile clients to understand their data science needs Present and visualize data to communicate findings to non-data science team members and Executive Team Working with related deep-learning technologies (Python, TensorFlow, PyTorch) Working with cloud platforms (AWS/Sagemaker, Snowflake) Experience with Tableau is an asset Experience with Golang is an asset Permanent position, 40 hours/week Remote applicants are welcome 
ScrapedJobID242:
Provide insight into leading analytic practices, designs and leads iterative learning and development cycles, and ultimately produce new and creative analytic solutions that will become core work you're doing Work closely with business owners to find opportunities and serve as an ambassador for data science Design and deliver enterprise analytic solutions for customers Develop powerful business insights from social, marketing and industrial data using advanced machine learning techniques Build complex statistical models that learn from and scale to petabytes of data. Analytical thought leadership and staying ahead of developments in data mining and the application of data science Work independently as a senior lead and may manage and direct activities related to analysis, design and support of technical data management solutions on various projects ranging in complexity and size Generally accountable for a significant business management area that typically has enterprise wide impact or accountability Enterprise or functional expert, requiring broad managerial and deep specialized knowledge at the enterprise, business, regulatory and industry levels Undergraduate degree or technical certificate Seven (7) or more years of relevant experience 
ScrapedJobID243:
Work with our clients and partners to understand their business needs and requirements to define the project plan, deliverables, and acceptance criteria. Research state-of-the-art methods for a given task, implement and improve upon these techniques to provide the best possible solution for our clients through collaboration with other team members. Develop end-to-end machine learning and optimization solutions including data acquisition, preprocessing, design, training and debugging machine learning models. Interpret the results of the developed machine learning or optimization solutions in a comprehensible manner backed by data and presenting them to our clients and partners. Work with internal teams as well as customers to build and serve machine learning and optimization-powered APIs. A passion for the healthcare industry, as well as novel technologies such as AI and advanced computing. Master’s degree in computer science, engineering physics, electrical engineering, mathematics, or another technical discipline. 2+ years of industry experience building and deploying machine learning or optimization solutions for business applications and/or in production environments. Familiarity with data science and machine learning algorithms and tools (e.g., deep learning, random forest, support vector machines). Familiarity with machine learning frameworks, such as Tensorflow and scikit-learn. Highly proficient in Python programming. Familiarity with optimization algorithms and statistical methods. Experience with big data processing and database management. Experience with Git and related source control concepts. Ability to conduct research in an interdisciplinary environment, both independently and as part of a team. Proactively seek out opportunities to help move projects forward and contribute to their improvement. Excellent project management skills and the ability to adapt to a fast-paced, Agile environment with changing priorities. Strong communication and critical thinking skills. Excellent people and management skills in interacting with staff, colleagues, cross-functional teams and third parties. An eagerness to learn about new trends, tools, and technologies, and to continually consider how they will influence our products. Openness to receiving and giving feedback to elevate team performance. PhD degree in a related field. Familiarity with optimization packages such as Gurobi, or LocalSolver. Familiarity with heuristic and metaheuristic optimization techniques, such as tabu search, local search, and simulated annealing. 
ScrapedJobID244:
Working with project teams to address data science/computing challenges Identifying opportunities for technology to enhance service offerings Acting as a resource and participating in client engagements and research as part of the project team Maintaining up-to-date knowledge of computing tools, providing technical training and helping to grow the in-house knowledge base, specifically in a Linux environment Developing data engineering and machine learning production systems for full stack data science projects Using natural language processing methodologies to work with EMR data, social media data and other unstructured data Optimizing procedures for managing and accessing large databases (e.g., insurance claims, electronic health records, financial transactions) Creating interactive analytics portals and data visualizations (e.g., using R/Shiny, Python/Flask, D3) Building and maintaining high performance computing (HPC) tools on grid and cloud computing environments Developing and reviewing software and packages in R, Python and other Object Oriented Languages Establishing optimized procedures for repetitive or computationally intensive tasks (C, C++, Cuda-C) Pursuing an advanced degree is required, preferably in Computer Science, Data Analytics, Data Science, Economics, Mathematics, Statistics, or related subjects. Significant experience working within a Linux environment required, experience with Docker and front-end development using a Javascript framework (e.g., Vue.js, Angular) is highly preferred. Strong credentials and experience in database management and/or data visualization is preferred. Demonstrates strong interpersonal, written, and oral communication skills. Project experience with Python and/or R is preferred. Familiar with online/cloud computing/storage (e.g. Azure, AWS) is preferred. Demonstrated experience working on project teams and collaborating with others. Le masculin est utilisé ici en tant que genre neutre et sert uniquement à alléger le texte. Collaborer avec les équipes de projet pour relever les défis informatiques et liés à la science des données Identifier des façons dont la technologie peut améliorer l’offre de services Contribuer à l’activité et à la recherche du client en tant que spécialiste et membre de l'équipe de projet Maintenir les connaissances sur les outils informatiques à jour, former le personnel sur des points techniques et aider à développer la base de connaissances interne, en particulier dans un environnement Linux Développer des systèmes de production en ingénierie des données et apprentissage automatique pour des projets de science des données full-stack Utiliser des méthodologies de traitement automatique du langage pour travailler avec les données des DME et des médias sociaux et d’autres données non structurées Optimiser les procédures de gestion et d'accès aux grandes bases de données (déclarations de sinistre, dossiers de santé électroniques, transactions financières, etc.) Créer des portails d'analyse interactifs et des visualisations de données (en utilisant par exemple R/Shiny, Python/Flask, D3) Construire et alimenter des outils de HPC sur la grille informatique et l’informatique en nuage Développer et réviser des logiciels codés en R, Python et autres langages orientés objet Mettre en place des procédures optimisées pour les tâches répétitives ou gourmandes en calcul (C, C++, Cuda-C) Poursuivant un diplôme d'études supérieures exigé, dans l’idéal, en informatique, analyse de données, science des données, en économie, mathématiques, statistiques ou un autre diplôme scientifique pertinent accompagné d’une expérience professionnelle concordante. Expérience de travail significative dans un environnement Linux exigée ; une expérience du logiciel Docker et en développement frontal en JavaScript (Vue.js, Angular, etc.) est fortement souhaitée. Solides références et expérience dans la gestion de bases de données et/ou de la visualisation de données souhaitées. Excellentes aptitudes pour les relations interpersonnelles, la communication orale et écrite. Expérience de projets utilisant Python et/ou R souhaitée. Bonne connaissance de l'informatique en ligne/en nuage et du stockage (sur Azure ou AWS par exemple) souhaitée. Expérience avérée de travail au sein d'équipes de projet et de collaboration avec des tiers. Pour que votre candidature soit étudiée, vous devez soumettre une lettre de présentation, votre curriculum vitæ, et toutes vos relevés de notes officiels. 
ScrapedJobID245:
Conducts strategic data analysis, identifies insights and implications and make strategic recommendations, develops data displays that clearly communicate complex analysis Mines and analyzes data from various banking platforms to drive optimization and improve data quality Delivers analytics initiatives to address business problems with the ability to determine data required, assess time & effort required and establish a project plan Consults with business clients to determine system functional specifications. Applies comprehensive understanding of how multiple areas collectively integrate to contribute towards achieving business objectives Consults with users and clients to solve complex system issues/problems through in-depth evaluation of business processes, systems and industry standards; recommends solutions Leads system change process from requirements through implementation; provides user and operational support of application to business users Formulates and defines systems scope and objectives for complex projects through research and fact-finding combined with an understanding of applicable business systems and industry standards Impacts the business directly by ensuring the quality of work provided by self and others; impacts own team and closely related work teams Considers the business implications of the application of technology to the current business environment; identifies and communicates risks and impacts Drives communication between business leaders and IT; exhibits sound and comprehensive communication and diplomacy skills to exchange complex information Performs other duties and functions as assigned Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. 2-5 years experience using tools for statistical modeling of large data sets Ability to effectively use complex analytical, interpretive and problem solving techniques Analytical, flexible, team-oriented and has good interpersonal/communication skills Demonstrated influencing, facilitation and partnering skills Proficient in Microsoft Bachelor’s/University degree or equivalent experience 
ScrapedJobID246:

ScrapedJobID247:
In this role you will participate in developing system level end-to-end machine learning-based solutions for camera and computer vision applications running on AMD platforms Work with engineering teams cross technical functions, geographical regions and time zones, involving various facets of computer vision machine learning product Work closely with HW and SW teams and get your hands on a broad range of activities from solution design, software development, to optimization and deployment for Edge platforms Work closely with architecture teams to provide timely feedback and direction on various architectural design decisions Measure, analyze, and optimize power and performance for both application and system software/hardware stack Determine and implement unit testing and system level testing strategies Solid years experience with software engineering and C, C++ programming Experience with Machine Learning/Deep Learning frameworks like Tensorflow, Pytorch Good understanding of deep learning concepts like CNN, RNN/LSTMs Strong background in computer vision, computer system architecture, and algorithm design Effective communication skills, strong teamwork to join a global organization working cross geographical regions and time zones Experience with end-to-end software application development flow – from design to development to integration and testing Experience in developing computer vision algorithms using OpenCV and/or Deep Learning approaches Experience with system software (driver/OS level) on Android/Linux/Windows environment Experience of profiling and optimization techniques for software and system stacks Proven debugging and analysis skills, for root causing complex issues at both application and system level Experience with GPGPU compute like OpenCL, DirectX Compute Experience with camera architecture, camera APIs and other camera algorithms Experience in development of any of the deep learning compiler frameworks like TVM, Glow or XLA; or other LLVM-based compilers 
ScrapedJobID248:
Work closely with business subject-matter-experts to generate hypothesis, identify the data assets needed, and perform data analysis to test the hypothesis Identify areas of improvement for the business and new product opportunities Build proof of concept visualizations and iterate quickly to validate assumptions and/or test hypothesis with limited development time Become the subject-matter-expert of data assets across all J.D.POWER entities Collaborate cross functionally with Auto Consulting team, New Product Development team and other business units in the company Work in a team environment that encourages new input from everyone to build the best solutions Bachelor's degree in a quantitative field such as Mathematics, Statistics, Computer Science 5+ years of professional data analytics working experience. Experience with automotive data is a plus 2+ years of experience with database software (SQL, Google Bigquery etc) Proficiency in SQL and Python 2+ years of experience with Tableau and Excel 2+ years of experience working with large data Ability to start with vague business ideas to generate analysis that tells a story with key business insights and actionable recommendations Strong communication (verbal and written) and interpersonal skills Strong project management skills Ability to create both prescriptive and exploratory data analysis experiences Working knowledge of strategizing, analyzing, and recommending business solutions using automotive data Experience with publishing and maintaining workbooks on Tableau Server/Online 
ScrapedJobID249:
Own analytical frameworks that guide the product roadmap Design rigorous experiments and interpret results to draw detailed and actionable conclusions Develop statistical models to extract trends, measure results, and predict future performance of our product Build simulations to project impact of various product and policy interventions Enable objective decision making across the company by democratizing data through dashboards and other analytical tools Use expertise in causal inference, machine learning, complex systems modeling, behavioral decision theory etc. to shape the future of Instacart Present findings in a compelling way to influence Instacart's leadership 5+ years experience working in a quantitative role at a product company or a research organization Ability to run rigorous experiments and come up with scientifically sound recommendations Ability to write complex, efficient, and eloquent SQL queries to extract data Ability to write efficient and eloquent code in Python or R A desire to build and improve consumer software products Ability to translate business needs into analytical frameworks Eagerness to learn, flexibility to pivot when needed, savviness to navigate and thrive in a dynamic environment, and a growth mindset needed to build a successful team and company 
ScrapedJobID250:
Design, develop, test, advocate and build predictive models and segmentations Effectively communicate the analytics approach and how it will meet and address objectives to business partners. Advocate and educate on the value of data-driven decision making; focus on the "how and why" . Identify and develop long-term processes, frameworks, tools, methods and standards. Coordinate with different functional teams to implement data engineering, models and monitor outcomes Assists in the development of strategic plans. Understands and analyzes complex business problem, then formulates data-driven hypotheses to drive business value. Develops experimental design approaches to validate findings or test hypotheses. Diagnoses and resolves predictive / analytical model performance issues while monitoring system performance and implementation of efficiency improvements. Applies innovative and best practices to advanced analytics services to ensure high quality standards. Sets up change control and testing processes to ensure the quality and consistency of ongoing maintenance work. Develops analytical solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs. Works with various data owners to discover and select available data from internal sources and external vendors Applies scripting / programming skills to assemble various types of source data (unstructured, semi-structured, and structured) into well-prepared data sets with multiple levels of granularities (e.g., demographics, customers, products, transactions). Summarizes statistical findings and draws conclusions, presents actionable business recommendations. Presents findings & recommendations in a simple, clear way to drive action. Performs experimental design approaches to validate finding or test hypotheses. Supports development of tools and delivers training for data analytics and AI. Typically, between 5 - 7 years of relevant experience and post-secondary degree in related field of study or an equivalent combination of education and experience. Advanced degree (Master/Ph.D. preferred) in Computer Science, Mathematics, Physics, Engineering, Statistics, or other quantitative disciplines and/or equivalent experience Experience with distributed computing language & cloud technologies Experience with programming languages and machine learning /deep learning algorithms/packages, supervised learning, clustering, natural language processing, recommender engines, time series analysis, A/B testing, network/link analysis, sentiment analysis and data visualization. Deep proficiency in statistical analysis, quantitative analytics, forecasting/predictive analytics, multivariate testing, and optimization algorithms. Deep knowledge and technical proficiency gained through extensive education and business experience. Competitive salary and benefits package Associate discount up to 40% including top brands Flexible work environment that allows for work-life balance 
ScrapedJobID251:
Provides expertise in designing statistical methodologies and project execution support for standard and custom studies, moderately following guidelines While part of a team of experts:
Performs regular statistical method design, analysis and programming activities with moderate supervision
Performs statistical methodology and analytical work following standards and guidelines to ensure quality and relevance of derived insights, following moderate instructions from manager and senior members of the team
Supports existing methods enhancements, statistical quality control methods, ad-hoc requests and data investigations of moderate complexity
Provides some level of leadership input into protocol, validation plan, report, and analysis plan
Derives conclusions from assigned complex studies and investigations, prepares written summaries and reports study results with proper data visualization expertise under moderate supervision
Interprets data and insights with proper business meaning, draws conclusions and provide statistical recommendations on client actions following review with manager Performs regular statistical method design, analysis and programming activities with moderate supervision Performs statistical methodology and analytical work following standards and guidelines to ensure quality and relevance of derived insights, following moderate instructions from manager and senior members of the team Supports existing methods enhancements, statistical quality control methods, ad-hoc requests and data investigations of moderate complexity Provides some level of leadership input into protocol, validation plan, report, and analysis plan Derives conclusions from assigned complex studies and investigations, prepares written summaries and reports study results with proper data visualization expertise under moderate supervision Interprets data and insights with proper business meaning, draws conclusions and provide statistical recommendations on client actions following review with manager Gathers recommendations from others to identify appropriate data sources and delivery options whilst meeting client information and analyses needs Initiates improvement recommendations and alternative solutions for problem solving Under moderate guidance from manager, supports new offering development by outlining statistical requirements based on overall project objective, translates client business needs into requirements, and specify statistical analysis plan accordingly Works on components of projects of moderate scope within defined procedures and practices Progressively manages own project timelines, can identify risks and provides mitigation alternatives to manager With moderate help from manager, can handle multiple projects, and manage priorities accordingly Helps manager develop project plan of bigger scope Participates to internal cross-functional meetings of moderate scope with other members of the stats team or alone, and provides moderate level of insights Develops and maintains relationships with key cross-functional stakeholders Participates in internal initiatives e.g. knowledge sharing Supports more senior staff on specific business initiatives as required Develops ability to provide on-the-job coaching and knowledge sharing to more junior staff when appropriate Bachelor’s or Master’s degree or equivalent in Statistics, Mathematics, Operational Research or related field with a strong focus on quantitative analysis, including an acceptable number of courses in statistical methods and theory, with a minimum of two (2) years of relevant experience with large databases and systems Technical knowledge/skills include: multivariate analysis, regression analysis, forecasting, probability and survey sampling Excellent knowledge of SAS programming language on multiple environments (PC environment required, UNIX/mainframe an asset). Knowledge of SQL is also required Additional Knowledge of Python (or R) and big data tools such as Cloudera, Spark and Hadoop (an asset) Understanding and experience of classical machine learning and deep learning methods (an asset) Proven ability to carry out moderate to complex level analyses and information gathering to resolve problems on non-routine matters Proven ability to program statistical methodologies according to specifications, with emphasis on quality control, testing, and operational efficiencies 
ScrapedJobID252:
Provide expert input on architecture of Tonal's learning systems Architect and build our machine learning and computer vision solutions Identify innovative opportunities for deep learning and computer vision Advanced degree in mathematical field or equivalent experience 3+ years of research or engineering experience in one or more of the following: generative models (GANs, VAE, Glow), segmentation, object detection, classification, tracking, NLP, or other related applications of machine learning 2+ years of industry experience as a data scientist Deep learning, especially generative models, e.g, GANs, Image-to-Image translation Industry or project experience with deep learning frameworks (e.g. PyTorch, TensorFlow, Caffe2) Team player with high integrity Experience working on a team where feedback is routinely shared as a mechanism for professional development High degree of self-awareness Have worked on a distributed team across different geographies Experience with gyros and accelerometers Experience with deepfake technology Experience as a software engineer 
ScrapedJobID253:
Accountable for the manipulation of complex and extremely varied data sets within Air Canada and external sources to solve real world problems Design, develop and evaluate innovative models, data science products and solutions for internal clients as well as for our data science team Oversee the day-to-day operations including the testing and maintenance of data science solutions Write highly optimized code to advance our internal Data Science Toolbox and practice Work in a multi-disciplinary environment with specialists in machine learning, data engineering and design and provide acquired expertise in these areas Ensure the optimization of data science models, including feature selection and build, using different techniques in the data science toolbox Accountable for the integrity of Air Canada's data extended to third party sources Ensure the continued enhancement of data collection procedures, including information that is relevant for the building analytical solutions Accountable for the integrity of data used for analysis and modeling Develop automated processes for large scale data analysis Provide technical guidance to junior members of the team Mandatory Covid-19 Vaccination Required as of October 31st 2021 MSc or PhD level in the field of Computer Science, Machine Learning, Applied Statistics, or Mathematics 5 to 9 years of experience as a data scientist or in a similar role Experience in statistical modelling and machine learning techniques Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc. Experience with common data science toolkits, such as Scikit learn, XGBoost, Numpy, fbprophet, etc Experience with cloud machine learning tools (Azure ML, databricks), an asset Programming experience in at least two of the following languages: R, Python, Scala, SQL Experience in applying data science methods to business problems Experience in applying advanced analytical and statistical methods in the commercial world Strong presentation and communication skills, with the ability to explain complex analytical concepts to people from other fields Knowledge of distributed computing language such as pyspark Experience with data visualization tools such as plotly, seaborn, matplotlib, etc. Proficiency in using query languages such as SQL, Hive, Pig Experience with NoSQL databases, such as MongoDB, Cassandra, HBase Good applied statistics skills, such as distributions, statistical testing, regression, etc. Good scripting and programming skills Data-oriented personality Candidates must be eligible to work in the country of interest, at the time any offer of employment is made and seeking any required work permits/visas or other authorizations which may be required is the sole responsibly of the candidates applying for this position. 
ScrapedJobID254:
Formulate the information requests; performing queries and data extraction from relevant databases, checking data quality; analysis and modelling; interpreting the data; preparing reports and visualizations; and presenting the information and findings for administrative and operational decision making. Checking for data quality throughout the continuum, statistical analysis, and generating routine and ad hoc reports for internal and external stakeholders including but not limited to PHSA, the Ministry of Health (MoH), care providers in the BC Health Authorities, Canadian Blood Services, and the Public Health Agency of Canada. Demonstrated ability to perform data manipulation, analysis and information presentation at a moderate to advanced level through the use of database, spreadsheet and statistical software. Moderate to advanced data management skills and a high degree of computer literacy are required. Superior analytical and problem solving skills, including the ability to troubleshoot, comprehend, analyze and resolve complex issues. Moderate to advanced knowledge of relational database modeling and query writing tools to create ad-hoc queries and reports. Demonstrated ability to develop complex and customized SQL queries for relational databases, with applied experience with business intelligence tools (ex: Tableau, IBM Cognos, SAP BusinessObjects). Knowledge of descriptive statistics, statistical inference and modeling using statistical software such as SPSS, R and/or SAS. Demonstrated ability to communicate effectively both verbally and in writing. Strong interpersonal skills and collaboration skills and the ability to establish and maintain effective working relationships internally and externally. Excellent organizational skills, attentive to detail with the ability to multi-task and prioritize workload and work quickly and accurately under pressure to meet deadlines. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID255:
Setting strategies for data collection, maintenance, analysis and utility of insights Identifying business problems to solve with data-driven approaches Overseeing machine learning, AI and algorithmic development that automates various aspects of our deal operations and portfolio operations workflows Analyzing sales, marketing, logistics and other operational data to generate insights on opportunities for improvement Design and implement algorithms to tackle a wide variety of datasets using open source libraries, third party API's and in house developed algorithms Analyzing marketplace data to identify potential opportunities for acquisition Reporting on patterns and insights to cross-functional teams of M&A professionals, operators, and e-commerce brand founders Establish partnerships with technology and data vendors that aid in accomplishing Moonshot's analytics strategy Identify opportunities for continuous improvement to processes and propose solutions to be implemented Foster effective dialogue with cross-functional teams to facilitate processes. Anticipate needs and challenges and provide seamless solutions Ensure all activities are in compliance with applicable rules, regulations, policies and procedures Additional responsibilities as requested 5+ years of proven experience as a Data Scientist, similar role or career progression. Experience working as a data scientist in CPG/Retail/e-Commerce companies Deep knowledge in statistics, Machine Learning and Time Series Forecasting/Analysis Knowledge of data management, data engineering and visualization techniques Experience in writing complex SQL queries and working in a multi-database environment Relevant scientific academic background - ability to read and implement insights from academic papers Knowledge in building production-ready code (Object Oriented, Design Patterns etc.) - a plus Experience with Big Data technologies such as Spark, Hadoop, Hive - a plus Experience in building NLP models incl. relationship extraction, entity extraction, topic modelling etc. - a plus Bachelor's Degree in Computer Science, Engineering, or related field required Detail-oriented with strong analytical abilities Excellent mathematical, writing, verbal and computer skills Ability to adapt to new tasks with little notice Effective leadership and coaching skills Strong desire to win Sound judgement Deep, sophisticated understanding of accounting and finance Commitment to satisfying internal and external customers 
ScrapedJobID256:
Thrive on challenges and work best in a fast-paced environment where each day is different Work well in a project team environment and have strong collaboration and interpersonal skills Have a permanent “figure it out” mindset Work closely with clients in understanding key business issues. Gather and analyze requirements to develop impactful recommendations and solutions. Utilize advanced analytical techniques to solve challenging business problems. Leverage a diverse set of technologies and tools to deliver insights. Problem solving ability through the use and/or development of algorithms, models, testing, etc. Propose and develop results, models and rules engines using statistics, machine learning, Natural Language Processing, Linear Programming, etc. Work with large volumes of data (structured and unstructured). Architect the data platform models for scalability, repeatability and performance to build data solutions Investigate and perform deeper analysis to produce impactful algorithms to achieve targeted outcomes. Perform quantitative analysis of data issues. Effectively communicate orally and written with peers within Data & Analytics teams, KPMG and the client. Education and professional working experience in math, statistics, operations research, engineering, computer science or econometrics. Expert knowledge in advance modeling techniques and mathematical models, algorithm use and optimization, and data science technologies. Understand the full spectrum of data feature retrieval, selection, and engineering; model technique selection, model build, implementation, monitoring and integration; interpretation of outputs, and development of recommendations. Capable of identifying commonalities across seemingly disparate analytics use cases, in order to identify unique ways of approaching modeling. Strong experience in advanced analytics, statistics, data mining, predictive analysis, time-series analysis, natural language processing and deep learning. Proficient at SQL, Python or R and popular ML frameworks and libraries. Experience in mainstream cloud services: such as AWS, MS Azure, GCP and their data analytics, ML tools. Identify and present opportunities with new and existing clients that align with KPMG services to the appropriate partner. Manage the efficient and effective delivery of every engagement, producing high quality deliverables and delivering work on time, on budget and within project parameters and client expectations 
ScrapedJobID257:
Use predictive analytics to increase and optimize customer experiences, increase revenue generation, optimize operations, and to drive other high value business outcomes. Feature selection and engineering Work with business leaders throughout the organization to identify opportunities for leveraging company data to drive business solutions. Identify opportunities for improved data collection (including third party data) and working with businesses to make these reforms Model deployment and lifecycle management to monitor performance and maintain accuracy of results Build data visualizations where appropriate Three or more years’ experience in the identification of advanced analytics opportunities and the execution of advanced analytics projects with emphasis on developing, deploying, and maintaining advanced analytics solutions that optimize operations, reduce risk, and or prescribe outcomes Relevant educational background, e.g., Mathematics, Statistics, Computer Science, Economics, Engineering, or an applied science Supervised learning and unsupervised learning techniques Data science toolkits, such as R, Python, Tensorflow, MatLab, etc Excellence in at least one of these is highly desirable Experience with MLOps Data visualization with tools such as Tableau, PowerBI, or equivalent Proficiency in using query languages such as SQL Experience with NoSQL databases an asset, eg CosmosDB or Mongo Applied statistics skills, such as distributions, statistical testing, regression, etc. Strong problem-solving skills with an emphasis on product development Experience working with a variety of data architectures Customer focused: motivated by inspiring others to do things differently Technically inclined, process oriented and driven by a natural curiosity Happy in an environment where you can work independently as well as collaboratively A continuous learner: acquiring new skills is second nature A practiced communicator with strong verbal, written, and interpersonal skills Results driving with the ability to explain complex concepts intuitively 
ScrapedJobID258:
Design, train and evaluate models. You will solve challenging drug discovery problems by designing fit-for-purpose ML and statistical models and data splits from our massive in-house datasets – more than 8PB of cellular image data, and growing chemical, transcriptomic, and proteomic datasets – and training these models using our on-premise NVIDIA A100 superpods. You'll collaborate with biologists, chemists, automation engineers, data engineers, and other scientists to refine these models, possibly generating more data in the process, until they provide a reliable productionized solution. Create maps of biology. You will be an essential part of achieving Recursion's mission to decode biology and radically improve lives by turning our massive datasets into maps of human disease biology that allow drug hunters to quickly and accurately navigate to optimized small molecule therapies for hundreds of diseases. Share your work. You will represent Recursion to the scientific community by presenting your work at top conferences and publishing in top scientific journals. Define excellence in execution. You will use your technical knowledge to set a high standard of delivery, impact, learning, and growth across teams at Recursion. PhD in Computer Science or related quantitative field or the equivalent practical experience. 2+ years of hands-on experience applying modern machine learning methods to solve real-world problems. Experience applying modern ML and statistical methods to large datasets and reasoning about the outcomes. Experience with microscopy/biomedical imaging data, chemical data, or genomic data is a plus. A working knowledge of the drug discovery process is a huge plus. Extensive experience using modern technologies to accelerate machine learning (e.g. PyTorch, TensorFlow/Keras, Horovod, etc) Outstanding past projects, publications, and presentations, and a demonstrated ability to communicate results to cross-functional stakeholders. Curiosity and the professional skill-set to excel in an open, highly collaborative environment. 100% Coverage of health, vision, and dental insurance premiums 401(k) with generous matching (immediate vesting) Stock option, restricted stock unit (RSUs) and employee stock purchase plan (ESPP) programs Two one-week paid company closures (summer and winter) Flexible vacation/sick leave Generous paid parental leave (including adoptive) Onsite daycare facility** (Salt Lake City) Commuter benefit and vehicle parking to ease your commute** Complimentary chef-prepared lunches and well-stocked snack bars** (Salt Lake City) Monthly fitness/wellness stipend One-of-a-kind 100,000 square foot headquarters complete with a 70-foot climbing wall, showers, lockers, and bike parking** (Salt Lake City) 
ScrapedJobID259:
HOOPP Pension Plan (Defined Pension) Retirement Planning Program Generous vacation days for permanent and long-term contracts Work-life balance Career Planning Program Learning and Professional Development Program Flexible benefits program from your first day on the job for permanent and long-term contracts Strong problem solving skills, with an emphasis on developing products and services to support stakeholder business decisions. Strong organizational skills with a demonstrated ability to manage multiple tasks and priorities. Strong interpersonal and presentation skills are essential, including the ability to communicate (both orally and in writing) complex ideas in simple terminology. Proven ability to work as part of a team, and to work with minimal supervision. Teaching experience in higher education is an asset. Experience with federal, provincial, or hospital healthcare datasets is an asset. Familiarity with AWS, Google Cloud, or Microsoft Azure is an asset. Understanding of Canada's federal and provincial healthcare systems is an asset. Fluency in English required, bilingualism is an asset Undergraduate degree in Mathematics, Statistics, Biostatistics, Economics, Computing Science, Data Science, or related field or equivalent experience. Graduate degree is an asset. A minimum of three years’ experience in data engineering and/or data science, including either (1) data architectures and pipelines or (2) statistical and machine learning. Relevant tools and techniques may include SQL, Air Flow, gradient boosting, and neural networks, etc. Extensive working experience with Python or R to manipulate data and draw insights from datasets. Experience with SAS is an asset. une structure salariale concurrentielle un régime d'avantages sociaux flexible dès le premier jour de travail l'adhésion au régime de retraite HOOPP un programme de planification de la retraite un équilibre travail-vie personnelle un programme de planification de carrière des programmes d'apprentissage et de perfectionnement professionnel Solides aptitudes pour la résolution de problèmes, plus particulièrement en ce qui concerne l’élaboration de produits et de services visant à soutenir les décisions opérationnelles des intervenants. Excellentes aptitudes pour l’organisation et capacité manifeste à gérer de multiples tâches et priorités. Entregent et excellentes aptitudes pour la présentation, dont la capacité à vulgariser des concepts complexes (de vive voix et par écrit), essentiels. Capacité manifeste à travailler au sein d’une équipe et avec un minimum de supervision. Expérience de l’enseignement universitaire, un atout. Expérience d’ensembles de données sur les services de santé à l’échelle fédérale, provinciale ou des hôpitaux, un atout. Connaissance d’AWS, de Google Cloud ou de Microsoft Azure, un atout. Compréhension des systèmes de santé fédéral et provinciaux au Canada, un atout. Maîtrise de l’anglais essentielle; maîtrise du français, un atout. Diplôme de premier cycle en mathématiques, en statistique, en biostatistique, en économie, en informatique, en science des données ou dans un domaine connexe, ou expérience équivalente. Diplôme d’études supérieures, un atout. Au moins 3 années d’expérience en ingénierie des données ou en science des données, y compris (1) en architectures et pipelines de données ou (2) en apprentissage statistique et automatique. Les techniques et les outils pertinents peuvent inclure SQL, Airflow, le renforcement de gradient et les réseaux neuronaux. Vaste expérience de l’utilisation de Python ou de R pour manipuler des données et tirer des conclusions des ensembles de données. Expérience de SAS, un atout. 
ScrapedJobID260:
Lead discovery and assessment of data portfolio, data tools, and data applications by; Guide and support project teams in development and implementation of data management and analytics services by: Contribute to the vision for a platform of user-centric services, particularly as it relates to the use of common data components and services that can improve and accelerate service delivery. Contribute to the development of principles, metrics, and standards for service and program quality and delivery. Contribute to the development and deployment of data solutions in cloud, using services such as Amazon Web Services (AWS), Google Cloud Platform (GCP), and Microsoft Azure. Contribute to the development and deployment of database solutions using common tools (e.g. SQL. NoSQL). Contribute to data analytics and reporting through the use of common tools and languages for applied statistics, data analysis, and machine learning (e.g. Python, R, Matlab, and SPSS) Monday to Friday lead data science/analytics work: digital/nondigital service: 2 years (required) analytics, data visualizations, data modeling & storytelling: 2 years (required) working with cross-functional teams to align vision & needs: 2 years (required) working in a complex enterprise environment ( >10,000 staff): 2 years (preferred) agile projects in a public sector organization: 2 years (preferred) web development and digital product design: 2 years (preferred) providing analytic support to UX, UX or service design teams: 2 years (preferred) quantitative research methods such as surveys: 2 years (preferred) lead discovery/assessment of data portfolio/tool/application: 2 years (required) support dev & implementation of data management & analytics: 2 years (required) develop & deploy cloud data solutions using AWS, GCP & Azure: 2 years (preferred) dev & deploy data solutions to cloud using AWS, GCP, & Azure: 2 years (preferred) develop & deploy database solutions via SQL, NoSQL, etc.: 2 years (preferred) data analytics & reporting via tools (Python,R,Matlab,SPSS.): 2 years (preferred) Temporarily due to COVID-19 
ScrapedJobID261:
Develop the best suitable ML and NLP models or algorithms for various Zoom products such as task-oriented dialogue systems, Zoom meeting/phone/chat intelligence products; Research and investigate the latest technologies, then create and customize ML/DL models for conversation AI, information extraction, classification, sentiment analysis, text segmentation, topic modeling etc; Collaborate with various teams including offshore teams, exchange ideas, communicating requirements, providing technical guidance, code review. Participate in production integration and deployment, and result evaluation. Ph.D in NLP, NLU, Machine Learning, Computer Science or a related technical field; Experience in conversation AI and task-oriented dialogue systems; Expertise knowledge in NLP such as text classification, sentiment analysis, topic modeling, text summarization, ranking, text similarity, tokenization, word/sentence/doc embedding, NER, POS (Part-Of-Speech) tagging and parsing, intent detection, slot filler, dialog flow, KB graph, etc; Ability to understand the latest research paper in ML/DL/NLP, reproduce published result, build and customize the model for specific use cases; Hands-on experience in text pre-processing and normalization techniques, such as tokenization, word embedding, NER, POS (Part-Of-Speech) tagging and parsing and how they work at a low level; Expertise in machine learning, deep Learning (CNN, LSTM, XLNet, GPT, BERT or other transformer based models), meta learning, few shot learning, transfer learning etc; Hands-on experience on developing and training models with large-scale text data; Experience with open-source ML / DL / NLP toolkits such as TensorFlow, Caffe, PyTorch, CoreNLP, OpenNLP, StanfordNLP, SpaCy, AllenNLP, NLTK, gensim, etc. Prefer candidates with publications in top-tier venues such as ACL, EMNLP, NAACL, NeurIPS, ICLR, ICML etc; Experience in frontier topics such as meta-learning, multimodal learning, multilingual models, reinforcement learning is highly desirable; Industry experience in machine learning applications in production is preferred; Strong analytical skills and attention to detail. Strong mastery of Python or other programming languages, and general software development skills (source code management, debugging, testing, deployment, etc.); Mastery in English language. Deep understanding of English linguistics; Mastery in one or more non-English languages. Hear from our leadership team Browse Awards and Employee Reviews on Comparably Visit our Blog Zoom with us! Find us on social at the links below and on Instagram 
ScrapedJobID262:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID263:
Teach our 12-week Data Science Diploma program Help build a world class technical team passionate about designing and teaching Deliver lectures and provide expert technical guidance to students who are building exciting projects using the most cutting-edge technologies Facilitate in-class activities, group discussions, demos and mentor the next wave of emerging talent Co-create BrainStation's curriculum that will positively impact the lives and careers of hundreds of individuals across our campuses Actively work on writing and researching new content to teach the most up to date design skills to our students Apply BrainStation's "Agile Education" methodologies to the program to continuously improve the educational experience for students Constantly improve your own skills and apply these skills in collaboration with other BrainStation Educators in order to build the digital platform and tools needed to effectively deliver educational material Define the education experience of the future 3-5+ years experience as a Data Scientist or Analytics professional and a Bachelor's degree relevant to the subject matter OR 8+ years work experience in the vocation Strong command of querying and programming languages (SQL, R and python - numpy, pandas, sklearn, TensorFlow & Keras), and visualization tools (Excel, Tableau, matplotlib/seaborn/plotly in python packages Experience applying various methods of numerical and categorical modelling techniques and supervised and unsupervised machine learning methods (OLS regression and GLMs, logistic regression, KNN, SVM, decision trees/random forest, clustering and cluster analysis, dimensionality reduction, neural networks) Hands-on development experience working with version control systems (we use Git) and Big Data and Cloud platforms (Hadoop, Spark, Amazon Web Services (AWS), Google Cloud (GCP)) a strong asset regression and machine learning principles Practical experience designing and applying data science processes to conduct experiments using a variety of tools and methods, and can speak to their complexities in a simple and logical manner Experience building and leading technical teams Experience in a teaching role, and are comfortable speaking to large groups and mentoring others on the job A strong work ethic with the utmost integrity and desire to excel and succeed An empathetic, inclusive, enthusiastic personality, and is someone who enjoys helping others and facilitating learning A passion for teaching and mentoring others and creating positive learning experiences Comprehensive Health & Wellness Benefits Package Retirement Planning Parental Leave Program New Device Allowance Socials, Outings & Retreats Culture of Learning & Development Flexible Working Hours Work from Home Flexibility 
ScrapedJobID264:
Identify data integration patterns appropriate to the business context. Perform data profiling and assess the feasibility and challenges of integration. Identify metrics, management and performance indicators. Write and analyze data mapping. Contribute to the development of the enterprise data warehouse model and the architecture of the data management platform. Identify and recommend system improvement opportunities. Propose solutions, action plans and evaluate alternative solutions. Collaborate with data engineers and data architects to implement needed data pipelines for data science-related features and a robust data ecosystem. Bachelor's degree or DEC in computer science or another relevant discipline; Excellent competencies with BI tools like Power BI and Tableau; Have a good understanding of ETL tools and processes; Minimum of 5 years experience in the BI analyst role; Understanding of business intelligence tools and methods; Experience in relational and dimensional modeling; Fluency in French and English, both written and spoken; Good communicator, resourceful, autonomous, good analytical skills, and good team spirit. Diverse and stimulating projects Flexible hours Full group insurance coverage Charging days in addition to vacation time! 
ScrapedJobID265:
Research and implement state of the art NLP/NLU techniques to solve real world problems; Work in collaboration with researchers, Applied ML Specialists, Vector professional staff, and collaboration partners to build demos, minimum viable products (MVP), and prototypes; Provide scientific advice regarding overall machine learning application strategies and roadmaps; Provide scientific oversight for Vector-led or co-led efforts to prepare specific datasets for machine learning research; Serve as the lead Vector scientific contributor for health, industry, and responsible AI projects including contributing to or leading the authoring of peer-reviewed research papers; Contribute to training sessions and other initiatives for Vector staff and stakeholders that help increase AI knowledge and the capacity of the system to recognize and act on opportunities to apply machine learning; Serve as an expert and facilitate identification of experts among the Vector research community for external stakeholders (e.g., health and other sectors) to advise on machine learning research trends and applications; and, Other duties as assigned. PhD degree in computer science or computer engineering with a research focus on NLP preferred Demonstrated expertise in one or more of Nature language processing (NLP) or Natural language understanding application domain like speech recognition, text summarization, entity recognition, information retrieval and language generation Demonstrated experience applying machine learning research to novel problems and data sets Experience with software engineering and/or data engineering is considered an asset Strong knowledge and experience of Python Experience with parameter and architecture tuning of deep learning algorithms is considered an asset Experience using open-source deep learning software frameworks (PyTorch, Tensorflow, JAX, or CUDA) 
ScrapedJobID266:

ScrapedJobID267:
Fully understand our business model and how business operations translate in our existing data points (data sources and dashboards). Responsible for Insights presentations, from understanding business trends to extracting the right information and clearly presenting insights in a visually friendly way. Communicate with key stakeholders to collect and compile business requirements for the data science practice (ex. Dashboard visualizations, custom calculations, etc.). Conduct stakeholder interviews to ascertain business problems and understand business trends. Collaborate with other supporting areas (sales, website, content, marketing automation, etc.) to enrich and contextualize insights. Understand the existing data architecture and recommend changes based on stakeholders' requirements. Extract, Load, and Transform Data (ETL) and develop reports for assigned projects, including the use of SQL, Python (numpy/pandas), Excel (pivot tables, lookups, advanced formulas, etc.), and Tableau/Power BI. Develop interactive dashboards, reporting, and visualizations to provide insights and make recommendations. Use advanced data visualizations techniques to provide a concise and compelling summary of analysis findings in reports and presentations. Gather requirements from stakeholders and automate existing manual reports (mainly in Excel). Develop and deploy predictive models to forecast billings (such as Marketing Mix Modeling), propensity model, long term value (LTV) and churn rates. Be able to present technical procedures concepts and results (such as Machine Learning) in a simplified way. Understand technical requirements to upskill the Analytics practice and work with IT/BI for implementation. Work with third-party vendors to ensure seamless integration of new data sources with Sophos databases (Snowflake). Maintain accurate documentation of reporting processes and monitor for failures. Be resilient, open-minded, and search for alternative solutions if needed to reach the final objective. Bachelor in Mathematics, Engineering, Statistics or Economics, although candidates with outstanding logical reasoning will also be considered. Snowflake SQL knowledge such as grouping, joins, create tables and nested queries. Strong understanding of how visualization tools work (Tableau, Power BI, Data Studio), and their advanced features including calculated fields, parameters, table calculations, joins, data blending, and dashboard actions. At least 3 years of experience in generating insights and communicating to different levels of an organization. Ability to work in a time-sensitive environment and multi-task. Excellent communicator with creative data storytelling and delivering insights. Able to independently search for technical solutions using search engines (know how to query). A masters` degree is an asset. Background in Digital or B2B Marketing desirable. Experience in the Cybersecurity industry is an asset. Our people are what makes Sophos special – we demonstrate shared vision, talent, innovation, and creativity, all of which are accompanied by a great sense of fun and team spirit. Employee-led diversity and inclusion groups that build community within Sophos and provide internal education and advocacy (eg. Sophos Women in Tech group to improve gender parity, encourage gender-balanced leadership, and support career progression at Sophos) Sophos Environment Network and employee challenges to contribute to sustainability and reduce our environmental footprint Annual commitment to charity and fundraising across our global sites and volunteer days for employees to give back to local communities Global trivia competitions to keep our minds sharp Global Mental Health days off work for all Sophos to help employees relax and recharge Monthly employee wellbeing webinars and training to support employee health and wellbeing Employee rewards and thanks, such as our free annual subscription to Calm 
ScrapedJobID268:
Develop innovative solutions for trend recognition using machine learning and advanced statistics Transform complex databases into relevant conclusions and recommendations Keep pace with new approaches and trends and use them in your own solutions Help maintain our data mining tools and platforms Make actionable recommendations based on the findings Work with other departments to promote the adoption of analytical principles within the organization Validate the quality of the analytical approach and project outputs of the other team members Your Master’s degree in a relevant discipline (mathematics, science, engineering, operational research, economics, statistics, AI, computer science or a related field) Your 5 years of experience in the field of advanced statistics, data mining and text mining A multi-platform production experience with the following commercial and open-source data mining frameworks: Open-source frameworks: R, Python, GitHub Expert-level understanding of the underlying theory of machine learning Expert-level understanding in either computer image analysis, natural language processing or artificial intelligence Your enthusiasm for teamwork Your ability to focus on vaguely defined issues requiring the application of a creative approach Your strong communication, time management and work organization skills An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career Flexibility in how and where you work A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A casual ‘dress for your day’ culture that encourages you to be yourself A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID269:
Write SQL queries to gather real-time data on our recruiting pipeline, so that we can provide our data science, marketing, finance, and people teams with evidence to support key decisions and major company-wide initiatives Lead data quality and issue investigations for HR/recruiting data, and collaborate with stakeholders across the company to fix them Assist with the automation of the creation, data validation, and distribution of mission critical reports across the company Work with data science team to build data models within our business intelligence tools (Looker and Tableau) 0-2 years of experience working at a finance or technology company in an analytical function. Proficiency in writing SQL Prior experience in working with Python a plus. Strong Excel skills, prior experience working with VBA a plus Familiarity with some kind of business intelligence or data visualization tool (Looker, Tableau, DOMO, PowerBI, etc.) You have the ability to recognize data patterns and understand when a particular field or table is not in line with business expectations. 
ScrapedJobID270:
Design and implement bioinformatic data pipelines to meet objectives of the project Work with other project team members to develop and test code, and implement analysis Evaluate and incorporate third-party software into pipelines Produce thorough but concise written documentation of experiments, algorithms, validations, and other procedures as required. Graduation from a recognized Bachelor of Science Program in Computer Science or relevant program. A Master’s degree in a relevant field would be a strong asset. Two (2) years of recent related experience or an equivalent combination of education, training, and experience. Expertise with scientific programming and able to provide links to code samples via GitHub Familiarity with molecular and cellular biology Excellent verbal and written communication skills Demonstrated ability to interpret results Comfortable working in a Unix environment, including experience with shell scripting and common command-line tools Established ability to efficiently organize work assignments and establish priorities Demonstrated interpersonal skills including the ability to work effectively with others in a team environment. Familiarity in statistical analysis using modern computational tools (experience with any relevant tools will be considered, but R and Python are preferred) Familiarity in next-generation sequencing datasets Understanding of cancer biology Functional knowledge of distributed version control systems, such as SVN or GIT 
ScrapedJobID271:
Diriger l'analyse fonctionnelle et technique au sein des entreprises Ericsson et pour les clients stratégiques afin de comprendre les besoins et les opportunités des entreprises basées sur les systèmes d'information. Permettre le développement rapide et itératif d'une solution minimale viable validée répondant à ces besoins. Cela implique de travailler avec des pétaoctets de réseaux 4G/5G, des données IoT et exogènes, et de proposer/sélectionner/tester des modèles prédictifs, des moteurs de recommandation, des systèmes de détection d'anomalies, des modèles statistiques, des systèmes d'apprentissage en profondeur, d'apprentissage par renforcement et autres systèmes d'apprentissage machine. Mener des études et utiliser de manière créative des sources de données nouvelles et/ou existantes. Travailler avec les architectes de données pour exploiter les modèles de données existants et en créer de nouveaux selon les besoins. Collaborer avec les équipes de développement de produits et les partenaires des entreprises Ericsson pour industrialiser les modèles et solutions d'apprentissage machine dans le cadre des offres Ericsson, notamment en fournissant le code source, les flux de travail et les documents. Travailler avec les nouvelles technologies et les promouvoir au sein des communautés d'entrevue de motivation d'Ericsson. Contribuer au renforcement des compétences en matière d'entrevues de motivation au sein des entreprises et des unités de service à la clientèle d'Ericsson. Élaborer de nouveaux concepts, méthodologies et techniques, et appliquer ou développer les concepts, méthodologies et techniques existants pour les projets interfonctionnels. Une maîtrise ou un doctorat en ingénierie électrique, en informatique, en intelligence artificielle, en apprentissage machine, en physique ou dans un domaine connexe Expérience pratique : Plus de 2 ans d’expérience d'apprentissage automatique dans le domaine de la science des données. Une expérience confirmée dans la rédaction de logiciels de production Une grande expérience dans le développement de modèles et la gestion du cycle de vie dans un ou plusieurs secteurs d'activité/applications De solides compétences en programmation dans divers langages (C++, Scala, Java, R) et une maîtrise de Python ou C++ Des compétences confirmées en apprentissage automatique, par exemple en analyse discriminante par régression linéaire/logistique, ensachage, forêt aléatoire, modèle bayésien, MVC, réseaux neuronaux, etc. De solides compétences dans l'utilisation des cadres d'apprentissage automatique de pointe actuels tels que Scikit-Learn, H2O, Keras, TensorFlow and Spark, etc. La capacité confirmée à mettre en œuvre de nouveaux algorithmes et de nouvelles méthodologies issus d'initiatives et de documents de recherche de premier plan sur les logiciels libres et portant sur leurs fonctionnalités, leur évolutivité et leur viabilité globale d'industrialisation Des connaissances en statistiques, telles que l'analyse descriptive et l'analyse supervisée et non supervisée Une certification IM de MOOC, un atout Des applications et des connaissances spécialisées en télécommunications ou en IdO, un atout La capacité à travailler de manière indépendante avec beaucoup d'énergie, d'enthousiasme et de persévérance Une bonne aptitude à communiquer en anglais écrit et parlé Une capacité à travailler dans un environnement de collaboration, notamment à travailler avec des unités commerciales complexes à parties prenantes multiples, des clients mondiaux, des partenaires technologiques et d'autres partenaires de l'écosystème dans une organisation matricielle mondiale multiculturelle, avec tact et persévérance Conduct functional and technical analysis within Ericsson organization and strategic customers to understand MI-driven business needs and opportunities Contribute to rapid and iterative development of validated minimum viable solution addressing these needs. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical model, deep learning, reinforcement learning and other machine learning systems Conduct studies and find creative usage of new and/or existing data sources. Work with Data Architects to leverage existing data models and build new ones, as needed. Collaborate with product development teams and partners in Ericsson Businesses to industrialize machine learning models and solutions as part of Ericsson offerings including providing source code, workflows and documents Work with new technologies and champion them in MI Communities within Ericsson. Assist MI Competence build-up in Ericsson Businesses and Customer Serving Units Help to develop new and apply/extend existing, concepts, methodologies, techniques for cross functional initiatives MS, or PhD in Electrical Engineer, Computer Science, Artificial Intelligence, Machine Learning, Physics, or related field Applied experience: 2+ years of Machine Learning experience in data science. Proven experience writing production-grade software Extensive experience in model development and life-cycle-management in one or more industry/application domain Strong Programming skills in various languages (C++, Scala, Java, R) with proficiency in Python and/or C++ Proven skills in Machine Learning, e.g., linear/logistics regression discriminant analysis, bagging, random forest, Bayesian model, SVM, neural networks, etc. Strong skills in the use of current state of the art machine learning frameworks such as Scikit-Learn, H2O, Keras, TensorFlow and Spark, etc. Demonstrated ability to implement new algorithms and methodologies from leading open source initiatives and research papers addressing their functionalities, scalability and overall industrialization viability Strong knowledge in Statistics, e.g., descriptive analysis and supervised and unsupervised analysis Certifying MI MOOCS, a plus Applications/Domain-knowledge in Telecommunication and/or IoT, a plus. Ability to work independently with high energy, enthusiasm and persistence Good communication skills in written and spoken English Ability to work in a collaborative environment, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence 
ScrapedJobID272:
Originate discrete and systematic trade ideas, primarily from market or fundamental insights, utilizing advanced analytics and quantitative methods. Regularly review trades and exposure to assess risk, rebalancing, optimization, and new insights in partnership experienced traders. Design quantitative models and machine learning algorithms to identify trade worthy opportunities in each respective product/market. Develop tools to assist trading and risk management. Maintain detailed technical documentation and collaborate with other divisions to share best practices. Master’s degree or PhD in computer science, finance, machine learning, financial engineering, or any other related field. Quantitative experience particularly focused on designing models, portfolio valuation techniques, risk measurement, and simulation tools. Strong programming skills for real-time processing applications (Python, C#, SQL). Experience with Machine Learning (Classifications / Neural Networks / Regularization techniques). Clear and concise written and verbal communication in English. Knowledge of Bloomberg, booking systems, trading protocol, closing technicalities. A professional title (CFA, FRM, PRM, CAIA) is an asset. An entrepreneurial culture based on collaboration, communication, and transparency. A work environment located in the heart of Old Montreal, in modern offices, walking distance from the Square Victoria metro station and bicycle paths. A gym, locker rooms, and showers for athletes of all kinds. Group insurance, RRSP, DPSP, and employee assistance program. Partial reimbursement of your public transit pass. Social, charitable and sports activities. Refreshments and snacks all week long. And much more! 
ScrapedJobID273:
Develop and document credit origination and monitoring models/strategies for the Personal Banking, Credit Card and SME business lines Frequently assess the performance of the models/strategies in place and present recommendations for better risk optimization Suggest improvements to existing methodologies and processes Carry out analyses that will guide risk management decisions and strategies at the Bank Establish and maintain effective communication with internal and external stakeholders Use various statistical techniques to model ratings (e.g., scorecards) and decisioning strategies Work in SAS and coordinate data analytics and exploration, including the data transformation and visualization steps (reporting) Organize and conduct meetings with partners from the business lines and risk management to get approval for the models and strategies being developed. Demonstrate acute understanding of partners’ business needs by making recommendations on their actions and strategic orientations Identify irregularities that may pose a risk to the Bank and recommend the necessary corrective measures Act as an expert and advisor for various stakeholders and committees in their decisions related to managing credit risks. Demonstrate leadership in adopting innovative analytical approaches, including artificial intelligence, to solve risk management issues Bachelor’s degree in a related field and 5 years of experience in credit risk, OR master’s degree in a related field and 3 years of experience in credit risk, OR university certificate/undergraduate diploma from the National Bank University Program and 7 years of experience in credit risk Excellent knowledge of quantitative methods Advanced proficiency in SAS and SQL Proficiency in R and/or Python, an asset Experience in applying machine learning, an asset Experience in the banking industry, an asset Excellent analytical and summarizing skills Proven ability to influence and innovate Strong interpersonal and collaboration skills, advisory and communication experience, as well as good ability to explain analytical concepts. Comfortable applying expertise in an ever-changing multidisciplinary environment Fluency in French (required) and a working knowledge of English. Health and wellness program, including many benefits Flexible group insurance Defined benefit pension plan Employee Share Ownership Plan Employee and Family Assistance Program Preferential banking services Community involvement program Telemedicine Virtual sleep clinic 
ScrapedJobID274:
Design and implement complex predictive models necessary to address both MPI’s strategic initiatives and the operational business issues facing the Corporation. This includes building and refining predictive and descriptive statistical models to improve insights and enhance data-driven business strategies. As lead designer, identify the data sources, confirm business rules and other requirements with MPI business areas, and design, build, test and maintain models using MPI’s predictive analytics software, as well as any other tools relevant to the duties. Determine when and how to use quantitative research tools and models and assist in the interpretation and development of implications to address internal client business problems. Conduct quantitative analysis using the models described above, and prepare clear concise reports and presentations outlining findings and recommendations. Degree in Computer Science, Statistics, Engineering, Economics or related quantitative fields of study. Four years of progressive experience performing analysis, including:
Two years of related experience conducting research, undertaking complex data analysis with structured and unstructured data, as well as developing and evaluating applied statistical and predictive models (i.e., feature selection, feature transformation, feature engineering, algorithm selection and assessing model performance).
Two years of experience working with data science programming tools and open source frameworks such as: Python (Jupyter), R, SPSS, SQL programming (writing and modifying queries on platforms such as Microsoft SSMS), Github. Two years of related experience conducting research, undertaking complex data analysis with structured and unstructured data, as well as developing and evaluating applied statistical and predictive models (i.e., feature selection, feature transformation, feature engineering, algorithm selection and assessing model performance). Two years of experience working with data science programming tools and open source frameworks such as: Python (Jupyter), R, SPSS, SQL programming (writing and modifying queries on platforms such as Microsoft SSMS), Github. One year experience leading predictive initiatives. Experience with tools for model monitoring is an asset. Experience in a leadership capacity is an asset. Experience within an enterprise data warehouse environment is an asset. Intermediate knowledge of underlying theory and practical applications behind machine learning algorithms and methods. Working knowledge with large scale data processing tools (e.g., Spark) and deep learning libraries (e.g. Tensorflow, Keras, Pytorch). Working knowledge of predictive modeling using large datasets in a cloud environment (e.g., AWS, Azure or GCP) or using GPUs. Advanced written and oral communications skills with the ability to convey technical information in a clear, concise and understandable manner for both technical and non-technical audiences, and the ability to be a key champion for the use of predictive analytics within MPI. Knowledge of quantitative and qualitative data analysis techniques. flexible health, dental and vision plans health spending account travel health coverage other extended health benefits such as ambulance, massage and physiotherapy registered pension plan group, dependent, and optional life insurance coverage critical illness insurance sick leave to cover short-term disability long-term disability vacation entitlement maternity, parental and adoptive leaves bereavement and family responsibility leaves employee and family assistance program mental-health programming lunch-and-learn offerings discounted gym memberships and wellness account 
ScrapedJobID275:
Grow and lead a team of Data Scientists and ensure both your team and the organization embrace a culture of continuous learning. Work with your Engineering leadership counterparts to evaluate and select the right customer engagements to ensure your team has interesting, challenging, and high impact projects. Influence the vision, strategy, and roadmap for the Connected Reality product portfolio Prioritize for largest customer impact and write specifications to help Engineering team build these skills into the product in rapid fail-fast manner to learn and optimize with customer inputs. Identify key areas where data science research and prototyping can support agile product innovation. Analyze and resolve complex business and technical problems with internal stakeholders and customers. Build deep understanding around unique challenges related to deploying intelligent edge-cloud solutions Ensure your team adheres to solid engineering and rigorous data science principles. 7+ years of people management 5+ years experience building practical machine learning models with applications to real-world problems. Experience managing both technical and non-technical stakeholders and able to resolve complex business and technical issues. Proven track record of influencing product or business decisions. Proven track record of influencing product or business decisions using scale data from product usage and by identifying adoption patterns Demonstrated leadership experience with the full ML life-cycle - from data exploration to model building to experimentation to shipping models to customers. Excellent oral and written communication skills, with the ability to communicate complex technical concepts and solutions to all levels of the organization. Real-world experience with data privacy and responsible AI principles and practices. Strong python coding skills including experience with ML tools to build models and analyze and visualize data. (e.g. PyTorch, TensorFlow, scikit-learn, altair, vega-lite). Advanced education in Computer Science, EE, Machine Learning, Data Science, Computational Linguistics, or equivalent technical fields, or equivalent demonstrated work experience. A background in 3D, Mixed Reality, AI, and/or Computer Vision Knowledge of distributed/cloud computing systems (e.g. Spark, Hadoop, Azure, AWS, Cosmos) Familiarity with computer vision and related technologies Experience managing data engineering teams and their associated deliverables. Demonstrated passion for fostering relationships across disciplines and teams to create coherent, best-in-class customer experiences Experience with UX analytics, user data, and segmentation. Ability to define UX metrics and establish KPIs to track the success and failure of design changes. 
ScrapedJobID276:
Le poste est offert aux personnes cherchant à appliquer l’apprentissage profond pour simplifier les stratégies d’enchères du marketing des moteurs de recherche d’Expedia Group dans un environnement d’apprentissage en ligne. Si les problèmes de modélisation d’importance non triviaux vous intéressent, et que la rareté des données, les tendances en constante évolution et les millions d’enchères et de modificateurs ne vous font pas peur, saisissez l’occasion de faire avancer votre carrière. En étroite collaboration avec nos équipes Bidding Operations (opérations d’enchères), vous soutiendrez notre stratégie d’enchères pour nos partenaires, comme Bing et Google. Notre équipe de recherche, composée de cinq personnes, gère des milliers de dollars de dépenses en marketing des moteurs de recherche par jour. Bonne compréhension de la théorie et de la pratique relatives aux probabilités et aux statistiques Expérience pratique en apprentissage automatique : préparation d’ensembles de données, sélection et développement de fonctionnalités, conception et optimisation d’algorithmes de formation, évaluation des résultats par rapport aux références de production Expérience en création et en maintenance de pipelines d’extraction, de transformation et de chargement (« ETL ») à grande échelle à l’aide d’outils comme PySpark, Apache Airflow, SQL, DataBricks et Notebooks Expérience en développement d’apprentissage profond (TensorFlow ou PyTorch) qui généralise quelques exemples pour déduire de nombreuses prédictions Bonnes pratiques de programmation, capacité à écrire des codes lisibles et performants Capacité à appliquer la méthode scientifique pour suggérer des améliorations à partir de données Expérience dans l’optimisation d’enchères de marketing Expérience en apprentissage par renforcement Connaissance des systèmes de contrôle pour les pipelines d’apprentissage en ligne Expérience en production d’applications d’apprentissage automatique à grande échelle dans le monde réel Curiosité intellectuelle et volonté d’apprendre, notamment en ce qui a trait aux nouvelles techniques et technologies The position is open for people looking to apply deep learning to streamline Expedia Group SEM bidding strategies in an online learning setting If you are interested in non-trivial high impact modelling problems that involves dealing with data scarcity, constantly evolving trends, and millions of bids and modifiers, this is a great opportunity to further your career Working closely with our Bidding Operations teams, you will support our bidding strategy for our partners, such as Bing and Google Our 5-person research team handles thousands of dollars of SEM spend per day Strong grasp of Probability and Statistics theory and practice Hands on experience in machine learning: preparing datasets, selecting and engineering features, building and optimizing training algorithms, evaluating results against production baselines Experience building and maintaining large-scale Extract Transform and Load (ETL) pipelines using tools such as PySpark, Apache Airflow, SQL, DataBricks, Notebooks Experience developing Deep Learning (TensorFlow or PyTorch) that generalize from few examples to many inferred predictions Good programming practices, able to write readable, performant code Ability to apply the scientific method to suggest improvements from data Experience optimizing Marketing auctions Experience with Reinforcement Learning Knowledge of control systems for online learning pipelines Experience productionizing real-world large-scale ML applications Intellectual curiosity and desire to learn new things, techniques and technologies 
ScrapedJobID277:
Working with business teams in all parts of the business to gather conceptual business needs, translate them into clear functional business requirements Solving business problems using AI/ML solutions Developing AI/ML solutions in languages including Python/R Using libraries such as scikit-learn and tensorflow Deploying, managing and monitoring AI/ML models Creating process models, diagrams, charts, PowerPoint presentations Working with technical teams and/or study relational database tables to create Technical Data Requirements from the Business Requirements Working with application support, product management and engineering teams on quarterly upgrades and feature requests for Magellan product suite Self-motivated and driven to accomplish company goals and who is comfortable multitasking in a fast paced, matrixed environment Performing data preparation, linkage and feature selection Educating business partners in the benefits and uses of AI Bachelor’s degree in Computer Science, Engineering, Statistics or equivalent experience 5 + years proven abilities related to AI model development and deployment Solid understanding of ML/NLP algorithms including supervised and unsupervised learning, support vector machines, language/sequence modelling, parsing, sentiment analysis, sentence classification, etc Knowledge of production infrastructure and pipelines for Machine Learning models (MLOps) Experience with SQL, Python and R Excellent listening, interpersonal, written, and oral communication skills Experience with OpenText Magellan preferred Experience working in a complex, matrix, fast paced environment Attention to detail with emphasis on accuracy and quality Ability to prioritize work to balance multiple projects and deadlines The ability to work independently, as part of a team, and cross-functionally within the organization 
ScrapedJobID278:
Develop the best suitable ML and NLP models or algorithms for various Zoom products such as task-oriented dialogue systems, Zoom meeting/phone/chat intelligence products; Research and investigate the latest technologies, then create and customize ML/DL models for conversation AI, information extraction, classification, sentiment analysis, text segmentation, topic modeling etc; Collaborate with various teams including offshore teams, exchange ideas, communicating requirements, providing technical guidance, code review. Participate in production integration and deployment, and result evaluation. Ph.D in NLP, NLU, Machine Learning, Computer Science or a related technical field; Experience in conversation AI and task-oriented dialogue systems; Expertise knowledge in NLP such as text classification, sentiment analysis, topic modeling, text summarization, ranking, text similarity, tokenization, word/sentence/doc embedding, NER, POS (Part-Of-Speech) tagging and parsing, intent detection, slot filler, dialog flow, KB graph, etc; Ability to understand the latest research paper in ML/DL/NLP, reproduce published result, build and customize the model for specific use cases; Hands-on experience in text pre-processing and normalization techniques, such as tokenization, word embedding, NER, POS (Part-Of-Speech) tagging and parsing and how they work at a low level; Expertise in machine learning, deep Learning (CNN, LSTM, XLNet, GPT, BERT or other transformer based models), meta learning, few shot learning, transfer learning etc; Hands-on experience on developing and training models with large-scale text data; Experience with open-source ML / DL / NLP toolkits such as TensorFlow, Caffe, PyTorch, CoreNLP, OpenNLP, StanfordNLP, SpaCy, AllenNLP, NLTK, gensim, etc. Prefer candidates with publications in top-tier venues such as ACL, EMNLP, NAACL, NeurIPS, ICLR, ICML etc; Experience in frontier topics such as meta-learning, multimodal learning, multilingual models, reinforcement learning is highly desirable; Industry experience in machine learning applications in production is preferred; Strong analytical skills and attention to detail. Strong mastery of Python or other programming languages, and general software development skills (source code management, debugging, testing, deployment, etc.); Mastery in English language. Deep understanding of English linguistics; Mastery in one or more non-English languages. Hear from our leadership team Browse Awards and Employee Reviews on Comparably Visit our Blog Zoom with us! Find us on social at the links below and on Instagram 
ScrapedJobID279:
Using your data science superpowers to advise clients on everything from use case development to solution design to performance measurement Collaborating with other Machine Learning Scientists on the team to problem-solve and develop best practices Principally delivering data ingest for our client data, including cataloguing the data and mapping it to our proprietary data schema Collaborating with our business team to create polished data visualizations and pull high level business insights from client data Working closely with our machine learning research team in the early stages of statistical/machine learning model development to identify valuable patterns and information in the data Collaborating with our engineers to translate complex business logic into our proprietary data schema Supporting engineers to do carry out reliable and efficient integrations Sending feedback to our engineering, product, and machine learning research teams to develop requirements for our product roadmap - specifically our ingest, structuring, and integration capabilities 5+ years in a lead Machine Learning (or Data) Science role, including experience providing strategic guidance to clients and fellow Machine Learning (or Data) Scientists An appreciation for the beauty of data. You love a challenge, and you're excited about bringing a narrative to complex business problems using what you learn from a dataset Worked directly with clients and understand the importance of prioritizing client needs A bachelor's degree in computer science or a related discipline Strong technical abilities, creative problem solving skills and high adaptability Extraordinary interpersonal, organization and communications skills Experience working directly with business users to build reports and answer business questions with data Experience working with big data structures and ETL tools and other big data technologies (Hadoop/Spark, Hive SQL, etc.) to uncover meaningful business insights A strong understanding of statistical modeling and you're passionate about deriving insights from large datasets Programming experience with Python, R, or SAS Adaptability and interest in working with a dynamic, early stage company 
ScrapedJobID280:
Lead and participate in design, implementation, and execution across a variety of features, including directly building ML/DL models. Drive innovations in NLP applications, ranking and recommendation algorithms. Drive architectural changes into the product to expand our footprint and increase developer agility. Regularly communicate team progress internally and evangelize progress and opportunities to a wider audience including management and leadership. BS/MS in Computer Science, Statistics, Applied Mathematics, Physics, or other engineering or science fields and 4+ years industry experience in related fields OR PhD with 2+ years industry experience. Proficient experience with C#/C++/Java/Python/Scala or any other OOP skills with a good knowledge of Data Structures/Algorithms. Do you have a minimum of 1 year experience in machine learning, deep learning and/or related fields? PhD with research experience on Machine Learning. Experience developing end to end ML/DL systems. Have research or work experience in NLP, Document understanding ML systems. Strong knowledge in deep learning computational graph frameworks, such as Tensorflow/Pytorch 
ScrapedJobID281:
Lead Firstlight’s core data science team as a thought leader inclusive of debating and influencing our technical strategies as they apply to the data science discipline Identify business trends and problems through complex big data analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations Communicating verbally and in writing to customers/prospects with various levels of technical knowledge, pitching Firstlight’s data science capabilities, educating them about our data systems, as well as sharing insights and recommendations Determine the appropriate tools, techniques, and methodologies to extract data that produces meaningful results Interpret results using a variety of techniques, ranging from simple data aggregation via statistical analysis to complex data mining independently Provide thought leadership and influence various aspects of the AI/ML pipeline including feature extraction, feature engineering, AI/ML model selection, training and deployment Work closely with Product Management/Analytics teams to ensure that key customer KPIs are tracked, monitored and improved Work with academic institutions/universities to conduct research in strategic problem areas for our business Setting and executing on the technical roadmap for the Data Science Firstlight Media staff reports into offices in a hybrid capacity (i.e partially at home, and partially at the office based on role/team needs) leveraging safety protocols aligned with local public health guidelines as they relate to COVID-19. Delivering on advanced, complex technical projects or business issues requiring state of the art technical or industry knowledge Creating functional strategies and specific objectives for the data science function and developing policies/procedures to support the functional infrastructure Lead strong partnerships with Firstlight’s Engineering and Product teams Inspiring and leading your team to deliver data and strategic data science approaches that help optimize and guide Firstlight’s product decisions Help set technical strategy, represent data science and, initiate and debate key strategic topics and opportunities from your team’s work, and drive bold high-impact decisions Grow and expand your team with an eye toward diverse and forward-pushing skills that span machine learning methods, data engineering, tooling, data products, and analytics Applied experience with machine learning on large datasets Experience articulating and translating business questions and using statistical techniques to arrive at an answer using available data Demonstrated leadership and self-direction. Willingness to both teach others and learn new techniques Demonstrated skills in selecting the right statistical tools given a data analysis problem. Effective written and verbal communication skills You have experience building and leading an expert data practice at a software platform company, and/or analytics teams Your technical background is broad, spanning multiple areas among data products and visualization, data and behavioral analytics, advanced metrics, statistics, machine learning, causal methods, and data architecture. You likely have a graduate degree or studies in a quantitative field such as Economics, Analytics, Mathematics, Computer Science, Statistics, Machine Learning, etc.. You are skilled at having an impact in complex or ambiguous problem spaces that cannot be empirically proven and require blending data and scientific methods with judgment-based approaches You have exceptional oral and written communication skills and are articulate with both technical and business partners. You create effective frameworks to aid the discussion of complicated topics. You are a self-starter, with an ability to work with some ambiguity and comfort working cross functionally; but ultimately comfortable working towards initiatives in an autonomous capacity. Experience with statistical software (e.g., R, Python, MATLAB, Pandas), SQL and cloud-based data warehousing technologies such as BigQuery/Snowflake; strong organizational skills and strong attention to detail 
ScrapedJobID282:
Experience using Structured Query Language (SQL); Experience analyzing and transforming functional requirements and change requests into technical Experience with Business Intelligence (BI) and Data Analytics, including data mart, reporting models Experience in providing application support to clients and end users of data solutions. Experience using SQL Server Integration Services (SSIS) or Azure Data Factory; Experience performing data modelling for transactional databases, data warehouse or data marts; Significant experience* using Structured Query Language (SQL); Significant experience* mapping, developing and loading data warehouse systems; Significant experience* analyzing and transforming functional requirements and change requests into technical specifications; Significant experience* with Business Intelligence (BI) and Data Analytics, including data mart, reporting models (E.g., cubes, tabular models, datasets in Power BI), and visualization (i.e., reports and dashboards); Experience in providing application support to clients and end users of data solutions; and Experience assisting in the development of project plans, assigning appropriate technical resources, and cost estimation. Significant is defined as depth and breadth of experience normally associated with the performance of those duties for a period of approximately two years. Graduation with a degree from a recognized university with an acceptable specialization in computer science, computer engineering, information technology, or other related area. Microsoft Certification on cloud technologies relating to data analysis, data engineering and data science. Microsoft Certification on non-BI cloud technologies and platforms such as Dynamics 365, Power Apps, Power Automate, and Azure services that are not relating directly to data and analytics. Experience using SQL Server Integration Services (SSIS) or Azure Data Factory. Experience developing and loading data warehouse systems. Experience working with REST API or OData in data solutions. Experience of using ERWin as a data modelling tool. Experience on non-BI Microsoft cloud technologies and platforms such as Dynamics 365, Power BI, Power Apps, Power Automate, and other Azure services that are not relating directly to data and analytics. Experience of leading data management and data governance activities. Experience supervising a technical team via formal reporting structure. Experience providing functional leadership to a technical team in a matrix environment. Experience providing functional or hierarchical leadership to employees or managing the work of contractors. Advance knowledge of data management and data governance principles and best practice. Knowledge of Microsoft Cloud technologies relating to data analysis and data engineering. Knowledge of relational database design principles and SQL scription languages such as T-SQL. Knowledge of Agile Software Development Lifecycle, and that applies to Data Analysis and Business Intelligence initiatives. Knowledge of Microsoft Cloud technologies relating to data analysis, and data science. Advanced knowledge of Microsoft Cloud technologies relating to data engineering. Advanced knowledge of data modelling, relational database design principles and SQL scription languages such as T-SQL. Advanced Knowledge of Agile Software Development Lifecycle, and that applies to Data Analysis and Business Intelligence initiatives. Demonstrating integrity and respect Thinking things through Working effectively with others Showing initiative and being action oriented Autonomy Digital literacy and competency Create Vision and Strategy Mobilize People Uphold Integrity and Respect Collaborate with partners and stakeholders Promote Innovation and Guide Change Achieve Results Autonomy Digital Literacy and competency 
ScrapedJobID283:
Research and build machine learning algorithms for search ranking, leveraging our images, metadata, and/or customer interactions to significantly improve our customer’s image/video discovery experiences. Develop and implement online and offline testing and validation methodologies Partner closely with other data scientists, data engineers, machine learning engineers, and search engineers to implement and deploy models in production Collaborate closely with product, engineering, design/research, and data science leaders Recommend changes to our search ranking strategy presented in a clear manner to team members and leadership Share your expertise by mentoring others on the team Proven experience building and validating search, personalization, recommendation, and/or newsfeed algorithms for customer-facing products A minimum of 2 years validated experience An understanding of the real-world advantages and drawbacks of various algorithms and the ability to measure success Ability to handle ambiguity, priorities, and competing objectives. Experience solving highly technical problems Hands-on experience with accessing data, Python, machine learning libraries, and deep learning libraries (ex: scikit-learn, numpy, pandas, scipy, TensorFlow, SQL, hive, spark, etc.). Ability to write clean, understandable code that follows leading industry standards and practices and is well-documented, and to build easily reproducible models An ability to consider biases that exist in the data and develop solutions to mitigate biases appropriately Outstanding communication skills. Strong communication skills at all levels, including sophisticated technical solutions to non-experts Open listener, ability to be open to many diverse voices and perspectives You are clear, credible, and forward-thinking A Ph.D. or MS in Computer Science, Statistics, Data Science, Mathematics, Economics, Sociology, Natural Sciences, or any other equivalent quantitative field is preferred 
ScrapedJobID284:
Thrive on challenges and work best in a fast-paced environment where each day is different Work well in a project team environment and have strong collaboration and interpersonal skills Have a permanent “figure it out” mindset Work closely with clients in understanding key business issues. Gather and analyze requirements to develop impactful recommendations and solutions. Utilize advanced analytical techniques to solve challenging business problems. Leverage a diverse set of technologies and tools to deliver insights. Problem solving ability through the use and/or development of algorithms, models, testing, etc. Propose and develop results, models and rules engines using statistics, machine learning, Natural Language Processing, Linear Programming, etc. Work with large volumes of data (structured and unstructured). Architect the data platform models for scalability, repeatability and performance to build data solutions Investigate and perform deeper analysis to produce impactful algorithms to achieve targeted outcomes. Perform quantitative analysis of data issues. Effectively communicate orally and written with peers within Data & Analytics teams, KPMG and the client. Education and professional working experience in math, statistics, operations research, engineering, computer science or econometrics. Expert knowledge in advance modeling techniques and mathematical models, algorithm use and optimization, and data science technologies. Understand the full spectrum of data feature retrieval, selection, and engineering; model technique selection, model build, implementation, monitoring and integration; interpretation of outputs, and development of recommendations. Capable of identifying commonalities across seemingly disparate analytics use cases, in order to identify unique ways of approaching modeling. Strong experience in advanced analytics, statistics, data mining, predictive analysis, time-series analysis, natural language processing and deep learning. Proficient at SQL, Python or R and popular ML frameworks and libraries. Experience in mainstream cloud services: such as AWS, MS Azure, GCP and their data analytics, ML tools. Identify and present opportunities with new and existing clients that align with KPMG services to the appropriate partner. Manage the efficient and effective delivery of every engagement, producing high quality deliverables and delivering work on time, on budget and within project parameters and client expectations 
ScrapedJobID285:

ScrapedJobID286:
Working with project teams to address data science/computing challenges Identifying opportunities for technology to enhance service offerings Acting as a resource and participating in client engagements and research as part of the project team Maintaining up-to-date knowledge of computing tools, providing technical training and helping to grow the in-house knowledge base, specifically in a Linux environment Developing data engineering and machine learning production systems for full stack data science projects Using natural language processing methodologies to work with EMR data, social media data and other unstructured data Optimizing procedures for managing and accessing large databases (e.g., insurance claims, electronic health records, financial transactions) Creating interactive analytics portals and data visualizations (e.g., using R/Shiny, Python/Flask, D3) Building and maintaining high performance computing (HPC) tools on grid and cloud computing environments Developing and reviewing software and packages in R, Python and other Object Oriented Languages Establishing optimized procedures for repetitive or computationally intensive tasks (C, C++, Cuda-C) Pursuing an advanced degree is required, preferably in Computer Science, Data Analytics, Data Science, Economics, Mathematics, Statistics, or related subjects. Significant experience working within a Linux environment required, experience with Docker and front-end development using a Javascript framework (e.g., Vue.js, Angular) is highly preferred. Strong credentials and experience in database management and/or data visualization is preferred. Demonstrates strong interpersonal, written, and oral communication skills. Project experience with Python and/or R is preferred. Familiar with online/cloud computing/storage (e.g. Azure, AWS) is preferred. Demonstrated experience working on project teams and collaborating with others. Le masculin est utilisé ici en tant que genre neutre et sert uniquement à alléger le texte. Collaborer avec les équipes de projet pour relever les défis informatiques et liés à la science des données Identifier des façons dont la technologie peut améliorer l’offre de services Contribuer à l’activité et à la recherche du client en tant que spécialiste et membre de l'équipe de projet Maintenir les connaissances sur les outils informatiques à jour, former le personnel sur des points techniques et aider à développer la base de connaissances interne, en particulier dans un environnement Linux Développer des systèmes de production en ingénierie des données et apprentissage automatique pour des projets de science des données full-stack Utiliser des méthodologies de traitement automatique du langage pour travailler avec les données des DME et des médias sociaux et d’autres données non structurées Optimiser les procédures de gestion et d'accès aux grandes bases de données (déclarations de sinistre, dossiers de santé électroniques, transactions financières, etc.) Créer des portails d'analyse interactifs et des visualisations de données (en utilisant par exemple R/Shiny, Python/Flask, D3) Construire et alimenter des outils de HPC sur la grille informatique et l’informatique en nuage Développer et réviser des logiciels codés en R, Python et autres langages orientés objet Mettre en place des procédures optimisées pour les tâches répétitives ou gourmandes en calcul (C, C++, Cuda-C) Poursuivant un diplôme d'études supérieures exigé, dans l’idéal, en informatique, analyse de données, science des données, en économie, mathématiques, statistiques ou un autre diplôme scientifique pertinent accompagné d’une expérience professionnelle concordante. Expérience de travail significative dans un environnement Linux exigée ; une expérience du logiciel Docker et en développement frontal en JavaScript (Vue.js, Angular, etc.) est fortement souhaitée. Solides références et expérience dans la gestion de bases de données et/ou de la visualisation de données souhaitées. Excellentes aptitudes pour les relations interpersonnelles, la communication orale et écrite. Expérience de projets utilisant Python et/ou R souhaitée. Bonne connaissance de l'informatique en ligne/en nuage et du stockage (sur Azure ou AWS par exemple) souhaitée. Expérience avérée de travail au sein d'équipes de projet et de collaboration avec des tiers. Pour que votre candidature soit étudiée, vous devez soumettre une lettre de présentation, votre curriculum vitæ, et toutes vos relevés de notes officiels. 
ScrapedJobID287:

ScrapedJobID288:
3+ years (or equivalent) experience as a Data Scientist/Machine Learning Developer/Engineer Excellent understanding of ML. Preferably worked on NLP problems before but not required Experienced in designing and tracking efficient and thorough data science experimentsHighly skilled in Python and Pytorch Strong software and data engineering practices Become an owner of Ada’s machine learning architecture and lead the improvement and maintenance of our ML technologies Execute on our ambitious Machine Learning product roadmap through the implementation of features Review the team’s code and experiments, provide insightful feedback, and teach everyone something new Help identify areas of opportunity and innovation within our product Competitive salary and generous stock option plan Unlimited vacation Wellness account Extended health coverage Dental/optical/travel insurance Life insurance Employee and family assistance plan Flexible work schedule Digital first, fully remote with WFH budget In-house social worker Paid parental leave for Canadian and U.S. residents Development opportunities 
ScrapedJobID289:
Experience using Structured Query Language (SQL); Experience analyzing and transforming functional requirements and change requests into technical Experience with Business Intelligence (BI) and Data Analytics, including data mart, reporting models Experience in providing application support to clients and end users of data solutions. Experience using SQL Server Integration Services (SSIS) or Azure Data Factory; Experience performing data modelling for transactional databases, data warehouse or data marts; Significant experience* using Structured Query Language (SQL); Significant experience* mapping, developing and loading data warehouse systems; Significant experience* analyzing and transforming functional requirements and change requests into technical specifications; Significant experience* with Business Intelligence (BI) and Data Analytics, including data mart, reporting models (E.g., cubes, tabular models, datasets in Power BI), and visualization (i.e., reports and dashboards); Experience in providing application support to clients and end users of data solutions; and Experience assisting in the development of project plans, assigning appropriate technical resources, and cost estimation. Significant is defined as depth and breadth of experience normally associated with the performance of those duties for a period of approximately two years. Graduation with a degree from a recognized university with an acceptable specialization in computer science, computer engineering, information technology, or other related area. Microsoft Certification on cloud technologies relating to data analysis, data engineering and data science. Microsoft Certification on non-BI cloud technologies and platforms such as Dynamics 365, Power Apps, Power Automate, and Azure services that are not relating directly to data and analytics. Experience using SQL Server Integration Services (SSIS) or Azure Data Factory. Experience developing and loading data warehouse systems. Experience working with REST API or OData in data solutions. Experience of using ERWin as a data modelling tool. Experience on non-BI Microsoft cloud technologies and platforms such as Dynamics 365, Power BI, Power Apps, Power Automate, and other Azure services that are not relating directly to data and analytics. Experience of leading data management and data governance activities. Experience supervising a technical team via formal reporting structure. Experience providing functional leadership to a technical team in a matrix environment. Experience providing functional or hierarchical leadership to employees or managing the work of contractors. Advance knowledge of data management and data governance principles and best practice. Knowledge of Microsoft Cloud technologies relating to data analysis and data engineering. Knowledge of relational database design principles and SQL scription languages such as T-SQL. Knowledge of Agile Software Development Lifecycle, and that applies to Data Analysis and Business Intelligence initiatives. Knowledge of Microsoft Cloud technologies relating to data analysis, and data science. Advanced knowledge of Microsoft Cloud technologies relating to data engineering. Advanced knowledge of data modelling, relational database design principles and SQL scription languages such as T-SQL. Advanced Knowledge of Agile Software Development Lifecycle, and that applies to Data Analysis and Business Intelligence initiatives. Demonstrating integrity and respect Thinking things through Working effectively with others Showing initiative and being action oriented Autonomy Digital literacy and competency Create Vision and Strategy Mobilize People Uphold Integrity and Respect Collaborate with partners and stakeholders Promote Innovation and Guide Change Achieve Results Autonomy Digital Literacy and competency 
ScrapedJobID290:
Researching industry best practices for features to be implemented in the Data Analytics platform, with a focus on Data Science features including Data Preparation, Machine Learning, AutoML and Explainable AI Features Ensuring that new features fit within the architecture of the Data Analytics Platform Developing Python or R prototypes of the above Data Science features Working closely with multiple developer teams to productize the Python and R templates in the Data Analytics platform, ensuring incremental value delivered with each software version release Advanced Python, SQL and R (optional), including experience with data processing and ML pipelines Excellent knowledge of the landscape of data analytics tools, including open source tools (e.g. Python sklearn/Pandas, Keras, Jupyter, R, Docker) as well as enterprise platforms. Experience working with big data 2+ years experience building models that have achieved business value or reached production Able to work in a fast-paced environment Can collaborate with others and build relationships with multiple teams, including developers, designers, subject matter experts and stakeholders Empathy to translate end-user needs into valuable features Excellent communication skills – able to communicate complex technical features to non-technical teams and stakeholders. Not afraid to ask for help when needed Envision the Future Communicate Honestly and Broadly Seek Technology and Business “Firsts” Embrace Diversity and Take Risks Competitive Salary Comprehensive Benefit Package Outstanding Work/Life Balance Flex Time Paid holidays Paid time off for community services Collaborative environment 
ScrapedJobID291:
Develop automated reporting, analytics solutions, and controls using SAS Viya Provide expertise in creating high quality controls to analyze revenue and mitigate risks. Support critical wireless projects/programs that impact Revenue Assurance controls. Conduct deep dive analysis on large volumes of data to support Revenue Assurance initiatives. Undertake self-initiated analysis to uncover opportunities or instances of revenue or cost exposure/overbilling. Support data analysis requests from all levels of the Revenue Assurance team. Drive process efficiencies through automation. Collaborate with key internal and external stakeholders as required to resolve issues or identify and implement opportunities that improve operational processes. Bachelor’s degree in Computer Science, Statistics, or related field. 2+ years of progressive experience in SAS code development, documentation, and testing. 2+ years of experience creating dashboards in SAS, Tableau or Power BI Advanced knowledge of SQL and SAS required. Experience working with large datasets with emphasis on development, implementation and maintenance of reporting and analytical structures. Knowledge of data science concepts and programming in Python an asset. Strong interpersonal and communication skills. Practical experience with ETL (extract, transform, load) processes and associated tools. Adapts to fast-changing environment – works well under pressure and has ability to act with urgency. Excellent organizational and time management skills with strong attention to detail. Our people are at the heart of our success Our customers come first. They inspire everything we do We do what’s right, each and every day We believe in the power of new ideas We work as one team, with one vision We give back to our communities and protect our environment 
ScrapedJobID292:
Work as a member of the Digital Accelerator with a fusion team of highly talented Data Scientists, developers and opportunity managers, to unlock substantial value from operations Work closely with the business teams to understand their goals, business problems and assist in identifying potential analytical and data science solutions and feasibility Support the full range of problem solving activities including data wrangling, ETL pipeline development, rapid scoping level / exploratory data analysis, proof of concept solutions as well as end-to-end execution plans for scaling proven models and deploying into an operational environment Ensure your models and analytics are tested with the end users and iterate to deployable adoptable solutions Communicate key metrics and results to stakeholders, as you progress through delivery leveraging visualization tools as appropriate for effective story telling Continue model / tool support in operational phases, including model performance monitoring and retraining Mentor and guide junior members of the team through the modeling and problem solving process Keep up to date with the latest advances in the data science field and actively participate in data science communities Share and grow data science knowledge across Imperial Conduct peer reviews with the data science team to ensure high-quality products Help mature ML Ops framework and adoption Work closely with the platform and data infrastructure team to ensure data science needs are properly considered in architecture and data pipelines are robust 5+ years work experience in advanced analytics and data science solving business problems Degree in machine learning, computer science, statistics, mathematics, physics, engineering, economics, operations research or related quantitative field Proven track record completing and deploying data science solutions in an industrial operating environment Broad array of ML and AI skills (supervised, unsupervised, reinforcement learning and mathematical optimization) Strong Python programming skills, additional benefit for Pyspark and Databricks experience Ability to explain data science solutions and concepts to the end users Strong mentorship skills, and enthusiasm for sharing knowledge Ability to effectively iterate and communicate results to stakeholders and team members using appropriate visualization and communication tools Preference for domain knowledge in energy and mining industrial processes 8 hour shift Monday to Friday Calgary, AB: reliably commute or plan to relocate before starting work (required) advanced analytics and data science: 5 years (preferred) ML and AI skills: 5 years (preferred) Python programming skills: 1 year (preferred) Pyspark and Databricks: 1 year (preferred) mentorship skills: 1 year (preferred) energy and mining industrial: 1 year (preferred) No 
ScrapedJobID293:
gives back to the community has leadership that inspires, coaches and mentors allows you to speak up and be heard AND ... likes to have FUN? Post-graduate degree in one of the STEM disciplines (minimum MSc) 5+ years of data science experience in industry Team leadership/and or project leadership experience in data science Strong and fundamental understanding of statistics Solid understanding of ML and it's application in a variety of use cases Coding experience (python or java, etc) Skills in graphical data visualization (important for communicating with clients) Strong communication skills, including the ability to explain complex ideas to an audience with a non-technical background Some experience with SQL Experience with pyspark Strong SQL skills Remote Work Environment #ChooseOurOwnAdventure . Read more about our remote work environment here! Summer Hours ️ Wellness Program Lunchtime virtual gym sessions? Count me in! Course Reimbursement Program – We want you to keep learning, so we can too! Personal Days in addition to Vacation days An extra day off during the month of your birthday - our gift to you! Open and transparent communication, including bi-weekly All Hands Meetings with our CEO Pelmorex Learning Academy includes offerings like French, Leadership (for people leaders and non-leaders alike), yoga, mindfulness Your mental health is important to us! We partner with Inkblot for virtual counseling sessions Free online doctor visits with Maple Online Healthcare Personal Spending Account - Full-Time employees will receive $500 per year While we encourage 1:1 conversations, we recognize that not everyone is comfortable with speaking up. We have an anonymous reporting platform (Speakfully) to ensure everyone’s voice is heard Weather is inclusive, we will be too. We have an IDEAS (Inclusion, Diversity, Equity, Awareness, Solidarity) team committed to making this happen! 
ScrapedJobID294:
5 to 6 year Experience in Data science, ML Model, Azure (ADF, databricks, SQL) to read the data landed, review results from model output and compare with on-prem results. Resource should have knowledge on automating ML Model and writing algorithms Resource should have Knowledge on SQL, Oracle and Hadoop Knowing Pyspark, Scala and Spark could be a added advantage Knowing ETL Testing. Should have experience on Waterfall and/or Agile projects. Should be quick learner, and should be able to work independently, co-ordinate with client and dev team. Should co-ordinate with multiple stakeholders and build Test strategy/ Test Approach Should communicate any issues or risks to the client along with mitigation plan. Should Lead a team of testers, and be capable of driving the team towards the project goal 8 hour shift Monday to Friday Bachelor's Degree (preferred) Data Scientist: 6 years (preferred) Databricks, SQL, ADF: 3 years (preferred) Machine learning: 3 years (preferred) Azure, SQL: 3 years (preferred) Temporarily due to COVID-19 
ScrapedJobID295:
Use our modern tech stack, AWS (Redshift & Kinesis), Databricks and PySpark, Airflow, and Tableau to develop innovative tools Work closely with marketing teams to craft, test, verify and implement end-to-end data pipelines that ingest data from multiple sources and output meaningful insights to optimize Zynga audience growth Apply statistical methodologies to evaluate performance and account for uncertainties in major initiatives Design and develop using standard practices within a GitHub environment BS in Computer Science, Math, Statistics, Economics, or other quantitative field; Masters or PhD strongly preferred 3+ years of work experience in data science or analytics roles Demonstrated experience with some or all of the following: data mining, predictive modeling, statistics, experimental design, application development, computational analytics, econometric modeling, data visualization Proficient in Python, SQL, and other programming languages; Experience with visualization software such as Tableau and/or app design using libraries such as Plotly Dash Strong written and oral communication skills Competitive salary, bonus plan, Zynga RSU’s (Restricted Stock Units), ESPP (Employee Stock Purchase Plan) RRSP Company Match Contribution Extended Health coverage, dental, disability, critical illness, EAP, and life insurance Virtual mental health and neurodiversity support programs Goodlife fitness annual membership Open vacation policy Family planning support program Generous paid maternity/parental leave Subsidized Back-up child care Zynga happy hours and frequent employee events Casual dress every single day Culture of diversity and inclusion including employee resource groups Work with cool people and impact millions of daily players 
ScrapedJobID296:
Competitive salary Employee share plan A flexible office/work-from-home environment Unlimited vacation time Weekly team bonding events (that aren’t lame) And so much more! Build data architecture for sustainability, company, and product data Build scripts to ingest data from various sources Combine data sources to create meaningful insights Assist in forming ML/AI strategy Clean and prepare data for ML/AI Strong data analysis background Strong data cleaning abilities Preferred history working with ML/AI Preferred history working with sustainability, company and product data Preferred Dev-ops/Data-ops experience 
ScrapedJobID297:
Four or more years’ experience developing robust code on larger projects, including code review, refactoring, unit testing, version control, etc. Knowledge of and experience with machine learning techniques, including deep neural networks, recurrent neural networks, generative models, and attention mechanisms. Expertise in Python and PyTorch. Intellectual curiosity and drive to excel. Experience with AWS, containerization, and Linux server/network/cluster management (desirable). Degree in CS, applied mathematics, statistics, physics, or related discipline; preferably a Master’s degree or Ph.D. No prior knowledge of chemistry or pharmacology is required. 
ScrapedJobID298:
Live our One Team strategy as a culture builder and transformative leader Provide the organization with data insights, analytics, and tools to achieve business goals, foster innovation, and promote data-driven decision-making. Continuously improving the business’s data analysis model, creating industry-leading performance through the leveraging of new and creative data-sources, and employing the latest in machine learning in the department Engages stakeholders and champions the design and development of data science initiatives. Researches and incorporates emerging technologies and methods to continuously improve analytic capabilities and enhance capacity to provide valuable results. Oversee the identification and integration of technology advancements that support the organization’s delivery of services and products. Lead the development of big data capabilities and utilization as well as the coordination of cross-functional analytic initiatives. Builds team capability with mentoring, coaching, and professional development. Enable the team to develop custom models and algorithms to uncover insights, trends, and patterns in the data, which will be useful in availing informed courses of action. Master's degree in computer science, mathematics, engineering, or related area preferred. 15 + years of professional experience, including statistics and analytics experience. Minimum 7 years management experience in high performing organizations Strong knowledge of analytics and statistical software Exceptional integrity, with the ability to stay true to one's own cause and purpose while incorporating the opinions, needs, and feedback of others The desire and ability to work collaboratively and virtually with staff members across teams Strong leadership skills, with an ability to lead a cross-functional group in a unified direction as well as an ability to influence and move top business leadership and executives. Extensive experience solving analytical issues through quantitative approaches and machine learning methods as well as using advanced statistical methods, data mining techniques, and information retrieval. Experience in analyzing and manipulating large, complex, high-dimensional data from numerous sources. The candidate must also be highly familiar with modern machine learning techniques for classification and regression as well as knowledge of A/B testing, experimental design, and general statistical modeling. Exceptional communication skills in order to be able to tailor and convey technical messages in a clear and understandable manner, leading to business-wide improvement of data management, informed decision making, and ultimate improvement in performance. 
ScrapedJobID299:
Design, development and evaluation of highly innovative models Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation Work closely with software engineering teams to drive real-time model implementations and new feature creations Analyze internal behavior tracking data and forecast Wish demand Implement the strategies and set up A/B test experiments to gauge the impact, and reiterate Propose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process Create & own dashboards and analytical reports to track progress & share learnings Bachelor's or advanced degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics or similar) 3+ years of hands-on experience in predictive modeling and analysis 3+ years experience writing complex SQL queries in a business environment 2+ years in Python A/B test experience Experience collaborating with business & eng teams Analytical mindset and ability to see the big picture and influence others Detail-oriented and must have an aptitude for solving unstructured problems Ability to work effectively in a multi-task, high volume environment Ability to be adaptable and flexible in responding to deadlines and workflow fluctuations Experience operating in a Unix/Linux environment Strong presentation skills 
ScrapedJobID300:
A machine learning engineer, with professional experience or equivalent applied research, strongly motivated by building impactful and dependable products based on pragmatic and rigorous application of ML techniques. You have the drive to learn, evaluate, and apply a range of data science and ML techniques. The applications are real-time smart grid control and optimization solutions in the context of best scalability, availability, and security principles. You are a pragmatic innovator who thrives in a fast-paced, disciplined, and team-oriented environment where we strive individually while supporting, learning from, and building on each other's ideas and efforts to succeed as a team. You have strong verbal and written communication skills with the ability to distill complex technical concepts to the level that non-specialists can comprehend. You are effective at teamwork, and you enjoy mentoring. Analysis, design, and implementation of ML solutions to prediction and optimization tasks. Develop statistical and machine learning solutions for analysis, data mining, and modeling of IOT data. Develop resilient testing strategies to monitor model performance. Prepare documents and presentations to inform and demonstrate. Experience as a ML scientist within a commercial environment, or equivalent academic research experience with pragmatic experimentation or industry collaborative projects. Experience with cleaning, reshaping, exploring, and visualizing data in various formats. Strong programming knowledge and skills in Python. Familiarity with machine learning tools and platforms such as TensorFlow, Keras, etc. Experience in developing ML techniques for time-series prediction: e.g. regression, support vector machines, and neural networks. Familiarity with control and optimization of modern power and energy systems. MSc or PhD in Mathematics, Statistics, Computer Science, or related data-intensive fields. Exceptional Candidates with a Bachelor's degree with strong relevant solution delivery experience are encouraged to apply. Motivation to serve to the greater cause of climate change mitigation. Knowledge, skills, and professional networking in one of the most exciting and positively impactful technology domains on the intersection of electrical engineering, machine learning, optimization, and software development. Startup experience and ground floor opportunities for growth in an inter-disciplinary team that includes PhD Smart Grid and Machine Learning Scientists, recent grads, and seasoned business professionals. Competitive compensation. High quality of life and career in Canada's National Capital Region or remote work. Working on a team with a serious approach towards our work, rather than ourselves, together with fun and random team events. 
ScrapedJobID301:
Identify opportunities, advocate and direct changes to regional pricing, fraud prevention, vendors and customized offers ensuring positive player value and sentiment. Collaborate with Insight, Marketing and Development teams to improve the player purchasing experience Working closely with the Finance team ensuring proper management of VAT, sales tax, financial tracking and chargebacks Manage relationships and data pipeline with third party vendors Use iterative experimental approaches, statistical methods and modelling to measure the effectiveness of changes Extract and organize data into a reliable user-friendly form and present it to the interested and affected parties on the team Conduct ad hoc data analysis based on current team needs and management priorities Bachelor’s degree in a technical or quantitative discipline (Mathematics, Economics, Statistics, Computer Science, MIS, other) Minimum 3 years of experience using Data Science techniques A passion for video games and understanding of gaming culture Experience with regional pricing, custom offers and fraud of digital goods In-depth knowledge of Postgres SQL, Mongo DB, Python Notebooks Experience in the gaming industry, specifically Free to Play gaming is a plus Strong quantitative analysis techniques and qualitative methods, as well as predictive modelling Demonstrated success presenting complex research data (both qualitative and quantitative) in a clear and compelling manner that inspires action Excellent organizational, communication and interpersonal skills Self-starter who can manage their time effectively and has the interest of integrating into a team of passionate, highly intelligent game developing ninjas Competitive salary with bonus opportunities Excellent benefits and paid time off Matching RRSP plan Employee Assistance Program (EAP) Professional development and career support Fitness and parking/transit subsidies Daily lunches prepared onsite by our in-studio Executive Chef and professional kitchen staff All-day snacks and drinks, sleep pods, massage chairs, cold brew, dog therapy days and more 
ScrapedJobID302:
8 hour shift Monday to Friday machine learning: 1 year (preferred) 
ScrapedJobID303:
Safe work environment Food provided Adapt statistical methods to solve specific problems in many fields, such as economics, biology, and engineering. Analyze and interpret statistical data to identify significant differences in relationships among sources of information. Design research projects that apply valid scientific techniques and use information obtained from baselines or historical data to structure uncompromised and efficient analyses. Determine whether statistical methods are appropriate, based on user needs or research questions of interest. Evaluate sources of information to determine any limitations, in terms of reliability or usability. Evaluate the statistical methods and procedures used to obtain data to ensure validity, applicability, efficiency, and accuracy. Identify relationships and trends in data, as well as any factors that could affect the results of research. Plan data collection methods for specific projects and determine the types and sizes of sample groups to be used. Present statistical and nonstatistical results, using charts, bullets, and graphs, in meetings or 8 hour shift machine learning: 1 year (preferred) No 
ScrapedJobID304:

ScrapedJobID305:
Create models of the world and extract insights from complex, unstructured 3D point clouds Write production code for use in extracting geospatial insights from a variety of data sources Increase the efficiency and repeatability of our ML training process on new datasets and/or additional features classes Create infrastructure for rapid training and testing ML systems Provide insight into trends and novel work in machine learning 3+ years experience in 2 or 3D computer vision/machine learning Expertise with object semantic segmentation and classification Mastery of Python and prior experience with GPU acceleration Capability with deep learning frameworks (ie, TensorFlow, Keras, etc) Prior experience with cloud computing, AWS preferred Excellent communication skills Rigorous analytical thinking BS in engineering, computer science, or a related field Prior experience with GIS, lidar, or photogrammetry MS or PhD in engineering, computer science, or a related field Opportunity to play a foundational role at a well-funded startup with major clients and revenue Work with people like yourself—talented and thoughtful; passionate about solving challenging problems Unlimited vacation policy (we're serious about this - do great work, have fun and live life) Internet Reimbursement Supplemental health insurance benefits 
ScrapedJobID306:
Design, train and evaluate models. You will solve challenging drug discovery problems by designing fit-for-purpose ML and statistical models and data splits from our massive in-house cellular imaging datasets. You'll help train these models using our on-premise NVIDIA A100 superpods and collaborate with biologists, chemists, automation engineers, data engineers, and other scientists to refine models, possibly generating more data in the process, until they provide a reliable productionized solution. Create maps of biology. You will be an essential part of achieving Recursion's mission to decode biology and radically improve lives by helping to turn our massive datasets into maps of human disease biology that allow drug hunters to quickly and accurately navigate to optimized small molecule therapies for hundreds of diseases. Share your work. You will represent Recursion to the scientific community by presenting your work at top conferences and publishing in top scientific journals. Define excellence in execution. You will use your technical knowledge to set a high standard of delivery, impact, learning, and growth across teams at Recursion. PhD in Computer Science or related quantitative field or the equivalent practical experience. For Senior leveling an additional 2+ years working in a relevant area. Experience applying modern ML and statistical methods to large datasets and reasoning about the outcomes. Experience with microscopy/biomedical imaging data, chemical data, or genomic data is a plus. A working knowledge of the drug discovery process is a huge plus. Extensive experience using modern technologies to accelerate machine learning (e.g. PyTorch, TensorFlow/Keras, Horovod, etc) Outstanding past projects, publications, and presentations, and a demonstrated ability to communicate results to cross-functional stakeholders. Curiosity and the professional skill-set to excel in an open, highly collaborative environment. 100% Coverage of health, vision, and dental insurance premiums 401(k) with generous matching (immediate vesting) Stock option, restricted stock unit (RSUs) and employee stock purchase plan (ESPP) programs Two one-week paid company closures (summer and winter) Flexible vacation/sick leave Generous paid parental leave (including adoptive) Onsite daycare facility** (Salt Lake City) Commuter benefit and vehicle parking to ease your commute** Complimentary chef-prepared lunches and well-stocked snack bars** (Salt Lake City) Monthly fitness/wellness stipend One-of-a-kind 100,000 square foot headquarters complete with a 70-foot climbing wall, showers, lockers, and bike parking** (Salt Lake City) 
ScrapedJobID307:
Work with product managers and other stakeholders to understand their requirements, business problems and insights they are seeking to gain from data analysis. Utilize statistical tools to interpret data sets and prepare reports that effectively communicate trends, patterns, and predictions based on relevant findings. Examine large data sets to identify trends, develop charts, and create visual presentations to help businesses make more strategic decisions. Deliver presentations to demonstrate the insights and learnings from the analysis with context from other stakeholders to deliver the story. Write SQL queries to find answers to complex business questions. Identify any data quality issues and partialities in data acquisition and work with the necessary teams to identify and resolve. Coordinate with the engineering team to gather incremental new data. Process, cleanse, and verify the integrity of data used for analysis. Use data mining, model building, and other analytical techniques to support internal initiatives. Work with data scientists and leverage machine learning models that have been developed against Geotab’s big data environment. Post-secondary Degree/Diploma specialization in Computer Science, Software Engineering, Science, Mathematics, or a related field. 0-5 years experience as a Data Analyst or a similar role. 3-5 years experience with SQL. 3-5 years experience with data science tools (e.g. Python, Pandas, NumPy). Experience working with big data and an understanding of techniques used to extract value out of very large datasets. Experience working with stakeholders of different levels across the organization from individual contributors to VPs and to deliver presentations that drive business decisions Experience with database design and writing queries. Familiarity with machine learning concepts is an asset. Strong analytical skills with the ability to problem solve well-judged decisions. Strong team player with the ability to engage with all levels of the organization. Technical competence using software programs, including but not limited to, Google Suite for business (Sheets, Docs, Slides). Google Cloud Platform & Google Analytics. Entrepreneurial mindset and comfortable in a flat organization. 
ScrapedJobID308:
Master's degree in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field 3+ years of applied research experience 2+ years of experience in building machine learning models for business application Experience with machine learning, data mining, and/or statistical analysis tools Significant hands-on experience with at least two programming languages, such as Python, Scala, Java, C# or similar languages Excellent communication, writing and presentation skills Collaborate with engineering teams to design and implement software solutions for science problem Contribute to progress of the Amazon and broader research communities by producing publications Ph.D. in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field 4+ years of practical experience applying ML to solve complex problems in an applied environment Significant peer-reviewed scientific contributions in premier journals and conferences with high quality citations/h index Strong CS fundamentals in data structures, problem solving, algorithm design and complexity Strength in clarifying and formalizing complex problems Superior verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts 
ScrapedJobID309:
An accomplished and performance-driven professional with over a minimum of 7+ years of technical & managerial experience in IT sector across technical consulting, designing a future proof of Data Architect for Telecom, Network preferably or in Billing, IN and VAS, DWH, CRM, CC, HRIS, Big Data Tools, RDBMS, ERP, POS & Marketing Data Analysis. Expertise in Business Intelligence, Data Warehousing, and Reporting tools in the Telecom industry. Having 4 years of experience working with Tableau Desktop, Tableau Server in various versions including Tableau. Having 4 years of work experience with statistical data analysis such as linear models, multivariate analysis, statistical Analysis, Data Mining, and Machine Learning techniques. Expertise working with statistical data analysis such as linear models, Statistical Analysis, and Machine Learning techniques. Hands-on experience Python to develop analytic models and solutions mapper & reducer. Hands-on experience in creating insightful Tableau worksheets, dashboards to generate segment analysis and financial forecasting reports. Proficient in creating data modeling for 360 customer view & customer behavior. Strong skillset in PLSQL, ETLS, Business Intelligence, SQL Server Integration Server (SSIS), and SQL Server Reporting Services (SSRS). Proficient in Data Cleansing and Data Validation checks during staging before loading the data into the Data warehouse. Highly proficient at using PLSQL for developing complex Stored Procedures, Triggers, Indexes, Tables, User Defined procedures, Relational Database models and SQL joins to support data manipulation and conversion tasks. Highly skilled in creating, maintaining, and deploying Extract, Transform and Load(ETL) packages to Integration Server using Project Deployment and Package Deployment models. Outstanding interpersonal communication, problem-solving, documentation, and business analytical skills. Data Analytics Tools/Programming: Python (numpy, scipy, pandas), MATLAB, Microsoft SQL Server, Oracle PLSQL, Python. Data Visualization: Tableau, Visualization packages, Microsoft Excel. Machine Learning Algorithms: Classifications, Regression, Clustering, Feature Engineering. Data Modeling: Star Schema, Snow-Flake Schema. Big Data Tools: Hadoop, MapReduce, SQOOP, Pig, Hive, NoSQL, Spark. Databases: Oracle, SQL Server, Teradata. ETL: Informatica, SSIS. Others: Deep Learning, Text Mining, c, Javascript, Shell Scripting, Spark MLLib, SPSS, Cognos. Involved in developing analytics solutions based on the Machine Learning platform and demonstrated creative problem-solving approach and strong analytical skills. Interact with the other departments to understand and identify data needs and requirements and work with other members of the IT organization to QlikView-based deliver data visualization and reporting solutions to address those needs. Worked with the Architecture team to get the metadata approved for the new data elements that are added for this project. Data Storyteller, Mining Data from different Data Sources such as SQL Server, Oracle, Cube Database, Web Analytics, Business Object, and Hadoop. Provided ad-hoc analysis and reports to the executive-level management team. Creating various B2B Predictive and descriptive analytics using R and Tableau. Exploratory analysis and model building to develop predictive insights and visualize, interpret, report findings, and develop strategic uses of data. Utilize Spark, Scala, Hadoop, HBase, Kafka, Spark Streaming, MLLib, R, a broad variety of machine learning methods including classifications, regressions, dimensionally reduction, etc. Designed and provisioned the platform architecture to execute Hadoop and machine learning use cases under Cloud infrastructure. Selection of statistical algorithms - (Two-Class Logistic Regression Boosted Decision Tree, Decision Forest Classifiers, etc). Used MLlib, Spark's Machine learning library to build and evaluate different models. Involve in creating Data Lake by extracting customer's Big Data from various data sources into Hadoop HDFS. This included data from Excel, Flat Files, Oracle, SQL Server, Mongo DB, HBase, Teradata, and also log data from servers. Create high-level ETL design documents and assist ETL developers in the detailed design and development of ETL maps using Informatica. Used R, SQL to create Statistical algorithms involving Multivariate Regression, Linear Regression, Logistic Regression, PCA, Random forest models, Decision trees, Support Vector Machines for estimating the risks of welfare dependency. Helped in migration and conversion of data from the Oracle database, preparing mapping documents, and developing partial SQL scripts as required. Generated ad-hoc SQL queries using joins, database connections, and transformation rules to fetch data from legacy Oracle and SQL Server database systems. Worked on predictive and what-if analysis using R from HDFS and successfully loaded files to HDFS and loaded from HDFS to HIVE. Analyze data and predict end customer behaviors and product performance by applying machine learning algorithms using Spark MLlib. Performed data mining on data using very complex SQL queries and discovered patterns and used extensive SQL for data profiling/analysis to provide guidance in building the data model. Create numerous dashboards in tableau desktop based on the data collected from zonal and compass, while blending data from MS-excel and CSV files, with MS SQL server databases. 
ScrapedJobID310:

ScrapedJobID311:
Apply advanced analytics to large data sets to drive the development of use cases that meet customer needs Work with subject matter experts to determine relevant use cases Collaborate with Data Engineers to develop use cases into deployable models Develop tools to monitor and analyze the effectiveness of use cases and new data sources Remain current with cyber threat trends to enhance use cases Other related data analytics support as may be required Master’s degree in Computer Science, Mathematics, Machine Learning or similar 5+ years related work experience with advanced analytics and machine learning Experience with Spark, R, Python, Java, SQL, Hadoop Knowledge of advanced statistical and machine learning techniques General knowledge of enterprise data security Working knowledge of Unix/Linux command line tools Excellent written and verbal communication skills and experience presenting Experience in GCP machine learning and big data tools is an asset Dental care Extended health care Vision care Master's Degree (preferred) Data Science: 3 years (required) Yes 
ScrapedJobID312:
Teach our 12-week Data Science Diploma program Help build a world class technical team passionate about designing and teaching Deliver lectures and provide expert technical guidance to students who are building exciting projects using the most cutting-edge technologies Facilitate in-class activities, group discussions, demos and mentor the next wave of emerging talent Co-create BrainStation's curriculum that will positively impact the lives and careers of hundreds of individuals across our campuses Actively work on writing and researching new content to teach the most up to date design skills to our students Apply BrainStation's "Agile Education" methodologies to the program to continuously improve the educational experience for students Constantly improve your own skills and apply these skills in collaboration with other BrainStation Educators in order to build the digital platform and tools needed to effectively deliver educational material Define the education experience of the future 3-5+ years experience as a Data Scientist or Analytics professional and a Bachelor's degree relevant to the subject matter OR 8+ years work experience in the vocation Strong command of querying and programming languages (SQL, R and python - numpy, pandas, sklearn, TensorFlow & Keras), and visualization tools (Excel, Tableau, matplotlib/seaborn/plotly in python packages Experience applying various methods of numerical and categorical modelling techniques and supervised and unsupervised machine learning methods (OLS regression and GLMs, logistic regression, KNN, SVM, decision trees/random forest, clustering and cluster analysis, dimensionality reduction, neural networks) Hands-on development experience working with version control systems (we use Git) and Big Data and Cloud platforms (Hadoop, Spark, Amazon Web Services (AWS), Google Cloud (GCP)) a strong asset regression and machine learning principles Practical experience designing and applying data science processes to conduct experiments using a variety of tools and methods, and can speak to their complexities in a simple and logical manner Experience building and leading technical teams Experience in a teaching role, and are comfortable speaking to large groups and mentoring others on the job A strong work ethic with the utmost integrity and desire to excel and succeed An empathetic, inclusive, enthusiastic personality, and is someone who enjoys helping others and facilitating learning A passion for teaching and mentoring others and creating positive learning experiences Comprehensive Health & Wellness Benefits Package Retirement Planning Parental Leave Program New Device Allowance Socials, Outings & Retreats Culture of Learning & Development Flexible Working Hours Work from Home Flexibility 
ScrapedJobID313:
Research and develop analysis, modeling, and optimization methods to improve the AI in Oracle CX Marketing products. Participate in cutting edge research in machine intelligence and machine learning applications in enterprise marketing cloud. Work with large, complex data sets. Solve difficult, non-routine analysis problems, applying advanced ML methods as needed. Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations. Provide recommendations on our ML and experimentation roadmap, proposing what to study and to develop to bring ML methods to scale at Oracle CX. Develop the experimentation platform by researching new methods and conducting rigorous analyses Mentor other Data Scientists, and help them to develop their projects related to experimentation and evaluation Provide guidance on statistical, deep learning and machine learning methodological problems across the Oracle CX Develop solutions for real world, large scale problems. Implement data science pipelines and applications in a general programming language such as Python, Scala, or Java, or Spark Craft a measurement strategy to evaluate the performance of complex systems against challenging requirements Experience in Natural Language Understanding, Computer Vision, Machine Learning, Algorithmic Foundations of Optimization, Data Mining or Machine Intelligence (Artificial Intelligence). In-depth knowledge of machine learning algorithms and their applications including practical experience with and theoretical understanding of algorithms for classification, regression, clustering, deep learning and reinforcement learning. Programming experience in C, C++, Python. Strong communication, and ability to explain difficult technical topics (especially causal topics) to everyone from data scientists to engineers to business partners. Ability to ingest large data using at least one query language (e.g., SQL, Spark, etc.), and use one of scripting language for more sophisticated analyses (e.g., R, Python, Scala). Self-starter with strong leadership abilities. Excellent presentation skills, distilling complex analysis and concepts into concise business-focused takeaways Excellent problem solving, critical thinking, analytical and interpersonal skills Able to work well with diverse roles such as product managers and engineers Ability to handle multiple projects with strict deadlines Experience with the machine learning life cycle and libraries in Python/Scala Experience with one or more deep learning frameworks e.g., TensorFlow, PyTorch. Working knowledge of relational databases, including SQL, and large-scale distributed systems such as Hadoop and Spark Bachelors, Masters, or PhD Degree in Computer Science/Machine Learning or equivalent professional experience. 
ScrapedJobID314:
Awesome work-from-home policy with quarterly in-person meetings around the world Competitive salaries for quick-learners and fast-paced individuals You will have the ability to gain career experience beyond strict job requirements, with decision-making power to be the master of your own projects Resources for self-improvement including courses, software, workshops, and conferences We are committed to hiring great people from diverse backgrounds, not just because it’s the right thing to do, but because it makes our company stronger Architect and develop end-to-end Machine Learning models/Reinforcement learning systems, working collaboratively with the Data Science team to optimize train operations in real world settings Collaborate with the software development team to integrate ML/RL solutions into RailVision’s product offering Design and build environments to simulate realistic rail operations that perform with high accuracy to live environments Collaborate with members of the Operations and Engineering teams to proactively deliver critical insights about product performance and customer operations Maintain a high-level of communication between managers and development team Conduct formal presentations to other team members, managers, and in public Contribute to various aspects of a growing company Be an ambassador of technological advancement and revolutionized transportation Grow personal connections to the industry to understand trends and opportunities 1-2 years of relevant work experience Hands-on experience developing and deploying ML models, data pipelines, and running experiments to validate your models Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and common CS algorithms Strong working knowledge of statistical techniques (distributions, regressions, error bounds, etc.) Experience with git version control, docker, agile methodology, MS 365, and other common software tools Educational background in Computer Science, Engineering, Physics, or Mathematics (MSc. preferred) (Bonus) Experience in the rail industry Python including data processing modules NumPy, Pandas, SciPy Python Machine Learning modules such as Keras, TensorFlow, PyTorch SQL (MySQL and Postgres) TimeSeries database (InfluxDB) Cloud computing specifically AWS (VPC, S3, Aurora, RDS, EC2, Step Functions, Lambda, SageMaker) APIs: REST, GraphQL Data Formats: CSV, JSON, XML Development tools: PyCharm, Docker, GIT, Jira, Confluence Agile Development (Kanban, SCRUM) Driven, self-motivated, and detail-focused individuals Clear and concise communicators Passion for career growth and continuous learning Organized in work habits, schedules, timelines, documentation and correspondence Remote work with quarterly in-person meetings (location is voted on every quater) Incentives offered such as Employee Stock Options and yearly bonuses 
ScrapedJobID315:
Design and build models/algorithms to drive predictive & prescriptive analytics and help accelerate business decisions and drive real-time analytical insights Research and brainstorm with internal stakeholders to identify advanced analytics opportunities and advance automation, help with knowledge discovery, support decision-making, gain insights from data, streamline business processes, and enable new capabilities Lead efforts in advanced analytics solutions to produce value from the company’s unstructured and structured data assets utilizing methodologies from machine learning, deep learning, artificial intelligence, and natural language processing Develop end-to-end efficient model solutions that drive measurable outcomes. Manage the model development lifecycle, including both working with data engineers to identify what data are needed, and training the business end-users on how to leverage the modeling output Work with stakeholders in development, assessment, improvement, and transfer of solutions as needed Prepare documentation, reports, and presentations that explain advanced analytics concepts, technology, and inner workings of solutions to broader teams including non-technical audiences Masters/ PhD in a quantitative field such as data science, statistics, economics, operations research, computer science, applied mathematics, engineering, etc. 5-7 years relevant industrial experience (preferably B2B, eCommerce), in solving complex business problems using data science, statistical techniques & machine learning to build predictive & prescriptive solutions to grow customer base and sales Proven experience in managing and manipulating large, complex datasets Demonstrated experience in executing on complex projects, extracting, cleansing, and manipulating large, diverse structured and unstructured data sets on relational – SQL, NOSQL databases Working knowledge of machine learning/artificial intelligence. These technical skills include, but not limited to, regression techniques, neural networks, decision trees, clustering, pattern recognition, probability theory, stochastic systems, Bayesian inference, statistical techniques, deep learning, supervised learning, unsupervised learning 5+ years of hands-on experience with programming languages such as Python (preferred), R and common machine learning packages such as dplyr, xgboost, glmnet, randomForest, H2o, Numpy, Pandas,scikit-learn, keras, tensorflow, etc. Experience in Spark environment is a plus Hands-on experience in developing and productionizing solutions using tools in AWS, data aggregation platforms such as Snowflake or similar. Good communication and presentation skills, with the ability to tailor the communication style to the right audience Experience working in an agile environment with iterative development & business feedback Experience providing insights to support strategic decisions, including preparing and delivering insights and recommendations Competitive pay Medical, Dental & Vision 401k/RSP with Match Paid time off Flexible working environment Continuous Learning And an amazing culture to top it all off! 
ScrapedJobID316:
Use data analytics and data science techniques to plan and implement consulting projects from customers and other Geotab stakeholders. Provide expert project leadership as a SME: guidance to team members and participate in cross-departmental projects. Assist in shaping the direction of analytics consulting projects and internal initiatives related to Data Analytics. Collaborate with internal technical teams and external stakeholders to gather requirements. Create algorithms and predictive models to extract information required to solve complex business problems. Conduct causality experiments by applying A/B experiments or epidemiological approach to identify the root issues of an observed result. Provide feedback to product managers on the Data & Analytics and Product teams to improve Geotab’s products. Maintain technical knowledge of the Geotab ecosystem and act as the SME to enable end-users to better understand Geotab solutions. Lead and create training sessions for audiences with a variety of technical backgrounds. Although this position has no direct reports, the Senior Solutions Engineering, Data Science candidate is expected to mentor junior team members to help them implement projects successfully. 3-5 years of experience in Analytics Consulting or Data Science (customer facing preferred), or related field. Post-Secondary Diploma/Degree specialization in Engineering, Statistics, Math, Computer Science or a related field. Knowledgeable in data science tools and language (SQL, Python). Knowledge of Google BigQuery and Google Cloud Platform is a plus. Strong aptitude for understanding business requirements and creating a plan of analysis based on these requirements. Strong knowledge of statistics and data science techniques. Previous experience with Airflow, Spark, Beam, or similar tools. Experience withCloud Composer, Dataflow, Dataproc, Cloud Functions, Cloud Build a plus. Knowledge of programming languages (e.g. JavaScript). Excellent verbal communication skills, including comfort with delivering presentations and training. Excellent written communication skills, able to document technology solutions in precise detail, while also being able to summarize it succinctly. Data Visualization Skills, particularly in dashboarding platforms. Strong interpersonal relationship building skills. Highly organized and able to manage multiple tasks and projects simultaneously. Be highly accountable, and possess strong communication skills. Ability to travel up to 20% of the time when required even internationally. 
ScrapedJobID317:
To work with some of the best professionals in the business - for a firm that values individual intellect as much as teamwork State-of-the-art offices that are designed to maximize collaboration Flexible working arrangements Enriching challenges that provide opportunity for constant learning and advancement An environment which is leveraging technology to its highest potential Bachelor's degree required, Ph.D. desire Development experience in Python or R (C, C++, Java, etc. is a plus) Track record of publications in competitive venues is highly desired Deep understanding of statistical learning methods Strong communications and organizational skills 4+ years of applicable research experience Video dated October 2019. 
ScrapedJobID318:
Apply deep learning techniques to the simulation of virtual environments, developing methods to generate synthetic data for training neural networks to achieve results comparable to networks trained on real data Work on improving realism for agents in synthetic environments – using reinforcement learning techniques to control behavior and animation of simulated characters, crowds, and vehicles Conduct research into novel Deep Learning network architectures and techniques for achieving the above. Perform additional development around related technologies as applied to games, VR and visual effects applications. Currently pursuing a PhD, MS, or BS in Computer Science or related field. 1+ year experience with C++/C, CUDA, DirectX, or OpenGL in addition to Python, PyTorch and TensorFlow. Expertise in neural networks, computer graphics, simulation or game development. Dedication to producing high quality and creative results You are a great communicator and self-motivated towards team goals You welcome mentoring others around you Sharp mathematics skills 
ScrapedJobID319:
Software Development Environments - Experience in either Java, Scala, or Python; Software content management tools such as git (preferred) or SVN; Experience with functional programming. Software Engineering - Understanding of core software design patterns; Practical experience with distributed computing is an asset; Apache Spark is preferred, Apache Hadoop Map/Reduce or experience with other similar distributed compute engines; Automated code deployment to various environments. Machine Learning - Experience with any of the following machine learning toolkits: Weka, Spark, h20.ai, Tensorflow, Keras, Pytorch, R is valued Natural Language Processing - Experience with any of the following toolkits: Gate NLP, Open NLP, Stanford NLP, Python NLTK, Apache UIMA, R We thank you for your interest, however, only those who qualify for an interview will be contacted. 
ScrapedJobID320:
Working with stakeholders, including Tech Leadership, Marketing, Product Management, Platform Operations, to formulate critical business operation questions for investigation and analysis Conducting data analysis and research in line with critical business questions to provide insights, recommendations and drive improvements Communicating results of analysis and recommendations clearly and concisely to a variety of stakeholders Defining and running experiments that deliver impactful results Creating dashboards, reports and papers presented in an appropriate way for stakeholder consumption Understanding our data model, contributing to shared data model documentation, and recommending new data collection to Engineering when required to support objectives Extracting, integrating and validating sample data sets from various sources including big data environments 3+ years of professional experience, ideally in a similar role Post-secondary education with a strong analytical component, e.g. statistics, business, social sciences, sciences Able to prioritize and manage multiple projects in a fast-paced environment Resourceful and self-reliant; a strong self-starter with a passion for learning Excellent communicator with an ability to clearly explain complex technical subjects to a variety of stakeholders Ability to translate data analysis into stories, insights and recommendations Experience applying statistical methodologies to test design, measurement and analysis Knowledgeable about best practices around data manipulation, extracting data from big data systems, feature engineering and creating dashboards Experience working with Relational Databases including SQL Experience with Python, R or similar language for data analysis Experience working with data visualization tools (e.g. PowerBI, Tableau) Knowledge of the digital advertising industry (e.g. AdWords, DSPs, ad-serving). Experience defining and running experiments. 
ScrapedJobID321:
As a ML engineer, you will design and build large scale ML systems that can process billions of products ML models for wrapper induction that require few training examples, NLP models for understanding free-texts Drive cross functional collaborations with partner teams working on shopping 3+ years of industry experience Hands-on experience on large scale machine learning systems (full ML stack from modelling to deployment at scale.) Hands-on experience with big data technologies (e.g., Hadoop/Spark) and scalable realtime systems that process stream data Nice to have: PhD in Machine Learning or related areas, publication on top ML conferences, Familiarity with information extraction techniques for web-pages and free-texts, Experience working with shopping data is a plus 
ScrapedJobID322:
A University Degree or Technical Diploma from an accredited institution in computer science, software engineering, or a combination of related education and experience. Experience in deep learning and computer vision – academic experience is acceptable Working understanding of Python and Matlab Working understanding of ML tools and frameworks (PyTorch, TensorFlow, CUDA, Docker etc.) Knowledge of convolutional neural networks such as U-Net for biomedical image segmentation Experience with deploying ML into a real-time C++ application Experience in mathematical optimization, linear algebra and signal processing Possess excellent problem-solving, critical thinking skills. Excellent verbal and written communication skills. Medical imaging, image processing and, in particular, ultrasound imaging Software as a medical device (SaMD) and related regulations/standards including ISO 13485, ISO14971, Health Canada and US FDA QSR 
ScrapedJobID323:
Huge market ($800 billion market size), we are building the first AI-powered super app to help people own a car; Innovative product with the combination of cutting edge mobile, AI and big data technologies; Open, transparent, merit-based culture; Best user experience: #1 ranked app in the insurance comparison category; Strong leadership: from Amazon, Microsoft, Facebook, Nvidia, Alibaba, etc. and rockstar colleagues. Create a smart prediction engine for customers’ insurance coverage needs. Build predictive models on customer purchase behavior based on a large data set. Use telematics tracking to build customer driving risk profile. Analyze large amounts of data to discover trends and patterns, solve a wide array of challenging problems using different analytical and statistical approaches. Apply technical expertise with quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products. Identify and measure the success of product efforts through goal setting, forecasting, and monitoring of key product metrics to understand trends. Partner with relevant teams (e.g. product, engineering, and marketing) to build better models, solve problems and identify trends and opportunities from both a market and user perspective. SQL and MapReduce job tuning to improve data processing performance. Bachelors/Masters Degree with 1+ years of experience working within an analytical role. Strong SQL skills. Able to write algorithms needed for modeling and prediction that deal with advanced data structures. Experience solving analytical problems using quantitative approaches. Follow Data Science literature and advancements. The most successful candidates possess the ability to apply cutting-edge advancements in data science methodologies to relevant business problems. 
ScrapedJobID324:
Monday to Friday Temporarily due to COVID-19 
ScrapedJobID325:
State-of-the-art offices that are designed to maximize collaboration Flexible working arrangements Enriching challenges that provide opportunity for constant learning and advancement An environment which is leveraging technology to its highest potential Analyze financial news and build machine learning/NLP models for sentiment detection, volatility signals, and other information signals. Apply these models to automated market making for trading and risk management. Collaborate with other quantitative researchers and data scientists to create innovative solutions for the various problems in electronic options market making. Analyze terabytes of equity and options market data to derive actionable intelligence to improve trading performance. PhD in NLP, automated speech recognition, or other closely related field Strong programming skills and experience in a scripting language such as Python Strong interest in quantitative trading and finance Excellent communication skills and ability to interact with traders and technology Knowledge of C++ Exposure to quantitative finance Video dated October 2019. 
ScrapedJobID326:
We offer excellent compensation packages with market competitive pay, comprehensive healthcare packages, schedule flexibility, work from home opportunities, paid time off, and organizational growth potential. Grow at your own pace through online courses at Learning @ Equifax You will utilize tools, including Python, nd SQL to extract data and assist others users to improve the performance of queries. By working closely with customers, you will understand the objectives of their projects and be able to interpret the business needs into a sound analysis plan that considers all relevant data. Build and create advanced machine learning algorithms such as regression, simulation, scenario analysis, modeling, clustering and decision trees Effectively communicate analytical results to key partners using strong data visualizations, strong presentation skills and business language to emphasize the so what of the analysis. You’ll act as the primary contact for Equifax customers using Ignite solutions (Equifax product) to answer technical inquiries or provide guidance on the use of Equifax data within specific analytical methodologies. By demonstrating your experience with data visualization tools, you will improve productivity while ensuring results are consistent across the organization. Use advanced techniques or partner with statisticians to build out predictive models that address new opportunities for a customer based on a deep understanding of their business need Bachelor’s or advanced degree in a quantitative discipline such as Engineering, Economics, Mathematics, Statistics, or Physics (essential) 4+ years’ data manipulation experience with deep knowledge of Python, spark and SQL in a large data environment 4+ years using advanced analytical techniques including decision trees, logistic regression, and, preferably, machine learning methodologies Demonstrable experience in a client-facing role with direct contact and client management responsibilities for specific deliverables and delivering high quality analytical output within tight deadlines Strong knowledge of Hadoop Tools such as Hive or Impala and Experience with developing credit scorecards is an asset, also any experience with data visualization tools (Spotfire, Tableau, Qlik) would be a plus Master’s level degree in a business-related field/MBA (preferred) Experience in working with credit data and cloud environment such as GCP is an asset Working knowledge of database design, data modeling, risk management and/or marketing practices, statistical/predictive modeling Accountability Curiosity Collaboration Think and act differently Trust Ownership 
ScrapedJobID327:
Bachelor’s degree in Computer Science, Statistics, Data Science, or any other quantitative field. 2+ years of non-internship professional experience with machine learning, statistical modeling, data mining, and/or analytics techniques. 2+ years of experience with Python, R, or other scripting languages. Advanced ability to draw insights from data and clearly communicate them (verbal/written) to the stakeholders and senior management. Computer vision and augmented reality (AR) experiences: We bring exciting experiences directly to the customer's mobile phone using their cameras and combinations of facial recognition and AR. Personalization using machine learning: We will be working with machine learning (ML) technologies such as data classification and reinforced learning models to provide better-personalized shopping experiences. Elevated customer experiences: We will create beautiful and dynamic customer experiences that require deep knowledge of relevant UI technologies and user-centric design patterns. Amazon scale systems: All our technology needs to work at Amazon scale, serving millions of customers with millisecond-level latency. Data pipeline and analytics tools: Amazon is data-driven, and a robust data backbone is necessary for our systems. We build on robust and scalable data pipelines and tools using core AWS services. Master’s degree or PhD in a highly quantitative field (Machine Learning, Statistics, Data Science, Math, etc.). Experience applying various machine learning techniques, and understanding the key parameters that affect their performance. Familiarity with deep learning algorithms and/or computer vision. Familiarity with at least 1-2 popular AI/ML frameworks and tools - TensorFlow, PyTorch, MXNet, scikit-learn, OpenCV, ARCore, and ARKit. Expertise in estimation, experimental design, hypothesis, and A/B testing. Experience partnering with engineering teams to build and test production systems. Familiarity with AWS services such as EC2, DynamoDB, RDS, AWS Lambda, and Amazon SageMaker. Ability to achieve stretch goals in a highly innovative and startup-like environment. 
ScrapedJobID328:
Gathering training data for the existing deep learning, ML and NLP solutions Providing actionable ad hoc analytics insights for internal stakeholders Designing and building recurring reports for internal stakeholders to make data-driven decisions Identifying and implementing ways to supercharge data quality and data integrity Using advanced analytical methods to explore and extract additional data value for existing and emerging products Documenting analysis results and presenting value to stakeholders Creating reusable processes to assist data evaluation and analysis across teams within Data Center 3-5 years of direct experience performing advanced data analytics or a Master’s Degree in Statistics, Data Analytics or related field 3+ years’ experience in SQL/Spark, R, Python Strong grasp of statistical modeling techniques such as linear regression, logistic regression, GLM, etc. Understand NLP concepts like: Named Entity Recognition (NER), Sentiment Analysis, Data Tokenization, Lexical Semantics, Relationship Extraction, etc. Ability to effectively communicate analysis and insights to all levels of the organization A passion for continuous learning Confidence to challenge the status quo Automotive industry experience a plus 
ScrapedJobID329:
Collaborate with cross-functional teams (Sales, Marketing, Engineering) to define, design, and ship new features In collaboration with others, design, build and validate predictive algorithms for vehicle prognostics Perform exploratory analyses and develop procedures for feature extraction in preparation for algorithm analyses Participate in software integration work to implement algorithms in production. Work on bug fixing and improving architecture performance Write documentation and present the results of work to others on the team Undergraduate or Master's degree in Engineering, Physics, Computer science or equivalent Good knowledge of statistics, experimental design, and probability 3+ years of experience in Python, R or similar scripting language 1+ years experience shipping high-quality software to enterprise customers Experience with SQL (PostgreSQL or similar) Understanding and experience with machine learning techniques such as Regression, Naive Bayes, Random Forests, Perceptrons, SVM, Deep Learning DevOps experience (Amazon, Google, Docker, Jenkins) Previous startup experience (preferably in an early-stage startup) Knowledge of automotive data, automotive physics or experience in the industry Experience with version control systems (Git, CVS or SVN) Knowledge of other programming languages including node js, C++ Experience with big data frameworks such as Spark, Hadoop. 
ScrapedJobID330:
Maintain an acute awareness of the industry and what the competitors are putting out. Investigate new options for the system from code to core. Coordinate with Senior Technical Leads regarding AI tech. Coordinate with team members to discover the best solution for the clients. Conceptualize new features that we could offer exclusively. Manage R&D Data Science Developers. 2+ years of Experience in Software Development Education: M.tech or Ph.D. in Computer Science/Engineering preferably with a focus on AI. Strong hold on Data structures and Algorithms. Experience with Anaconda/Python/Tensorflow. French Language skills. Hours: 30-40 hours/week. Wage: $85,000 - $100,000/year. 3 Weeks of Vacation. A great environment and the right tools to do great work. 
ScrapedJobID331:
Huge market ($800 billion market size), we are building the first AI-powered super app to help people own a car; Innovative product with the combination of cutting edge mobile, AI and big data technologies; Open, transparent, merit-based culture; Best user experience: #1 ranked app in the insurance comparison category; Strong leadership: from Amazon, Microsoft, Facebook, Nvidia, Alibaba, etc. and rockstar colleagues. Create a smart prediction engine for customers’ insurance coverage needs. Build predictive models on customer purchase behavior based on a large data set. Use telematics tracking to build customer driving risk profile. Analyze large amounts of data to discover trends and patterns, solve a wide array of challenging problems using different analytical and statistical approaches. Apply technical expertise with quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products. Identify and measure the success of product efforts through goal setting, forecasting, and monitoring of key product metrics to understand trends. Partner with relevant teams (e.g. product, engineering, and marketing) to build better models, solve problems and identify trends and opportunities from both a market and user perspective. SQL and MapReduce job tuning to improve data processing performance. Bachelors/Masters Degree with 1+ years of experience working within an analytical role. Strong SQL skills. Able to write algorithms needed for modeling and prediction that deal with advanced data structures. Experience solving analytical problems using quantitative approaches. Follow Data Science literature and advancements. The most successful candidates possess the ability to apply cutting-edge advancements in data science methodologies to relevant business problems. 
ScrapedJobID332:
Monday to Friday Temporarily due to COVID-19 
ScrapedJobID333:
State-of-the-art offices that are designed to maximize collaboration Flexible working arrangements Enriching challenges that provide opportunity for constant learning and advancement An environment which is leveraging technology to its highest potential Analyze financial news and build machine learning/NLP models for sentiment detection, volatility signals, and other information signals. Apply these models to automated market making for trading and risk management. Collaborate with other quantitative researchers and data scientists to create innovative solutions for the various problems in electronic options market making. Analyze terabytes of equity and options market data to derive actionable intelligence to improve trading performance. PhD in NLP, automated speech recognition, or other closely related field Strong programming skills and experience in a scripting language such as Python Strong interest in quantitative trading and finance Excellent communication skills and ability to interact with traders and technology Knowledge of C++ Exposure to quantitative finance Video dated October 2019. 
ScrapedJobID334:
We offer excellent compensation packages with market competitive pay, comprehensive healthcare packages, schedule flexibility, work from home opportunities, paid time off, and organizational growth potential. Grow at your own pace through online courses at Learning @ Equifax You will utilize tools, including Python, nd SQL to extract data and assist others users to improve the performance of queries. By working closely with customers, you will understand the objectives of their projects and be able to interpret the business needs into a sound analysis plan that considers all relevant data. Build and create advanced machine learning algorithms such as regression, simulation, scenario analysis, modeling, clustering and decision trees Effectively communicate analytical results to key partners using strong data visualizations, strong presentation skills and business language to emphasize the so what of the analysis. You’ll act as the primary contact for Equifax customers using Ignite solutions (Equifax product) to answer technical inquiries or provide guidance on the use of Equifax data within specific analytical methodologies. By demonstrating your experience with data visualization tools, you will improve productivity while ensuring results are consistent across the organization. Use advanced techniques or partner with statisticians to build out predictive models that address new opportunities for a customer based on a deep understanding of their business need Bachelor’s or advanced degree in a quantitative discipline such as Engineering, Economics, Mathematics, Statistics, or Physics (essential) 4+ years’ data manipulation experience with deep knowledge of Python, spark and SQL in a large data environment 4+ years using advanced analytical techniques including decision trees, logistic regression, and, preferably, machine learning methodologies Demonstrable experience in a client-facing role with direct contact and client management responsibilities for specific deliverables and delivering high quality analytical output within tight deadlines Strong knowledge of Hadoop Tools such as Hive or Impala and Experience with developing credit scorecards is an asset, also any experience with data visualization tools (Spotfire, Tableau, Qlik) would be a plus Master’s level degree in a business-related field/MBA (preferred) Experience in working with credit data and cloud environment such as GCP is an asset Working knowledge of database design, data modeling, risk management and/or marketing practices, statistical/predictive modeling Accountability Curiosity Collaboration Think and act differently Trust Ownership 
ScrapedJobID335:
Bachelor’s degree in Computer Science, Statistics, Data Science, or any other quantitative field. 2+ years of non-internship professional experience with machine learning, statistical modeling, data mining, and/or analytics techniques. 2+ years of experience with Python, R, or other scripting languages. Advanced ability to draw insights from data and clearly communicate them (verbal/written) to the stakeholders and senior management. Computer vision and augmented reality (AR) experiences: We bring exciting experiences directly to the customer's mobile phone using their cameras and combinations of facial recognition and AR. Personalization using machine learning: We will be working with machine learning (ML) technologies such as data classification and reinforced learning models to provide better-personalized shopping experiences. Elevated customer experiences: We will create beautiful and dynamic customer experiences that require deep knowledge of relevant UI technologies and user-centric design patterns. Amazon scale systems: All our technology needs to work at Amazon scale, serving millions of customers with millisecond-level latency. Data pipeline and analytics tools: Amazon is data-driven, and a robust data backbone is necessary for our systems. We build on robust and scalable data pipelines and tools using core AWS services. Master’s degree or PhD in a highly quantitative field (Machine Learning, Statistics, Data Science, Math, etc.). Experience applying various machine learning techniques, and understanding the key parameters that affect their performance. Familiarity with deep learning algorithms and/or computer vision. Familiarity with at least 1-2 popular AI/ML frameworks and tools - TensorFlow, PyTorch, MXNet, scikit-learn, OpenCV, ARCore, and ARKit. Expertise in estimation, experimental design, hypothesis, and A/B testing. Experience partnering with engineering teams to build and test production systems. Familiarity with AWS services such as EC2, DynamoDB, RDS, AWS Lambda, and Amazon SageMaker. Ability to achieve stretch goals in a highly innovative and startup-like environment. 
ScrapedJobID336:
Gathering training data for the existing deep learning, ML and NLP solutions Providing actionable ad hoc analytics insights for internal stakeholders Designing and building recurring reports for internal stakeholders to make data-driven decisions Identifying and implementing ways to supercharge data quality and data integrity Using advanced analytical methods to explore and extract additional data value for existing and emerging products Documenting analysis results and presenting value to stakeholders Creating reusable processes to assist data evaluation and analysis across teams within Data Center 3-5 years of direct experience performing advanced data analytics or a Master’s Degree in Statistics, Data Analytics or related field 3+ years’ experience in SQL/Spark, R, Python Strong grasp of statistical modeling techniques such as linear regression, logistic regression, GLM, etc. Understand NLP concepts like: Named Entity Recognition (NER), Sentiment Analysis, Data Tokenization, Lexical Semantics, Relationship Extraction, etc. Ability to effectively communicate analysis and insights to all levels of the organization A passion for continuous learning Confidence to challenge the status quo Automotive industry experience a plus 
ScrapedJobID337:
Collaborate with cross-functional teams (Sales, Marketing, Engineering) to define, design, and ship new features In collaboration with others, design, build and validate predictive algorithms for vehicle prognostics Perform exploratory analyses and develop procedures for feature extraction in preparation for algorithm analyses Participate in software integration work to implement algorithms in production. Work on bug fixing and improving architecture performance Write documentation and present the results of work to others on the team Undergraduate or Master's degree in Engineering, Physics, Computer science or equivalent Good knowledge of statistics, experimental design, and probability 3+ years of experience in Python, R or similar scripting language 1+ years experience shipping high-quality software to enterprise customers Experience with SQL (PostgreSQL or similar) Understanding and experience with machine learning techniques such as Regression, Naive Bayes, Random Forests, Perceptrons, SVM, Deep Learning DevOps experience (Amazon, Google, Docker, Jenkins) Previous startup experience (preferably in an early-stage startup) Knowledge of automotive data, automotive physics or experience in the industry Experience with version control systems (Git, CVS or SVN) Knowledge of other programming languages including node js, C++ Experience with big data frameworks such as Spark, Hadoop. 
ScrapedJobID338:
Maintain an acute awareness of the industry and what the competitors are putting out. Investigate new options for the system from code to core. Coordinate with Senior Technical Leads regarding AI tech. Coordinate with team members to discover the best solution for the clients. Conceptualize new features that we could offer exclusively. Manage R&D Data Science Developers. 2+ years of Experience in Software Development Education: M.tech or Ph.D. in Computer Science/Engineering preferably with a focus on AI. Strong hold on Data structures and Algorithms. Experience with Anaconda/Python/Tensorflow. French Language skills. Hours: 30-40 hours/week. Wage: $85,000 - $100,000/year. 3 Weeks of Vacation. A great environment and the right tools to do great work. 
ScrapedJobID339:
Liste non limitative. 
ScrapedJobID340:
Manage intake and execute new reporting requests from the product management team and key stakeholders Communicate insights with team Critical analysis of insights, help predict and answer larger problems that the team may have Develop strategy of overall data model, both within the team and throughout the other business portfolios Bachelor’s degree in Applied Math, Statistics, Data Science/Analytics, Engineering, or a related technical degree. 5+ years of product management experience that includes product execution and go-to-market strategy. Deep knowledge of customer life cycle (awareness, acquisition, conversion, engagement, and retention). Proven ability to learn things quickly and stay up to date on breakthroughs in Data Science techniques. Experience with at least one of the following programming languages: Python, R, or Golang (IT Background in BI is a must) Comfortability with manipulating data BI tools Experience with common statistics methodologies such as clustering, regression, forecasting, classification, regularization, resampling, etc. Strong analytical skills to pull insights from quantitative and qualitative data sets. Demonstrated results working by influencing stakeholders in a matrixed cross-functional organization. Telecom experience a plus Excellent interpersonal skills. Excellent communication skills Be able to drive/display ownership/proactive behavior. Attend client-based meetings. Managing the project efficiently. Conducting presentations for the employees. Experience working with different project managers. Analyzing the technical customer requirements. Development of client-specific solutions. 
ScrapedJobID341:
Diriger l'analyse fonctionnelle et technique au sein des entreprises Ericsson et pour les clients stratégiques afin de comprendre les besoins et les opportunités des entreprises basées sur les systèmes d'information. Permettre le développement rapide et itératif d'une solution minimale viable validée répondant à ces besoins. Cela implique de travailler avec des pétaoctets de réseaux 4G/5G, des données IoT et exogènes, et de proposer/sélectionner/tester des modèles prédictifs, des moteurs de recommandation, des systèmes de détection d'anomalies, des modèles statistiques, des systèmes d'apprentissage en profondeur, d'apprentissage par renforcement et autres systèmes d'apprentissage machine. Mener des études et utiliser de manière créative des sources de données nouvelles et/ou existantes. Travailler avec les architectes de données pour exploiter les modèles de données existants et en créer de nouveaux selon les besoins. Collaborer avec les équipes de développement de produits et les partenaires des entreprises Ericsson pour industrialiser les modèles et solutions d'apprentissage machine dans le cadre des offres Ericsson, notamment en fournissant le code source, les flux de travail et les documents. Travailler avec les nouvelles technologies et les promouvoir au sein des communautés d'entrevue de motivation d'Ericsson. Contribuer au renforcement des compétences en matière d'entrevues de motivation au sein des entreprises et des unités de service à la clientèle d'Ericsson. Élaborer de nouveaux concepts, méthodologies et techniques, et appliquer ou développer les concepts, méthodologies et techniques existants pour les projets interfonctionnels. Une maîtrise ou un doctorat en ingénierie électrique, en informatique, en intelligence artificielle, en apprentissage machine, en physique ou dans un domaine connexe Expérience pratique : Plus de 2 ans d’expérience d'apprentissage automatique dans le domaine de la science des données. Une expérience confirmée dans la rédaction de logiciels de production Une grande expérience dans le développement de modèles et la gestion du cycle de vie dans un ou plusieurs secteurs d'activité/applications De solides compétences en programmation dans divers langages (C++, Scala, Java, R) et une maîtrise de Python ou C++ Des compétences confirmées en apprentissage automatique, par exemple en analyse discriminante par régression linéaire/logistique, ensachage, forêt aléatoire, modèle bayésien, MVC, réseaux neuronaux, etc. De solides compétences dans l'utilisation des cadres d'apprentissage automatique de pointe actuels tels que Scikit-Learn, H2O, Keras, TensorFlow and Spark, etc. La capacité confirmée à mettre en œuvre de nouveaux algorithmes et de nouvelles méthodologies issus d'initiatives et de documents de recherche de premier plan sur les logiciels libres et portant sur leurs fonctionnalités, leur évolutivité et leur viabilité globale d'industrialisation Des connaissances en statistiques, telles que l'analyse descriptive et l'analyse supervisée et non supervisée Une certification IM de MOOC, un atout Des applications et des connaissances spécialisées en télécommunications ou en IdO, un atout La capacité à travailler de manière indépendante avec beaucoup d'énergie, d'enthousiasme et de persévérance Une bonne aptitude à communiquer en anglais écrit et parlé Une capacité à travailler dans un environnement de collaboration, notamment à travailler avec des unités commerciales complexes à parties prenantes multiples, des clients mondiaux, des partenaires technologiques et d'autres partenaires de l'écosystème dans une organisation matricielle mondiale multiculturelle, avec tact et persévérance Conduct functional and technical analysis within Ericsson organization and strategic customers to understand MI-driven business needs and opportunities Contribute to rapid and iterative development of validated minimum viable solution addressing these needs. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical model, deep learning, reinforcement learning and other machine learning systems Conduct studies and find creative usage of new and/or existing data sources. Work with Data Architects to leverage existing data models and build new ones, as needed. Collaborate with product development teams and partners in Ericsson Businesses to industrialize machine learning models and solutions as part of Ericsson offerings including providing source code, workflows and documents Work with new technologies and champion them in MI Communities within Ericsson. Assist MI Competence build-up in Ericsson Businesses and Customer Serving Units Help to develop new and apply/extend existing, concepts, methodologies, techniques for cross functional initiatives MS, or PhD in Electrical Engineer, Computer Science, Artificial Intelligence, Machine Learning, Physics, or related field Applied experience: 2+ years of Machine Learning experience in data science. Proven experience writing production-grade software Extensive experience in model development and life-cycle-management in one or more industry/application domain Strong Programming skills in various languages (C++, Scala, Java, R) with proficiency in Python and/or C++ Proven skills in Machine Learning, e.g., linear/logistics regression discriminant analysis, bagging, random forest, Bayesian model, SVM, neural networks, etc. Strong skills in the use of current state of the art machine learning frameworks such as Scikit-Learn, H2O, Keras, TensorFlow and Spark, etc. Demonstrated ability to implement new algorithms and methodologies from leading open source initiatives and research papers addressing their functionalities, scalability and overall industrialization viability Strong knowledge in Statistics, e.g., descriptive analysis and supervised and unsupervised analysis Certifying MI MOOCS, a plus Applications/Domain-knowledge in Telecommunication and/or IoT, a plus. Ability to work independently with high energy, enthusiasm and persistence Good communication skills in written and spoken English Ability to work in a collaborative environment, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence 
ScrapedJobID342:
Collaborate with business partners to develop innovative solutions to meet objectives utilizing cutting edge techniques and tools. Effectively communicate the analytics approach and how it will meet and address objectives to business partners. Advocate and educate on the value of data-driven decision making; focus on the “how and why” of solutioning. Lead analytic approaches; integrate solutions collaboratively into applications and tools with data engineers, business leads, analysts and developers. Create repeatable, interpretable, dynamic and scalable models that are seamlessly incorporated into analytic data products. Engineer features by using your business acumen to find new ways to combine disparate internal and external data sources. Share your passion for Data Science with the broader enterprise community; identify and develop long-term processes, frameworks, tools, methods and standards. Collaborate, coach, and learn with a growing team of experienced Data Scientists. Stay connected with external sources of ideas through conferences and community engagements. Bachelors Degree in Data Science, Computer Science, or related field 5+ years of Data Science and Machine Learning experience required Proficiency in Python or R. Ability to write complex SQL queries Proficiency with Machine Learning concepts and modeling techniques to solve problems such as clustering, classification, regression, anomaly detection, simulation and optimization problems on large scale data sets Ability to implement ML best practices for the entire Data Science lifecycle Ability to apply various analytical models to business use cases (NLP, Supervised, Un-Supervised, Neural Nets, etc.) Exceptional communication and collaboration skills to understand business partner needs and deliver solutions Bias for action, with the ability to deliver outstanding results through task prioritization and time management Experience with data visualization tools — Tableau, R Shiny, etc. preferred 
ScrapedJobID343:
Design, development and evaluation of highly innovative models Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation Work closely with software engineering teams to drive real-time model implementations and new feature creations Analyze internal behavior tracking data and forecast Wish demand Implement the strategies and set up A/B test experiments to gauge the impact, and reiterate Propose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process Create & own dashboards and analytical reports to track progress & share learnings Bachelor's or advanced degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics or similar) 3+ years of hands-on experience in predictive modeling and analysis 3+ years experience writing complex SQL queries in a business environment 2+ years in Python A/B test experience Experience collaborating with business & eng teams Analytical mindset and ability to see the big picture and influence others Detail-oriented and must have an aptitude for solving unstructured problems Ability to work effectively in a multi-task, high volume environment Ability to be adaptable and flexible in responding to deadlines and workflow fluctuations Experience operating in a Unix/Linux environment Strong presentation skills 
ScrapedJobID344:
Research, analyze, and evaluate a wide variety of issues in occupational health and safety, management oversight, internal operations and disability management Extract and transform data from a variety of databases using tools such as SQL, Python, PowerBI, and Tableau Identify industry trends, emerging issues, and opportunities of business significance to WorkSafeBC Develop and improve complex analytical models (e.g. for evaluation, prediction, classification, prescription) Provide ongoing consultation, decision support, analytics, and business intelligence to various WorkSafeBC department leads Present research information to audiences of varying levels of expertise that include detailed findings, implications, and recommendations Independently plan, prioritize, schedule, monitor, and complete complex multi-task workload projects and activities to consistently meet deadlines Clearly and concisely present analysis results and recommendations both in written reports and verbally to individuals and groups of varying levels of expertise Identify significant information from a variety of sources, collect and analyze data to develop, assess, and establish meaningful ways of grouping and transforming data to draw conclusions Interpret, evaluate, infer, and explain business data or concepts and develop alternatives and recommendations appropriate for the business Apply quantitative and qualitative research methods (e.g. statistical analyses, data modeling, text mining, machine learning, predictive analytics, sampling, survey and questionnaire design). Write scripts and formulas for extracting, compiling and, displaying information A master’s degree in a quantitative-related discipline such as statistics/mathematics, operations research, big data, data science, computer science, information technology, finance, business, management information systems, or engineering. A minimum of 12 months of recent directly related experience within five years in business intelligence, statistical analysis, strategic analysis, and/or advanced analytics. 
ScrapedJobID345:
Provides expertise in designing statistical methodologies and project execution support for standard and custom studies, moderately following guidelines While part of a team of experts:
Performs regular statistical method design, analysis and programming activities with moderate supervision
Performs statistical methodology and analytical work following standards and guidelines to ensure quality and relevance of derived insights, following moderate instructions from manager and senior members of the team
Supports existing methods enhancements, statistical quality control methods, ad-hoc requests and data investigations of moderate complexity
Provides some level of leadership input into protocol, validation plan, report, and analysis plan
Derives conclusions from assigned complex studies and investigations, prepares written summaries and reports study results with proper data visualization expertise under moderate supervision
Interprets data and insights with proper business meaning, draws conclusions and provide statistical recommendations on client actions following review with manager Performs regular statistical method design, analysis and programming activities with moderate supervision Performs statistical methodology and analytical work following standards and guidelines to ensure quality and relevance of derived insights, following moderate instructions from manager and senior members of the team Supports existing methods enhancements, statistical quality control methods, ad-hoc requests and data investigations of moderate complexity Provides some level of leadership input into protocol, validation plan, report, and analysis plan Derives conclusions from assigned complex studies and investigations, prepares written summaries and reports study results with proper data visualization expertise under moderate supervision Interprets data and insights with proper business meaning, draws conclusions and provide statistical recommendations on client actions following review with manager Gathers recommendations from others to identify appropriate data sources and delivery options whilst meeting client information and analyses needs Initiates improvement recommendations and alternative solutions for problem solving Under moderate guidance from manager, supports new offering development by outlining statistical requirements based on overall project objective, translates client business needs into requirements, and specify statistical analysis plan accordingly Works on components of projects of moderate scope within defined procedures and practices Progressively manages own project timelines, can identify risks and provides mitigation alternatives to manager With moderate help from manager, can handle multiple projects, and manage priorities accordingly Helps manager develop project plan of bigger scope Participates to internal cross-functional meetings of moderate scope with other members of the stats team or alone, and provides moderate level of insights Develops and maintains relationships with key cross-functional stakeholders Participates in internal initiatives e.g. knowledge sharing Supports more senior staff on specific business initiatives as required Develops ability to provide on-the-job coaching and knowledge sharing to more junior staff when appropriate Bachelor’s or Master’s degree or equivalent in Statistics, Mathematics, Operational Research or related field with a strong focus on quantitative analysis, including an acceptable number of courses in statistical methods and theory, with a minimum of two (2) years of relevant experience with large databases and systems Technical knowledge/skills include: multivariate analysis, regression analysis, forecasting, probability and survey sampling Excellent knowledge of SAS programming language on multiple environments (PC environment required, UNIX/mainframe an asset). Knowledge of SQL is also required Additional Knowledge of Python (or R) and big data tools such as Cloudera, Spark and Hadoop (an asset) Understanding and experience of classical machine learning and deep learning methods (an asset) Proven ability to carry out moderate to complex level analyses and information gathering to resolve problems on non-routine matters Proven ability to program statistical methodologies according to specifications, with emphasis on quality control, testing, and operational efficiencies 
ScrapedJobID346:
Collaborate with AI Researchers to build scalable AI systems Design cloud and data architecture Contribute to multiple projects to integrate AI within the product Challenge the team to have robust code, design, and processes Develop backend services, client libraries and tools You have a BA in Computer Science or related field You have 5+ years of experience as a software developer You have expertise programming in Node.js and Python including in terms of best practices You have skills developing cloud-based product using AWS (S3, Lambda, ECS, etc.) You know how to work with the following technologies: ElasticSearch, Docker, RESTful API You are highly resourceful with debugging in asynchronous environments You are comfortable with a microservice architecture You have an interest in AI and/or Data Science You’re able to work in English (French is a plus) Group insurance including(telemedicine application) from day one Here, everyone starts with 4 weeks of vacation. Of course, flexible work hours ;) 
ScrapedJobID347:
Researching, designing and implementing analytical models and machine learning algorithms that will be utilized for promotion, pricing, product, media & revenue optimization. Identify how data science can be applied to improve and optimize the models, targeting and offer assignment Build pragmatic, scalable, and statistically rigorous solutions that can be applied across products and partners by leveraging or developing statistical and machine learning methodologies. Working with diverse data sets (partner, product, performance, 3rd party) and continuously showcasing the added value generated by incremental data Continuously improve the predictive models and algorithms by researching, designing and testing & learning. Elevate the data science discipline by aligning with other Data Science Team Leads on best practices, automation and standardization on all advanced analytical solutions, the end to end modeling process, offer assignment and personalization. Drive execution through fast iteration. Over 5 years of experience of researching, developing and applying machine learning algorithms Familiarity & proficiency with machine learning, big data technologies, predictive analytics, segmentation, econometric modeling, time series analysis, recommender systems, visualization tools with a solid understanding of best practices in data science. Strong programming with Python and associated machine learning packages Relational database expertise (SQL) Natural curiosity to solve problems and find meaning in complex data sets & customer behaviour analysis. Strong business acumen to apply recommendations in the proper commercial context. Masters or PhD in quantitative field (e.g. Computer Science, Engineering, Mathematics, Statistics, Operations Research or other related field) 
ScrapedJobID348:
Identify opportunities for machine learning in our products Query our petabyte-scale database to extract game data Conduct exploratory data analysis, hypothesis testing, and feature engineering Build and evaluate machine learning models to improve in-game features and boost product metrics Work with engineers to deploy models (batch predictions, microservices, and monitoring) Communicate a machine learning roadmap to company leadership Coordinate machine learning initiatives with production, design, and engineering teams Mentor data science team members Push and design the machine learning tech stack Help develop strategy and vision of the data science team Master’s Degree in a STEM discipline, preferably thesis-based 4+ years of industry experience in data science, preferably in large scale client-facing software/web/application companies Professional level Python programming skills (NumPy, pandas) Proficient with machine learning libraries: eg. scikit-learn, TensorFlow, PyTorch Strong SQL skills (joins, subqueries, analytic functions) Experience identifying and delivering machine learning solutions for business problems Significant experience with end to end machine learning including deploying machine learning models to production Can drive projects independently, maneuver through imperfect data or experimentation, and pivot goals or targets with ease Communicates in a clear, concise, and professional manner with staff at all levels; justifies decisions, and achieves peer consent Software/ML or data engineering experience Ph.D. in a STEM discipline Management Experience Experience working with Docker, Airflow, Bigquery, Tableau, Github Game industry experience Experience with Pytorch, Tensorflow, Other Deep Learning Libraries Experience with recommendation systems Background in advanced statistics Experience working with Google Cloud Platform, or other cloud-based machine learning platform Evidence of continued learning Active Github or Kaggle Profile 
ScrapedJobID349:
Prototype, develop and deploy CV models that find the best placement opportunities with a focus on video classification, action recognition, image-audio consistency and video analytics. Build and maintain production-ready CV code that analyzes thousands of hours of video content. Research state-of-the-art solutions for video content understanding and apply them to our products. Build new products and workflows in collaboration with TripleLift's Product and Engineering teams Ship reliable, scalable, efficient, and elegant code Hands-on experience with deep learning algorithms like CNN, RNN, GAN or VAE. Demonstrated experience with Tensorflow/Pytorch/MXNet/Keras. Deep understanding of computer vision, image processing, computational photography and 3D geometry. Mathematical knowledge of linear algebra, optimization, statistics and probability. 3+ years of experience with OpenCV/Dlib/Scikit or other computer vision processing library 3+ years of experience with FFMPEG or other video processing tools Experience shipping production code Strong communication skills, particularly in conveying technical concepts in a manner that is easy for clients and non-technical partners to understand Ability to work under intense pressure and multitask in a fast-paced start-up environment M.S., or Ph.D in Computer Science or equivalent experience 
ScrapedJobID350:
Applying geospatial climate data science knowledge and skills to advise teams on how best to approach their climate science-related projects Helping teams develop, adjust and finalize novel and/or sophisticated data analysis plans involving geospatial climate change-related datasets Working closely with international teams on project goals and timelines Help guide teams in writing robust, well-documented, and well-tested research code and code libraries Providing climate science expertise and strategic insight both internally and with external partners Collaboration with fellow research analysts and scientists Other duties and roles as agreed upon with supervisor Demonstrated ability to apply spatial statistical methods and/or data science to real-world problems related to climate science. Excellent scientific and quantitative problem-solving skills, with demonstrated ability to build, test, and iterate on a variety of model forms. Strong quantitative research skills, including cleaning and pre-processing of geospatial data, assessment of data quality, designing and implementing models exploring spatio-temporal dynamics in various settings. Excellent understanding of environmental science concepts. Prior experience analyzing datasets related to climate science. Prior quantitative research experience applying advanced statistical techniques. Understanding and experience with challenges of geospatial data. Knowledge of geospatial data analysis, data aggregation, and geo visualization (e.g., QGIS or ArcGIS). Experience with ModelBuilder and ArcGIS Online will be considered assets. Familiarity with publicly available geospatial datasets. Experience with a scientific programming language (e.g., R, Python). Experience working with Cloudera or comparable cloud-based environments is a plus. Knowledge of machine learning and deep learning libraries (Scikit-learn, Pytorch, Tensorflow…), version control systems (git)appreciated. Extensive knowledge of statistical software such as Stata, SAS, or SPSS. Proficiency with Microsoft Office Suite. Excellent interpersonal, communication (oral and written) and organizational skills. Detail-oriented, with excellent analytical thinking skills, a propensity to take initiative and a demonstrated ability to exercise good judgment. The ability to produce high-quality, accurate work in a timely way, and in accordance with project deadlines. Excellent teamwork skills and a demonstrated ability to collaborate effectively with team members and liaise with study investigators. Work from home Monday to Friday Master's Degree (preferred) applied geospatial datasets and modeling: 2 years (preferred) Yes 
ScrapedJobID351:
Le poste est offert aux personnes cherchant à appliquer l’apprentissage profond pour simplifier les stratégies d’enchères du marketing des moteurs de recherche d’Expedia Group dans un environnement d’apprentissage en ligne. Si les problèmes de modélisation d’importance non triviaux vous intéressent, et que la rareté des données, les tendances en constante évolution et les millions d’enchères et de modificateurs ne vous font pas peur, saisissez l’occasion de faire avancer votre carrière. En étroite collaboration avec nos équipes Bidding Operations (opérations d’enchères), vous soutiendrez notre stratégie d’enchères pour nos partenaires, comme Bing et Google. Notre équipe de recherche, composée de cinq personnes, gère des milliers de dollars de dépenses en marketing des moteurs de recherche par jour. Bonne compréhension de la théorie et de la pratique relatives aux probabilités et aux statistiques Expérience pratique en apprentissage automatique : préparation d’ensembles de données, sélection et développement de fonctionnalités, conception et optimisation d’algorithmes de formation, évaluation des résultats par rapport aux références de production Expérience en création et en maintenance de pipelines d’extraction, de transformation et de chargement (« ETL ») à grande échelle à l’aide d’outils comme PySpark, Apache Airflow, SQL, DataBricks et Notebooks Expérience en développement d’apprentissage profond (TensorFlow ou PyTorch) qui généralise quelques exemples pour déduire de nombreuses prédictions Bonnes pratiques de programmation, capacité à écrire des codes lisibles et performants Capacité à appliquer la méthode scientifique pour suggérer des améliorations à partir de données Expérience dans l’optimisation d’enchères de marketing Expérience en apprentissage par renforcement Connaissance des systèmes de contrôle pour les pipelines d’apprentissage en ligne Expérience en production d’applications d’apprentissage automatique à grande échelle dans le monde réel Curiosité intellectuelle et volonté d’apprendre, notamment en ce qui a trait aux nouvelles techniques et technologies The position is open for people looking to apply deep learning to streamline Expedia Group SEM bidding strategies in an online learning setting If you are interested in non-trivial high impact modelling problems that involves dealing with data scarcity, constantly evolving trends, and millions of bids and modifiers, this is a great opportunity to further your career Working closely with our Bidding Operations teams, you will support our bidding strategy for our partners, such as Bing and Google Our 5-person research team handles thousands of dollars of SEM spend per day Strong grasp of Probability and Statistics theory and practice Hands on experience in machine learning: preparing datasets, selecting and engineering features, building and optimizing training algorithms, evaluating results against production baselines Experience building and maintaining large-scale Extract Transform and Load (ETL) pipelines using tools such as PySpark, Apache Airflow, SQL, DataBricks, Notebooks Experience developing Deep Learning (TensorFlow or PyTorch) that generalize from few examples to many inferred predictions Good programming practices, able to write readable, performant code Ability to apply the scientific method to suggest improvements from data Experience optimizing Marketing auctions Experience with Reinforcement Learning Knowledge of control systems for online learning pipelines Experience productionizing real-world large-scale ML applications Intellectual curiosity and desire to learn new things, techniques and technologies 
ScrapedJobID352:
Design and implement reliable distributed data pipelines Design and implement scalable machine learning solutions geared towards solving natural language processing, knowledge representation, and natural language generation problems Create parallelized and/or distributed versions of existing algorithms Research, design and develop novel algorithms Collaborate with research scientists, architects, software developers, and product management to design and program innovative strategic and tactical solutions that meet market needs with respect to functionality, performance, reliability, realistic implementation schedules, and adherence to development goals and principles Gather and determine requirements for new features from internal colleagues Experience with architecting data intensive applications Experience with data mining or machine learning applications Experience writing software in one or more languages such as Python, Scala and/or similar. Experience working with data structures, algorithms and software design Knowledge of data warehousing concepts, including data warehouse technical architectures, infrastructure components, tools and environments (such as Apache Beam, Hadoop, Spark, Pig, Hive, MapReduce, Flume) Experience with fast prototyping Experience working effectively with software engineering teams Mentor others in achieving their career growth potential MS in Computer Science, Computer Engineering, Deep Learning, Machine Learning, Statistics, Computational Linguistics, or a very related field; other exceptional candidates with extensive ML/DL/NLP/NLG backgrounds may also be considered At least 2 years of research engineering experience with respect to ML/DL/NLP/NLG At least 1 year of distributed or highly threaded software development experience Experience with workflow tools like Airflow, Luigi, etc. Hands-on experience implementing new research ideas with a neural network training framework such as Tensorflow, Keras, or PyTorch A PhD in machine learning Experience with academic machine learning research 
ScrapedJobID353:
Implement real-time machine learning algorithms in production for Ads campaign optimization, with help from other data scientists, engineers and developers Optimize our Deep Learning algorithms and implementation of the algorithm's output Perform exploratory data analysis, run pipelines, deploy your work on a live Deep Learning algorithm and run AB tests Experience in building machine learning based online decision-making systems either in production, as a hobby or during a project Good knowledge of deep learning and statistics Experience with the tech stack of Python/TensorFlow/GCP ecosystem, or equivalent. Excellent communication and collaboration skills Being open minded, curious, creative and friendly Knowledge of DevOps principles and technologies (such as CI/CD, microservices, containerization, infrastructure-as-code) Experience with distributed and containerized systems (such as Docker, Kubernetes, Helm, KubeFlow) Being a Masters or PhD student is a bonus Duration: 15 or 16 weeks depending on your academic calendar. Start date May 2 or May 9 2022 Mentorship: You'll be working simultaneously with a manager and a mentor to help you develop your skills throughout your internship. Impact: Our interns are working right alongside full time team members on projects that have a lasting impact on our product and services. Networking & Development: Learning activities, networking opportunities, and social events take place throughout the summer to enrich your internship experience. Current students pursuing a relevant degree, masters or PhD, returning to their degree program for at least one semester, and graduating in December 2022 or in the year 2023. Mettre en œuvre des algorithmes d'apprentissage machine en temps réel en environnement de production pour optimiser les campagnes publicitaires, avec l'aide des scientifiques des données, ingénieurs et développeurs de l'entreprise Optimiser nos algorithmes d'apprentissage profond et la mise en œuvre des résultats de l'algorithme Effectuer des analyses de données exploratoires, exécuter des pipelines, déployer votre travail sur un algorithme d'apprentissage profond en direct et exécuter des tests A/B Une expérience dans la construction de systèmes de prise de décisions en ligne fondés sur l'apprentissage machine, que ce soit dans une production, comme passe-temps ou dans le cadre d'un projet Une bonne connaissance de l'apprentissage profond et des statistiques Une expérience de la pile technologique de l'écosystème Python/TensorFlow/GCP, ou équivalent D'excellentes compétences en matière de communication et de collaboration Être ouvert d'esprit, curieux, créatif et amical Une connaissance des principes et technologies du développement et de l'exploitation (CI/CD, Bash, microservices, conteneurisation, infrastructure en tant que code, etc.) Une expérience avec des systèmes distribués et conteneurisés (Docker, Kubernetes, Helm, KubeFlow, etc.) Être un étudiant en master ou en doctorat est un atout Durée : 15 ou 16 semaines en fonction de votre calendrier académique. Dates de début : 2 ou 9 mai 2022 Mentorat : Vous travaillerez à la fois avec un(e) gestionnaire et un(e) mentor pour vous aider à développer vos compétences tout au long du stage. Impact : Nos stagiaires travaillent aux côtés des membres de l'équipe à temps plein sur des projets qui ont un impact durable sur nos produits et nos services. Réseautage et développement : Des activités d'apprentissage, des possibilités de réseautage et des événements sociaux ont lieu tout au long de l'été pour enrichir votre expérience de stage. Tout étudiant en cours d'obtention d'un diplôme pertinent (ou une maîtrise ou un doctorat), retournant à son programme d'études pour au moins un semestre et qui obtiendra son diplôme en décembre 2022 ou en 2023 
ScrapedJobID354:
Responsible for the life-cycle of back-end development of the business’s data warehouse, including dimensional design of the data and defining and implementing best practices Build modern approaches to scalable and reusable data pipelines on cloud services such as AWS Design, develop, enhance and implement key components of a modern data warehouse based on the requirements of the business Work with the BI and Analytics area to create short-term tactical solutions to achieve long-term objectives Develop and maintain logical and physical data models that support needs that are currently defined while being adaptable to future needs Work with business teams across the organization to understand their data-driven goals Partner with data science teams to build powerful data assets and processes Bachelor’s degree in Computer Science or Engineering, or related field or relevant experience Experience working with databases (such as MySQL, PostgreSQL) and cloud data warehouses (such as Snowflake, Redshift) Hands-on experience with data mining, large-scale data modeling, and business requirements gathering/analysis Strong understanding of relational data structures, theories, principles, and practices Experience integrating with 3rd party restful APIs Data Management experience including Data Governance, Master Data Management, Reference Data Management, and Metadata Management Familiarity with agile tooling to efficiently build as a team: Git, Jira, Confluence, etc Experience building scalable data pipelines and databases on cloud services such as AWS Strong programming background. Java and Python preferred Experience working in Agile Scrum and Kanban environments Experience with Segment would be valuable Excellent communication skills and stakeholder management Familiarity with data management capabilities (data registration, data quality, etc.) and ability to learn advanced data management toolsets Exposure to Docker, Kubernetes, Airflow, Spark an asset Be part of a collaborative, progressive and high-performing team, building revolutionary products that matter. Generous benefits, including a company match RRSP program. Continued professional development opportunities through programs such as Six Sigma. A modern workspace centrally located in Toronto’s thriving downtown core, easily accessed by transit and a few minutes’ walk from Union Station. Flexible time-off options 
ScrapedJobID355:
Use exploratory data analysis and visualization techniques to simplify analyzing large-scale performance data and extract actionable insights. Collaborate closely with the team of Performance Engineers, developers to innovate, discover and deliver novel solutions for operational excellence. Rapidly build prototype product solutions, communicate findings, iterate & enhance. Draw from prior experience and technical expertise to identify product improvements and inform testing plans; break overall objectives down into underlying problems, prioritize and solve Work with product and engineering teams to implement performance improvements. Apply machine learning, data mining, and statistical analysis techniques where appropriate 5+ years of hands-on data science and statistics experience, demonstrating increasing responsibility and impact over time, including experience as the point person on projects B.S, M.S. or Ph.D. in Applied Statistics, Mathematics, Computer Science, Machine Learning or other quantitative disciplines Highly proficient in Python (packages: pandas, scikit-learn, statsmodels) and SQL; experience working with AWS preferred Experience working with large quantities of data to develop models that work in a stable, production approach with live data Advanced knowledge of statistical analysis and data mining techniques (regression, multilevel regression, poststratification, semi-supervised learning, forecasting, decision trees, clustering, A/B testing, etc.) Experience building ETL & Data pipelines and familiarity with Git, Jira, etc. is plus Experience working with engineering to roll out software to production including monitoring, and documentation Comfortable (and excited!) about ambiguity and breaking goals down into tangible and actionable work plans Strong communication skills and ability to work across internal teams Flexible PTO Allocations for continuous learning & development Health & wellness programs 
ScrapedJobID356:
PhD in Computer Science or similar area Track record of publishing scientific papers in top conferences and journals Strong communication skills (written and verbal), motivation for international collaboration Self-motivated, independent, and able to work well in a fast-paced, collaborative environment Expertise in the latest applications of deep learning algorithms to problems in computer vision and natural language processing Solid technical and programming skills (Python/Java/C++, PyTorch/TensorFlow) 
ScrapedJobID357:
Only applies to full-time positions. Formulates and leads guided, multifaceted analytic studies against large volumes of data. Interprets and analyzes data using exploratory mathematic and statistical techniques based on the scientific method. Coordinates research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the data. Experiments against data points, provide information based on experiment results and provide previously undiscovered solutions to command data challenges. Work with business leaders to identify and define analytical requirements for teams and projects. Using multiple data sources, create reporting and performance monitoring tools and dashboards for end users. Understand and effectively communicate trends and analysis on user behavior, player segmentation, virality, and marketing campaigns. Continuously develop thorough analysis and conclusive insights that drive decisions and strategies for user acquisition, retention, and monetization. Create regular presentations for GM and other team leads to discuss game performance and suggest improvements. Experience performing the above in a successful tech or game company. Bachelor degree in a business or quantitative discipline (Economics, Statistics) – Master’s preferred. 5+ years of experience analyzing very large, multi-dimensional data sets using SQL, excel, statistical software, etc. Strong quantitative skills, good working knowledge of advanced statistics and predictive modeling. Ability to communicate effectively and combine both technical and business perspectives. Demonstrated ability to use data to influence decision making and reach out to a broader audience. Ability to execute research projects, and generate practical results and recommendations. Experience in top-tier consulting, venture capital, investment bank or social gaming. Company news and events on our LinkedIn Company Blog Employee Feedback on our Comparably page Find videos on our teams and games on our Youtube 
ScrapedJobID358:
Research and build machine learning algorithms for search ranking, leveraging our images, metadata, and/or customer interactions to significantly improve our customer’s image/video discovery experiences. Develop and implement online and offline testing and validation methodologies Partner closely with other data scientists, data engineers, machine learning engineers, and search engineers to implement and deploy models in production Collaborate closely with product, engineering, design/research, and data science leaders Recommend changes to our search ranking strategy presented in a clear manner to team members and leadership Share your expertise by mentoring others on the team Proven experience building and validating search, personalization, recommendation, and/or newsfeed algorithms for customer-facing products A minimum of 2 years validated experience An understanding of the real-world advantages and drawbacks of various algorithms and the ability to measure success Ability to handle ambiguity, priorities, and competing objectives. Experience solving highly technical problems Hands-on experience with accessing data, Python, machine learning libraries, and deep learning libraries (ex: scikit-learn, numpy, pandas, scipy, TensorFlow, SQL, hive, spark, etc.). Ability to write clean, understandable code that follows leading industry standards and practices and is well-documented, and to build easily reproducible models An ability to consider biases that exist in the data and develop solutions to mitigate biases appropriately Outstanding communication skills. Strong communication skills at all levels, including sophisticated technical solutions to non-experts Open listener, ability to be open to many diverse voices and perspectives You are clear, credible, and forward-thinking A Ph.D. or MS in Computer Science, Statistics, Data Science, Mathematics, Economics, Sociology, Natural Sciences, or any other equivalent quantitative field is preferred 
ScrapedJobID359:
Develop production ready and high performance machine learning code, working most of the time in projects dealing with Natural Language Processing tasks. Work cross functionally with our Research team to assess and validate machine learning models, code and hyperparameters. Collaborate with our development team to ensure our system is highly performant, stable, and robust to failure. Create and maintain official machine learning regression tests and tooling. Demonstrated experience implementing machine learning algorithms, probabilistic techniques, or deep learning. Strong production experience in Java, C/C++, Go or Python Familiarity with frameworks like Tensorflow, PyTorch, Theano, Keras, Caffe(2), or CNTK. As well as key machine learning applications in NLP such as Classification or Sequence Labeling. An understanding of modern software development practices. Experience with Linux and DevOps is a huge plus. We’ve got a dream team. Zuva is filled with smart, curious, independent, and self-motivated people. Together, we make up a culture that values diversity of thought, creative thinking and fun. There is room to grow. We work on challenging problems. It’s hard (in a good way) and it gives ample opportunities for growth. We also believe in the power of learning. We provide an annual learning budget to all Kirans, as well as regular learning sessions hosted by internal and external experts. The future is flexible. While we’re all remote right now, we have a number of fully remote team members around the world. Covid-19 has reminded us that our health and well-being come before anything, which means you have flexibility when it comes to designing your work day. It also means that we have a flexible vacation policy that allows you to take time off when you need it. We’ve always got your back. Literally. Got a knot in your back? We have a comprehensive health and benefits plan for you and your family, as well as access to Employee Assistance Programs. We’ve also implemented and are continuing with “company shut-down days” that we started since last year. These provide an opportunity for everyone to step back and recharge at the same time. Proven Technology and Design. Machine learning is driving a new industrial revolution, and we have a product with proven technology and clients who are excited about our product! Moreover, we care about great design and a great customer experience. 
ScrapedJobID360:
BS/MS Degree in Data Science, Engineering, Computer Science or similar. 5+ years proven experience in Project Leadership of cross functional initiatives. 5+ years experience in Analytics / Data Science. Fluent and current on analytics tools and data architecture trends with an eye on market/technical conditions and future direction. Verbal and written communication skills with the ability to present and sell solutions/concepts to other architects and to business users and stakeholders. Data & Analytics project implementation experiences that exploit the full capabilities (discover, design, implement and optimization). Pharmaceutical, manufacturing, and/or GXP compliance industry data experience preferred. Experience in a professional services / consulting firm or role is an asset. Strong Project Management understanding. Technology and data savviness, passionate on scale and interconnectivity while maintaining an innovative and curious mindset Self driven and proactive, comfortable to deliver as a team leader, team member and individual contributor Ability to effectively communicate and influence others across ALL levels of the organization in order to drive transformational change Financial and Business Acumen including business case development Knowledge of: SCRUM, Agile Methodologies, Change Management, Project Management. Proficient in authoring, editing and presenting both business and technical documents. Ability to elicit requirements and communicate clearly with non-technical individuals, development teams, and other ancillary project members. Excellent problem-solving skills. Mobility: Ability to travel up to 10% 
ScrapedJobID361:
Design, train and evaluate models. You will solve challenging drug discovery problems by designing fit-for-purpose ML and statistical models and data splits from our massive in-house datasets – more than 8PB of cellular image data, and growing chemical, transcriptomic, and proteomic datasets – and training these models using our on-premise NVIDIA A100 superpods. You'll collaborate with biologists, chemists, automation engineers, data engineers, and other scientists to refine these models, possibly generating more data in the process, until they provide a reliable productionized solution. Create maps of biology. You will be an essential part of achieving Recursion's mission to decode biology and radically improve lives by turning our massive datasets into maps of human disease biology that allow drug hunters to quickly and accurately navigate to optimized small molecule therapies for hundreds of diseases. Share your work. You will represent Recursion to the scientific community by presenting your work at top conferences and publishing in top scientific journals. Define excellence in execution. You will use your technical knowledge to set a high standard of delivery, impact, learning, and growth across teams at Recursion. PhD in Computer Science or related quantitative field or the equivalent practical experience. 2+ years of hands-on experience applying modern machine learning methods to solve real-world problems. Experience applying modern ML and statistical methods to large datasets and reasoning about the outcomes. Experience with microscopy/biomedical imaging data, chemical data, or genomic data is a plus. A working knowledge of the drug discovery process is a huge plus. Extensive experience using modern technologies to accelerate machine learning (e.g. PyTorch, TensorFlow/Keras, Horovod, etc) Outstanding past projects, publications, and presentations, and a demonstrated ability to communicate results to cross-functional stakeholders. Curiosity and the professional skill-set to excel in an open, highly collaborative environment. 100% Coverage of health, vision, and dental insurance premiums 401(k) with generous matching (immediate vesting) Stock option, restricted stock unit (RSUs) and employee stock purchase plan (ESPP) programs Two one-week paid company closures (summer and winter) Flexible vacation/sick leave Generous paid parental leave (including adoptive) Onsite daycare facility** (Salt Lake City) Commuter benefit and vehicle parking to ease your commute** Complimentary chef-prepared lunches and well-stocked snack bars** (Salt Lake City) Monthly fitness/wellness stipend One-of-a-kind 100,000 square foot headquarters complete with a 70-foot climbing wall, showers, lockers, and bike parking** (Salt Lake City) 
ScrapedJobID362:
Collaborate with autonomy teams to understand their pain points and priorities. Research new machine learning problems and models. Derive practical solutions and deploy them on the NuroBot. Have the potential to lead a team on increasingly ambitious new projects. Ph.D. in Computer Science or related fields, or B.S./M.S. in computer science or related fields with 5+ years of relevant experience. Deep understanding of many advanced machine learning techniques and hands-on experience of training deep models. Passionate for researching and solving near-impossible research problems. Strong desire to deploy the solutions into the product. Outstanding communication skills to lead projects with multi-team collaboration. Strong programming skills in C++ or Python. Enthusiastic about self-driving technology and its potential impact on society. Highly cited publications in top conferences in machine learning or related fields. Experience of using large scale machine learning systems in production. Experience of leading a project from conception and experimentation to product-ionization. 
ScrapedJobID363:
Please note, this role is not able to offer visa transfer or sponsorship now or in the future* 
ScrapedJobID364:
Liste non limitative. 
ScrapedJobID365:
Design, development and evaluation of highly innovative models Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation Work closely with software engineering teams to drive real-time model implementations and new feature creations Analyze internal behavior tracking data and forecast Wish demand Implement the strategies and set up A/B test experiments to gauge the impact, and reiterate Propose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process Create & own dashboards and analytical reports to track progress & share learnings Bachelor's or advanced degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics or similar) 3+ years of hands-on experience in predictive modeling and analysis 3+ years experience writing complex SQL queries in a business environment 2+ years in Python A/B test experience Experience collaborating with business & eng teams Analytical mindset and ability to see the big picture and influence others Detail-oriented and must have an aptitude for solving unstructured problems Ability to work effectively in a multi-task, high volume environment Ability to be adaptable and flexible in responding to deadlines and workflow fluctuations Experience operating in a Unix/Linux environment Strong presentation skills 
ScrapedJobID366:
This is an on-site position - not remote. Work from home as appropriate Bachelor’s in computer science, data science, or equivalent Expertise in working with at least one deep learning framework, such as PyTorch, TensorFlow, Caffe Strong analytical and problem solving skills Ability to understand and execute on the company’s mission and values Maintain a high degree of ethical standard and trustworthiness Strong technical written and oral communication skills 2+ years’ software development experience Proficient in Python Experienced in cloud providers such as GCP or AWS Experienced in working with ETL pipelines A track record for delivering Machine Learning projects for a product Excellent written and verbal communication skills Strong and proactive communication, natural curiosity. Ambition to apply skills to a wide variety of fields Be able and open to pick up new skills, work with 3rd party technologies and devices 
ScrapedJobID367:
Write and edit technical, data-centred content for the Shopify Data blog Collaborate with internal marketing teams to create and review technical-focused marketing content (e.g. social copy, landing page copy, video scripts...) Work closely with Shopify data scientists and engineers to identify and write key technical stories that we should be sharing externally Create and manage a content funnel, intake process and strategy for data-centered stories Build relationships across Shopify Data, Engineering, and Marketing Strong writing and editing skills based on past experience in a technical writing or editorial role Exceptional storytelling skills and ability to identify interesting stories Ability to quickly grasp the fundamentals of a technology and turn it into a long-form story, or distill it into a few words. Can own the creation of a technical piece of content from intake interview with subject matter expert, to ideation, to final copy. A commitment to understanding our data audiences’ needs Well-versed in building and managing a network of subject matter experts and stakeholders at multiple levels High standards, an obsessive eye for detail, and a strong sense of ownership Demonstrated ability to manage and deliver on deadlines A self-starter who takes initiative and is excited to problem-solve Proven ability to thrive on change Experience managing or writing for a technical blog Background in data science or engineering In 500 words, please write a post re-introducing the algorithm behind Shopify Capital. You should explain what Shopify Capital is and how data drives the product. Please spend no more than 1 hour on this! Go to our blog and find an article that you think could be made better with a few tweaks. Explain what’s missing, how the story could flow better or how you would write it differently. 
ScrapedJobID368:
Disruptive and a naan-traditional mindset An inclusive and dynamic culture Accelerated career progression Commitment to learning and development Opportunity to be impactful Competitive compensation Research on the latest technologies and state of the art AI and ML models with the goal of importing them into manufacturing industry Understand business requirements and develop AI driven solutions addressing those requirements Analyze structured and unstructured data from various data sources, clean data, transform raw data into business insights by building ETL pipelines and visualization dashboards 5+ years of experience in machine learning, data analysis and data visualization Education in engineering or analytical fields, Master’s degree is preferred Proficiency in python, SQL and common data analysis packages (numpy, pandas, sklearn, etc.) and machine learning platforms (Tensorflow, Pytorch,etc.) Experience in deploying AI solutions in production environment Tech-savvy, autonomous, eager to learn, comfortable working in ambiguous environments Experience with one or more common workflow frameworks such as MLFlow or equivalents Experience in DevOps and developing MLOps pipelines Experience in time series analysis, predictive modeling, customer segmentation Experience in IOT, software development, deep learning, web apps development, distributed computing, sensor fusion Experience in deploying ML solutions in cloud environment using containers (Docker, Kubernetes) Experience in computer vision and state of the art vision models Experience in big data platforms such as spark and business intelligence tools such as power bi Experience using cloud-based technologies (Azure, AWS) Customer and Product Centricity -You are always keeping our products front and center. Flexibility, Agility, Adaptability- You embrace speed, change and uncertainty. Teamwork and Collaboration -You are a relationship builder. Passion for Excellence -You look for innovative solutions and challenges the status quo. Drives Execution -You are a risk taker! 
ScrapedJobID369:
Lead discovery and assessment of data portfolio, data tools, and data applications by; Guide and support project teams in development and implementation of data management and analytics services by: Contribute to the vision for a platform of user-centric services, particularly as it relates to the use of common data components and services that can improve and accelerate service delivery. Contribute to the development of principles, metrics, and standards for service and program quality and delivery. Contribute to the development and deployment of data solutions in cloud, using services such as Amazon Web Services (AWS), Google Cloud Platform (GCP), and Microsoft Azure. Contribute to the development and deployment of database solutions using common tools (e.g. SQL. NoSQL). Contribute to data analytics and reporting through the use of common tools and languages for applied statistics, data analysis, and machine learning (e.g. Python, R, Matlab, and SPSS) Monday to Friday lead data science/analytics work: digital/nondigital service: 2 years (required) analytics, data visualizations, data modeling & storytelling: 2 years (required) working with cross-functional teams to align vision & needs: 2 years (required) working in a complex enterprise environment ( >10,000 staff): 2 years (preferred) agile projects in a public sector organization: 2 years (preferred) web development and digital product design: 2 years (preferred) providing analytic support to UX, UX or service design teams: 2 years (preferred) quantitative research methods such as surveys: 2 years (preferred) lead discovery/assessment of data portfolio/tool/application: 2 years (required) support dev & implementation of data management & analytics: 2 years (required) develop & deploy cloud data solutions using AWS, GCP & Azure: 2 years (preferred) dev & deploy data solutions to cloud using AWS, GCP, & Azure: 2 years (preferred) develop & deploy database solutions via SQL, NoSQL, etc.: 2 years (preferred) data analytics & reporting via tools (Python,R,Matlab,SPSS.): 2 years (preferred) Temporarily due to COVID-19 
ScrapedJobID370:
Technical implementation and ongoing management and continuous improvement of data models, meta-data models, mining models, and machine learning models which include regression, classification and unsupervised learning. Collaborate with BI group and department leads in delivering a working prediction models to meet business objectives for forecast accuracy. Oversees the machine learning architecture resulting in the delivery of production prediction model results to business stakeholders. Driven from business requirements, architects, implements and builds solutions to assist in the generation of prediction models that add value to the business and partner with stakeholders from the business for successful deployment. Leads the BI group in the creation and maintenance of machine learning tools, meta-data, prediction models, validation/testing of models, model change management and model design methodology. Rationalizes new model requires to avoid excessive complexity and assist other business analysts in use and application of model. Provide input into the development of model testing strategies and plans to ensure models are always up to date and relevant. Validate that developed solutions align with defined business objectives. Provide technical documentation and technical support for existing models, meta-data catalogs, or other tools. Maintain a library of model documents, templates, or other reusable knowledge Develop statistical methods for evaluating information accuracy and ensure data published in BI solutions meets business expectations for data quality. Analyze and resolve end user problems related to databases and data warehouses, reports in a timely and accurate fashion, and provides end user training where required. Contribute to the strategic direction of the BI platform, the creation of the BI roadmap, the selection of new tools, and the overall integrity of model delivery. Expand knowledge of broader range of Business Intelligence products and tools University degree in computer science, mathematics, finance, statistics or equivalent experience. A master’s degree in any of these and/or a core data science curriculum is highly desired. Strong understanding data analysis, SQL queries, advanced statistics, machine learning and business intelligence report applications required. Proficient with the design of data models, prediction models, and implementation user machine learning solutions based upon business requirements and content knowledge. Advanced statistics including probability, descriptive statistics, distributions, correlation, inference, T-tests, linear/multiple regression, ANOVA, etc. Advanced skills in one or more Statistical computing languages such as R/Studio and/or Python/Anaconda. Experience using predictive machine learning model building packages such as R/Studio CARET and/or Python/Anaconda Sci-kit learn/statsmodels/sciblox. Solid understanding of model building activities including preprocessing, imputation, unskewing, normalizing, standardizing, removing outliers, and splitting data (training, testing and hold-out). Ability to diagnose and improve models using statistical model diagnostics such as RMSE, MAPE, AIC, goodness of fit, sensitivity, specificity, receiver operating characteristics, etc. Previous business experience architecting, implementing, and developing machine learning models considered an asset. Knowledge of one or more Data Warehouse design methodologies and implementation (Inmon CIF, Kimball Dimensional, Data Vault 2.0) with preference to Kimball or Data Vault 2.0. Microsoft SQL server knowledge and experience. SQL language skills (SQL, MDX, DDL, DML, DQL, DCL, ADX, XML) Knowledge of data governance including meta-data and data modelling. Prior experience with report writing tools (Business Objects, Crystal Reports, Tableau, QlikView, PowerBI, Looker, DundasBI, SiSense, Reporting Services) considered an asset. Intermediate Excel/Access skills, including VBA scripting considered an asset. Intermediate PowerPoint, Word, Visio skills considered an asset. Active collaborator and listener with excellent oral, written, presentation, one-on-one and group communication skills. Demonstrated ability to learn quickly and produce results. Organized, thoughtful and likes to make a difference by sharing knowledge with others and seeing improvements. Energetic, positive, driven and independent. Objective driven yet tactful and respectful of others' contributions. Thinks broadly, resolves problems, and has ability to see multiple perspectives on issues. Manages competing priories in an effective and positive manner. Experience interacting directly with customers to elicit, document, and implement solutions Demonstrates Intermediate project management skills 
ScrapedJobID371:
Involved in process and functional/technical design activities Involved in analysis of as-is and to-be processes Running analytics workshops and programs, including KPI definition, analytics systems implementations, data governance, and analytics competencies Creating functional or technical requirements and documentation as an input to application design Involved in application build, test, and deploy activities Plans and executes data conversion activities Develops and tests detailed functional and technical designs for business solution components Drives test planning and execution break-fix, enhancements, and problem management delivery Develops SAC stories in canvas, responsive, grid, advanced story designing blending data, formulas, cross calculations, input controls, linked analysis. Connect data sources to SAC to enable live feeds. Builds analytics and planning models, visualizations with their usage charts, tables, maps, filters, dropdown menus, hiding functions, interactive objects, pictures. Supports business development processes as a subject matter expert. Performs other duties as assigned. Bachelor’s degree in computer science, business, or statistics, or a related field SAP Analytics Cloud certification Experience creating Dashboards on several SAP systems (e.g. S/4 HANA, SAC, SuccessFactors) as well as Non-SAP systems (Flat Files, other non-SAP Data sources) Must have worked on a minimum of 2 implementation projects in SAP Analytics Cloud. Experience in Designing SAP HANA Views and consuming them in SAP Analytics on Cloud. Experience in creating models, Interactive Stories/Dashboards, storyboards using Input controls, filters, tables, charts, geo maps, smart data insight, smart discovery, mobile-enabled dashboards Experience in SAP Analytics Cloud security concepts, authorizations, roles, and collaborations. Fluency in English, with professional communication skills. People analytics experience Experience with tools and languages including R, Python, SQL, R, Power BI, Tableau, and in the design and implementation of data pipelines that support the continuous delivery of insights. SAP Workforce Analytics certification and experience Experience using SAP platforms, including SuccessFactors, S/4 Hana and C/4 Advanced knowledge of MS Office programs including Word, Excel, and PowerPoint. Advanced knowledge of R and Python Understand business requirements through interacting with data analysts and end-users Ability to build strong relationships with customers and senior stakeholders Knowledge of data modeling and preparing datasets, merging, custom calculations, formatting values, dimensions and measures Demonstrable track record of dealing well with ambiguity, ability to self-motivate, prioritizing needs, and delivering results in a dynamic environment. Combination of deep technical skills and business savvy to interface with all levels and disciplines within our and our customer’s organizations Ability to extract, manipulate, transform and analyze large volumes of data with a high level of accuracy Excellent at presenting data visually Excellent attention to detail - you value getting things right Ownership mentality: don't just execute what's asked, consider whether it could be done a better way Conflict resolution skills, with the ability to influence decisions and manage relationships Ability to meet a deadline and manage priorities Work is home-based as part of a global organization. Some travel to office or customer site and working outside of core hours may be required. Routinely uses standard office equipment such as computers, keyboards, printers/scanners, and telephone applications 
ScrapedJobID372:
Researching industry best practices for features to be implemented in the Data Analytics platform, with a focus on Data Science features including Data Preparation, Machine Learning, AutoML and Explainable AI Features Ensuring that new features fit within the architecture of the Data Analytics Platform Developing Python or R prototypes of the above Data Science features Working closely with multiple developer teams to productize the Python and R templates in the Data Analytics platform, ensuring incremental value delivered with each software version release Advanced Python, SQL and R (optional), including experience with data processing and ML pipelines Excellent knowledge of the landscape of data analytics tools, including open source tools (e.g. Python sklearn/Pandas, Keras, Jupyter, R, Docker) as well as enterprise platforms. Experience working with big data 2+ years experience building models that have achieved business value or reached production Able to work in a fast-paced environment Can collaborate with others and build relationships with multiple teams, including developers, designers, subject matter experts and stakeholders Empathy to translate end-user needs into valuable features Excellent communication skills – able to communicate complex technical features to non-technical teams and stakeholders. Not afraid to ask for help when needed Envision the Future Communicate Honestly and Broadly Seek Technology and Business “Firsts” Embrace Diversity and Take Risks Competitive Salary Comprehensive Benefit Package Outstanding Work/Life Balance Flex Time Paid holidays Paid time off for community services Collaborative environment 
ScrapedJobID373:

ScrapedJobID374:
experimentalists to design studies focused on using Inscopix technology to discover and validate novel neuro-therapeutics. fellow computational neuroscientists to design and develop methods for analyzing and interpreting our large in vivo datasets. data engineers to optimize and harden your algorithms into robust, performant data products that can be executed at scale. software engineers who will bring your analysis methods to life in intuitive user interfaces and scalable backend compute architectures. collaborate with neuroscientists and engineers to develop innovative analyses of large scale video & time-series data, including calcium imaging and behavioral data. lead external neuroscience data analysis collaborations in industry and academia. perform and report exploratory analyses on novel and existing algorithms for analysis of high dimensional brain activity and animal behavior datasets. assist with integration of new data processing algorithms into existing software products. has a PhD in computational neuroscience or related field has a strong publication/conference record where major contributions relate to processing, analyzing, and modeling neuroscience research data enjoys working together with experimentalists to design studies and interpret results is excited to work alongside data and software engineers to translate innovative computational methods into robust data products. in vivo calcium imaging & related processing and analysis methods supervised and unsupervised models for inferring ethograms from behavior movies. mouse models of neurodegenerative diseases (e.g. Parkinson's Disease, Alzheimer's Disease) manipulating, analyzing, and visualizing data in Python (e.g. NumPy, SciPy, Pandas, Matplotlib, Seaborn) applying machine learning and/or deep learning techniques to answer neuroscience questions (e.g. using scikit-learn, statsmodels, Keras, Tensorflow). training and optimizing machine learning models for deployment in customer-facing products. using tools like git to version control & share code. scripting in Unix command line environment Vancouver, BC (remote possible) 
ScrapedJobID375:
Influence how we build a mission-driven, high-throughput data science and analytics organization, and contribute to our collaborative culture Establish data rigor, data integrity, accuracy, responsiveness and execution cadence across all data science and analytics programs Build frameworks and tools to automate ad-hoc and post-hoc analysis requests Help Machine Learning team with exploratory data analysis for enabling semantic search and analysis to support applied machine learning across all product initiatives Create and implement machine learning models to support products Mine structured and unstructured data platforms to understand customer attributes, user journeys, engagement with the products, and growth opportunities for our business Design and analyze A/B tests and propose innovative A/B testing techniques to help us learn about our millions of users Propose strategic initiatives and goals to help our functional partners to achieve their goals and drive growth Effectively communicate data findings to internal and external team members 5+ years of working experience in data science or analytics Deep understanding of statistics and probability, quantitative sciences, data analysis, natural language processing, text mining, econometrics, and distributed data processing Skilled in predictive modeling, statistical modeling, data mining, numerical simulation, stochastic modeling, time series analysis, and portfolio modeling Quantitative experience in B2C markets Track record of delivering decision support models and quantitative analysis with actionable insights Hands-on technical skills in Python, SQL, Map/Reduce, RegEx, and Linux scripting Experience with big data platforms such as Hadoop, MapReduce, Spark, Hive, and Pig MS or PhD degree in a scientific or quantitative field Experience mentoring or managing other data scientists Past experience with unstructured data and NLP Knowledge and experience working with Google Analytics, Tableau, Amplitude, and Treasure Data Full private medical coverage (medical, dental, vision) Retirement savings program Paid Parental Leave Education Reimbursement Quarterly team events and outings Team lunches Social responsibility program (volunteer hours and donation matching program) Front row seat to Master Educator lectures – check out our Lecture Series videos 
ScrapedJobID376:
Architecting, implementing, and stewarding end-to-end data infrastructure Building agent-based simulations of smart contracts and blockchain networks using our Python SDK Designing and optimizing incentive models for blockchain protocols and help discover potential attack vectors Build data models and visualizations of public blockchain data and simulation results that provide intuitive analytics to customers Understand product, risk, and business requirements and how to apply ML to solve our most challenging problems in impactful ways Automating and scaling simulation model deployment on cloud infrastructure Make business recommendations to the executive and cross-functional teams (e.g. cost-benefit, forecasting, experiment analysis) effectively through findings from quantitative information Driving best practices around security in data engineering Driving data literacy and data-driven decision making across functions 8-10 years of relevant experience Experience developing production quality software in Python, Go, or other high-performance languages Experience with scientific computing packages such as Numpy/Scipy, Pandas, etc.. Track record of designing, building, scaling and maintaining production services, and composing service-oriented architecture Experience with distributed computation frameworks such as Spark, Flink, TensorFlow M.S. or Ph.D. in STEM field, with experience building production Blockchain pipelines (development, deployment, inference and monitoring) at scale Smart contract development experience (e.g. Solidity) Experience with building Machine Learning infrastructure at scale 
ScrapedJobID377:

ScrapedJobID378:
Build and maintain our ML development stack hosted on AWS and running with Sagemaker Work with the data science team to facilitate model development and deployment Write Airflow ETLs to prepare data for consumption by ML models Participate in maintaining our MLOps best practices and tool selection You understand the main elements of the ML lifecycle, including data connection, ETLs, model training and deployment and the tools necessary to test and monitor models in productions You are familiar with Snowflake and how to efficiently query data from it You are familiar with the AWS cloud environment and how to deploy components Bonus points if you are familiar with Machine Learning enablement tools such as experiment tracking systems, feature store and similar systems Bonus points If you are familiar with the internal of model compilers to help find potential ways to accelerate or distribute the training and inference of models Competitive compensation packages Generous group health insurance plan Access to the virtual healthcare platform Dialogue Access to the company's stock option plan 16 days of vacation per year, which increases with seniority at the company 3 paid Caring days 1 paid volunteer day Offices closed during the holidays Wellness allocation of $840 per year (for gym memberships, sportswear, etc.). In-house training programs on our company and industry Encouragement and funding of continuing education and training Very active social committee and free online sports classes Access to a tool that measures your engagement and job satisfaction anonymously Pairing with a buddy for your first 6 months Advantageous referral program Inclusive, inspiring, and dynamic work environment Casual dress code Work from home and flexible hours And more! 
ScrapedJobID379:
Working with our ML scientists to develop highly scalable models and algorithms for predicting molecular phenotypes using state-of-the-art neural network methodologies. Developing evaluation, visualization, and productivity tools for streamlining machine learning research Adapting our algorithms and architectures to best exploit modern cloud computing environments Working with our software engineers, biologists and geneticists to operationalize and deploy research output to match the needs of stakeholders. Solid Engineering and Computer Science fundamentals, ideally with a degree in CS, Math, or equivalent experience. Senior candidates should have experience in architecting, developing, and deploying large software systems in a leading position Experience in building, testing, training, and deploying production-ready ML workflows. Experience developing machine learning algorithms or machine learning infrastructure in Python or C/C++. Experience with frameworks like PyTorch, Caffe2, Tensorflow, Keras, JAX, Chainer, etc. Experience in the operationalization of Machine Learning projects (MLOps) using at least one of the popular frameworks or platforms (e.g. Kubeflow, AWS Sagemaker, Google AI Platform, Azure Machine Learning). Leading role in developing the future of drug development to cure genetically defined diseases. A highly competitive salary and meaningful equity compensation. Exceptional opportunities for learning and growth. A bright, collegial, highly motivated team working at the intersection of the most exciting areas of science and technology. 
ScrapedJobID380:
Improve the efficiency and effectiveness of farming operations Ease collaboration Successfully deploy autonomous farm machinery Develop machine learning algorithms for the perception system, Work with data from a variety of sensors (e.g. cameras, LiDAR, IMU), Adapt state-of-the-art models to run efficiently on edge devices, Develop scalable and robust infrastructure for model training and deployment Prepare reports and presentations on progress, status and results internally, externally, verbally and in writing, Strong background in machine learning, linear algebra, mathematics and optimization, Strong software development skills and experience with C++ and Python, Recent hands-on experience with at least one of the following deep learning techniques: object detection, object classification, semantic segmentation, scene understanding, 3D pose estimation. Experience with common deep learning frameworks (e.g. TensorFlow, PyTorch), Bonus: experience with C++, CUDA and TensorRT development, Bonus: experience deploying deep learning models on embedded systems, 8 hour shift Bachelor's Degree (preferred) Temporarily due to COVID-19 
ScrapedJobID381:
Conduct discovery sessions with business teams to understand and capture their processes, formulate alternative to improve productivity using analytics and automation, and define the related key performance indicators Take on assigned data mining, analysis, profiling, and modeling activities and complete them within competing priorities and deadlines Devise design alternatives for ingesting data for analytics, management reports and dashboards Complete data and access governance assessments for internal and external regulatory and legislative compliance Prepare test plans and test cases and conduct and coordinate quality assurance testing with end-users and obtain business acceptance sign off Prepare defined documentation where required within the framework of the project and solution delivery – including and not limited to requirements, process and data flow diagram, and data mapping Contribute to the story mapping, creating user stories, and furnishing user stories with details were needed Work closely with business stakeholders, product owner, and developers and addressing their ad-hoc data, information, and analysis requests You are curious and highly motivated to discover new relations in business data, understand and interpret data, tell the story of how it is used in business processes, and how to deliver business value by transforming it You have 5-7 years extensive knowledge of business intelligence tools and programming languages You have 5-7 years experience in working for large projects and have advanced experience with SQL, ETL, data analysis and profiling, data mapping, data modeling, data lakes, and analytics You are excellent in written and spoken English to clearly communicate complex issues and interface with all levels of the organization with ease You have excellent interpersonal, prioritization, and issues management skills for building strong collaborative relationships with stakeholders and coworkers You are highly organized, disciplined, and responsive in a fast paced and demanding environment You constantly and strongly demonstrate the core values that continuously advance the productivity of high-performing and self-organizing teams: respect, commitment, courage, openness, and focus We are technology partners who help the business transform how our employees around the world work We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success! You'll get to work with and learn from diverse industry leaders, who have hailed from top technology companies around the world We foster an environment of innovation and continuous learning We care about our people, allowing them to design how they work to deliver amazing results We offer a competitive total rewards package, including a performance bonus, company matching programs (on pension & profit sharing), and generous vacation 
ScrapedJobID382:
Expérience de 5 ans en Data Visualisation Expertise reconnue sur Power BI Expérience combinée avec l'un des rôles suivants : Développeur Python - Atout Data Analyst - Atout Business Analyst - Atout Expérience avec les langages SQL, Dax, Power Query Curiosité, excellent relationnel, créativité, force de proposition Avoir le goût du challenge et l'envie de réussir. Passionné par ce que vous faites Bonne maitrise du français et de l’anglais, à l’oral comme à l’écrit Certification Power BI - Atout Collecte et analyse des besoins Anime des ateliers du type « Design Thinking » Définit les indicateurs de performance (KPI) Rédige le cahier des charges au niveau fonctionnel et technique Développe des visualisations sur Power BI Automatise les rapports et tableaux de bord Interprète les données Présente ses analyses et visualisation devant la direction (Data Storytelling) Une rémunération annuelle fixe et une bonification annuelle selon l’atteinte de ta performance Des objectifs individuels accessibles et réalistes pour garantir un environnement sans pression Des assurances collectives Manuvie (dentaire, vision, soins paramédicaux…) 4 semaines de vacances Remboursement des abonnements de sport et du transport Horaires flexibles et télétravail Plan de développement pour chaque employé et coaching avec un mentor Environnement non hiérarchique favorisant l’intrapreneuriat Activités mensuelles de team building Du Lundi au Vendredi Repos la Fin de Semaine Visualisation de données: 5 ans (Souhaité) Power BI: 3 ans (Souhaité) Anglais (Souhaité) Français (Souhaité) Temporairement en raison de la COVID-19 
ScrapedJobID383:
Perform analysis with business units to support ongoing decision-making and to identify quantifiable project value Perform requirement analysis with the business units to understand business issues and generate hypotheses Deliver and support models throughout the data lifecycle: build, test, deploy and improve Communicate results of analytics outcomes with business partners effectively Implement measurement and documentation framework against all project work Provide thought leadership related to analytics methodology, tools and measurement Innovate and find creative ways to source data to support modelling efforts A master’s degree or PhD in computer science, data science, operations research, statistics, applied mathematics, or related quantitative field Minimum 5 (five) years of experience specifically in statistical analysis, predictive modelling, machine learning, and/or artificial intelligence Proficiency in Python or R Working knowledge of SQL, Java, VBA Expert knowledge of BI development Excellent communication skills with non-data focused business partners Financial Services experience is an asset Experience working in Microsoft Azure and Amazon AWS is an asset Self-driven, curious and creative in developing hypotheses 
ScrapedJobID384:
Possess a successful track record of designing and developing AI/ML algorithms for private or public sector solutions Up-to-date with the latest technology trends, have a strong desire to constantly learn and be ready to put on the hacker's hat at any time to convert an idea into a demonstration Highly detailed-oriented with exceptional organizational and follow-through skills Self-started and able to execute without a lot of direction or oversight Exceptional communication skills, with an ability to make advanced analytics concepts accessible and understandable to non-technical business users Value collaboration and urgency; and have a passion for driving impact Solve some of the most challenging and impactful problems for financial services, insurance and the government by using artificial intelligence, machine learning, natural language processing and big data Drive innovation into Analytics solutions and focus on humanizing enterprise software to achieve better customer experience and to enable data-driven business decisions Work on high priority initiatives using advanced analytics, predictive modeling and a variety of data sources to produce actionable business insights Ideate, conceptualize, design, develop and maintain AI/ML algorithms that provide data insights that drive operational efficiencies and cost savings Build production grade models on large-scale datasets. Utilize advanced statistical modeling, machine learning, and data mining techniques Provide guidance to a customer and project team with respect to technical feasibility, complexity, and level of effort required to deliver a solution Work closely with other team members to further develop metrics, KPIs, and insights that measure business performance improvements Assist in the development and delivery of pre and post sales POCs, presentations and proposals for client engagements Travel periodically in support of sales and delivery as needed At least 2 years of experience working on predictive analytics and data mining projects 2 years of hands-on experience using complex machine learning methods and algorithms At least 2 years of experience working with one or more data mining tools such as R, Python, Scala or SAS Hands-on experience working with Big Data technologies such as Spark, Cassandra, and/or Hadoop Hands-on experience writing complex SQL queries and working with relational databases such as Oracle, DB2 or SQL Server Hands-on experience constructing and manipulating JSON and XML documents and working with NoSQL databases such as MangoDB and CouchDB Good understanding of microservices architecture and hands-on experience working with REST APIs Self-directed and demonstrable problem-solving skills Knowledge of modern software development techniques and methodologies Knowledge and practice of secure software development processes Ability to handle multiple priorities and deadlines Bachelor’s degree in mathematics, business, statistics, economics, computer science or information systems (or equivalent combination of skill and experience) Asset : Data Analysis Engineering 
ScrapedJobID385:
Participate in analysis of client data and formulate well-defined problem statements and recommendations for advanced analytical workflows that are usually provided as very open-ended problems Create and design dashboards by using different data visualization tools to present reports and insights, and support business decision making Design and develop ETL workflows for serving data to the dashboards as needed Write complex SQL queries with multiple joins to automate and manipulate data extracts Perform exploratory data analysis to identify patterns from historical data, generate and test hypotheses, and provide product owners with actionable insights Create advanced analytical models using advanced statistics, machine learning or other methods for client-specific use cases Create production-worthy ML workflows and pipelines. Participate in the creation of Statements of Work and other Prospecting activities that require technical expertise and inputs. Participate in end to end analytical system design when needed, including end to end ETL, reporting and visualization workflows, ML pipelines (continuous training, continuous serving) and data modelling as required Design testing process, create and execute test cases for advanced analytical workflows Troubleshoot and resolve issues and defects Maintain and exceed client satisfaction with DRVN Intelligence Inc.’s deliverables, day-to-day work and overall value as a partner Cultivate opportunities for company growth, always seek areas where DRVN Intelligence Inc.’s role could be expanded Adapt to ever-changing client needs and expectations Maintain dedication toward achieving excellence in DRVN Intelligence Inc.’s delivery against client needs, and overall success as an organization Be an enthusiastic, positive and generally awesome team mate, mentor & constantly curious learner Stay up-to-date on relevant technologies, plug into user groups, understand trends and opportunities to ensure we are using the best possible techniques and tools Enthusiasm to take on new challenges Ability to learn and adapt quickly 1+ years experience working on Data systems and advanced analytical workflows built on the cloud. GCP, AWS or Azure preferred Strong understanding of statistical analysis of data including correlation analysis, outlier analysis and hypothesis testing Strong understanding of data visualization concepts, different types of visualisation charts and choosing the appropriate visualisations to convey insights effectively 1+ years of experience building interactive dashboards using at least 1 data visualization tool such as Data Studio, Tableau, PowerBI or Looker. Experience building visualisations exclusively using Python or other programmatic libraries will also be considered. 2+ years of experience using Python. Java or other programming language experience will also be considered 2+ years of experience using SQL. Experience writing large dynamic analytical queries will be a strong asset Strong understanding of regression models, classification models, neural networks, decision tree models and unsupervised learning models such as k-means clustering. Ability to analyze a problem and make decisions on the appropriate candidate models for the problem Experience building machine learning models on large datasets Experience in hyperparameter tuning and evaluation of ML models Experience using data science libraries such as pandas, matplotlib, scikit-learn, keras, nltk etc. Experience using Tensorflow is a strong asset Strong understanding of Feature Selection and Feature Engineering concepts Experience using ETL/orchestration/workflow management frameworks like Apache Airflow preferred, but not required Strong understanding of and experience with large scale OLAP databases and data warehouses. Strong understanding of Google Cloud BigQuery preferred Understanding of digital marketing ecosystems and tools like Google Marketing Platform, GA360, Google Ads, Adobe Suite etc. a strong asset Technical understanding of a range of marketing concepts such as cookie-based data collection, setting and leveraging audience segments, attribution modelling, A/B testing, knowledge of marketing KPIs and their calculation will be a strong asset. Excellent written & verbal communication skills are essential; candidate should be comfortable presenting and participating in group discussions of concepts with internal and external stakeholders 100% employer-paid benefits package Monthly yoga and meditation classes Regular Lunch and Learns from your Team Mates Fun Employee Events and Activities Participation in Community Engagement 
ScrapedJobID386:
The CIC NS is one of IBM’s highest performing delivery centres worldwide – for retention, client satisfaction and utilization. Our employees are empowered to stay and grow within IBM. We are very focused on continuous skill development – staff training is our third largest annual Centre investment. Employees are immersed in a culture of learning and constant growth Investment in key partnership with universities, government and private sector groups which has resulted in IBM having a key influencing role in Nova Scotia’s ICT industry, especially in talent development. Object oriented programming with Python Scaling the code for an existing model Deploying the scaled model into production Identify model drifting and how to retrain a drifted model in production Creating CI/CD pipelines to automatically deploy the trained/retrained models into production Ability to work independently on tasks and deliver with a high-level of quality; Ability to work in teams and be open to comments and feedback; Ability to learn quickly and to adapt to a fast-paced environment; Data processing, data design and modeling, deploying the model Proficiency in English both verbal and written) an asset Proficiency with a deep learning framework such as TensorFlow or Keras Proficiency with Python and basic libraries for machine learning such as scikit-learn and pandas Expertise in visualizing and manipulating big datasets Knowledge of Kubernetes and containerization Participate in teams working in an Agile/Scrum or Waterfall process and ensure the stories/tasks are well defined and have all the information and tools to be successful; Work with the Project Manager and project stakeholders to ensure we meet our commitments; 
ScrapedJobID387:
Artificial Intelligence / Machine Learning Data Science Cognitive Computing Computational Linguistics Computer Science 7+ years of experience with general purpose programming languages e.g., Python, C/C++, Java 7+ years of hands-on experience in machine learning and deep learning Key requirement: Strong understanding and exposure to the Multi-Armed Bandit (MAB) problem and its variants (e.g., contextual MAB, dueling MAB, adversarial MAB, combinatorial MAB, etc.) Key requirement: 2+ years of hands-on experience in resource optimization and reinforcement learning techniques such as Thompson Sampling, Upper Confidence Bound algorithms, and other solution approaches to the MAB class of problems Strong understanding of problems in the ad optimization and personalization space Exposure to machine learning platforms such as TensorFlow, TensorFlow Extended, PyTorch Good to have experience building and deploying machine learning models on the Cloud (Google Cloud, Azure, AWS) Good to have experience with production architecture of machine learning systems Excellent communication skills Ability to collaborate cross-functionally Good presentation skills Attention to detail Collaborate with the Engineering and Product teams to build machine learning models into the products and offerings of [24]7.ai, primarily in the space of ad optimization and personalization Lead a small team of data scientists. Be responsible for implementing the machine learning models, testing them, refining them, and taking them to production for our ad optimization and personalization product/offering. Collaborate with other teams in the Data Science Group to review and refine your work to ensure the highest quality Collaborate with the product owners and the data science leadership to chart the AI vision for ad optimization and personalization. 
ScrapedJobID388:
Wrangling both structured and unstructured data Organizing and joining data sets from disjoint data storage systems Doing exploratory data analysis on imaging, sequence, and wet bench experimental data sets Implementing automated, repeatable, testable pipelines that join together and process diverse data sets Designing metrics to measure data set characteristics and quality Discovering data characteristics that influence ML model inference accuracy, and ways to mitigate problems Cleverly repurposing or augmenting existing internal and external tools to build manual data labeling workflows, and orchestrating data labeling efforts Auditing data access for compliance with data governance policies Providing valuable insights into platform and data pipelines development and deployment Participating in code reviews with the machine learning team and broader data science group A team-first attitude and thirst to learn and improve in machine learning, software engineering, data science, and the life sciences! B.S. in computer science, data science, machine learning, or similar 2+ years of experience working with machine learning data sets using Python, Pandas, and SQL, at the level of querying and joining together data sets Excellent organizational skills and attention to detail Enthusiasm for cross-team collaborative work, especially across life science disciplines Experience in the life sciences, including imaging and bioinformatics Experience with other components of our opinionated ML stack, including PyTorch, Plotly / Dash, Parquet, DVC, and Dask Experience with our infrastructure stack, including AWS (S3, IAM, CloudWatch, Route53, RedShift), Terraform, Kubernetes, Docker, bazel The opportunity to work with an inspired team on challenging problems that matter An attractive compensation package, including health and lifestyle benefits A minimum of 3 weeks’ vacation Opportunities for personal and professional development 
ScrapedJobID389:
Leverage industry best practices to collect, analyze and present various data aspects of the program Work in an agile team of software developers, testers and other data analysts Work with the team to ensure the data needed is being collected at all times and is enumerated, tracked and valid Ensuring the team is aware of personal identifiable information and that all processes are being followed. Write code to perform complex data queries across various data collection systems Perform complex analysis of the data taking into account the problem/feature being looked at and the source of data in order to identify trends and relationships. Present summaries and visualizations to the team and others on findings either as a one time investigation or as a report that is continuously pulling data on a timely basis. Bachelor’s Degree in data science, data engineering or related field (Successful candidates will be required to provide proof of degree completion for the highest level of education attained. If the degree was obtained from a school outside of Canada, an Education Credential Assessment report showing Canadian equivalency is also required.) 2+ years work experience Ability to deep dive into complex issues and help drive investigations via data. Ability to recognize when the results don't make sense, and help identify why. Extensive experience with data querying tools such as HiveQL and SQL. Extensive experience with building and managing ETL processes through tools such as SSIS, SSAS. Extensive experience with data analysis methods and employing tools such as PySpark Extensive experience with data reporting, visualization and presentation employing tools such as PowerBI (Preferred), Microsoft BI Stack (SSIS, SSRS, SSAS), and Tableau. Excellent communication, interpersonal and presentation skills Experience with automotive technologies. Knowledge of ML/AI technologies. Experience working in an agile environment. 
ScrapedJobID390:
Teach a class of beginners (in collaboration with 1-2 other instructors and the Lead Instructor) with the goal of ensuring they graduate ready for junior level roles in Data Science Act as coach/mentor to students as they work their way through the course Care profoundly about every student's success Present lectures on Math, Stats, Python, Pandas, SQL, Data Visualization, and more Communicate regularly with the Administration Team and Lead Instructor to provide ongoing updates on the students' process and feedback Follow each student independently and ensure that they develop a mastery of the subject matter Experience teaching (as a TA), coaching, managing or supporting junior staff or managing projects Experience in the field of Data Science, have graduated from a Data Science Bootcamp and/or have an educational background in Data Science Outgoing, personable, friendly and empathetic Comfortable explaining difficult concepts because of your ability to dissect and disseminate them into bite-sized, understandable ideas Well-versed in both front-end and back-end development Strong active listening skills and ability to motivate Ability to help all students equally - both those that are excelling and those who are falling behind, with patience, kindness and empathy Lifelong learner who loves sharing their learnings and experiences with others Loves the idea of helping people lead better lives through education Fixed amount of $17,500 CAD for the entire duration of the contract (divided into monthly instalments) Fully remote work Work with an amazing and fun team Possibility to extend your contract and teach more courses 
ScrapedJobID391:
Develop, implement, and deploy machine learning models that leverage our unique combination of threat data, user behavior and subscription data to improve consumer value from our products Deliver data based intelligent personalization in all our touch points consumer including marketing, product and customer service Mine, analyze and build predictive and descriptive machine learning models on structured and unstructured data sources Utilize code (Python, R, Scala, etc.) for analyzing data and building statistical models to solve business problems Apply or design highly innovative models for predictive learning, forecasting, recommendations, content ranking, and anomaly detection. Use machine learning to help us anticipate and cater to consumer's personalized needs for threat protection. Use data and machine learning to create differentiated and personalized experiences for consumers across multiple touch points with Mcafee. Create algorithms for optimizing consumer journey and increasing conversion and monetization Perform statistical analysis on the outputs of these machine learning models to help update, re-train, and then deploy new ML models Contribute to the creation, deployment, and scaling of machine learning and predictive algorithms in a production environment Help identify new opportunities for applying machine learning and statistics based models for improved customer and business outcomes You will have 5+ years of experience as a Data Scientist. You will be proficient with designing, analyzing, and troubleshooting controlled experiments (Causal A/B tests, Multivariate tests). Knowledge mentoring team members in the use of data science tools such as R, Python, SQL, MapReduce, Hadoop, Hive and Big Data technologies. Experience with applied machine learning (like scikit-learn) and deep learning frameworks (like Keras, tesorflow or PyTorch). Experience in optimization mathematics (linear programming, nonlinear optimization) You will work with large amounts of structured and unstructured data in a consumer facing online business. You will have algorithmic problem-solving skills and practical experience with machine learning. You will work with natural language processing (NLP), text mining, statistical modeling, and hypothesis testing. Pension and Retirement Plans Medical, Dental and Vision Coverage Paid Time Off Paid Parental Leave Support for Community Involvement 
ScrapedJobID392:
Gathering training data for the existing deep learning, ML and NLP solutions Providing actionable ad hoc analytics insights for internal stakeholders Designing and building recurring reports for internal stakeholders to make data-driven decisions Identifying and implementing ways to supercharge data quality and data integrity Using advanced analytical methods to explore and extract additional data value for existing and emerging products Documenting analysis results and presenting value to stakeholders Creating reusable processes to assist data evaluation and analysis across teams within Data Center 3-5 years of direct experience performing advanced data analytics or a Master’s Degree in Statistics, Data Analytics or related field 3+ years’ experience in SQL/Spark, R, Python Strong grasp of statistical modeling techniques such as linear regression, logistic regression, GLM, etc. Understand NLP concepts like: Named Entity Recognition (NER), Sentiment Analysis, Data Tokenization, Lexical Semantics, Relationship Extraction, etc. Ability to effectively communicate analysis and insights to all levels of the organization A passion for continuous learning Confidence to challenge the status quo Automotive industry experience a plus 
ScrapedJobID393:
Power Bi Report Development Expert in using advanced-level calculations on the data set. Responsible for design methodology and project documentaries Create and maintain interactive data visualization through data interpretation and analyses, integrating various reporting components from multiple data sources Developing visual reports, KPI scorecards, and dashboards using Power BI desktop. Developing and building data models Connecting data sources, importing data, and transforming data for Business intelligence. Hands on experience with DAX Experience with SQL queries Support and enhance of existing reports and dashboards based on evolving business needs Assess the effectiveness and accuracy of new data sources and data wrangling techniques Support ad-hoc analyses with decision-grade quality Expert in using advanced-level calculations on the data set. Assist in facilitating hands-on sessions in prioritizing user-stories, designing analytical approaches, running experiments, and assessing data product performance Prepare compelling, meaningful and memorable messaging and presentations to address business questions (both written and verbal) Have an open mind and a knack to collaborate effectively across internal and external partners to further capitalize on data assets Handle ambiguity and apply first principles with structured approaches to solving problems Apply design- and system-thinking concepts with an agile mindset to create and deploy incremental, viable data products by leveraging tools available in-house and in the open-source ecosystems Bachelor’s degree with exceptional academic standing, and/or master degree(s) in an analytical discipline such as: mathematics, applied science and engineering, physics, computer science, management analytics, data science 2+ years of professional experience in analytics or other quantitative disciplines 2+ years in Power Bi Experience in modeling and data visualization Experience in problem solving and analytical skills to develop creative, unique and pragmatic approaches and solutions to address complex problems Technology experience in Power BI and SQL (Azure, VBA, Python is a plus) Business domain knowledge in one or more of the following: Sales, Call Center Operations, Billing and Collections, Accounting and Finance Excellent oral and written communications skills 
ScrapedJobID394:
Collaborate with the ecommerce, performance marketing, retention, sales and affiliate teams to understand their data needs and generate data insights; Perform SQL data queries and manage data to support the teams to take the right business decisions; Conceptualize, create and maintain reports, dashboards, and data visualizations that can be go-to reference assets; Be a resource for internal stakeholders and the go-to person for all data related topics within the marketing team; You will be responsible for developing automated, scalable reporting and analytics solutions for our marketing and finance teams; Analyze performance, identify internal & external trends from data, troubleshoot issues, identify new opportunities and address ad hoc data requests; Coordinate research and analytic activities utilizing various data points (unstructured and structured) able to clean, massage, and organize the data; Ability to analyze and extract relevant information from large, complicated data sets of structured and unstructured data; Using multiple data sources, create reporting and performance monitoring tools and dashboards for end users; Partner with internal and external team members to design relevant data visualizations using Looker and work with team members to build dashboards for data quality and analysis; Gather requirements and translate business problems into structured quantitative problems; Develop and maintain reports, dashboards, reporting tools and structures to track key metrics; Strong understanding of SQL or Snowflake and proficiency in data visualization (Matplotlib, Plotly, Altair, etc); Proficiency with data science analysis and modeling packages in Python (including Pandas, NumPy, etc); Familiarity with marketing metrics such as first/last touch attribution, CAC, contribution margin, COGS, etc. Experience completing a data project from ideation to data ingestion to dashboarding/modeling; Proven ability to use data (statistics and analytics) for sound decision making across multiple functions; You have a proven ability to work on interdisciplinary teams with parallel projects and agendas on tight deadlines; Experience solving unique problems, thinking outside of the box, and experimenting on new solutions; E-commerce experience, especially with Shopify Experience with Google Ads and Facebook marketing Previous experience working in a manufacturing environment or Startup; 
ScrapedJobID395:
Analyze and test large volumes of data for outliers, anomalies, patterns and trends to support the evaluation of the adequacy and effectiveness of controls. Develop efficient audit testing programs based on data trends and their underlying control deficiencies. Support the strategic objectives established by the Audit Manager, Information Technology (IT) through the identification and risk classification of data focus areas. Build dashboards in Power BI or through other tools/reports to provide meaningful insights to business data. Utilize audit test results to further evaluate risk implications and raise recommendations that will add value in implementing cost efficient solutions and/or identify cost savings opportunities. Collborate with the City Auditor, Audit Manager IT and audit staff to define and prioritize data analytic requirements. Effectively communicate audit findings to Audit Committee, Senior Management, Business Unit Leaders and process stakeholders in an understandable document to easily communicate complex ideas. Deliver reliable audits that comply with professional audit standards and are delivered within quality, time and budget parameters. A degree in Data Science, Computer Science, Information Management or Business Administration or related field and at least 5 years of related experience. Certified Internal Auditor (CIA) designation or Certified Information Systems Auditor (CISA) is required. Experience in leading complex audits and at least 2 years of related data analytics experience is required. Other relevant data analytics, accounting, and information technology professional certifications would be an asset. Success in this position requires the following: superior analytical and problem solving skills, critical thinking, verbal and written communication, technical auditing competence, and team collaboration. Equivalent combinations of experience and education may be considered. Successful applicants must provide proof of qualifications. Effective November 1, 2021, all City of Calgary employees must be fully vaccinated against COVID-19. For more information, please refer to COVID-19 Vaccination Policy. 
ScrapedJobID396:
The candidate needs to have a solid understanding of software development methodologies (like Agile and SAFE) with either a proven history of delivering to the enterprise, or a strong passion to do so using Python The ultimate candidate would have a strong mathematics background and a desire to work with Machine Learning (ML) technologies in Python in an effort to elevate the customer's experience when interacting with client Ability to wear many hats at a time and willing to train some of these skills if you bring the passion and desire to grow professionally and technically Independent self-motivated worker but team aligned Passionate about creating new things using software Interested in delivering practical applications of Machine Learning Hands-on person with good communication abilities both written and presenting to leadership Ability or desire to work closely with DevOps on infrastructure and release planning Hungry generalist with a passion for learning, especially interest in bringing Data Analytics / Machine Learning to bear in practical applications 2-5 years of experience, preferably in a data heavy role, but not required for the appropriate candidate Knowledge of one or more of the following technologies: Python, ML, AI, Big Data (Hadoop, Spark, Hive, etc.), AWS, Docker, Kubernetes, DB (PlSQL, HQL, Mongo) Has participated in, or is willing to understanding Agile / Scrum development methodologies Ability to learn and operate independently while still being an active participant in the team ceremonies Ability to learn and cross-train on full-stack SDLC cycles: Imagine, Architect, Design, Document, Code, Delivery, DevOps, Debug, Support Extended Healthcare with Prescription Drugs, Dental and Vision Insurance (Company Paid) Life and AD&D Insurance (Company Paid) Employee Assistance Program (Company Paid) Long-Term Disability Registered Retirement Savings Plan (RRSP) with company match Paid Time Off Critical Illness Insurance Employee Discounts Unlimited access to LinkedIn learning solutions 
ScrapedJobID397:
Dental care Extended health care Flexible schedule Paid time off Work from home 8 hour shift Microsoft Excel: 3 years (preferred) Yes 
ScrapedJobID398:
Apply advanced statistical and machine learning techniques to build models for underwriting, experience studies, assumption development, pricing, and claims management. Help us drive innovation by enabling new underwriting paradigms, distribution models, and data management. Build and implement solutions that enable operational units to improve quality and speed of core processes in order to generate incremental revenue or reduce expense. Proactively research new ways of modeling data to unlock actionable insights or improve processes. Collaborate across Munich Re functions and with clients to use analytics to influence business decisions. Work with existing data science groups at Munich Re and collaborate with internal partners to leverage capabilities in big data technology. Undergraduate Degree in Computer Science, Engineering, Statistics, or Applied Mathematics, plus 3 years’ experience OR Graduate Degree in Computer Science, Engineering, Statistics, or Applied Mathematics, plus 1 years’ experience. Insurance or financial services background is preferred but not required. Actuarial examinations or designation is an asset but not required. Expertise in advanced predictive analytic techniques. Strong experience working with Python, or R; working knowledge of SQL (familiarity with multiple languages considered an asset). Experience working with analytics through the modeling lifecycle including gathering data, design, recommendations, testing, implementation, communication, and retraining. Familiarity with cloud computing platforms (ex. AWS, Microsoft Azure). Familiarity with big data technologies (ex. Apache Spark, Hadoop, etc.), natural language processing and deep learning frameworks (ex. Tensorflow, Pytorch) is an asset but not required. Excellent communication skills, effectively interpreting modeling results, distilling actionable insights and presenting them to partners. The ability to learn quickly. A drive to make a difference. Thrive in a dynamic environment and successfully deliver on multiple assignments under deadlines. 
ScrapedJobID399:
Build an understanding of the fundamental business drivers and metrics, and how data science can improve the business Based on analysis, recommend and implement data science-driven initiatives across the business Work closely with business leadership to integrate data into every part of the product Coordinate with external partners on AI projects Mentor and lead a growing team of data scientists and analysts 10+ years of experience working in data science / analysis 3+ years managing a data science organizationAdvanced degree in Statistics, Computer Science, Econometrics, or similar domain Practical experience in full life-cycle of data science projects including research, development, production, and evaluation Influential and respected leader with track record of successfully running DS driven orgs through mentorship, guidance, vision and execution Strong familiarity with experimental design Experience working in an org where data science-driven work is important part of the core product offering Comfortable collaborating with leadership to distill down high level business goals and provide data driven recommendations Experience with machine learning techniques and how they are applied in production systems Experience in adtech would be helpful Competitive compensation packages Generous group health insurance plan Access to the virtual healthcare platform Dialogue Access to the company's stock option plan 16 days of vacation per year, which increases with seniority at the company 3 paid Caring days 1 paid volunteer day Offices closed during the holidays Wellness allocation of $840 per year (for gym memberships, sportswear, etc.). In-house training programs on our company and industry Encouragement and funding of continuing education and training Very active social committee and free online sports classes Access to a tool that measures your engagement and job satisfaction anonymously Pairing with a buddy for your first 6 months Advantageous referral program Inclusive, inspiring, and dynamic work environment Casual dress code Work from home and flexible hours And more! 
ScrapedJobID400:
Buying intelligence Recommendation systems & customer insights Performance marketing Pricing strategies Network planning & intelligence Data support (10%)
Translate complex analytical results into actionable business initiatives
Develop a deep understanding of the business, its data, and its patterns
Extract data from multiple sources to uncover opportunities or detect issues
Contributes actively to the design of novel solutions to generate value from data Translate complex analytical results into actionable business initiatives Develop a deep understanding of the business, its data, and its patterns Extract data from multiple sources to uncover opportunities or detect issues Contributes actively to the design of novel solutions to generate value from data Project delivery (50%)
Develop a deep understanding of a specific business area & challenges the roadmap
Solve unstructured problems while exhibiting independence and work ownership
Work in collaboration with different teams to refine initial concepts and prototypes that can be presented to stakeholders for feedback
Research, develop and deploy data models and systems to various stakeholders under multiple projects to clearly communicate, elucidating patterns and generating actionable insights and tools
Partner with strategic business stakeholders to provide evidence-based guidance
Maintain & support data science solutions & projects
Delivers & support decision making and decision support systems
Review & contribute to technical documentation Develop a deep understanding of a specific business area & challenges the roadmap Solve unstructured problems while exhibiting independence and work ownership Work in collaboration with different teams to refine initial concepts and prototypes that can be presented to stakeholders for feedback Research, develop and deploy data models and systems to various stakeholders under multiple projects to clearly communicate, elucidating patterns and generating actionable insights and tools Partner with strategic business stakeholders to provide evidence-based guidance Maintain & support data science solutions & projects Delivers & support decision making and decision support systems Review & contribute to technical documentation Ownership and accountability (20%)
Be accountable for code quality
Measure accuracy & performance of developed models & solutions
Monitor deployed decision making and decision support systems Be accountable for code quality Measure accuracy & performance of developed models & solutions Monitor deployed decision making and decision support systems Knowledge sharing and coaching (10%)
Contribute to data mining architecture, modeling standards and data analysis methodologies
Coach more junior data scientists on best practices and machine learning solution design Contribute to data mining architecture, modeling standards and data analysis methodologies Coach more junior data scientists on best practices and machine learning solution design Architecture (10%)
Identify dependencies & impacts between systems
Develop and continuously improve processes, tools, and techniques Identify dependencies & impacts between systems Develop and continuously improve processes, tools, and techniques Master's degree in Engineering, Computer Science, Mathematics, Statistics, or a related field [PhD, an asset] A minimum of 3 years experience in analytics and data science with a focus on driving business impact Strong understanding of advanced modeling techniques, such as machine learning, nonparametric approaches and neural networks Understanding (experience as asset) of data products, from design up to their deployment Experience in building end-to-end data science solutions Excellent programming skills using SQL, Python Experience working with GitHub Experience with data manipulation technologies and knowledge of programming languages Extensive experience solving analytical problems using quantitative approaches Experience working with AWS cloud solutions, an asset e-commerce experience, an asset Understanding of web analytics, an asset Highly analytical and detail oriented Capacity to synthesize, simplify and present complex information to technical and business stakeholders at various levels of the organization Ability to design and present complex data sets in a variety of visually compelling formats Ability to thrive in a fast-paced, performance-driven environment Ability to grasp interrelation, dependencies and assess quickly impact in complex systems Solution-oriented mindset and can-do attitude to overcome challenges Team player with solid interpersonal skills Stay abreast of emerging tools and technologies 
ScrapedJobID401:
Use our modern tech stack, AWS (Redshift & Kinesis), Databricks and PySpark, Airflow, and Tableau to develop innovative tools Work closely with marketing teams to craft, test, verify and implement end-to-end data pipelines that ingest data from multiple sources and output meaningful insights to optimize Zynga audience growth Apply statistical methodologies to evaluate performance and account for uncertainties in major initiatives Design and develop using standard practices within a GitHub environment BS in Computer Science, Math, Statistics, Economics, or other quantitative field; Masters or PhD strongly preferred 3+ years of work experience in data science or analytics roles Demonstrated experience with some or all of the following: data mining, predictive modeling, statistics, experimental design, application development, computational analytics, econometric modeling, data visualization Proficient in Python, SQL, and other programming languages; Experience with visualization software such as Tableau and/or app design using libraries such as Plotly Dash Strong written and oral communication skills Competitive salary, bonus plan, Zynga RSU’s (Restricted Stock Units), ESPP (Employee Stock Purchase Plan) RRSP Company Match Contribution Extended Health coverage, dental, disability, critical illness, EAP, and life insurance Virtual mental health and neurodiversity support programs Goodlife fitness annual membership Open vacation policy Family planning support program Generous paid maternity/parental leave Subsidized Back-up child care Zynga happy hours and frequent employee events Casual dress every single day Culture of diversity and inclusion including employee resource groups Work with cool people and impact millions of daily players 
ScrapedJobID402:
You’ll be applying ML algorithms to solve real world problems. You’ll be working with on high impact datasets mission critical to the rest of the world from healthcare, operations, and infrastructure You’ll be working with frontend and backend engineers building an intelligence layer on top of email, calendars and contacts You’ll be able to use your models and solutions in real-time and see it in action on the front-end You’ll be independent enough to build and evaluate robust models You’ll be using the latest and greatest tools to build things the way you want with little to no legacy code to stand in your way You’ll be building out machine learning infrastructure for billions of datasets with trillions of connections Strong foundations in Statistics, Data Modeling, and Machine Learning Strong foundations in Computer Science or Software Engineering At least 3+ years of experience on developing and deploying to production systems You’ve trained models and shipped them to production Experience with python, scala, golang or java Experience working with natural language processing packages Experience working with industry standard machine learning packages and tools Track record and references from great people Ability and confidence to pick up any technical concept to get the job done Comfortable in the dark and exploring ideas never done before Strong belief that product and design decisions are inextricably linked Busy creating magic from your code A power user of the tools of your trade or building your own tools Never stop learning Communicate design decisions openly and confidently, regardless of the audience—engineers, PMs, executives, other designers, etc. Not afraid to change your opinion in the face of new information or understanding of the product goals—you have strong beliefs, but you’re open-minded Unlimited Paid Time Off (PTO): we take this very seriously as we care about the well-being of our employees Healthcare: 90% premium coverage for medical, dental and vision for you and your family One Medical onsite and tele-health membership for you and dependents Additional: Health and DC FSA, Life insurance, with options for STD, LTD Retirement Plan: match up to 1% of annual salary for 401k or RRSP contributions Education Stipend: $1k annual education & development benefit Perk card: $150 per month towards health, wellness, and other perks via Assembly Cell Phone: $50 per month stipend towards cell phone reimbursement Fully Paid Parental Leave: 12 weeks parental leave (maternity & paternity) 
ScrapedJobID403:
Respond to ad hoc requests from various stakeholders Follow Vendasta’s analysis workflow
Hypothesis Generation: Work with stakeholders to refine and transform questions into hypotheses
Exploratory Data Analysis: Gather, clean, and explore large data sets
Model Building: Create a visual and/or mathematical representation of the real world
Interpret Results: Understand the conclusions that can be reached and know the implications
Communicate Results: Deliver findings to stakeholders
Follow-up: Ensure that the data was effectively implemented and measure results Hypothesis Generation: Work with stakeholders to refine and transform questions into hypotheses Exploratory Data Analysis: Gather, clean, and explore large data sets Model Building: Create a visual and/or mathematical representation of the real world Interpret Results: Understand the conclusions that can be reached and know the implications Communicate Results: Deliver findings to stakeholders Follow-up: Ensure that the data was effectively implemented and measure results Build, maintain & monitor internal dashboards for each department to track productivity, revenue, quality, staffing patterns, expenses, efficiency metrics and more Provide prompt reports on monthly, quarterly, and yearly information Provide analytical support and identify business trends that require action Review and critique other’s analysis Develop and foster a working relationship with other analysts, software developers, product managers, sales, marketing, and executive Become the expert in multiple data sources and create/implement innovative and sustainable solutions Participate in process improvement initiatives and assist in automating processes currently requiring manual efforts 3-5 years experience in data analysis or science Demonstrated expertise with databases and various querying techniques (SQL, NoSQL, API) Strong understanding of statistical inference and descriptive statistics Demonstrated ability to retrieve and clean data by whatever means is necessary Proven ability to analyze and report information Well developed communication and presentation skills Ability to engage in multiple initiatives simultaneously while working in a dynamic environment subject to impromptu changes in schedules and priorities Strong initiative—establish goals and take responsibility for meeting them within defined timelines 
ScrapedJobID404:
Oversee implementation of large scale technical projects on the analytics team Ensure the integrity of the Data Science code base and its integration with the rest of engineering stack Provide technical mentorship and coaching to the analytics team members Ensure the relevance of current technology by tracking evolution of the data science methods Provide guidance to others on the technical execution of your solutions Advanced degree (MSc) in computer science, data science, software engineering and 5 years of industry experience Proficiency with Python and version control (Git) Ability to leverage disparate data sources (i.e SQL, CSV, APIs ) Proficiency with Unix-like operating systems (Linux, MacOS X) and command line interface Proficiency with classical and deep learning methods and Big Data Frameworks Ability to keep high level of alignment with the internal and external stakeholders Ability to effectively plan the work and manage time Competitive compensation Comprehensive health benefits Stock options (at Validere, we're all owners) RRSP/401(k) matching programs Flexible working arrangements Professional development budget to master your craft Generous time-off with parental/family leave Quarterly Employee Wellbeing Days and No Meeting Friday Afternoons An inclusive, ego-free environment where diversity of people and thought is valued Opportunity to impact the trajectory of a fast growing tech company Deliver (the highest) value Remove friction Everyday is more scalable Be well, fair & transparent 
ScrapedJobID405:
Maintain an acute awareness of the industry and what the competitors are putting out. Investigate new options for the system from code to core. Coordinate with Senior Technical Leads regarding AI tech. Coordinate with team members to discover the best solution for the clients. Conceptualize new features that we could offer exclusively. Manage R&D Data Science Developers. 2+ years of Experience in Software Development Education: M.tech or Ph.D. in Computer Science/Engineering preferably with a focus on AI. Strong hold on Data structures and Algorithms. Experience with Anaconda/Python/Tensorflow. French Language skills. Hours: 30-40 hours/week. Wage: $85,000 - $100,000/year. 3 Weeks of Vacation. A great environment and the right tools to do great work. 
ScrapedJobID406:
Buying intelligence Recommendation systems & customer insights Performance marketing Pricing strategies Network planning & intelligence Data support (10%)
Translate complex analytical results into actionable business initiatives
Develop a deep understanding of the business, its data, and its patterns
Extract data from multiple sources to uncover opportunities or detect issues
Contributes actively to the design of novel solutions to generate value from data Translate complex analytical results into actionable business initiatives Develop a deep understanding of the business, its data, and its patterns Extract data from multiple sources to uncover opportunities or detect issues Contributes actively to the design of novel solutions to generate value from data Project delivery (50%)
Develop a deep understanding of a specific business area & challenges the roadmap
Solve unstructured problems while exhibiting independence and work ownership
Work in collaboration with different teams to refine initial concepts and prototypes that can be presented to stakeholders for feedback
Research, develop and deploy data models and systems to various stakeholders under multiple projects to clearly communicate, elucidating patterns and generating actionable insights and tools
Partner with strategic business stakeholders to provide evidence-based guidance
Maintain & support data science solutions & projects
Delivers & support decision making and decision support systems
Review & contribute to technical documentation Develop a deep understanding of a specific business area & challenges the roadmap Solve unstructured problems while exhibiting independence and work ownership Work in collaboration with different teams to refine initial concepts and prototypes that can be presented to stakeholders for feedback Research, develop and deploy data models and systems to various stakeholders under multiple projects to clearly communicate, elucidating patterns and generating actionable insights and tools Partner with strategic business stakeholders to provide evidence-based guidance Maintain & support data science solutions & projects Delivers & support decision making and decision support systems Review & contribute to technical documentation Ownership and accountability (20%)
Be accountable for code quality
Measure accuracy & performance of developed models & solutions
Monitor deployed decision making and decision support systems Be accountable for code quality Measure accuracy & performance of developed models & solutions Monitor deployed decision making and decision support systems Knowledge sharing and coaching (10%)
Contribute to data mining architecture, modeling standards and data analysis methodologies
Coach more junior data scientists on best practices and machine learning solution design Contribute to data mining architecture, modeling standards and data analysis methodologies Coach more junior data scientists on best practices and machine learning solution design Architecture (10%)
Identify dependencies & impacts between systems
Develop and continuously improve processes, tools, and techniques Identify dependencies & impacts between systems Develop and continuously improve processes, tools, and techniques Master's degree in Engineering, Computer Science, Mathematics, Statistics, or a related field [PhD, an asset] A minimum of 3 years experience in analytics and data science with a focus on driving business impact Strong understanding of advanced modeling techniques, such as machine learning, nonparametric approaches and neural networks Understanding (experience as asset) of data products, from design up to their deployment Experience in building end-to-end data science solutions Excellent programming skills using SQL, Python Experience working with GitHub Experience with data manipulation technologies and knowledge of programming languages Extensive experience solving analytical problems using quantitative approaches Experience working with AWS cloud solutions, an asset e-commerce experience, an asset Understanding of web analytics, an asset Highly analytical and detail oriented Capacity to synthesize, simplify and present complex information to technical and business stakeholders at various levels of the organization Ability to design and present complex data sets in a variety of visually compelling formats Ability to thrive in a fast-paced, performance-driven environment Ability to grasp interrelation, dependencies and assess quickly impact in complex systems Solution-oriented mindset and can-do attitude to overcome challenges Team player with solid interpersonal skills Stay abreast of emerging tools and technologies 
ScrapedJobID407:
Use our modern tech stack, AWS (Redshift & Kinesis), Databricks and PySpark, Airflow, and Tableau to develop innovative tools Work closely with marketing teams to craft, test, verify and implement end-to-end data pipelines that ingest data from multiple sources and output meaningful insights to optimize Zynga audience growth Apply statistical methodologies to evaluate performance and account for uncertainties in major initiatives Design and develop using standard practices within a GitHub environment BS in Computer Science, Math, Statistics, Economics, or other quantitative field; Masters or PhD strongly preferred 3+ years of work experience in data science or analytics roles Demonstrated experience with some or all of the following: data mining, predictive modeling, statistics, experimental design, application development, computational analytics, econometric modeling, data visualization Proficient in Python, SQL, and other programming languages; Experience with visualization software such as Tableau and/or app design using libraries such as Plotly Dash Strong written and oral communication skills Competitive salary, bonus plan, Zynga RSU’s (Restricted Stock Units), ESPP (Employee Stock Purchase Plan) RRSP Company Match Contribution Extended Health coverage, dental, disability, critical illness, EAP, and life insurance Virtual mental health and neurodiversity support programs Goodlife fitness annual membership Open vacation policy Family planning support program Generous paid maternity/parental leave Subsidized Back-up child care Zynga happy hours and frequent employee events Casual dress every single day Culture of diversity and inclusion including employee resource groups Work with cool people and impact millions of daily players 
ScrapedJobID408:
You’ll be applying ML algorithms to solve real world problems. You’ll be working with on high impact datasets mission critical to the rest of the world from healthcare, operations, and infrastructure You’ll be working with frontend and backend engineers building an intelligence layer on top of email, calendars and contacts You’ll be able to use your models and solutions in real-time and see it in action on the front-end You’ll be independent enough to build and evaluate robust models You’ll be using the latest and greatest tools to build things the way you want with little to no legacy code to stand in your way You’ll be building out machine learning infrastructure for billions of datasets with trillions of connections Strong foundations in Statistics, Data Modeling, and Machine Learning Strong foundations in Computer Science or Software Engineering At least 3+ years of experience on developing and deploying to production systems You’ve trained models and shipped them to production Experience with python, scala, golang or java Experience working with natural language processing packages Experience working with industry standard machine learning packages and tools Track record and references from great people Ability and confidence to pick up any technical concept to get the job done Comfortable in the dark and exploring ideas never done before Strong belief that product and design decisions are inextricably linked Busy creating magic from your code A power user of the tools of your trade or building your own tools Never stop learning Communicate design decisions openly and confidently, regardless of the audience—engineers, PMs, executives, other designers, etc. Not afraid to change your opinion in the face of new information or understanding of the product goals—you have strong beliefs, but you’re open-minded Unlimited Paid Time Off (PTO): we take this very seriously as we care about the well-being of our employees Healthcare: 90% premium coverage for medical, dental and vision for you and your family One Medical onsite and tele-health membership for you and dependents Additional: Health and DC FSA, Life insurance, with options for STD, LTD Retirement Plan: match up to 1% of annual salary for 401k or RRSP contributions Education Stipend: $1k annual education & development benefit Perk card: $150 per month towards health, wellness, and other perks via Assembly Cell Phone: $50 per month stipend towards cell phone reimbursement Fully Paid Parental Leave: 12 weeks parental leave (maternity & paternity) 
ScrapedJobID409:
Respond to ad hoc requests from various stakeholders Follow Vendasta’s analysis workflow
Hypothesis Generation: Work with stakeholders to refine and transform questions into hypotheses
Exploratory Data Analysis: Gather, clean, and explore large data sets
Model Building: Create a visual and/or mathematical representation of the real world
Interpret Results: Understand the conclusions that can be reached and know the implications
Communicate Results: Deliver findings to stakeholders
Follow-up: Ensure that the data was effectively implemented and measure results Hypothesis Generation: Work with stakeholders to refine and transform questions into hypotheses Exploratory Data Analysis: Gather, clean, and explore large data sets Model Building: Create a visual and/or mathematical representation of the real world Interpret Results: Understand the conclusions that can be reached and know the implications Communicate Results: Deliver findings to stakeholders Follow-up: Ensure that the data was effectively implemented and measure results Build, maintain & monitor internal dashboards for each department to track productivity, revenue, quality, staffing patterns, expenses, efficiency metrics and more Provide prompt reports on monthly, quarterly, and yearly information Provide analytical support and identify business trends that require action Review and critique other’s analysis Develop and foster a working relationship with other analysts, software developers, product managers, sales, marketing, and executive Become the expert in multiple data sources and create/implement innovative and sustainable solutions Participate in process improvement initiatives and assist in automating processes currently requiring manual efforts 3-5 years experience in data analysis or science Demonstrated expertise with databases and various querying techniques (SQL, NoSQL, API) Strong understanding of statistical inference and descriptive statistics Demonstrated ability to retrieve and clean data by whatever means is necessary Proven ability to analyze and report information Well developed communication and presentation skills Ability to engage in multiple initiatives simultaneously while working in a dynamic environment subject to impromptu changes in schedules and priorities Strong initiative—establish goals and take responsibility for meeting them within defined timelines 
ScrapedJobID410:
Oversee implementation of large scale technical projects on the analytics team Ensure the integrity of the Data Science code base and its integration with the rest of engineering stack Provide technical mentorship and coaching to the analytics team members Ensure the relevance of current technology by tracking evolution of the data science methods Provide guidance to others on the technical execution of your solutions Advanced degree (MSc) in computer science, data science, software engineering and 5 years of industry experience Proficiency with Python and version control (Git) Ability to leverage disparate data sources (i.e SQL, CSV, APIs ) Proficiency with Unix-like operating systems (Linux, MacOS X) and command line interface Proficiency with classical and deep learning methods and Big Data Frameworks Ability to keep high level of alignment with the internal and external stakeholders Ability to effectively plan the work and manage time Competitive compensation Comprehensive health benefits Stock options (at Validere, we're all owners) RRSP/401(k) matching programs Flexible working arrangements Professional development budget to master your craft Generous time-off with parental/family leave Quarterly Employee Wellbeing Days and No Meeting Friday Afternoons An inclusive, ego-free environment where diversity of people and thought is valued Opportunity to impact the trajectory of a fast growing tech company Deliver (the highest) value Remove friction Everyday is more scalable Be well, fair & transparent 
ScrapedJobID411:
Maintain an acute awareness of the industry and what the competitors are putting out. Investigate new options for the system from code to core. Coordinate with Senior Technical Leads regarding AI tech. Coordinate with team members to discover the best solution for the clients. Conceptualize new features that we could offer exclusively. Manage R&D Data Science Developers. 2+ years of Experience in Software Development Education: M.tech or Ph.D. in Computer Science/Engineering preferably with a focus on AI. Strong hold on Data structures and Algorithms. Experience with Anaconda/Python/Tensorflow. French Language skills. Hours: 30-40 hours/week. Wage: $85,000 - $100,000/year. 3 Weeks of Vacation. A great environment and the right tools to do great work. 
ScrapedJobID412:
Bachelor's degree and enrollment within the PEY program at University of Toronto Strong Python and C++ programming skills Strong fundamental knowledge of OOP, Data Structures & Algorithms, Computer Architecture and/or Machine Learning Familiarity with TensorFlow, PyTorch or Caffe Familiarity with GPU, CPU, or parallel architectures Experience in vertical such as computer vision, language modeling or speech recognition Toronto 
ScrapedJobID413:
Develop state-of-the-art machine learning based audio signal processing and analysis technologies and modules Collaborate with other colleagues to integrate audio signal processing and analysis modules into the prototype systems for Bosch Audio Event Detection applications and improve the performance with various technologies Summarize research findings in high-quality paper and/or patent submissions Ph.D. in Computer Science, Electrical Engineering or related fields Experience in audio signal processing, machine learning and related fields Hands-on experience of audio event detection or audio scene classification technologies Hands-on experience of deep learning technologies and familiar with state-of-the-art deep learning toolkits Programming experience with C/C++ and/or Python Programming experience with Matlab Publication record in top machine learning and audio analytics venues (e.g. ICASSP, Interspeech, AAAI, ICML). Experience on noise cancellation or source separation Experience on audio signal localization Good communication and team-working skills Good leadership skills to drive research topics FIRST Robotics (For Inspiration and Recognition of Science and Technology) AWIM (A World In Motion) 
ScrapedJobID414:
Identify key business levers underlying Unstoppable Domains' growth, establish cause & effect, perform analyses, and communicate key findings to facilitate data-driven decision-making Mine and analyze company data and external data to optimize our approach to user acquisition, engagement and retention Identify key metrics and build exec-facing dashboards to track the progress of the business and its highest priority initiatives Set up measurement frameworks, KPIs, A/B testing and Universal Control Group setups to make sure that experiments executed by the Product and Marketing team meet the learning objectives Advanced proficiency in SQL, including the ability to optimize queries for large datasets Proficiency with one or more major BI tools (Tableau, Mode, Google Analytics, etc.) Experience in causal analytics and experimental design, implementation and analysis(e.g. A/B, split and holdout testing) Knowledge of applying statistical techniques in a business and/or marketing context using Python, R Experience working in short development cycles to rapidly build prototypes and iterate quickly 3+ years of work experience in Data Science, Marketing Analytics, Product Analytics, and/or Business Intelligence Bachelor's Degree in Computer Science, Engineering, Data Science, Business Analytics, Mathematics, Statistics or related field or equivalent practical experience Prior background in E-Commerce or Blockchain industry Startup experience 100% employer-paid medical, dental and vision insurance 401(k) with 4% company match Equity 100% remote-work environment Monthly co-working space stipend Home office budget 15 days of PTO, in addition to time off for national holidays Disability insurance Life Insurance Employee Assistance Program Travel Assistance Program 
ScrapedJobID415:

ScrapedJobID416:
Analyzing complex, high-volume data from varying sources and identifying key regularities, patterns and trends. Prototyping and developing machine learning models in collaboration with an agile, high-functioning team. Spotting new opportunities in data collection, feature creation, feature selection, model tuning and evaluation practices, and taking those ideas from the first concepts to live product integrations. Implementing effective monitoring and benchmarking for model performance comparison. Leveraging new research in data modelling to identify opportunities, pioneering algorithms and systems that become key commercial products. Maintaining model development pipelines, libraries and machine learning infrastructure. Statistically adept. You have studied in a quantitative field (i.e. mathematics, statistics, economics, data science) at a doctoral or master’s level. You have the depth of knowledge required to identify appropriate techniques, follow and create formal proofs, define apt performance measures and adeptly explore or transform data. Someone with a strong foundational knowledge of principles underlying common statistical learning techniques such as linear regression, support vector machine, tree-based methods, bagging and boosting methods. A strong problem solver with critical thinking skills who can formulate a problem into solution. Able to challenge assumptions and validate modeling solutions from a statistical inference perspective. Capable of writing complex SQL queries to process data. Proficient with manipulating and analyzing data to gain meaningful insights using tools such as Pandas for Python. Experienced in creating algorithms and applying machine learning models to solve real business problems. You have the vision to see what the next generation model looks like and can iterate over production models to generate a competitive edge in the market. A capable coder, able to write well-abstracted, production-quality code in Python (preferred), R, Java and/or C++. You’re experienced in using cloud services (e.g. AWS, Microsoft Azure and/or Google Cloud), and machine learning tools (e.g. scikit-learn, Tensorflow and/or Keras). Experienced working with large data sets. You understand the benefits of batch processing and parallelization and know how to design a pipeline to scale-out machine learning workflows. You have experience working with distributed data processing frameworks such as Apache Spark. An effective communicator in visual, verbal and spoken channels, able to identify a narrative in complex data and convey clear, actionable findings to different types of audiences. Experienced in architecting end-to-end solutions for production deployment (considered an asset but not required). Collaborative. We do our best work as a team, which means sharing, being open to giving and receiving support and constructive input. Evidence-based. We work to eliminate assumptions and test our hypotheses, and we value rigour. Responsible. We offer the opportunity to drive major projects that protect consumers every day, internationally. We are looking for colleagues who care about that. Motivated. We’re a team of data scientists with personal and collaborative side projects, and we’re looking for someone who shares our enthusiasm. Innovative. Data Science is a continuously growing field. We like our team to keep pushing for new ideas and methods. We are looking for someone who is creative and not just always satisfied with the status quo. 
ScrapedJobID417:
Build and implement advanced machine learning models for flight Arrival and Departure Prediction Research, develop and evaluate advanced text speech processing algorithms and implementations. Research, develop and evaluate advanced ATI Messaging processing algorithms and implementations. Utilize Machine Learning (ML) technology for speech processing and air transport messages processing Prototype and develop algorithms and advanced machine learning techniques for applications such as speech modeling, QAR data modelling rendering, speech recognition, blind source separation, and speaker ID. Stay up to date with tech, prototype with and learn new technologies, proactive in technology communities Learn from peers in data science and engineering community Deliver on time with a high bar on quality of research, innovation and engineering Create Advanced OCR and Cognitive Data Extraction capability as well as its execution Responsible for Cognitive extraction, technology delivery and operating model setup Develop innovative solutions in areas such as machine learning, computational linguistics, Natural Language Processing (NLP), advanced and semantic information search, extraction, induction, classification and exploration Develop & maintain Client & NLP Pipeline for Document Data Extraction semantics and sentiment processing and understanding Create products that provide a great user experience along with high performance, security, quality, and stability Master’s or PhD degree in STEM or AI/ML areas 5+ years of professional experience as a data scientist or related roles 3+ years of work experience in voice related projects and 3+ years of work experience in software development Experience in setting up supervised & unsupervised learning Client/NLP models including data cleaning, data analytics, feature creation, model selection & ensemble methods, performance metrics & visualization Knowledge in signal processing techniques including adaptive filtering, filter banks and wavelet processing, speech analysis and synthesis, speech and audio coding. Experience in text classification topic mining speech enhancement and speech/audio coding and compression. String experience in prediction using Machine Learning and Deep Learning Hand on experience in feature extraction techniques (GMM, HMM, NMF / spectrograms, MFCC etc) for voice recognition and audio event classification. 4+ years of work experience with at least one of the following languages: Python, Java, and R, Ph. D. preferred 3+ years of experience working in Agile team environment Hand on experience with machine learning techniques such as deep neural nets (DNN, CNN, LSTM-RNN) Published research on signal processing NLP , NLU or machine learning related to voice technology or messaging Experience working in a cloud environment (AWS, Azure, GCP) or a containerized environment (Mesos, Kubernetes) Good understanding of the complexity of developing and productizing real-world AI/ML applications such as prediction, recommendation, computer vision, bots, NLP, sentiment, knowledge and content intelligence, etc. Knowledge of Text Analytics with a strong understanding of Client & NLP algorithms and models (GLMs, SVM, PCA, NB, Clustering, DTs) and their underlying computational and probabilistic statistics Deep knowledge of some of the popular ML frameworks such as TensorFlow, Pytorch Keras, SparkML, scikit-learn, XGBoost, H2O etc Designing and documenting data architecture at multiple levels (high-level to detailed) and across multiple views (conceptual, logical, physical, data flow and sequence diagrams) Providing active hands-on architectural guidance and leadership through the entire lifecycle of development projects Ability to translate business requirements into conceptual and detailed system architecture and technology solutions Ability to develop and lead proof-of-concepts, deliver practical, working solutions Experience in building modern Machine Learning platforms a big plus Being a committer or a contributor to an open source project is a plus Design, implement and deploy scalable, distributed solutions to support real-time NLP data analytic platform using modern engineering principles and techniques At least 4 years' experience building Machine Learning & NLP solutions over open source platforms such as SciKit-Learn,Tensorflow, SparkML, Torch, Caffe, H2O Excellent knowledge and demonstrable experience in using open source NLP packages such as NLTK, Word2Vec, SpaCy, Gensim, Standford CoreNLP. At least 2 years' experience in designing and developing enterprise-scale NLP solutions in one or more of: Named Entity Recognition, Document Classification, Document Summarization, Topic Modelling, Dialog Systems, Sentiment Analysis, OCR text processing 
ScrapedJobID418:
other Analysts within the department the use of data and analytics for various data improvement projects and initiatives the department’s data stewards group, providing guidance and technical leadership in data management the Bank wide data communities to share organizational activities and priorities relating to data and analytics. Understanding of Currency’s business and Currency’s data. Working knowledge of:
Lean six sigma projects
Agile methodology
Organizational change management principles
ISO 9001 & ISO 27001. Lean six sigma projects Agile methodology Organizational change management principles ISO 9001 & ISO 27001. Bachelor’s degree in computer science, engineering, statistics, business administration or other related fields. At least 3 years of experience in:
working with and optimizing large complex data sets with a variety of tools (Tableau, PowerBI, etc), data science languages (Python, R, etc) and relational databases (SQL, Oracle, etc).
identifying patterns and insights from data, performing trend analysis, and creating easily digestible analytics products such as dashboards, presentations, etc. working with and optimizing large complex data sets with a variety of tools (Tableau, PowerBI, etc), data science languages (Python, R, etc) and relational databases (SQL, Oracle, etc). identifying patterns and insights from data, performing trend analysis, and creating easily digestible analytics products such as dashboards, presentations, etc. Experience
working with data models, data dictionnaries and data pipelines to organize, collect, cleanse and standardize data to ensure it is easily consumed by others.
participating in or leading the establishment of data management principles and guidelines. working with data models, data dictionnaries and data pipelines to organize, collect, cleanse and standardize data to ensure it is easily consumed by others. participating in or leading the establishment of data management principles and guidelines. Language requirement: English and French essential (bilingual) with a minimum starting level of functional (level 4) in second official language. Training may be provided to help reach the required level of fully functional (level 5) in second official language. Priority will be given to Canadian citizens and permanent residents Security level required: Reliability Relocation assistance may be provided, if required Please save a copy of the job poster. Once the closing date has passed, it will no longer be available. In response to the COVID-19 pandemic and further to public health guidelines, preventative measures are being taken to ensure health and safety during the recruitment process. All interviews are conducted virtually. Salaries are based on qualifications and experience and typically range from $85,100 to $106,300 (job grade 17) Depending on performance, you may be eligible for performance pay for successfully meeting (7 to 10% of your base salary) or for exceeding expectations (15% of your base salary). Exceptional performers who far exceed expectations may be eligible for higher performance pay. Flexible and comprehensive benefits so you can choose the level of health, dental disability and life and/or accident insurance coverage that meets your needs Extra vacation days (up to five each year) that you can purchase to add to your vacation entitlement Indexed, defined-benefit pension #LI-POST 
ScrapedJobID419:
8 hour shift DevOps Engineer: 1 year (required) Machine Learning: 1 year (required) AWS/ GCP/ Azure: 1 year (required) 
ScrapedJobID420:
Travail significatif qui favorise le perfectionnement professionnel. Possibilité d’entrer dans l’industrie technologique et de s’y épanouir. Environnement de travail axé sur la collaboration. Équipe de haut niveau. Régime d’assurance collective souple Régime de retraite à prestations déterminées Régime d’achat d’actions du personnel Régime enregistré d’épargne-retraite collectif Programme pour le bien‑être physique Programme d’aide aux employés Prestations de maternité complémentaires Horaire de travail variable « Vendredis Californie » tout au long de l’année Extraire et analyser les données se trouvant dans les bases de données de l’entreprise afin d’optimiser et d’améliorer le développement des produits, les techniques de marketing et les stratégies commerciales. Évaluer l’efficacité et l’exactitude des nouvelles sources de données et techniques de collecte de données. Élaborer des algorithmes et des modèles de données personnalisées à appliquer aux ensembles de données. Utiliser une modélisation prédictive pour accroître et optimiser l’expérience des clients, les revenus générés, le ciblage publicitaire et d’autres résultats opérationnels. Élaborer un cadre de tests A/B pour l’entreprise et mettre à l’essai la qualité du modèle. Coordonner différentes équipes fonctionnelles pour mettre en œuvre des modèles et surveiller les résultats. Élaborer des processus et des outils pour le contrôle et l’analyse du rendement des modèles et de l’exactitude des données. Titulaire d’une maîtrise ou d’un doctorat en statistique, informatique, analyse des systèmes de gestion ou autre domaine connexe. Au moins 5 ans d’expérience en science des données ou en statistiques appliquées. Solides aptitudes pour la résolution de problèmes, et surtout le développement de produits. Expérience dans l’utilisation de langages informatiques statistiques (R, Python, SLQ, etc.) pour manipuler les données et extraire des renseignements de grands ensembles de données. Expérience dans la manipulation d’ensembles de données et l’élaboration de modèles statistiques. Connaissance de diverses techniques d’apprentissage automatique (algorithme Random Forests, remontée de gradient, réseaux de neurones artificiels, etc.) et de leurs avantages et inconvénients dans le monde réel. Connaissance de techniques et de concepts statistiques sophistiqués (MLG/régression, séries chronologiques, propriétés des distributions, tests statistiques et utilisation conforme, etc.), expérience dans leur application. Expérience dans l’utilisation et la création d’architectures de données. Expérience dans l’utilisation de services Web : Redshift, S3, Azure, Spark, DigitalOcean, etc. Expérience dans l’analyse de données provenant de fournisseurs tiers : Microsoft Application insights, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc. Expérience dans la visualisation et la présentation de données pour des intervenants, à l’aide de : Periscope, Microsoft Power BI, Business Objects, D3, ggplot, etc. Penchant naturel pour l’apprentissage et la maîtrise des nouvelles technologies et techniques. Expérience de direction d’initiatives axées sur le client. Expérience de travail dans un environnement Agile, un atout. Excellentes aptitudes pour la communication verbale et écrite en vue de la coordination des équipes. Meaningful work that drives professional development Ability to enter and grow within the technology industry Working in a collaborative environment Being part of a high performance team Flexible Group Insurance Plan Defined Benefits Retirement Plan Employee Stock Purchase Plan Group Registered Retirement Savings Plan (RRSP) Physical Wellness Plan Employee Assistance Plan Supplementary Maternity Plan Flextime California Fridays all year As a member of the Data Science team, you will analyze and synthesize information to understand issues, identify options, and support sound decision-making. You will be generating viable, new approaches and solutions. You have an understanding of applying functional and technical knowledge and skills to accomplish work objectives in an agile environment. As the ideal candidate, you are adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies. Assess the effectiveness and accuracy of new data sources and data gathering techniques. Develop custom data models and algorithms to apply to data sets. Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes. Develop company A/B testing framework and test model quality. Coordinate with different functional teams to implement models and monitor outcomes. Develop processes and tools to monitor and analyze model performance and data accuracy. Have a Master or PhD in Statistics, Computer Science, Business Analytics or a related field Possess at least 5 years experience in Data Science or applied statistics. Strong problem solving skills with an emphasis on product development. Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets. Experience manipulating data sets and building statistical models. Knowledge of a variety of machine learning techniques (Random Forests, Gradient boosting, artificial neural networks, etc.) and their real-world advantages/drawbacks. Knowledge of advanced statistical techniques and concepts (GLM/Regression, Time Series, properties of distributions, statistical tests and proper usage, etc.) and experience with applications. Experience working with and creating data architectures. Experience using web services: Redshift, S3, Azure, Spark, DigitalOcean, etc. Experience analyzing data from 3rd party providers: Microsoft Application insights, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc. Experience visualizing/presenting data for stakeholders using: Periscope, Microsoft Power BI, Business Objects, D3, ggplot, etc. A drive to learn and master new technologies and techniques. Experience leading customer driven initiatives. Experience working in an Agile environment an asset. Excellent written and verbal communication skills for coordinating across teams. Benefits: fully flexible for you to choose what is important Retirement: Defined Benefits Retirement Plan & Group Registered Retirement Savings Plan (RRSP) Financial Perks: Employee Stock Purchase Plan & numerous corporate discounts Personal and Family Programs: Physical Wellness Plan & Supplementary Maternity Plan Work-Life Balance: Flextime & California Fridays all year Fun at work: social and community events all-year round! 
ScrapedJobID421:
Expérience de 5 ans en Data Visualisation Expertise reconnue sur Power BI Expérience combinée avec l'un des rôles suivants : Développeur Python - Atout Data Analyst - Atout Business Analyst - Atout Expérience avec les langages SQL, Dax, Power Query Curiosité, excellent relationnel, créativité, force de proposition Avoir le goût du challenge et l'envie de réussir. Passionné par ce que vous faites Bonne maitrise du français et de l’anglais, à l’oral comme à l’écrit Certification Power BI - Atout Collecte et analyse des besoins Anime des ateliers du type « Design Thinking » Définit les indicateurs de performance (KPI) Rédige le cahier des charges au niveau fonctionnel et technique Développe des visualisations sur Power BI Automatise les rapports et tableaux de bord Interprète les données Présente ses analyses et visualisation devant la direction (Data Storytelling) Une rémunération annuelle fixe et une bonification annuelle selon l’atteinte de ta performance Des objectifs individuels accessibles et réalistes pour garantir un environnement sans pression Des assurances collectives Manuvie (dentaire, vision, soins paramédicaux…) 4 semaines de vacances Remboursement des abonnements de sport et du transport Horaires flexibles et télétravail Plan de développement pour chaque employé et coaching avec un mentor Environnement non hiérarchique favorisant l’intrapreneuriat Activités mensuelles de team building Du Lundi au Vendredi Repos la Fin de Semaine Visualisation de données: 5 ans (Souhaité) Power BI: 3 ans (Souhaité) Anglais (Souhaité) Français (Souhaité) Temporairement en raison de la COVID-19 
ScrapedJobID422:
Manage/execute accounts payable, accounts receivable, payroll processing and general ledger and cash transactions both in QuickBooks and with payroll providers Maintain the payroll management system, ensuring that employees are paid in a timely and accurate manner, processing and submitting statutory and benefits remittances on a timely basis. Run a timely and accurate monthly close process with appropriate internal controls Produce consolidated financial statements and a complete financial package every month, quarter and year-end Prepare monthly, quarterly, annual and ad-hoc financial reports including forecasts and cash flow projections. Lead the preparation of the annual budget along with the Director of Corporate Services Monitor progress on financial objectives and key performance indicators, review the timing of schedule expenditure, analyze variables, and suggest corrective actions when required. Interaction with the business domains (departments) will be critical. Maintain up-to-date knowledge of current accounting practices and relevant legislation. 12+ experience in accounting in a mid-sized organization. Experience in a professional services organization is nice to have. Of the 12+ years, at least 5+ years running a finance department complete with a month-end close, year-end close and audit and associated reporting Chartered Accountant or CPA is desirable Proficient in the use of QuickBooks, ideally Intacct Sage (or equivalent), Excel, ADP (or equivalent), Concur, tableau, Power BI or equivalent Skilled in the use of data analysis and reporting tools including advanced report design. Proficient in the technology required to work in a virtual environment. Demonstrated attention to detail, ability to prioritize work and to meet deadlines. Demonstrated initiative, tact and judgement in interactions with employees, vendors and stakeholders. Ability to think strategically and operationalize plans; good analytical skills as well as solid business acumen. Proactivity with proven ability to work independently. Ability to work collaboratively and in a cross-functional environment with colleagues in Canada and the United States. Ability to work efficiently and effectively to meet tight and shifting deadlines. The chance to be an early joiner in a young company that's rapidly growing into a unique position where we can enable real progressive change in the world. A work environment where you can be your whole and honest self. We don't believe in hiring for culture "fit." We're more interested in how you will add to our existing culture and help shape our future. We encourage and incentivize all employees to seek professional development opportunities that support their learning and growth. A generous annual allowance is provided to all employees in order to create and maintain a safe and comfortable workspace. We believe all systems require rest, including our organization. Therefore, we go offline for two weeks in December/January of each year, during which employees continue to receive their salary. Each employee also earns three weeks of paid time off per year and paid personal days to use as they see fit. We offer all employees extended health benefits, including an EAP and a Wellness Spending Account. 
ScrapedJobID423:
Collect data in the lab using laboratory instruments such as microscopes Perform exploratory data analysis, statistical analysis, data mining, data visualization Prepare data sets and assist data scientists in the development of machine learning based image processing algorithms Assist in technical report writing Strong knowledge in data science Experience with Python programming language and Python packages for data science Currently enrolled in a Campus Alberta college, polytechnic or university in one of the following or equivalent programs: Data Science Computer Science Computer Engineering Computer Engineering Technology All employees, regardless of their work location will be required to be fully vaccinated against COVID-19 or have an approved accommodation. Everyone coming to NAIT campuses, including students, staff, contractors and visitors, will be required to be fully vaccinated against COVID-19. Everyone coming to NAIT campuses will be required to provide proof of vaccination. Rapid testing will not be accepted as an alternative to vaccination, except for campus community members who cannot be vaccinated based on medical or other protected grounds outlined in the Alberta Human Rights Act. 
ScrapedJobID424:
Independently maintain and organize data and tools for data transfer, mining, cleaning/processing, and validation Provide structured, quality data for downstream enrichment and modeling, and recommend ways to improve data quality and efficiency Develop, test, and improve data processes and architectures Work with multiple disparate sources of data, storage systems, and building processes and pipelines to provide cohesive datasets for analysis and modeling Collaborate with cross-functional teams and have opportunities to grow and develop as a data scientist Data engineering experience Experience with SQL language and one or multiple of the following database technologies: PostgreSQL, Hadoop, Netezza. Good knowledge of Linux / Bash environment Experience in Python Good communication skills Highly skilled problem solver Exhibits a high degree of initiative At least an undergraduate in Data Engineering, CS, or STEM related field. Masters preferred Experience in multiple scripting languages and storage systems Programming Languages: Java, Python Understanding of the importance of data organization and security Detail oriented, efficient, strong work-ethic Loves working with error-prone, messy, disparate, unstructured data Can lead design efforts for improving data storage and processing, and future efforts to transition to cloud environments 
ScrapedJobID425:
Research and develop models that predict customers’ risks (ability to pay, cashflow forecast) and interact with them during their lifecycles Apply scientific methods and mathematical approaches to solve problems across domains 5+ years of experience in quantitative finance, simulations and machine learning (academics qualifies) Strong theoretical knowledge and understanding of Bayesian statistics, stochastic processes and inner workings of ML models, such as time series forecasting, change point detection, classification and regression Advanced knowledge of Python with focus on ML (PyTorch, TF, scikit-learn) and SQL Good communication skills in terms of scope, requirements, dependencies and business impact Entrepreneurial and self-starter PhD degree in Computer Science, Statistics, Mathematics or related quantitative field Familiarity with Cloud modeling tools like Sagemaker, GC Datalab, or Azure ML. Past experiences with version control tools such as Git or CI/CD tools Familiar with financial concepts, commercial credit and bank transactional data Familiarity with large-scale data pipelines Be part of a dynamic, collaborative, progressive and high-performing team, building revolutionary products that matter Generous benefits, including a company match RRSP program. Continued professional development opportunities through programs such as Six Sigma. A modern workspace centrally located in Toronto’s thriving downtown core, easily accessed by transit and a few minutes’ walk from Union Station. Flexible time-off options 
ScrapedJobID426:
Create and maintain the platform services used by other teams to build products that collect, transform and deliver data Leverage cloud resources to support the acquisition and ingestion of event-driven/streaming data sources Maximize the availability, recoverability, and operational efficiency of the data platform and supporting systems Build up and improve the observability of the platform as well as provide visibility into system health Champion the use of modern software development processes and tooling (e.g., CI/CD, everything as code, feature flags) to ensure a reliable and scalable data platform Work with the appropriate Business Support partners to seamlessly lead the day-to-day function of the department in support of corporate objectives, while enabling progressive career development and an incredible employee experience A commitment to learn and apply Aritzia's Business and People Leadership principles An enthusiastic approach to taking on new opportunities and challenges A commitment to navigating our internal operations to achieve the best team and business results The ability to collaborate fluently with cross-functional partners The skills to set clear objectives with an emphasis on accountability while striving to reach your highest potential Proven skills, education, and/or applicable certifications in:
As a lead for strong engineers, technical leadership and a solid background in software development is a must, so that you're able to challenge and grow your team members
Excellent SQL and Python development skills
Strong experience designing and implementing Cloud solutions; including building modern applications using containerized microservices (e.g., Kubernetes, Docker) and serverless approaches
Experience with site reliability engineering practices, like service level objectives (SLOs), error budgets, blameless postmortems, toil reduction
Experience with Infrastructure-as-Code and observability tooling (e.g., Terraform, OpenTelemetry)
Experience with a cloud-based data warehouse (e.g., BigQuery, Snowflake) and modern data processing framework (e.g., Apache Beam) As a lead for strong engineers, technical leadership and a solid background in software development is a must, so that you're able to challenge and grow your team members Excellent SQL and Python development skills Strong experience designing and implementing Cloud solutions; including building modern applications using containerized microservices (e.g., Kubernetes, Docker) and serverless approaches Experience with site reliability engineering practices, like service level objectives (SLOs), error budgets, blameless postmortems, toil reduction Experience with Infrastructure-as-Code and observability tooling (e.g., Terraform, OpenTelemetry) Experience with a cloud-based data warehouse (e.g., BigQuery, Snowflake) and modern data processing framework (e.g., Apache Beam) A commitment to quality and investing in results that add value to the business A sense of urgency and ability to prioritize important work An understanding and a passion for the industry in which we operate A-OK Commissary & Café - Our in-office, world-class bistro and café The SET - Our in-house gym, with state-of-the art equipment and custom classes Dog Friendly Office - Bring your best friend to work Amenities - Facilities include private parent's room, bike storage rooms, and shower facilities with complimentary conveniences Product Discount - Our famous product discount, online and in store Extras - A multitude of other perks like dry-cleaning, hotel and restaurant discounts, self-care promos, on-site medical care and more. Health & Safety - Industry-leading health and safety precautions, including on-site screenings, mask and distancing protocols, and cleaning supplies 
ScrapedJobID427:

ScrapedJobID428:
Stimuler la croissance des revenus en développant, déployant et testant des algorithmes et des stratégies de tarification optimales à travers le portefeuille d'unités de Sonder. Résoudre des problèmes fondamentaux de stratégie de prix tels que Comment développer une stratégie de prix unique sur notre large éventail de marchés ? Comment identifier et fixer des prix optimaux pour les différents segments de clientèle ? Comment allouer les stocks de manière optimale et créer des réservations à travers les canaux (ventes, groupes, grossistes et canaux de vente directe aux consommateurs) ? Comment fixer les prix et répartir les stocks en fonction des différentes durées de séjour afin de maximiser l'utilisation du calendrier et la marge sur coûts variables ? Comment tester et mesurer l'efficacité de notre stratégie de prix ? Définir et mettre en œuvre un ensemble rigoureux de mesures de tarification et de méthodologies d'expérimentation. Collaborer avec les équipes d'ingénierie, d'analyse et de tarification pour mettre en œuvre et rendre opérationnelles diverses solutions de tarification. Collaborer avec d'autres fonctions telles que les ventes, la distribution et les marchés pour définir la stratégie de revenus, les objectifs et les garde-fous en matière de tarification. Une licence en économie/économétrie, finance quantitative, informatique, mathématiques, ingénierie ou dans un domaine quantitatif connexe. Expérience de travail avec des équipes de produits et d'ingénierie dans des entreprises à forte croissance pour résoudre des problèmes, identifier des tendances et des opportunités, produire des recommandations. Une expérience préalable en optimisation des prix dans un secteur connexe (hôtellerie, compagnies aériennes, billets) est un gros bonus. Minimum 3 ans d'expérience dans un rôle de Data Science Minimum 3 ans d'expérience avec SQL et Python Excellentes compétences en communication - capacité à expliquer votre travail et son impact sur l'entreprise à tous les types de partenaires commerciaux. Vous avez une grande énergie, une passion pour les données, le souci du détail et une attitude positive. Un salaire compétitif Plan d'options sur actions généreux Assurance médicale, dentaire et visuelle Vacances illimitées Crédits annuels gratuits et remises pour rester à Sonders Une entreprise avec une grande vision, un environnement de travail dynamique, et une équipe de collègues intelligents, ambitieux et avec lesquels il est agréable de travailler ! Drive revenue growth by developing, deploying and testing optimal pricing algorithms and strategies across Sonder's portfolio of units Solve fundamental pricing strategy problems such as How do we develop a unique pricing strategy across our wide range of markets How do we identify and price optimally across different customer segments How do we optimally allocate inventory and build up bookings across channels (sales, group, wholesale and direct to consumer channels) How do we price and allocate inventory across different lengths of stay to maximize calendar utilization and contribution margin How do we test and measure the effectiveness of our pricing strategy Define and implement a rigorous set of pricing metrics and experimentation methodologies Partner with Engineering, Analytics and Pricing Ops team to implement and operationalize various pricing solutions Partner with other functions such as Sales, Distribution and Markets to define revenue strategy, targets and pricing guardrails Bachelor Degree in Economics/Econometrics, Quantitative Finance, Computer Science, Math, Engineering, or related quantitative field. Experience working with Product and Engineering teams at high growth companies to solve problems, identify trends and opportunities, productionize recommendations Prior experience in pricing optimization in a related industry (hospitality, airlines, tickets) is a big bonus Minimum 3 years experience in a Data Science role Minimum 3 years of experience with SQL and Python Great communication skills – being able to explain your work and the impact on the business to all types of business partners High-energy self-starter with a passion for data, attention to detail, and a positive attitude Competitive compensation Generous stock option plan Medical, dental and vision insurance Exempt team members have paid time off. Non-exempt team members accrue paid time off. Annual free credits and discounts to stay in Sonders A company with a huge vision, a dynamic work environment, and a team of smart, ambitious and fun to work-with colleagues! 
ScrapedJobID429:
Lead all things data for a product team Analyze rich data sets Improve our product to help 100,000+ developers ship code faster Be an excellent analyst: Uncover business questions. Write research plans. Explore data in clean and raw forms. Soundly use statistics. Make clear visualizations. Uncover insights. Tell compelling stories. Present to technical and executive audiences. Drive action and outcomes. Support a product team: Collaborate with product managers, product leaders, designers, and engineers. Define, root cause, and forecast product metrics. Analyze products, customers, and business outcomes. Uncover what drives process success. Use a growth toolkit: Think in terms of product activation, engagement, retention, and growth. Support iterative cycles of build, measure, and learn. Design, interpret and support product experiments and A/B tests. Educate partners on statistical validity. Improve our analytics practice: Turn repetitive analyses into dashboards. Improve team processes. Build data pipelines and tables. Define requirements for better data. Improve data automation and analytics capabilities. Partner with data and analytics engineers. One to two years of product analytics: Successful candidates typically have from one to two years supporting product, growth, or marketing as a dedicated analyst. Typically, that experience is at a high-growth company with a well-defined product funnel. Often, candidates have an additional few years supporting other functions as a data analyst or in BI-, reporting-, or analytics-engineering roles. Technical education: A bachelor's degree in a technical or quantitative field (e.g., Analytics, Data Science, Statistics, Mathematics, Computer Science, Engineering, Economics, Finance, etc.). Bonus for a similar Master's degree or a data science bootcamp. Proficiency across analytics tools: Analytical SQL. Scripting in a notebook environment, using Python and Pandas. Intermediate statistics. Basic data science. Ability to quickly ramp up on GitHub, Snowflake, Looker, Amplitude, Segment, Optimizely, Airflow, DBT, and others. Right soft skills: Curious; confident; open to questioning assumptions and being questioned. Effective communicator across technical and business audiences. An incremental worker, able to balance vision and execution, and not easily discouraged. 
ScrapedJobID430:
Manage our infrastructure: Work with Marketing Technology, ML Platforms, & engineering to design, build, maintain and optimize our data management and machine learning architecture. Build our feature engineering pipeline: Work with machine learning scientists to build data processing pipelines supporting data analysis and machine learning tasks, and automate feature engineering pipelines in production. Handle ML integration: Develop software to deliver and integrate machine learning product capabilities into our platform. Get our models into production: Work with data scientists, Marketing Technology, and ML Platforms to deploy machine learning models in production. Maintain a high-quality product: Develop processes and frameworks to ensure data and model quality. Perform code reviews and testing to ensure software quality is high and requirements are met. Develop reusable building blocks for quantitative models, leveraging high parallel, distributed machine learning and advanced data analysis techniques (e.g. 'Feature Engineering' , ‘Model Training DAG’, ‘Model Scoring DAG’, ‘Hyperparameter Optimizer DAG’, 'Monitoring Model Performance DAG', etc…). Leverage our work in order to increase adoption across our business partners, to drive real business value. Build and maintain strong partnership with business and engineering teams. 4+ years of software engineering experience or advanced degree in quantitative field w/ material exposure to coding (e.g. mathematics, economics, computer science, physics, neuroscience, operations research etc.). Experience developing data science / machine learning-driven products Interest in and have done work in statistical modeling and machine learning A good understanding of data warehousing, data modeling and data architecting The knowledge to work with machine learning scientists and facilitate translation of proof-of-concept models into production-strength systems Strong understanding in model inferencing lifecycle, monitoring, feedback loop and data capture in real time at scale Ability to ramp up quickly on our tech stack which includes GCP, Kubernetes, Airflow, Kafka, Pandas, Scikit Learn, Pytorch, Python, and Java. A Bachelor’s Degree in Computer Science or a related field 
ScrapedJobID431:
Work with product designers, product managers and other stakeholders to discover, understand and quantify the scale of our customer and business problems. Analyze user behaviour and business impact to help guide product and business decisions. Conduct analysis on A/B tests, including assessing core KPIs, offensive metrics, defensive metrics and basic effectiveness measures. Perform deep-dive analyses to wholly assess initiatives or problems the business faces and present these findings to director-level management. Own the instrumentation of analytics, reporting and problem discovery for your team’s domains. Identify opportunities for applying machine learning and AI in your team’s domains by acting as a link between product managers and data scientists. Collaborate with other data analysts, data scientists, data engineers and directors to further the organization’s analytical competence. Excellence in quantitative business analysis(business analytics, product analytics, operations research and marketing analytics). 3+ years of experience uncovering insights with data, driving quantifiable results for the business. Strong understanding of sizing business problems and incrementality. Experience answering ambiguous questions. Self-guided problem solver who digs deeper for a greater understanding of business and user value. Inclination to ask insightful questions, actively listen and engage with problems. Ability to perceive and proactively manage analysis bias to control any bias-influenced conclusions. Experience visualizing data using Excel, Tableau, Power BI, Looker, or similar tools. An understanding of basic statistical concepts such as statistical significance, normal distribution, correlation and causation. A team player who collaborates and communicates with developers, business stakeholders and product designers. At least a basic understanding of SQL with a desire to learn more. Have experience with app and digital analytics metrics. Have a good understanding of how modern mobile apps work. Have worked in either an internal or external management consulting role. Have experience with DBT, Python and Jupyter notebooks. RVezy stock options (we believe every colleague should be an owner). Fifteen paid vacation days with extra time off over the winter holidays. One paid RV rental every year. Flexible work hours and a relaxed dress code. A chance to attend festivals, concerts and RV shows across Canada and the U.S. (once things reopen)! Frequent social events and a steady supply of coffee and snacks in the office. 
ScrapedJobID432:
Have at minimum, an undergraduate in related fields: business, analytics, economics, statistics, mathematics, or computer science Be able to perform statistical programming in R or Python Understand the fundamentals of data types, analytics, and have the passion to learn deeper into the subject Be interested in consulting and technology Be proficient at presentation skills and conducting meetings Be a team player, be organized, be punctual Have Master’s level education in relevant fields Has experiences in data visualization, such as Tableau or Qlik Have sales and business development experience Have a coding background Competitive salary + Sales Bonus + Year End Profit Bonus Admitted into a customized education program that will focus on personal and professional growth of the individual Working in a very challenging and fast paced environment that will require you to push yourself intellectually Working with the founder directly in open concept downtown Toronto office. Attend analytics, data science, AI and industry conferences and workshops, developing your own network Flexible working arrangements 
ScrapedJobID433:
Train deep learning models using open source datasets and our in-house proprietary datasets Advance the current open-sourced deep learning architectures Find, create, synthesize datasets to advance current system capabilities Stay updated with the latest and greatest in the field of NLP, more specifically, information retrieval, dialogue systems, multi-step reasoning and conversational-ai Foster a quantitative approach to problem solving. Lead by example. Be passionate about leveraging technology and making the law accessible for all Observe and overcome your own biases, and see what's possible Brainstorm. Invent. Test. Repeat! PhD in Computer Science (or similar) with a focus on Natural Language Processing. Masters degree candidates with a solid research thesis in NLP are also welcome to apply. 3+ years industry experience in NLP Extensive experience using PyTorch, TensorFlow, or similar Extensive experience in Software Development Experience working with cloud platforms (AWS/GCP) Ability to rapidly prototype Legally authorized to work 40 hours/week in Canada Effective Communication Skills An in-depth demo/presentation of your NLP research/projects Demonstrated advanced abilities in mathematics and/or linguistics Competitive Stock Options Competitive Pay Unlimited vacation days 16" MacBook Pro dedicated for work Additional winter holidays (Dec 25 - Jan 1) Flexible work hours and location. We’re cool with remote work! In-person office workspace can be made available in Toronto (if required), in accordance with City of Toronto Public Health guidelines. 1 day, every alternate week, dedicated to projects you’d like to innovate on within the context of the work the company is doing Growing in to more senior roles, starting with hiring and training a co-op for your team and/or the project your team is leading No red tape, no unnecessary processes, accelerated learning and growth. Health benefits Work for a fast growing AI startup and make an impact. We are building something legit and impactful, not just another app. 
ScrapedJobID434:

ScrapedJobID435:
Bring your expertise to customers who want to transform their company into a data-driven organization. You will be able to leverage all the existing assets created by Deloitte around AI applications, and combine them with your knowledge to build perfectly tailored applications for each customer Work with high profile clients on a variety of Canadian and international engagements, including opportunity to travel across Canada and internationally (as needed) Experience in development deployment automation using Terraform. Experience in deployment automation Some experience in working with the AWS technologies stack Working knowledge of cloud security Experience in developing Terraform automation within the AWS technology stack Working knowledge with the following technologies in AWS Athena and Sagemaker, Beanstalk, ELB Experience in working with GitHub and a CI/CD infrastructure automation workflows. Experience working with AWS security and advance security measure such as temporary credentials. You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster. You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful. You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work. 
ScrapedJobID436:
PhD in received within the last 5 years or graduating PhD candidate in computer science, biomedical engineering, physics, computational neuroscience, or a related quantitative field Solid publication record related to machine learning and signal processing Interest in brain signal processing Strong programming skills in MATLAB, R / Bioconductor, or Python Ability to communicate complex information clearly, orally and in writing Ability and willingness to work in a dynamic interdisciplinary team environment Experience with machine learning libraries such as Scikit-learn, Theano, Tensorflow, Keras, Pytorch Python software packaging, virtual environments, Anaconda/Conda, Jupyter/IPython Experience with version control systems (Git) and software testing Experience with human EEG and other human physiological signal recording and analysis Sunnybrook sleep and brain health laboratory: https://sleepandbrainhealth.ca/ Sunnybrook Research Institute: sunnybrook.ca/research University of Toronto: utoronto.ca 
ScrapedJobID437:
Research: Discover solutions to unique data science challenges while satisfying business needs Develop and Implement full solutions
Load and clean the data
Prepare and train the model
Deploy, monitor and maintain the solution Load and clean the data Prepare and train the model Deploy, monitor and maintain the solution PhD in a quantitative STEM field with an important data analysis component OR Msc. in a quantitative STEM field with 3+ years of experience as a Data Scientist Strong programming skills in Python and experience with Machine Learning tools (numpy, scipy,scikit-learn, pandas, pytorch/ tensorflow, ...) Strong knowledge of data science algorithms and their limitations (execution speed, memory considerations, etc) Experience dealing with very large datasets Familiarity with database environments (including distributed big data solutions) and functional SQL knowledge Experience with UNIX/Linux environments Good team player and open to give and receive constructive feedback Ability to communicate clearly to non-experts Understanding and/or familiarity with non-interpreted (compiled) programming languages Experience with cloud providers (AWS, GCP, Azure) Data science side projects or Kaggle competitions 
ScrapedJobID438:
Analyze and test large volumes of data for outliers, anomalies, patterns and trends to support the evaluation of the adequacy and effectiveness of controls. Develop efficient audit testing programs based on data trends and their underlying control deficiencies. Support the strategic objectives established by the Audit Manager, Information Technology (IT) through the identification and risk classification of data focus areas. Build dashboards in Power BI or through other tools/reports to provide meaningful insights to business data. Utilize audit test results to further evaluate risk implications and raise recommendations that will add value in implementing cost efficient solutions and/or identify cost savings opportunities. Collborate with the City Auditor, Audit Manager IT and audit staff to define and prioritize data analytic requirements. Effectively communicate audit findings to Audit Committee, Senior Management, Business Unit Leaders and process stakeholders in an understandable document to easily communicate complex ideas. Deliver reliable audits that comply with professional audit standards and are delivered within quality, time and budget parameters. A degree in Data Science, Computer Science, Information Management or Business Administration or related field and at least 5 years of related experience. Certified Internal Auditor (CIA) designation or Certified Information Systems Auditor (CISA) is required. Experience in leading complex audits and at least 2 years of related data analytics experience is required. Other relevant data analytics, accounting, and information technology professional certifications would be an asset. Success in this position requires the following: superior analytical and problem solving skills, critical thinking, verbal and written communication, technical auditing competence, and team collaboration. Equivalent combinations of experience and education may be considered. Successful applicants must provide proof of qualifications. Effective November 1, 2021, all City of Calgary employees must be fully vaccinated against COVID-19. For more information, please refer to COVID-19 Vaccination Policy. 
ScrapedJobID439:
Scale and manage a growing team of data engineers, data analysts, and business intelligence developers Serve as the organizational leader and designer for the corporate data and analytics strategy, having high visibility and interaction with the Executive Team Collaborate with engineering and product development teams to optimize our current offerings; This includes building an aligned strategy with continuous improvement for data capturing and management, setting the data engineering and quality strategy that will support our company’s goals, and communicating the technical vision to executive leadership and non-technical stakeholders Architect our data collection, management, and storage platforms Be a champion for a data-driven culture, lead a team of cross-functional analysts and support and train staff in data systems and reporting Enable cross-collaboration teams to access our various data sources through business application and visualization tools Build and optimize the development of our predictive models and machine-learning algorithms Build a world-class reporting and insights platform that enables the business to operate with a data-driven approach A work ethic that demonstrates dedication and commitment to Bold’s mission and belief in our BUILDERS Code 5+ years experience in a hands-on analytics/data science role and 3+ years experience developing relevant strategies or consulting Advanced degree in a quantitative field such as statistics, engineering, mathematics, or computer science Expert SQL and strong proficiency in Python and R; Experience with DLP, Relational databases, Google Analytics, BigQuery, and Looker Experience managing and leading a team and fostering their growth through 1:1s, coaching, and setting clear expectations Track record of developing and delivering a highly functioning analytics platform enabling performance insights which drive strategic business decisions Experience with overseeing data aggregation, machine learning techniques, data visualization, and experimentation architecture Experience overseeing/developing model experimentation and optimization in a production environment The ability to effectively communicate analytical insights to a non-technical audience Track record of solving analytical problems creatively, with clear outcomes and a strong sense of accountability 
ScrapedJobID440:
Assist in defining project scope and objectives and developing plans to monitor and track progress. Communication of the analysis processes and insights to stakeholders and other analytics teams across the organization. Partner and align with stakeholders to brainstorm, test and develop analysis that delivers quick insights to validate business hypotheses. Helping our partners make more informed decisions quickly Proactively identify analytical opportunities that will lead to improved business results Synthesizing and framing analysis and translate findings into clear, actionable insights and recommendations. Create supporting material such as reporting templates, trackers, and post mortems. Use systems such as Tableau, SQL, and Python for comprehensive database creation and management. Provide ad hoc analysis supporting the MP&A team Bachelor of Business Degree 2 - 4 years of Business, Marketing/ Project Management Experience Strong data mining and analytical skills and able to translate findings into clear, actionable insights and recommendations. Ability to “storytell” through analytics and presentation materials Advanced Excel skills with experience with Tableau, SQL, Python, database creation and management is preferred. Creative thinker and solutions oriented, committed to driving business improvements Ability to handle multiple demands and competing priorities. Ability to be flexible and adaptable while operating independently and as part of a team. A genuine interest in new approaches, fresh innovative ideas, and a strong belief in your ability to make ideas real. Proactive approach to problem-solving, working collaboratively, and supporting the team. Ability to think strategically and execute methodically. Be part of a world-class team; work with an adventurous spirit; think and act like an owner- operator Exposure to rewarding career advancement opportunities, from retail to supply chain, to digital or corporate. A culture that promotes a healthy, fulfilling work/life balance Benefits package for all eligible full-time employees (including medical, vision and dental). An amazing employee discount 
ScrapedJobID441:
Participate in client meetings and assist in identifying client needs; help to recommend solutions from among EA’s data, software and advanced marketing capabilities to meet those needs. Design and build analytical files and analytical frameworks for client projects. Analyze, interpret and communicate the results of the analytical solution. In conjunction with the model development team participate in the development and validation of predictive models. Summarize data in tables and charts, interpret the data, looking for relevant insights and write reports in support of client objectives. Prepare and present Powerpoint presentations of research results including extensive use of data visualization. Manage projects from start to finish, managing timelines while maintaining a high level of quality. Work closely with other staff in Client Advocacy, Client Services, Standard Research, Custom Research and Sales to meet client requirements. Other duties as required. Education - Post-secondary degree in Geography, Business or related field Experience - Minimum of 2-4 year of relevant experience in Data Science Technical Skills – Possesses programming skills to allow for self-sufficiency in handling data (Alteryx, SQL, SAS, SPSS). Expertise in all Microsoft applications (Word, Excel, Powerpoint). Must be comfortable working with large quantities of data. Intermediate to advanced skills in Excel and Tableau are required. Analytical Skills – Effectively researches and synthesizes complex or diverse information; uses intuition and experience to complement data and designs work flows and procedures. Judgment - Displays willingness to make timely decisions, including appropriate people in the decision-making process and exhibits sound and accurate judgment; supports and explains reasoning for decisions Planning/Organizing - Prioritizes and plans work activities effectively. Ability to multi-task. Teamwork - Balances team and individual responsibilities; Exhibits objectivity and openness to others' views, giving and welcoming feedback. Puts success of team above own interests and demonstrates ability to build morale and group commitments to goals and objectives. Supports everyone's efforts to succeed. Innovation - Displays original thinking and creativity and meets challenges with resourcefulness. Generates suggestions for improving work. Presents ideas and information in a manner that gets others' agreement. Communication Skills – Able to clearly communicate ideas and expectations. Effectively listens for understanding and asks questions for clarification. Presents ideas effectively in both verbal and written form. Interpersonal Skills – Approachable and easy to talk to. Relates well to all kinds of people in the organization. Able to effectively build rapport with others. Uses diplomacy and tact. Maintains composure and shows an ability to resolve conflicts and gain agreement. Client Focus – Dedicated to meeting the expectations and requirements of clients and acts with the client in mind. Establishes effective relationships and gains and maintains the trust and respect of clients. Presentation Skills – Able to create and deliver informative, compelling presentations that capture and keep the audience’s attention – both in person and via Teams. Uses a strong voice, consistent eye contact, and exudes a confident presence. Observes the reactions of the audience and adjusts tone, pace, style and content to address any issues. 
ScrapedJobID442:
Bachelor's degree in computer science/electrical engineering or equivalent practical experience. Strong grasp of statistical machine learning, linear algebra, and deep learning for computer vision Experience with one or more general purpose programming languages including but not limited to: C/C++, or Python. Familiarity with PyTorch or TensorFlow or other ML Frameworks. Master's or PhD degree in Computer Science, Artificial Intelligence, Machine Learning, or related technical field. Strong research experience with a track record of publishing or internship experience focussed in one or more of the following: Computer Vision, Natural Language Processing, pattern recognition, recommendation systems, or similar. Excellent communication and documenting skills. Design and implement ML components, systems and tools to automate and enable checkout free shopping. Apply research methodologies to identify the machine learning models to solve a business problem and deploy the model at scale. Own the ML pipeline from data collection, through the prototype development to production. Develop high-performance, scalable, and maintainable inference services that communicate with the rest of our tech stack Innovation - We have an ambitious vision, and any change, especially the zealous kind, requires big ideas. Integrity - We trust each other, and that trust is the foundation on which our relationships both internally and externally are built. Continuous Improvement - We see everything as improvable, and work at finding ways to do so, and enjoy moving toward our goals. Accountability - Our teammates have intrinsic enjoyment in taking ownership and delivering on what they say they will. Customer Focus - We care the most about what benefits our customers and partners. 
ScrapedJobID443:
Analyze and visualize business operations & market data Understand the business problem, identify the key challenges, formulate the machine learning problem and provide/prototype solutions Collaborate with other team members as well as new revenue management platform consultants Build data models and simulations Incorporate these models into the revenue management platform Minimum three years of experience working as a Data Scientist in core revenue management concepts such as demand forecasting, yield management, pricing, bidding, etc, ideally from the logistics, transportation or distribution industry Two years of experience working as a data analyst in a business or scientific context Bachelor or postgraduate degree in computer science, mathematics or physics Advanced Python programming skills related to data analysis and simulation Object-oriented design Experience working with large datasets in a performant manner: code optimization, vectorized operations, parallel execution Unit testing Data analysis using pandas and numpy Data visualization using matplotlib and seaborn: histograms, scatter plots, heatmaps Parsing and visualization of geolocation data Bilingual 
ScrapedJobID444:
Have at minimum, an undergraduate in related fields: business, analytics, economics, statistics, mathematics, or computer science Advanced skills in BI tools for tools like PowerBI, Qlik and Tableau Ability to transform business requirements into dashboard and BI processes and visuals Be able to perform statistical programming in R or Python. Knowledge of running embedded scripts into dashboards Understand the fundamentals of data types, analytics, machine learning and have the passion to learn deeper into the subject Be interested in consulting and technology Be proficient at presentation skills and conducting meetings Be a team player, be organized, be punctual Have Master’s level education in relevant fields Has advanced experience in insight delivery and ML using Power BI (Cognitive Services, PyCaret) Have a coding background with emphasis on data science applications and methodologies Admitted into a customized education program that will focus on personal and professional growth of the individual Working in a very challenging and fast paced environment that will require you to push yourself intellectually Working with the founder directly in open concept downtown Toronto office Attend analytics, data science, AI and industry conferences and workshops, developing your own network Flexible workhours and work from home arrangements 8 hour shift Yes 
ScrapedJobID445:
Use existing Models to score campaign files and make audience selections Design and manage predictive model development projects from start to finish by engaging both internal and external stakeholders Work with Director to identify opportunities where predictive model use would be beneficial in achieving higher constituent engagement and lifetime value Monitor use of predictive models to ensure proper application and best practice recommendations are followed Working with fundraising leads to developing domain knowledge for the different Fundraising programs supported Deliver actionable insight by analyzing data to identify, and interpret trends, and recommend tactical adjustments to improve performance Analyze donor behavior, and work with program leads to develop and implement donor segmentation strategies Using data insights identify opportunities to improve constituent engagement, upgrade, retention, and lifetime value Effectively communicate insights to key stakeholders through data visualization and strong storytelling Recommend and implement improvements to reporting methods including techniques and tools to allow timely insights Participation in CRM management including ongoing processes, UAT, QA, changing requirements, and enhancements Build strong lateral relationships with IT team to achieve maximum integrations and synergies, especially the development and use of CRM and other projects that support the advancement of the team University degree in analytics, data science, statistics, finance, or equivalent Minimum 2 years of analytics and/or data science experience in a customer-centered organization engaged in multi-channel marketing Experience in development, deployment, and monitoring of predictive models using ML/Auto ML Experience working with large data sets and data from CRM systems, as well as Cloud Analytics environments like BigQuery, Snowflake, or Redshift Experience delivering data analysis and insight through storytelling and visualization Experience in data-visualization and data modeling using tools like Power BI or Tableau Experience reporting on mass media campaigns including all types of digital and traditional media channels an asset Ceaseless curiosity and an ability to delve into the data to prove/disprove the hypothesis An extremely strong ability to translate data into action Excellent grasp of statistical analysis and Machine Learning principles and techniques Exceptional data analysis and modeling skills using Excel, SQL, DAX, R, Python Data-visualization using tools like Power BI/Tableau A good understanding of customer experience Development of sophisticated data models including donor segmentation Good project management skills and ability to oversee and execute on complex campaign schedules Ability to translate complex ideas to layperson language Very strong ability to manage multiple demands Understanding of customer file segmentation and strategic planning based on ongoing interactive communication Strong interpersonal skills including collaboration and consultation as part of a team Self-starter with comfort turning ambiguity into process and action 
ScrapedJobID446:
Create models of the world and extract insights from complex, unstructured 3D point clouds Write production code for use in extracting geospatial insights from a variety of data sources Increase the efficiency and repeatability of our ML training process on new datasets and/or additional features classes Create infrastructure for rapid training and testing ML systems Provide insight into trends and novel work in machine learning 3+ years experience in 2 or 3D computer vision/machine learning Expertise with object semantic segmentation and classification Mastery of Python and prior experience with GPU acceleration Capability with deep learning frameworks (ie, TensorFlow, Keras, etc) Prior experience with cloud computing, AWS preferred Excellent communication skills Rigorous analytical thinking BS in engineering, computer science, or a related field Prior experience with GIS, lidar, or photogrammetry MS or PhD in engineering, computer science, or a related field Opportunity to play a foundational role at a well-funded startup with major clients and revenue Work with people like yourself—talented and thoughtful; passionate about solving challenging problems Unlimited vacation policy (we're serious about this - do great work, have fun and live life) Internet Reimbursement Supplemental health insurance benefits 
ScrapedJobID447:
Build and maintain our ML development stack hosted on AWS and running with Sagemaker Work with the data science team to facilitate model development and deployment Write Airflow ETLs to prepare data for consumption by ML models Participate in maintaining our MLOps best practices and tool selection You understand the main elements of the ML lifecycle, including data connection, ETLs, model training and deployment and the tools necessary to test and monitor models in productions You are familiar with Snowflake and how to efficiently query data from it You are familiar with the AWS cloud environment and how to deploy components Bonus points if you are familiar with Machine Learning enablement tools such as experiment tracking systems, feature store and similar systems Bonus points If you are familiar with the internal of model compilers to help find potential ways to accelerate or distribute the training and inference of models Competitive compensation packages Generous group health insurance plan Access to the virtual healthcare platform Dialogue Access to the company's stock option plan 16 days of vacation per year, which increases with seniority at the company 3 paid Caring days 1 paid volunteer day Offices closed during the holidays Wellness allocation of $840 per year (for gym memberships, sportswear, etc.). In-house training programs on our company and industry Encouragement and funding of continuing education and training Very active social committee and free online sports classes Access to a tool that measures your engagement and job satisfaction anonymously Pairing with a buddy for your first 6 months Advantageous referral program Inclusive, inspiring, and dynamic work environment Casual dress code Work from home and flexible hours And more! 
ScrapedJobID448:
Contribute to BrainStation's Data Science Diploma program that will positively impact the lives and careers of hundreds of individuals across our campuses Deliver lectures and mentor the next wave of Data Science talent Facilitate in-class activities, group discussions, demos and provide constructive feedback for evaluating student work Apply BrainStation's Agile Education methodologies to the program to continuously improve the educational experience for students Constantly improve your own skills, and apply these skills in collaboration with other BrainStation Faculty members to build the digital platform and tools needed to deliver cutting-edge content Define the education experience of the future 2+ years experience as a Data Scientist or Analytics professional and a Bachelor's degree relevant to the subject matter Strong command of querying and programming languages SQL, R and python - numpy, pandas, sklearn, TensorFlow & Keras), and visualization tools (Excel, Tableau, matplotlib/seaborn/plotly in python packages Experience applying various methods of numerical and categorical modelling techniques and supervised and unsupervised machine learning methods (OLS regression and GLMs, logistic regression, KNN, SVM, decision trees/random forest, clustering and cluster analysis, dimensionality reduction, neural networks) Hands-on development experience working with version control systems (we use Git) Practical experience designing and applying data science processes to conduct experiments using a variety of tools and methods, and can speak to their complexities in a simple and logical manner Experience in a teaching or mentoring role, and are comfortable speaking to large groups Strong written and verbal communication skills A proven ability to work under pressure and meet deadlines An empathetic, friendly, and approachable demeanour A passion for education and creating positive learning experiences for others A passion for education and creating a positive learning experiences for others Comprehensive Health & Wellness Benefits Package Retirement Planning Parental Leave Program New Device Allowance Socials, Outings & Retreats Culture of Learning & Development Flexible Working Hours Work from Home Flexibility 
ScrapedJobID449:
Bachelor's degree and enrollment within the PEY program at University of Toronto Strong Python and C++ programming skills Strong fundamental knowledge of OOP, Data Structures & Algorithms, Computer Architecture and/or Machine Learning Familiarity with TensorFlow, PyTorch or Caffe Familiarity with GPU, CPU, or parallel architectures Experience in vertical such as computer vision, language modeling or speech recognition Toronto 
ScrapedJobID450:
Possess a successful track record of designing and developing AI/ML algorithms for private or public sector solutions Up-to-date with the latest technology trends, have a strong desire to constantly learn and be ready to put on the hacker's hat at any time to convert an idea into a demonstration Highly detailed-oriented with exceptional organizational and follow-through skills Self-started and able to execute without a lot of direction or oversight Exceptional communication skills, with an ability to make advanced analytics concepts accessible and understandable to non-technical business users Value collaboration and urgency; and have a passion for driving impact Solve some of the most challenging and impactful problems for financial services, insurance and the government by using artificial intelligence, machine learning, natural language processing and big data Drive innovation into Analytics solutions and focus on humanizing enterprise software to achieve better customer experience and to enable data-driven business decisions Work on high priority initiatives using advanced analytics, predictive modeling and a variety of data sources to produce actionable business insights Ideate, conceptualize, design, develop and maintain AI/ML algorithms that provide data insights that drive operational efficiencies and cost savings Build production grade models on large-scale datasets. Utilize advanced statistical modeling, machine learning, and data mining techniques Provide guidance to a customer and project team with respect to technical feasibility, complexity, and level of effort required to deliver a solution Work closely with other team members to further develop metrics, KPIs, and insights that measure business performance improvements Assist in the development and delivery of pre and post sales POCs, presentations and proposals for client engagements Travel periodically in support of sales and delivery as needed At least 2 years of experience working on predictive analytics and data mining projects 2 years of hands-on experience using complex machine learning methods and algorithms At least 2 years of experience working with one or more data mining tools such as R, Python, Scala or SAS Hands-on experience working with Big Data technologies such as Spark, Cassandra, and/or Hadoop Hands-on experience writing complex SQL queries and working with relational databases such as Oracle, DB2 or SQL Server Hands-on experience constructing and manipulating JSON and XML documents and working with NoSQL databases such as MangoDB and CouchDB Good understanding of microservices architecture and hands-on experience working with REST APIs Self-directed and demonstrable problem-solving skills Knowledge of modern software development techniques and methodologies Knowledge and practice of secure software development processes Ability to handle multiple priorities and deadlines Bachelor’s degree in mathematics, business, statistics, economics, computer science or information systems (or equivalent combination of skill and experience) Asset : Data Analysis Engineering 
ScrapedJobID451:
Contribute to BrainStation's Data Science Diploma program that will positively impact the lives and careers of hundreds of individuals across our campuses Deliver lectures and mentor the next wave of Data Science talent Facilitate in-class activities, group discussions, demos and provide constructive feedback for evaluating student work Apply BrainStation's Agile Education methodologies to the program to continuously improve the educational experience for students Constantly improve your own skills, and apply these skills in collaboration with other BrainStation Faculty members to build the digital platform and tools needed to deliver cutting-edge content Define the education experience of the future 2+ years experience as a Data Scientist or Analytics professional and a Bachelor's degree relevant to the subject matter Strong command of querying and programming languages SQL, R and python - numpy, pandas, sklearn, TensorFlow & Keras), and visualization tools (Excel, Tableau, matplotlib/seaborn/plotly in python packages Experience applying various methods of numerical and categorical modelling techniques and supervised and unsupervised machine learning methods (OLS regression and GLMs, logistic regression, KNN, SVM, decision trees/random forest, clustering and cluster analysis, dimensionality reduction, neural networks) Hands-on development experience working with version control systems (we use Git) Practical experience designing and applying data science processes to conduct experiments using a variety of tools and methods, and can speak to their complexities in a simple and logical manner Experience in a teaching or mentoring role, and are comfortable speaking to large groups Strong written and verbal communication skills A proven ability to work under pressure and meet deadlines An empathetic, friendly, and approachable demeanour A passion for education and creating positive learning experiences for others A passion for education and creating a positive learning experiences for others Comprehensive Health & Wellness Benefits Package Retirement Planning Parental Leave Program New Device Allowance Socials, Outings & Retreats Culture of Learning & Development Flexible Working Hours Work from Home Flexibility 
ScrapedJobID452:
Bachelor's degree and enrollment within the PEY program at University of Toronto Strong Python and C++ programming skills Strong fundamental knowledge of OOP, Data Structures & Algorithms, Computer Architecture and/or Machine Learning Familiarity with TensorFlow, PyTorch or Caffe Familiarity with GPU, CPU, or parallel architectures Experience in vertical such as computer vision, language modeling or speech recognition Toronto 
ScrapedJobID453:
Possess a successful track record of designing and developing AI/ML algorithms for private or public sector solutions Up-to-date with the latest technology trends, have a strong desire to constantly learn and be ready to put on the hacker's hat at any time to convert an idea into a demonstration Highly detailed-oriented with exceptional organizational and follow-through skills Self-started and able to execute without a lot of direction or oversight Exceptional communication skills, with an ability to make advanced analytics concepts accessible and understandable to non-technical business users Value collaboration and urgency; and have a passion for driving impact Solve some of the most challenging and impactful problems for financial services, insurance and the government by using artificial intelligence, machine learning, natural language processing and big data Drive innovation into Analytics solutions and focus on humanizing enterprise software to achieve better customer experience and to enable data-driven business decisions Work on high priority initiatives using advanced analytics, predictive modeling and a variety of data sources to produce actionable business insights Ideate, conceptualize, design, develop and maintain AI/ML algorithms that provide data insights that drive operational efficiencies and cost savings Build production grade models on large-scale datasets. Utilize advanced statistical modeling, machine learning, and data mining techniques Provide guidance to a customer and project team with respect to technical feasibility, complexity, and level of effort required to deliver a solution Work closely with other team members to further develop metrics, KPIs, and insights that measure business performance improvements Assist in the development and delivery of pre and post sales POCs, presentations and proposals for client engagements Travel periodically in support of sales and delivery as needed At least 2 years of experience working on predictive analytics and data mining projects 2 years of hands-on experience using complex machine learning methods and algorithms At least 2 years of experience working with one or more data mining tools such as R, Python, Scala or SAS Hands-on experience working with Big Data technologies such as Spark, Cassandra, and/or Hadoop Hands-on experience writing complex SQL queries and working with relational databases such as Oracle, DB2 or SQL Server Hands-on experience constructing and manipulating JSON and XML documents and working with NoSQL databases such as MangoDB and CouchDB Good understanding of microservices architecture and hands-on experience working with REST APIs Self-directed and demonstrable problem-solving skills Knowledge of modern software development techniques and methodologies Knowledge and practice of secure software development processes Ability to handle multiple priorities and deadlines Bachelor’s degree in mathematics, business, statistics, economics, computer science or information systems (or equivalent combination of skill and experience) Asset : Data Analysis Engineering 
ScrapedJobID454:
Research and analyze business partners’ needs, and discover business insights using statistical analysis, algorithmic processing, data science, machine learning, data mining, machine vision, natural language process, and/or reporting visualization techniques as befits the business problem Converts partners’ and customers’ questions and business requirements into documents to drive the development of analyses Develop analytical, report and dashboard specification documents Understand the overall data structure of required systems and the interaction of data in order to accurately develop analytical models, reports or dashboards Perform peer reviews to ensure data quality, solution quality, overall accuracy, and fit of solutions within business problem Completed University degree in computer science, Information Technology, Mathematics, Statistics or a related field; Knowledge of Python, R, SQL, Hadoop, data analysis tools Knowledge of Reporting and Dashboard tools Analytical, investigation & problem-solving skills Dedicated team player, who demonstrates initiative and independence Excellent communication, time, and project management skills Bilingualism a plus 
ScrapedJobID455:
30 days - Learn about the product (project goals, requirements, constraints, key stakeholders), familiarize with existing code and data, learn about a statistical or machine learning model that is used on our products. Implement tests for this model. 60 days - Full assessment of quality and correctness for one product. Analyze risks and develop a plan of attack. Learn about the infrastructure for machine learning R&D and improve on its automated testing features. 90 days - Full assessment of quality and correctness for an additional product. Analyze risks and develop a plan of attack. Take ownership of a significant feature of the infrastructure for machine learning R&D. Help productionize machine learning models Machine learning models in our products are production-quality Infrastructure for machine learning R&D is significantly improved, helping scientists develop, test, and verify models more quickly Multiple ADI products have their statistical and machine learning models assessed, have sufficient coverage of automated tests, and are regularly manually tested Model accuracies have reasonable correctness, and their errors are also reasonable Tests and quality is documented, including edge cases that are known to deteriorate quality Deep experience in test automation with Python applications Experience working with machine learning frameworks, such as numpy and pandas Experience in AWS, Docker, and API testing Making complex decisions Resourcefulness Focusing on performance Collaborates Courage Instills trust Being open Being flexible and adaptable 
ScrapedJobID456:
As a design champion within Deloitte’s cross-functional team, gain understanding of the end-to-end project objective and goal, validate business and technical requirements Collaborate extensively with clients, facilitate design thinking workshops, conduct UX exercises (user flow/workflow, story mapping) and document the process and outcomes Produce low- and high-fidelity wireframes and screen mock-ups for interactive data visualization dashboards, AI and analytics solution applications Facilitate playback sessions with clients to present the outcomes of processes as well as produce wireframe outputs to arrive at a final design Work through iterative cycles, incorporate feedback, complete user testing and quality checks, and hand over assets to the development team Manage expected scope and effort within the set timeline A critical and analytical thinker, and a creative problem solver who is able to navigate difficult discussions and ambiguity to arrive at design solutions A collaborative orchestrator who facilitates working sessions to bring user-centred design thinking to translate complex business and technical problems into design solutions A passionate designer who understands the role of design in supporting application of data, analytics and AI to solve complex business problems A versatile designer, who has the ability to execute a variety of deliverables, using tools such as Figma/Sketch, Adobe Suites, Miro, as well as non-traditional design tools such as Microsoft PowerPoint and Word A persuasive communicator who is able to explain complex concepts to stakeholders at all levels A university / college degree graduate in disciplines of design and/or with related experience Proficient with UX/UI design tools such as Figma and/or Sketch (or other prototyping tools), collaboration tools such as Miro to generate and iterate prototypes, wireframes, user flow, user journey and story mapping 
ScrapedJobID457:
You will be responsible for conducting R&D in deep learning and computer vision to support our technology offering in object tracking, detection and segmentation for images, videos and Lidar systems. You will be a key player in expanding our core Machine Learning technology to more use cases within our product. Through proper implementation and delivery, you will work collaboratively with Product Management and ML developers to deliver the best products and solutions to our customers. Ph.D. in Machine Learning, Computer Vision, Image Processing, or a related field with 2+ years of industry experience OR M.Sc. in Machine Learning, Computer Vision, Image Processing, or a related field with 5+ years of industry experience. Ability to carry out Machine Learning projects, from prototype to delivery. Experience with Deep Learning frameworks such as TensorFlow or Pytorch. Experience with Cloud Infrastructure (AWS, GCP, Azure). Ability to develop and prototype new Machine Learning techniques and run experiments to systematically improve model accuracy. Contribution to research communities and/or publications at conferences such as NeurIPS, ICML, ICLR, CVPR, ICCV. Experience with MLOps, and model deployment infrastructure in general. Understanding of service-oriented architectures. Comfortability working with a distributed team. Featured in Forbes: How Ethical Is Your AI? Sama Honored on Inc. Magazine’s Annual List of America’s Fastest-Growing Private Companies — the Inc. 5000 
ScrapedJobID458:
Bring your expertise to customers who want to transform their company into a data-driven organization. You will be able to leverage all the existing assets created by Deloitte around AI applications, and combine them with your knowledge to build perfectly tailored applications for each customer. Work with high profile clients on a variety of Canadian and international engagements, including opportunity to travel across Canada and internationally (as needed). Strong interest to bring Artificial Intelligence and Advanced Analytics to Enterprise applications 2+ years of experience in Data Modeling and ETL processes within Enterprise systems & Modern Analytic platforms: data lake, data warehouse, Datamart, dimensional models, ETL processes An experience writing SQL queries or python scripts, extracting and importing disparate data from source systems to Analytics Platforms Team player attitude Superior communication skills, intellectual curiosity, and strong analytical skills Undergraduate studies in Business/Engineering/Mathematics/Computer Science; postgraduate studies in Computer Science related specializations advantageous Projects experiences with the following: Azure Data lakes, Snowflake, Databricks and Agile development methods in data-oriented projects Bilingual (English / French) You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster. You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful. You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work. 
ScrapedJobID459:

ScrapedJobID460:
You will develop novel machine learning methods and algorithms that solve complex problems, including but not limited to, object detection, semantic segmentation, instance segmentation, depth estimation, optical flow, etc. Develop scalable and robust data pipelines that are able to process petabytes of data for model training, and deploy models in production Work fast and smart, and collaborate well with other awesome team members to deliver high-quality perception solutions that power the next generation of mobile robots Recent experience in state-of-the-art deep learning models for computer vision tasks on camera, lidar, radar Strong ML fundamentals and has demonstrated experience building and expanding model architectures Strong SWE fundamentals and has demonstrated SWE experience in both high and low-level languages (Python and C++) Strong research capabilities, track record of publishing papers at top conferences on relevant topics Bonus: Experience in deploying models in real time environments. Optimizing architectures to explore the accuracy vs. compute tradeoff Bonus: Experience working with productizing ML models and the infrastructure supporting model development (data, large scale training, eval, etc) 
ScrapedJobID461:
Ongoing practice and process development looking for ways to improve and streamline company processes to not only deliver a superior service to our clients, but also to improve our efficiency and profitability. Mentoring/managing Data Science team members Partner with your Group Director to educate clients on the value of adding Data Science products to their business, capturing & defining needs and solutions Synthesize business needs and create business/functional design documents which can be used to build analysis and data models around. Assess data for validity in terms of predictive capabilities, required feature engineering, opportunities for data widening, or alignment to business requirements Develops, implements, and supports methodologies, standards, and tools for analysis and data science work. Build cooperative, productive relationships with clients and vendors by utilizing excellent communication skills, while also interacting effectively internally and externally. Research, prototype, and explore future, non-standard analytics approaches that push the limits of current analysis output. This will include exploring novel machine learning techniques which enable our teams to tackle segmentation, clustering, and predictive models used in a wide variety of areas. Bachelor’s degree in Mathematics, Statistics, Business Analysis or related 5+ years’ experience as an Analyst / Data Scientist 2+ years’ of managerial and leadership experience Advanced knowledge of R, Python or SAS for model development Previous experience with web analytics tools such as Adobe Marketing Cloud, Google Analytics Extensive experience with statistical modelling techniques Experience connecting Tableau or other visualization systems and using for dashboarding or analysis Self-motivated and ability to work independently in meeting deadlines Exceptional written and verbal communication skills and is comfortable working with remote teams Previous experience with marketing analytics including database marketing techniques, campaign lift, attribution and media mix modelling Familiarity with analyzing data for digital marketing and ecommerce, as well as all other non-digital aspects of a business SQL skills A solid knowledge of ETL tools Understanding of how to deal with larger data sets and parallel computing problem 
ScrapedJobID462:

ScrapedJobID463:
Credit Risk Analytics Support the development of proposals/business cases for credit risk scorecards, system or rule changes that will enhance credit risk management performance Conduct pre and post-analyses of acquisition strategy performance. Provide objective and sound feedback on the performance of acquisition strategies. Make specific recommendations to improve future performance Quantify and grade risk-adjusted profit as well as credit risk performance Actively monitor the performance of key origination strategies. Alert senior management to any signs of potential emerging risk or performance degradation Build deep subject matter knowledge of (i) TTD adjudication system rules, tables and cutoffs and (ii) acquisition campaign criteria. Assess the merits of adjudication cutoffs and rules logic for TTD and campaign channels. Ensure that cutoffs align with RACD’s risk appetite Play a lead role in managing the TTD decision engine simulation environment Ensure accuracy and integrity of data throughout the analytical process. Play a lead role in continuously improving the breadth and quality of available data Invoke champion/challenger methodologies as appropriate Build and maintain sound working relationships with key business partner groups such as Product Management, Technology, etc. Design and build new tracking and reporting capabilities to evaluate strategy performance Reporting and Insights The candidate would be required to have extensive knowledge of how to develop dynamic dashboards, charts and graphs that senior leadership can drill down into and use to understand trends. Experience in Excel Pivot tables, calculations, graphs and charts is essential and candidate must be able to customize these as requested by team Being able to develop dynamic dashboards (in Tableau/PowerBI) that can be used for different types of views into the data Data Manipulation and Analytics Skills The candidate must be comfortable with advanced SQL queries and must be able to use SQL to draw relevant data, integrate it and clean it in a data hub environment. The Candidate should have an in-depth knowledge of how to work in SAS and should be comfortable understanding existing SAS code and developing their own SAS queries to pull, integrate and output data. Strong experience in Python is essential and the candidate must be able to manipulate and analyze large, complex datasets in addition to being able to build their own datasets from existing data sources. Knowledge of Data science and Analytics concepts is essential as candidate will be expected to support model development efforts in the Risk Modelling sphere Experience with models like Decision Trees. Random Forest, XG Boost as well as associated concepts such as hyper parameter tuning, model validation and model monitoring. Communicating findings Must be comfortable communicating complex ideas during presentations in a simple and concise manner to facilitate understanding Should be able to use data and visuals to derive narratives that explain trends and insights Knowledge of Financial Risk terms A strong grasp of financial terms used in Risk as well as their interpretation is strongly preferred. Candidate must be able to understand and interpret complex financial data as well as spot any anomalies and inconsistencies in financial data Comfortable working in Excel and Python to perform complex financial calculations that are dynamically updated with new inputs You can demonstrate atleast 2-3 years of experience in principles of credit analysis and risk management relating to retail lending portfolios, preferably in the autolending space. Prior experience in retail credit is essential You have a strong financial background and can understand financial information in the portfolio as well as spot and explain anomalies Ability to interpret and analyze information to formulate solutions. Strong problem solving skills evidenced by a proven track record Experience with acquisition risk strategy development, including implementation via automated risk management systems such as Decision Manager, Capstone Knowledge of advanced Excel functionality including pivot tables and charts, string manipulation, lookups, and filters. Knowledge of at least one dashboarding software (Tableau, PowerBI etc.) Strong experience in Python, SAS and SQL is a pre-requisite. You give meaning to data. You enjoy investigating complex problems, and making sense of information. You're confident in your ability to communicate detailed information in an impactful way. You put our clients first. You engage with purpose to find the right solutions. You go the extra mile, because it's the right thing to do. You're passionate about people. You find meaning in relationships, and surround yourself with a diverse network of partners. You build trust through respect and authenticity. You understand that success is in the details. You notice things that others don't. Your critical thinking skills help to inform your decision making. Values matter to you. You bring your real self to work and you live our values – trust, teamwork and accountability. Thrive: Benefit from an open and approachable culture that provides the flexibility and support you need to integrate your life at work and at home Connect: Work in a place where the right technology and infrastructure fosters innovation, collaboration and creativity Develop: Grow your skills and career through our best-in-class onboarding experience, ongoing learning opportunities, individual development planning, and comprehensive product training Prosper: Share in our collective success with a competitive salary, incentive pay, banking benefits, health benefits program, and employee share purchase plan CIBC is committed to creating an inclusive environment where all team members and clients feel like they belong. We seek applicants with a wide range of abilities and we provide an accessible candidate experience. If you need accommodation, please contact Mailbox.careers-carrieres@cibc.com You need to be legally eligible to work at the location(s) specified above and, where applicable, must have a valid work or study permit 
ScrapedJobID464:
Wrangling both structured and unstructured data Organizing and joining data sets from disjoint data storage systems Doing exploratory data analysis on imaging, sequence, and wet bench experimental data sets Implementing automated, repeatable, testable pipelines that join together and process diverse data sets Designing metrics to measure data set characteristics and quality Discovering data characteristics that influence ML model inference accuracy, and ways to mitigate problems Cleverly repurposing or augmenting existing internal and external tools to build manual data labeling workflows, and orchestrating data labeling efforts Auditing data access for compliance with data governance policies Providing valuable insights into platform and data pipelines development and deployment Participating in code reviews with the machine learning team and broader data science group A team-first attitude and thirst to learn and improve in machine learning, software engineering, data science, and the life sciences! B.S. in computer science, data science, machine learning, or similar 2+ years of experience working with machine learning data sets using Python, Pandas, and SQL, at the level of querying and joining together data sets Excellent organizational skills and attention to detail Enthusiasm for cross-team collaborative work, especially across life science disciplines Experience in the life sciences, including imaging and bioinformatics Experience with other components of our opinionated ML stack, including PyTorch, Plotly / Dash, Parquet, DVC, and Dask Experience with our infrastructure stack, including AWS (S3, IAM, CloudWatch, Route53, RedShift), Terraform, Kubernetes, Docker, bazel The opportunity to work with an inspired team on challenging problems that matter An attractive compensation package, including health and lifestyle benefits A minimum of 3 weeks’ vacation Opportunities for personal and professional development 
ScrapedJobID465:
Design, implement, test, and validate computer vision and machine learning algorithms Perform ML dataset definition and gathering activities to develop training data and models Implement, integrate, and optimize novel software components with libraries, APIs and hardware communication stacks Participate in Research and Development for hardware sensors and software platforms Work collaboratively with the team towards the development and commercialization of novel hardware-software platforms Perform technical performance benchmarking and analyses to facilitate engineering decisions Participate in the code review process 3+ Years Development Experience Proficiency in C, C++, or C# .NET and at least one of MATLab, R, or Python Education or Industry Experience in Machine Learning Algorithm Development Proficiency in algorithm analysis and optimization techniques Experience working in an Agile / Scrum development environment Git Collaboration and Management Industry Experience in Computer Vision and Machine Learning Algorithms Experience with Libraries such as OpenCV Image Processing Object Recognition and Analysis Experience with Industrial Vision Sensors: Cognex, Keyance, FLIR, PPT Experience in Driver-Level Hardware Interface Development Protocol-Level Component Communication Development (TCP/IP, UDP, Sockets) Education or Automation Industry Experience Ladder Logic for Programmable Logic Controllers (PLCs) and Human Machine Interfaces (HMIs): Rockwell, Siemens Electrical Schematic Design Computer Aided Design (CAD, Solidworks) Solid foundation in 3D geometry and linear algebra Strong Technical and Operational Communication Strong problem solving and analytical thinking skills Independent Research Collaborative Research, Development and Problem Solving Strong organization and discipline skills Creativity and curiosity for solving highly complex problems Passion for learning and developing experience with new technologies Strong attention to detail and high capacity to focus on task at hand. Fast learner, self motivated, can-do attitude and team player. Excellent time management. Excellent written and verbal communication skills. Strong analytical and problem-solving skills. Strong interpersonal skills – working at all levels of the organization. Ability to work successfully under pressure. A competitive salary and benefit package; Working in a multi-cultural and global organization; Ongoing on-the-job learning and development; Employee appreciation events; Working with innovative technology and with an industry leader. 
ScrapedJobID466:
Own BI projects through the lifecycle from business requirements, defining KPIs, and validating data, design, execution, and rollout Work with internal stakeholders to refine business requirements to capture the true users’ needs, pain points, and business questions Gain a deep understanding of the business’ data by investigating the source data, definitions, and lineage of the data elements in order Collect, clean, validate and analyze complex data from multiple sources. You will be responsible for detecting patterns and problems within data and suggesting improvements that will have an immediate impact Build engaging and beautiful data visualizations using Power BI or daily alerts with SSRS Lead training sessions with internal stakeholders to champion the efficient use of data and to roll out initiatives and improvements 2+ years of experience and knowledge in SQL programming Experience with visualization tools like Microsoft Power BI or Tableau Experience with data warehouse concepts and foundations Experience with relational and non-relational data sources Prior experience in Data Analysis Expressions (DAX) would be an asset Passion for UX and data visualization best practices Excellent written, oral, and interpersonal communication skills Ability to communicate ideas in both technical and user-friendly language Ability to balance multiple demands and work both independently and as part of a team Creative problem-solving skills with excessive attention to detail Experience working in a fast-paced environment with SCRUM/Agile methodologies Prior experience working within an eCommerce environment would be an asset 
ScrapedJobID467:

ScrapedJobID468:
Develop large scale shopping recommendation algorithms Build data pipelines to do data analysis and collect training data Train deep learning models to improve quality and engagement of shopping recommenders Work on backend and infrastructure to build, deploy and serve machine learning models Develop ML algorithms to balance different objectives and model long term values Drive the roadmap for next generation of shopping recommenders 3+ years working experience in the area of applied Machine Learning Interest or experience working on a large-scale search, recommendation and ranking problems Interest and experience in doing full stack ML, including backend and ML infrastructure Experience with big data technologies MapReduce/Hadoop/Hive/Presto/Spark Expert in Java, C++ or Python Ph.D. in an area of Machine Learning Experience with large scale Whole page Optimization, Search or Recommendation algorithms Domain expertise in Shopping Shopping is cross-cutting, touches all aspects of Pinterest, so a wide variety of ML problems Largely green-field so lots of opportunity Huge impact - shopping is one of the major expansion areas for Pinterest 
ScrapedJobID469:
Conduct end-to-end analyses, from wrangling data via SQL or Python, to statistical modeling, to hypothesizing and presenting business ideas. Work with large, complex datasets. Lead the development of machine learned models for offline, batch-based data products as well as models deployed to online, real-time services. Work in areas such as search, ads targeting, spam, and photo understanding. Productionize and automate model pipelines within Python services. Experience with data ETL and data analysis packages and workflows (SQL, MapReduce, Spark, etc.). Experience with machine learning using packages such as xgboost, sklearn, TensorFlow, etc. A love for writing beautiful and maintainable code. The curiosity to uncover promising solutions to new problems, and the persistence to carry your ideas through to an end goal. Comfort in using a Unix environment. If you don't have at least one year of experience in a similar role, please take a look at our College Engineering roles instead! 
ScrapedJobID470:
Design and implement reliable distributed data pipelines Design and implement scalable machine learning solutions geared towards solving natural language processing, knowledge representation, and natural language generation problems Create parallelized and/or distributed versions of existing algorithms Research, design and develop novel algorithms Collaborate with research scientists, architects, software developers, and product management to design and program innovative strategic and tactical solutions that meet market needs with respect to functionality, performance, reliability, realistic implementation schedules, and adherence to development goals and principles Gather and determine requirements for new features from internal colleagues Experience with architecting data intensive applications Experience with data mining or machine learning applications Experience writing software in one or more languages such as Python, Scala and/or similar. Experience working with data structures, algorithms and software design Knowledge of data warehousing concepts, including data warehouse technical architectures, infrastructure components, tools and environments (such as Apache Beam, Hadoop, Spark, Pig, Hive, MapReduce, Flume) Experience with fast prototyping Experience working effectively with software engineering teams Mentor others in achieving their career growth potential MS in Computer Science, Computer Engineering, Deep Learning, Machine Learning, Statistics, Computational Linguistics, or a very related field; other exceptional candidates with extensive ML/DL/NLP/NLG backgrounds may also be considered At least 2 years of research engineering experience with respect to ML/DL/NLP/NLG At least 1 year of distributed or highly threaded software development experience Experience with workflow tools like Airflow, Luigi, etc. Hands-on experience implementing new research ideas with a neural network training framework such as Tensorflow, Keras, or PyTorch A PhD in machine learning Experience with academic machine learning research 
ScrapedJobID471:
Lead and manage independently the onsite-offshore relation, at the same time adding value to the client Engage with clients and business partners to understand their requirement, identify their challenges Design & develop custom models based on in-depth understanding of underlying data, data structures, and business problems to ensure deliverables meet client needs, in collaboration with the offshore team in India Create repeatable, interpretable, and scalable models Present results, insights, and recommendations to a larger business audience with an emphasis on the “now what”, i.e., business impact Collaborate with team members, peers, and leadership at Tredence and client companies Bachelor's or master’s degree in a quantitative field (CS, machine learning, mathematics, statistics) or equivalent experience. 3-6 years of experience in data science, building hands-on ML models Experience leading the end-to-end design, development, and deployment of predictive modeling solutions. Excellent programming skills in Python. Strong working knowledge of Python’s numerical, data analysis, or AI frameworks such as NumPy, Pandas, Scikit-learn, Jupyter, etc. Advanced SQL skills with SQL Server and Spark experience. Knowledge of predictive/prescriptive analytics including Machine Learning algorithms (Supervised and Unsupervised) and deep learning algorithms and Artificial Neural Networks Experience with Natural Language Processing (NLTK) and text analytics for information extraction, parsing and topic modeling. Excellent verbal and written communication. Strong troubleshooting and problem-solving skills. Thrive in a fast-paced, innovative environment Experience with data visualization tools — PowerBI, Tableau, R Shiny, etc. preferred Experience with cloud platforms such as Azure, AWS is preferred but not required. 
ScrapedJobID472:
Drive innovation in our products by designing new capabilities based on advanced analytical techniques Develop prototypes and work with our software development teams to transform them into production level technology Design and implement scalable data pipelines that productionize your prototypes Generate value from a unique dataset that spans HR data across many enterprise level companies through research studies or by creating standardization technology Identify solutions to business problems, and opportunities to create value based on your experience in using statistical techniques Collaborate with stakeholders across the organization to support data-driven business solutions Must have a PhD or Master’s degree in Computer Science, Physics, Statistics, Mathematics or a similar field, as well as extensive experience in quantitative analysis and modelling; if only a Master’s degree is obtained, minimum 3 years’ experience working with different business stakeholders in a comparable work environment 1-2 years’ proven industry experience focusing on data science; experience working in a cloud/SaaS environment with experience on Jenkins and AWS Cloud Services will be strongly preferred Minimum 5 years’ experience working with advanced statistical techniques around hypothesis testing, regression analysis, and machine learning Strong problem solving skills, a passion for the scientific method, and a desire to keep the big picture in mind when connecting technology to business value Minimum 2 years of strong coding skills in Python; knowledge of Scala would be an added bonus Excellent written and verbal communication skills for cross-team collaboration and presenting ideas and results to stakeholders You roll up your sleeves You make it easy You are proud You never stop learning You play to win 
ScrapedJobID473:
AI & Analytics lifecycle: working with end users to understand the business need & translating business problems to technical requirements Requirement analysis and design documentation, build and test, user acceptance testing, documenting the solution Business analysis: working with end users to document their business requirements and translate those into functional requirements, data requirements and a modelling approach Product management: defining technical roadmap and the required product features to support that roadmap Taking ownership of the backlog and prioritizing features, and bugs Familiarity with a wide breadth of data science technologies and techniques Educating partners on how AI & Analytics can be applied to solve business problems Evangelizing about the benefits of AI & Analytics Bachelor’s degree in computer science, engineering, business, finance or a related area of study or significant experience in a similar role 8+ years experience in analytics, consulting, product management or a similar function Experience with product ownership - backlog prioritization, proven demonstration of analytical thinking, consensus building, superior communication skills Excellent analytical and problem-solving skills Attention to detail Knowledge of AI and Machine Learning and how they can be applied to solve problems Business analysis, project management, and software development lifecycle (SDLC). Familiarity with Waterfall and Agile methodologies Experience with Python or other relevant programming languages and Machine Learning frameworks Ability to work cross-functionally with IT infrastructure and database administrator teams on project implementations Knowledge of Jira and Confluence Experience with OpenText Magellan Good written and verbal communication skills Able to build a sense of trust and rapport with the team and partners A self-starter attitude, a strong desire to learn as you go, and the belief that you can make a meaningful contribution to your immediate team, the business users that you serve, and to the organization 
ScrapedJobID474:
Work with product designers, product managers and other stakeholders to discover, understand and quantify the scale of our customer and business problems. Analyze user behaviour and business impact to help guide product and business decisions. Conduct analysis on A/B tests, including assessing core KPIs, offensive metrics, defensive metrics and basic effectiveness measures. Perform deep-dive analyses to wholly assess initiatives or problems the business faces and present these findings to director-level management. Own the instrumentation of analytics, reporting and problem discovery for your team’s domains. Identify opportunities for applying machine learning and AI in your team’s domains by acting as a link between product managers and data scientists. Collaborate with other data analysts, data scientists, data engineers and directors to further the organization’s analytical competence. Excellence in quantitative business analysis(business analytics, product analytics, operations research and marketing analytics). 3+ years of experience uncovering insights with data, driving quantifiable results for the business. Strong understanding of sizing business problems and incrementality. Experience answering ambiguous questions. Self-guided problem solver who digs deeper for a greater understanding of business and user value. Inclination to ask insightful questions, actively listen and engage with problems. Ability to perceive and proactively manage analysis bias to control any bias-influenced conclusions. Experience visualizing data using Excel, Tableau, Power BI, Looker, or similar tools. An understanding of basic statistical concepts such as statistical significance, normal distribution, correlation and causation. A team player who collaborates and communicates with developers, business stakeholders and product designers. At least a basic understanding of SQL with a desire to learn more. Have experience with app and digital analytics metrics. Have a good understanding of how modern mobile apps work. Have worked in either an internal or external management consulting role. Have experience with DBT, Python and Jupyter notebooks. RVezy stock options (we believe every colleague should be an owner). Fifteen paid vacation days with extra time off over the winter holidays. One paid RV rental every year. Flexible work hours and a relaxed dress code. A chance to attend festivals, concerts and RV shows across Canada and the U.S. (once things reopen)! Frequent social events and a steady supply of coffee and snacks in the office. 
ScrapedJobID475:
Maintain an acute awareness of the industry and what the competitors are putting out. Investigate new options for the system from code to core. Coordinate with Senior Technical Leads regarding AI tech. Coordinate with team members to discover the best solution for the clients. Conceptualize new features that we could offer exclusively. Manage R&D Data Science Developers. 2+ years of Experience in Software Development Education: M.tech or Ph.D. in Computer Science/Engineering preferably with a focus on AI. Strong hold on Data structures and Algorithms. Experience with Anaconda/Python/Tensorflow. French Language skills. Hours: 30-40 hours/week. Wage: $85,000 - $100,000/year. 3 Weeks of Vacation. A great environment and the right tools to do great work. 
ScrapedJobID476:
Partners with Claim Leaders, Business Transformation, Internal Reinsurance Operations and Data Science to develop methods and analytics to drive technical individual and group claim solutions, trend analysis and design and deliver process transformation internally and for clients Evaluates, reserves and leads implementation of client and internal claim scoring; trains clients on implementing and interpreting claim scoring results and drive results/following up with clients on claims requiring primary focus due to resolution opportunities Provides statistical support, analysis and results presentation for Claim audits, surveys, studies, internal reports and publications, performing quality and process reviews as needed for Canada and US claims. Introducing and implementing client- focused claim scoring and segmentation models for Group Long and Short Term Disability products. Reporting on data modelling implementation, coordinating model creation with Integrated Analytics and client, respond to claim scoring client queries and Ensure consistent delivery of client training, accuracy of information provided to clients on claim scoring queries. Conducting regular and high quality communication with business partners and management to ensure that claim scoring requirements are clearly understood and documented and that implementation and maintenance plan meets business requirements. Leading claims data science initiatives from research to timely delivery. Training and developing client or others to learn and leverage new modeling tools and approaches. Actively influencing and engaging with analytics teams internally or with clients to ensure consistency and alignment where appropriate for Canada and US claims. Conducting technical quality and operational process reviews with a focus on transforming practices or claim outcomes, eliminating manual processes and finding more effective tools to improve service TATs and claim optimization for clients, MR New Ventures team and Munich Re Responsible for leading the claim department key initiatives that support Munich Re’s new ventures team, Third Party Administration claim liaison, case management flow and processes, and technical responses if necessary Developing and implement strategies to track and improve deteriorating client claim results Delivering on our commitment to improving claim outcomes for clients, adhering to treaty service level agreements and operating within compliance and audit controls. Exploring emerging technology trends with potential data and analytics applicability to our business. Understanding industry-specific and relevant data analytics, business intelligence and quantitative analysis trends and techniques to effectively contribute to the identification of new risk measurements, scoring opportunities, and process enhancements. University degree in STEM discipline; advanced curriculum in Accounting and/ or Business is welcome Medical, Insurance or financial services designation or progression towards is highly desired Experience in a data-related role performing quantitative analysis, modelling, and/or reporting Effectively interprets modelling results, distilling actionable insights and presenting them to partners; excellent attention to meeting time service and achieving deliverables High degree of self-motivation, forward thinking, proven ability to work independently and be a highly effective influencer Ability to build solid, trusted client relationships. Demonstrated flexibility and effectiveness working under tight timelines; proven ability to adapt in a dynamic environment Excellent oral and written communication skills and presentation skills Bilingualism (English/French) is a preferred asset Advanced experience using Power BI or Tableau, Excel (ie: VLOOKUP, IF function, Pivot Tables, etc), and additional Microsoft Suite applications (Access, Powerpoint and Outlook); 
ScrapedJobID477:
Understand client requirements, business processes and data sources and define project objectives accordingly Assist with data identification, data acquisition, data cleansing, data preparation, develop pipelines and databases, validate data including data quality issues and recommend the best course of action Write scripts to analyze data based on business rules for ad-hoc analytics projects and/or development and implementation of reusable data analysis tools Analyze and problem solve issues with current and planned systems as they relate to the integration and management of data In collaboration with others, interpret data and develop recommendations based on findings Prepare exceptions and findings in a clear, concise, and intuitive manner and communicate with relevant stakeholders Identify, analyze, and interpret trends or patterns in complex data sets with graphs, reports using tools such as Python libraries e.g. matplotlib, seaborn Perform statistical analyses including linear, logistics regression and machine learning models for predictive or classification problems Implementation of new features, patches, hotfixes and releases Lead data analysis client engagements, including scoping/budgeting/resourcing, coordinating and controlling project activities Maintaining strong client relationships Demonstrate deep technical capabilities and professional knowledge. Demonstrate ability to quickly assimilate new knowledge. Possess in-depth business acumen. Remain current on new developments in advisory services capabilities and industry knowledge. Bachelor's in Information Management, Computing, Mathematics, Statistics, or related fields 5+ years experience in data analytics, preferably in Banking, Supply Chain, and Retail Experience in Data Analytics and/or Data Management in a Big-4 or similar consulting environment would be a plus Strong programming language experience - Python / R and hands-on experience on data science libraries e.g. Pandas, Numpy, Scikit Experience in ETL, data mining with standard Python tools, Technical knowledge of data models, pipeline and database design development Experience using Oracle or other tools desirable for analyzing large datasets Experienced in Cloud technology and development Strong experience in MS Excel, Access, and PowerPoint Familiarity with visualization tools - Tableau and Power BI Ability to present complex information in an understandable and compelling manner Proven experience of successfully managing and delivering services to large, multi-national clients 
ScrapedJobID478:
Maintain an acute awareness of the industry and what the competitors are putting out. Investigate new options for the system from code to core. Coordinate with Senior Technical Leads regarding AI tech. Coordinate with team members to discover the best solution for the clients. Conceptualize new features that we could offer exclusively. Manage R&D Data Science Developers. 2+ years of Experience in Software Development Education: M.tech or Ph.D. in Computer Science/Engineering preferably with a focus on AI. Strong hold on Data structures and Algorithms. Experience with Anaconda/Python/Tensorflow. French Language skills. Hours: 30-40 hours/week. Wage: $85,000 - $100,000/year. 3 Weeks of Vacation. A great environment and the right tools to do great work. 
ScrapedJobID479:
State-of-the-art offices that are designed to maximize collaboration Flexible working arrangements Enriching challenges that provide opportunity for constant learning and advancement An environment which is leveraging technology to its highest potential Analyze financial news and build machine learning/NLP models for sentiment detection, volatility signals, and other information signals. Apply these models to automated market making for trading and risk management. Collaborate with other quantitative researchers and data scientists to create innovative solutions for the various problems in electronic options market making. Analyze terabytes of equity and options market data to derive actionable intelligence to improve trading performance. PhD in NLP, automated speech recognition, or other closely related field Strong programming skills and experience in a scripting language such as Python Strong interest in quantitative trading and finance Excellent communication skills and ability to interact with traders and technology Knowledge of C++ Exposure to quantitative finance Video dated October 2019. 
ScrapedJobID480:
Collaborate with cross-functional teams (Sales, Marketing, Engineering) to define, design, and ship new features In collaboration with others, design, build and validate predictive algorithms for vehicle prognostics Perform exploratory analyses and develop procedures for feature extraction in preparation for algorithm analyses Participate in software integration work to implement algorithms in production. Work on bug fixing and improving architecture performance Write documentation and present the results of work to others on the team Undergraduate or Master's degree in Engineering, Physics, Computer science or equivalent Good knowledge of statistics, experimental design, and probability 3+ years of experience in Python, R or similar scripting language 1+ years experience shipping high-quality software to enterprise customers Experience with SQL (PostgreSQL or similar) Understanding and experience with machine learning techniques such as Regression, Naive Bayes, Random Forests, Perceptrons, SVM, Deep Learning DevOps experience (Amazon, Google, Docker, Jenkins) Previous startup experience (preferably in an early-stage startup) Knowledge of automotive data, automotive physics or experience in the industry Experience with version control systems (Git, CVS or SVN) Knowledge of other programming languages including node js, C++ Experience with big data frameworks such as Spark, Hadoop. 
ScrapedJobID481:
PhD in Engineering, Computer Science, Statistics or related technical field plus 2 years of work experience in the job offered or related occupation Will accept Master's degree in Engineering, Computer Science, Statistics, or related technical field plus 5 years of work experience in the job offered or related occupation 5 years (or 2 years if PhD) experience with machine learning technologies and rules-based systems 2 years of project management experience across multiple stakeholders 2 years of experience with the entire life-cycle (requirements definition through specification, design, coding, quality assurance, implementation, integration, launch and production support) of a shipped product or online service 2 years of experience producing peer reviewed research reports or publications in the field of machine learning, statistics, or data mining Participate in the design, development, evaluation, deployment and updating of data-driven models and analytical solutions for machine learning (ML) and/or natural language (NL) applications Develop and/or apply statistical modeling techniques (e.g. Bayesian models and deep neural networks), optimization methods, and other ML techniques to different applications in business and engineering Routinely build and deploy ML models on available data Research and implement novel ML and statistical approaches to add value to the business Mentor junior engineers and scientists. 
ScrapedJobID482:

ScrapedJobID483:
Collaborate closely with the Data team improving internal processes. Help marketing and development teams to identify trends and opportunities. Develop advanced learning algorithms and statistical models to solve critical problems and help deliver incredible player experiences. Architect, implement, deploy, and maintain data science intensive applications. Synthesize data from various sources and extract useful information that will lead to improving the player experience, player retention, game design and effective marketing strategies. Extract and organize data into a reliable user-friendly form and present it to the interested and affected parties on the team. Follow up with additional analysis once initiatives have begun to determine success or need for continued improvements. Assist in designing and building business intelligence tools for data mining and reporting. Suggest improvements in tools and techniques to help scale the team. Conduct ad hoc data analysis based on current team needs and management priorities. Mentor other Data scientists with the team. Excellent organizational, communication and interpersonal skills Bachelor’s degree in a technical or quantitative discipline (Mathematics, Economics, Statistics, Computer Science, MIS, other) Minimum 3 years of tried and true statistical analysis and data mining experience A passion for video games and understanding of gaming culture Experience in the gaming industry, specifically Free to Play gaming is a plus In-depth knowledge of Postgres SQL, Mongo DB, Python Notebooks Experience in defining/designing/building/managing a data warehouse is a plus Strong quantitative analysis techniques and qualitative methods, as well as predictive modelling Demonstrated success presenting complex research data (both qualitative and quantitative) in a clear and compelling manner that inspires action Excellent organizational, communication and interpersonal skills Self-starter who can manage their time effectively and has the interest of integrating into a team of passionate, highly intelligent game developing ninjas Competitive salary with bonus opportunities Excellent benefits and paid time off Matching RRSP plan Employee Assistance Program (EAP) Professional development and career support Fitness and parking/transit subsidies Daily lunches prepared onsite by our in-studio Executive Chef and professional kitchen staff All-day snacks and drinks, sleep pods, massage chairs, cold brew, dog therapy days and more 
ScrapedJobID484:
Partner closely with business leaders across the organization to understand current and future business Guide the future direction of data strategy and processes, including intake, sources, database design Transform data and information into insights that inform high-level strategy and tactical decision-making Be a champion for a data driven culture, lead a team of cross-functional analysts and support and train Develop and execute a plan to maximize self-service capabilities for internal users and customers. Proactively communicate and collaborate with internal and external customers to ensure information Oversee internal and external application/tool development, integration and support. Where required, Liaise with HSB US, UK and Munich Re during forecasting business needs and requirements. Implement a formal data governance approach and increase the maturity of the enterprise data Influence and effect business process changes to support an efficient and cost-effective business Masters or bachelor’s degree in Analytics, Business Intelligence, Data Science, Economics, 7+ years as an analyst, data scientist or data engineer preferably in the Property and Casualty insurance Strategic mindset with demonstrated experience in implementing data frameworks and driving Expert communication skills and ability to influence varying audiences and business partners, Experienced people leader with focus on coaching and mentoring cross functional team members, Knowledge of (re)insurance & products, financial metrics used in insurance and industry data sources, Strong teamwork skills in order to collaborate and build strong relationships with co-workers and internal Project management skills including to plan, organize, motivate, and manage resources to achieve Decision making skills and able to solicit and objectively consider input from appropriate sources, and Agility with ability to adapt approaches that are appropriate for each and new situations, 
ScrapedJobID485:

ScrapedJobID486:

ScrapedJobID487:
You will develop novel machine learning methods and algorithms that solve complex problems, including but not limited to, object detection, semantic segmentation, instance segmentation, depth estimation, optical flow, etc. Develop scalable and robust data pipelines that are able to process petabytes of data for model training, and deploy models in production Work fast and smart, and collaborate well with other awesome team members to deliver high-quality perception solutions that power the next generation of mobile robots Recent experience in state-of-the-art deep learning models for computer vision tasks on camera, lidar, radar Strong ML fundamentals and has demonstrated experience building and expanding model architectures Strong SWE fundamentals and has demonstrated SWE experience in both high and low-level languages (Python and C++) Strong research capabilities, track record of publishing papers at top conferences on relevant topics Bonus: Experience in deploying models in real time environments. Optimizing architectures to explore the accuracy vs. compute tradeoff Bonus: Experience working with productizing ML models and the infrastructure supporting model development (data, large scale training, eval, etc) 
ScrapedJobID488:
Supports internal business partners globally by executing tasks outlined in the Global Data Operations Service Catalogue as well as the North America Portfolio Support Service Catalogue. Sets up, maintains, reviews, and validates security masters, brokers, and various reference data elements. Delivers production support tasks accurately and in a timely manner that meets established SLAs. Participates in the data reconciliation processes amongst various internal and external systems. Takes ownership, with some guidance (if needed), on complex escalated position, cash, coupon payment, and security master related reconciliation breaks requiring non-standard research and problem-solving abilities. Maintains an overall understanding of the assigned investment strategy (i.e. cash weights, financial instruments within the portfolio, cash management, etc.) Responsible for cash management support by calculating / verifying current day and net investable cash in multiple currencies for portfolio managers and resolve discrepancies within established deadlines. Participates in the analysis of the characteristics of new instruments to determine the associated data requirements and support procedures across all relevant systems. Participates in Product Shelf changes (e.g. new fund launch, new institutional mandates, portfolio manager change, fund name change, etc.) related activities within Support Services. Liaises with other functions to ensure the integrity of portfolio related data (position, cash, security master, pricing, corporate action, FX, derivatives, etc.) via reconciliation resolution oversight, coordination, and escalation globally. Acts as the escalation point for critical reconciliation breaks Contributes to the production of management reports and executive-level commentaries University degree in Accounting, Finance, Math or business area of concentration or equivalent experience MBA is an asset Certify Financial Analyst (CFA) or Professional accounting designation (CMA, CGA, CA, CPA) is an asset Minimum 3 years' financial services industry experience in a data analysis capacity Strong knowledge of investment products and global security markets is required Knowledge of market data services such as Bloomberg and Reuters is required Must have previous knowledge and work experience with data management applications (e.g. CADIS, Eagle PACE), order management systems (e.g. Charles River, Aladdin), portfolio administration applications (e.g. Eagle STAR, FMC), fund accounting applications (e.g. PAS, Eagle STAR), reconciliation tools (e.g. TLM), and data warehouse platforms (e.g. Eagle PACE) Must have a solid understanding of the end-to-end investment services processes, including but not limited to trade entry, trade process, settlement, security master set up/maintenance, valuation, corporate action processing, fund accounting and reconciliation resolution. Demonstrated ability to process and assimilate data and information into meaningful management and reporting information. Strong interpersonal, conflict resolution, written and verbal communication skills Customer focus and with a keen interest in providing superb services to clients. Strong organization skills and detail orientation, with an ability to understand the big picture and work under pressure with tight deadlines. Strong research, analytical as well as problem-solving skills. Aptitude for mathematical calculations and the ability to analyze detailed numerical data. Good Microsoft Office skills – in particular Excel, Access, Word, PowerPoint, Project, and Visio. Aptitude for learning new technology and adapting to rapid changes Rotating support coverage is required for international markets that are open during statutory holidays Participate in Business Recovery testing on an as-needed basis as defined by the manager Overtime, off-hours support, and travel may be required Staggering shift work is required on a rotational basis and as defined by the manager to provide global business coverage Current hours of business coverage for the North America Team (subject to change to fit global operations coverage needs): Mondays to Thursdays: Eastern Time 7:00a.m. – 8:00p.m, Fridays: Eastern Time 7:00a.m. – 6:00p.m, Sundays: Eastern Time 4:00p.m – 8:00p.m. Temporarily due to COVID-19 
ScrapedJobID489:
An experienced Data Scientist with a passion for digging deep and finding trends that others may miss You can release high-quality, production-ready products. This requires rapid iterations, robust debate, and technical skills. The better you are at writing code, the more efficiently we can release a product that's used daily to make critical decisions. Seen as an active contributor in the team problem-solving-process – you aren't afraid to share your opinions in a low-ego manner You enjoy solving challenging problems, all while having a blast with equally passionate and talented team members You are comfortable and enjoy working with data. This requires a high level of mathematical and statistical literacy and an intense interest in applying quantitative analysis to real-world problems You can extract meaning from data. Our product lives and dies based on the accuracy of our data-driven advice You are intellectually honest, not fooled by randomness, and obsessive about details You are well versed in techniques such as statistical analysis, exploratory analysis, and predictive analysis Rapidly design and implement machine learning and data products that our enterprise customers and internal teams will use to make informed data-backed decisions Design and implement the data and analytics products that are leveraged by our enterprise customers Provide data insights back to the organization in an accessible and end-user friendly manner Collaborate with software engineers, data engineers, and fellow scientists to create the best solutions for our customers internally and externally Work closely with stakeholders and contribute your suggestions to build optimal solutions Implement algorithms with modern software development and delivery techniques Remain up-to-date with the latest trends in data science and bring that knowledge to life in our products and analysis Be flexible to handle other duties as assigned Bachelor's degree in Computer or Data Science, Applied Mathematics, or a similar technical field of study, or equivalent practical experience Minimum of 5 years of experience as a Data Scientist, Data Engineer, or Machine Learning Engineer 3-5 years of experience with Python/Java and SQL as it pertains to Data Analytics / Data Mining Deep familiarity with BI/Data tools such as Tableau, Spark, Snowflake, etc. Familiarity with Kubernetes, C#, Docker, Apache Kafka a plus! Strong background in Machine Learning a must. Focus on recommendation systems, natural language processing (NLP), Bayesian estimation, or reinforcement learning would be a plus. Generous vacation policy, paid holidays, and paid parental leave Competitive Medical, Dental and Vision Plans Downtown Toronto Office in the Entertainment District- easy walk to TTC and Union Station Work from home flexibility Seismic Cares volunteer program #OneSeismic culture that celebrates wins, encourages autonomy, ownership, and transparency 
ScrapedJobID490:
Python, NumPy, pandas and scikit-learn Use of TensorFlow or Keras (caffe, pytorch, torch, mxnet) Deep Learning skills would be an asset 
ScrapedJobID491:
Lead NERv’s data science initiatives. Perform EDA to discover patterns, trends, and insights from extensive sensor data and peripheral data sources. Define analytical experiments in collaboration with R&D teams to validate hypothesis and test potential solutions using statistically-sound methods Train, validate, and test predictive and diagnostic clinical models using machine learning / deep learning algorithms for classification, time series analysis and anomaly detection Interface with various engineering and clinical teams to convert domain expertise into production-ready data science models. Work with the development team to improve NERv’s AI/ML solutions. Prepare technical data reports and summaries for regulatory submissions or external presentations on an as-needed basis. Drive and promote the use of innovative approaches within the organization through publications in scientific peer-reviewed journals and presentations at professional meetings. Contribute actively to IP portfolio by internally disclosing inventions and methods, and supporting patent filing activities. Provide support for clinical trial design. Ongoing evolution of models and regulatory conformance verification and validation. Master’s degree in Computer Science, Data Science, Statistics, or other related fields. 5+ years of experience with Data Science and solving tough data science problems in production. Extensive experience working with Time Series modelling and analysis. Strong knowledge of optimization, classification, clustering, and other ML technologies. Strong experience with Python, especially with its data science libraries. Familiarity with version control tools. Ability to adapt to changing priorities under high pressure situations. Team player, ability to take feedback from all team members. Ability to interpret and distill complex highly technical (Stats/Math/ML/etc.) concepts and explain it to a wide variety of audiences. Strong research organizational skills. Comfortable working in the Jupyter Notebook/Lab environment. Demonstrable experience in translating research outcomes to commercial products. Demonstrable experience in taking ML models/stacks into viable products. Proven excellence in technical and non-technical oral and written communication.  * Experience converting raw data into processed, actionable, insightful information. Demonstrable experience in ML Ops. Experience working with business stakeholders in understanding data analytics and information needs, and executing on transformation of high-level, abstract data needs into meaningful data management solutions, information, and analysis. Experience working with noisy, real-world data from biosensors. Experience with medical device development lifecycle. Experience with the SaMD framework (FDA and Health Canada). Comfortable working with PHI in HIPAA/PHIPA environment. Working knowledge of the healthcare ecosystem (stakeholders, technical jargon, etc.). Familiarity and experience with DataOps. Casual dress Dental care Extended health care Flexible schedule Life insurance On-site parking Work from home Monday to Friday Master's Degree (preferred) Data Science: 5 years (preferred) Temporarily due to COVID-19 
ScrapedJobID492:
Extract, consolidate, and analyze data from various data platforms; deliver insights and actionable next steps based on this data to help guide marketing and product decisions Build internal dashboards, spreadsheets and/or documents to track key performance metrics related to paid marketing and user acquisition Proactively work with agency partners and internal teams to optimize performance based on this tracking Manage paid user acquisition campaigns across mobile, PC, console and digital platforms. Coordinate with agency to set-up campaigns, report performance and work with our production team to identify product features that could support user acquisition strategies Manage mobile marketing agency to ensure campaigns are within budget and following strategic direction Manage in-game advertisers (i.e. Unity Ads, ironSource, Google, etc.) to optimize mobile ad revenue for rewarded videos, offerwalls and other placements Analyze creative performance for ad units to guide marketing and product teams in right direction Assist in creative development with art director, marketing and external agencies Collaborate with marketing, product, finance and sale teams Collaborate with product team to define how insights could have an impact on product features and propose best insight strategies based on product capabilities Identify market trends and insights, analyze competitive landscape, and brainstorm new and creative growth strategies Report to head of game division with dotted line to head of marketing Four (4) plus years of data analyst experience with mobile gaming or related company MS+ in Data Science, Analytics, Statistics, Computer Science or other quantitative discipline or BS in similar Skilled in creating visualizations Experience with large datasets and data cleansing Understanding of statistical concepts and applying them Highly organized, responsible and detail-oriented Ability to collaborate well cross-functionally Experience managing external vendors Financial industry experience/knowledge Developing predictive models Great employee benefits (Insurance package, sick days, etc) Possibility of advancement Dynamic and challenging work environment Training opportunities Team oriented culture Social events and gathering 
ScrapedJobID493:
Improve the efficiency and effectiveness of farming operations Ease collaboration Successfully deploy autonomous farm machinery Develop machine learning algorithms for the perception system, Work with data from a variety of sensors (e.g. cameras, LiDAR, IMU), Adapt state-of-the-art models to run efficiently on edge devices, Develop scalable and robust infrastructure for model training and deployment Prepare reports and presentations on progress, status and results internally, externally, verbally and in writing, Strong background in machine learning, linear algebra, mathematics and optimization, Strong software development skills and experience with C++ and Python, Recent hands-on experience with at least one of the following deep learning techniques: object detection, object classification, semantic segmentation, scene understanding, 3D pose estimation. Experience with common deep learning frameworks (e.g. TensorFlow, PyTorch), Bonus: experience with C++, CUDA and TensorRT development, Bonus: experience deploying deep learning models on embedded systems, 8 hour shift Bachelor's Degree (preferred) Temporarily due to COVID-19 
ScrapedJobID494:
Bachelor Degree (BA, BSc, B Commerce) with major focus on data analytics 4+ years of analytical experience with a focus on data mining, reporting and continuous improvement 4+ years of B2B service industry experience in data analysis role (CDMO experience ideal) Experience with time-tracking, manufacturing data and financial/ERP types of analysis Experience working with software implementations to configure new software platforms and define additional business requirements for new builds Power user in Excel; knowledge of Microsoft Power BI, Microsoft Power Automate and Tableau a major asset; knowledge of programming languages such as Python and R an asset Demonstrated track record of cross-functional expertise, working closely with project managers, functional leaders and executives to both report on current data and propose process improvements Demonstrated track record of strong multi-tasking skills and experience managing complex projects Very strong analytical and data management skills Excellent critical thinking, organizational and time management skills Diplomatic and professional approach in managing diverse stakeholder groups and various internal functions, while maintaining a strong bias to action Strong oral and written communications skills, with a focus on condensing key data into actionable reports, including for purposes of presentation to executives Strong attention to detail, with ability to parse large databases and filter/data-mine critical information Able to work both independently and within a matrixed team environment CCRM is a developing organization and represents a fluid working environment. Flexibility and adaptability are essential, and duties will be influenced by the needs of the organization. 
ScrapedJobID495:
Travail significatif qui favorise le perfectionnement professionnel. Possibilité d’entrer dans l’industrie technologique et de s’y épanouir. Environnement de travail axé sur la collaboration. Équipe de haut niveau. Régime d’assurance collective souple Régime de retraite à prestations déterminées Régime d’achat d’actions du personnel Régime enregistré d’épargne-retraite collectif Programme pour le bien‑être physique Programme d’aide aux employés Prestations de maternité complémentaires Horaire de travail variable « Vendredis Californie » tout au long de l’année Extraire et analyser les données se trouvant dans les bases de données de l’entreprise afin d’optimiser et d’améliorer le développement des produits, les techniques de marketing et les stratégies commerciales. Évaluer l’efficacité et l’exactitude des nouvelles sources de données et techniques de collecte de données. Élaborer des algorithmes et des modèles de données personnalisées à appliquer aux ensembles de données. Utiliser une modélisation prédictive pour accroître et optimiser l’expérience des clients, les revenus générés, le ciblage publicitaire et d’autres résultats opérationnels. Élaborer un cadre de tests A/B pour l’entreprise et mettre à l’essai la qualité du modèle. Coordonner différentes équipes fonctionnelles pour mettre en œuvre des modèles et surveiller les résultats. Élaborer des processus et des outils pour le contrôle et l’analyse du rendement des modèles et de l’exactitude des données. Titulaire d’une maîtrise ou d’un doctorat en statistique, informatique, analyse des systèmes de gestion ou autre domaine connexe. Au moins 5 ans d’expérience en science des données ou en statistiques appliquées. Solides aptitudes pour la résolution de problèmes, et surtout le développement de produits. Expérience dans l’utilisation de langages informatiques statistiques (R, Python, SLQ, etc.) pour manipuler les données et extraire des renseignements de grands ensembles de données. Expérience dans la manipulation d’ensembles de données et l’élaboration de modèles statistiques. Connaissance de diverses techniques d’apprentissage automatique (algorithme Random Forests, remontée de gradient, réseaux de neurones artificiels, etc.) et de leurs avantages et inconvénients dans le monde réel. Connaissance de techniques et de concepts statistiques sophistiqués (MLG/régression, séries chronologiques, propriétés des distributions, tests statistiques et utilisation conforme, etc.), expérience dans leur application. Expérience dans l’utilisation et la création d’architectures de données. Expérience dans l’utilisation de services Web : Redshift, S3, Azure, Spark, DigitalOcean, etc. Expérience dans l’analyse de données provenant de fournisseurs tiers : Microsoft Application insights, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc. Expérience dans la visualisation et la présentation de données pour des intervenants, à l’aide de : Periscope, Microsoft Power BI, Business Objects, D3, ggplot, etc. Penchant naturel pour l’apprentissage et la maîtrise des nouvelles technologies et techniques. Expérience de direction d’initiatives axées sur le client. Expérience de travail dans un environnement Agile, un atout. Excellentes aptitudes pour la communication verbale et écrite en vue de la coordination des équipes. Meaningful work that drives professional development Ability to enter and grow within the technology industry Working in a collaborative environment Being part of a high performance team Flexible Group Insurance Plan Defined Benefits Retirement Plan Employee Stock Purchase Plan Group Registered Retirement Savings Plan (RRSP) Physical Wellness Plan Employee Assistance Plan Supplementary Maternity Plan Flextime California Fridays all year As a member of the Data Science team, you will analyze and synthesize information to understand issues, identify options, and support sound decision-making. You will be generating viable, new approaches and solutions. You have an understanding of applying functional and technical knowledge and skills to accomplish work objectives in an agile environment. As the ideal candidate, you are adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies. Assess the effectiveness and accuracy of new data sources and data gathering techniques. Develop custom data models and algorithms to apply to data sets. Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes. Develop company A/B testing framework and test model quality. Coordinate with different functional teams to implement models and monitor outcomes. Develop processes and tools to monitor and analyze model performance and data accuracy. Have a Master or PhD in Statistics, Computer Science, Business Analytics or a related field Possess at least 5 years experience in Data Science or applied statistics. Strong problem solving skills with an emphasis on product development. Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets. Experience manipulating data sets and building statistical models. Knowledge of a variety of machine learning techniques (Random Forests, Gradient boosting, artificial neural networks, etc.) and their real-world advantages/drawbacks. Knowledge of advanced statistical techniques and concepts (GLM/Regression, Time Series, properties of distributions, statistical tests and proper usage, etc.) and experience with applications. Experience working with and creating data architectures. Experience using web services: Redshift, S3, Azure, Spark, DigitalOcean, etc. Experience analyzing data from 3rd party providers: Microsoft Application insights, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc. Experience visualizing/presenting data for stakeholders using: Periscope, Microsoft Power BI, Business Objects, D3, ggplot, etc. A drive to learn and master new technologies and techniques. Experience leading customer driven initiatives. Experience working in an Agile environment an asset. Excellent written and verbal communication skills for coordinating across teams. Benefits: fully flexible for you to choose what is important Retirement: Defined Benefits Retirement Plan & Group Registered Retirement Savings Plan (RRSP) Financial Perks: Employee Stock Purchase Plan & numerous corporate discounts Personal and Family Programs: Physical Wellness Plan & Supplementary Maternity Plan Work-Life Balance: Flextime & California Fridays all year Fun at work: social and community events all-year round! 
ScrapedJobID496:
Responsible for working with full range of data technologies and architectures including big data platforms, data lakes, object stores, logical and physical data warehouses and multiple analytic frameworks and tools Responsible for implementing a modern data platform using technologies such as cloud data technologies that will enable the consumption of different types of data (semi/non-structured) and integration with external and internal data by the analytics team for the purposes of analytical modeling. Enabling a platform with data ingested from on-premise or cloud technologies to connect, ingest, collect and store various types of data, either in batch or streaming and enable the data to be analyzed, visualized and apply advanced intelligence tools like machine learning and predictive modelling Keeping fluent in the industry and marketplace evolution-staying current with vendor product offerings and common and emerging data solutions in use across the industry. Execute proof-of-concept or innovation oriented technical efforts and projects to evaluate options, prove out the viability of new technologies or approaches. This position will work collaboratively with business and technology stakeholders to establish and maintain the enterprise data reporting architecture, strategy and roadmap and will define, document, and apply business rules to enterprise data. This resource will also assist as needed in the design and development of ETL standards, policies, procedures, and metadata to ensure accuracy, quality, integrity, and optimization of this information. Involved in all phases of the development life cycle right from development of data flow, transformation and loading data using optimized data marts, Analytic visualizations, testing, user acceptance, deployment, and post transition support Provide support with ongoing systems development and business intelligence activities within the assigned function(s). Architecting the growing landscape of interconnected systems, builds efficient and well-maintained data flows and ensures proper documentation and up to date systems. Utilizes standard methodologies, define, and govern BI architecture standards, leads, and supports development efforts Provide user support, resolve incidents, and ensure smooth functioning of data warehousing, analytics, and intelligence processes 6+ years of IT experience including development of large scale, complex data architectures Proven hands-on experience in advanced SQL & SQL Analytics Experience with Data Virtualization, on prem (MS SQL/ ORACLE/ DB2 etc.) & cloud data warehousing technologies (like AWS/ Snowflake/Azure/Google data cloud platform, Cloud data lakes using big data technologies. Experience in data pipelines connecting with different sources of data using JDBC, ODBC, APIs, XML, JSON, file based, streaming data ingesting technologies Exposure to Data science technologies like Python, JavaScript. Jupyter Notebooks using data science frameworks like Tensorflow, Sagemaker, Spark etc. or frameworks Understanding of data security and compliance Exposure to data visualization tools such as Tableau, Looker, Microstrategy, Qlik etc. Ability to adapt to new technologies in the field of data and analytics and data intelligence Creative in problem solving to provide cost effective and scalable solutions Strong team player and interpersonal skills in a multi-national and multi-cultural environment with cross functional and technical teams Willingness to "do what it takes" attitude and self-starter approach with a deep sense of customer/client satisfaction 
ScrapedJobID497:
Work in close partnership with I&A and commercial partners to execute the business analytics agenda using a methodical approach that conveys to stakeholders what business analytics will deliver. Work with best-in-class external partners to leverage analytics tools and processes to bring insights to action Develop custom models/algorithms to uncover signals/patterns and trends to drive long-term business performance Work in close partnership with I&A and commercial partners to execute the business analytics agenda using a methodical approach that conveys to stakeholders what business analytics will deliver. Work with best-in-class external partners to leverage analytics tools and processes to bring insights to action Develop custom models/algorithms to uncover signals/patterns and trends to drive long-term business performance Knowledgeable and highly proficient in using retailer, consumer data, shopper insights and analytics to develop compelling growth plans with BI tools like Nielsen data/applications. Excel, Tableau, PBI, Panel, etc. Drive to help the business realize current opportunities and the curiosity to continuously uncover new opportunities High proficiency in base business tools (Excel/PowerPoint), with expertise in data modelling with data visualization tools In-depth knowledge in analyzing and creating visualizations of large amounts of data Experience in presenting to commercial and leadership teams Strong knowledge and usage of market segmentation models Proven track record in persuasively influencing and aligning key business stakeholders in a highly matrixed organization Able to partner well with marketing, sales and external agencies Strong working knowledge of the Canadian CPG industry and retail environment 
ScrapedJobID498:
Responsible for the design, development, and maintenance of data pipelines and back-end services for data collection and related functions for large external and internal data sources. Manage Automated Unit and integration test suites Support and contribute to master data functions as required during critical junctures Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, Analytics and AI roadmaps, and ensure long term technical viability of new deployments. Infuse key analytics technologies where appropriate including but not limited to SQL Server, Azure Synapse, Azure ML, Azure Cognitive Services, Azure Data Factory, Big Data, Data Lake, Azure Databricks, Power BI Experiment and recommend new technologies that simplify or improve current data ingestion process A key relationship contact for all tools development suppliers including designers and third-party platform investments Indirect support and coaching for total company analytical initiatives and data science acceleration plans Support requests for both the individual and the team’s analysis Post-audit and compliance tracking for all projects and routines Support ad-hoc requests for deep dives and productivity projects Assist in analyzing data, fields, and overall hierarchy to support analytics projects and provide collaborative solutions Key item accountability within routines and rituals including project management, meeting ownership, documentation, cross-functional alignment, and measurement. Development of a continuous list of ongoing process improvement projects. Collaborative mindset Exceptional attention to detail and analytical thinking Strong ability to design effective and efficient data structures and schemas Strong ability for developing for continuous integration and automated deployments Problem solver that finds efficiencies through innovation Customer and Consumer first mindset Affinity for trial & error mentality A/B testing culture support Progress over perfection mentality with usability & simplicity at the forefront of decision making Performance driven with ability to meet deadlines in a fast-paced environment Willingness to learn with a team-oriented attitude Strong Aptitude for learning new technologies and tools Bachelor’s in computer science or related technical field or equivalent work experience 4+ years designing, building and maintaining end-to-end data systems Expert in wrangling large-scale data sets Strong ability to write high quality, maintainable rode in SQL, Python and spark Experience with Databricks, Snowflake a plus Hands-on Experience with leading commercial cloud platform: Azure preferred (services including: Blob storage, ADF, Azure Synapse etc.) Experience in scripting languages 
ScrapedJobID499:
MobSquad solves the significant and growing technology talent shortage faced by US-based start-ups and scale-ups by enabling its clients to quickly have a turnkey "virtual" Canadian subsidiary. MobSquad ensures technology professionals with US work visa challenges remain working with their current company, but nearshore from Canada. This is accomplished via MobSquad's unique partnership with the Canadian Government, enabling work visas to be issued for technology professionals and their respective families within four to six weeks, and Canadian permanent residency within six to eight months. Additionally, MobSquad has unfettered access to top-tier global technology talent which it relocates to Canada and pairs with American as well as Canadian clients on an exclusive, long-term basis, helping firms not only retain their existing world-class technology talent base, but grow it substantially. We're a Certified B corporation, and have made numerous contributions to charitable organizations, as well as a financial commitment to the Upside Foundation. We believe we are playing a key role in enhancing Canada's innovation economy, and have received financial support from the Government of Canada, Province of Alberta, Province of Nova Scotia, and City of Calgary, to support this ambition. For our workplace culture, we were recognized as the 3rd best place to work in Canada (for a small company) in 2020, as well as recognized specifically for being one of the best workplaces nationally for: inclusion; mental wellness; giving back; youth; and technology. We were also recognized as one of the best start-ups to work for across Canada. For our innovative business model, we have been featured in numerous media outlets including: Asian Pacific Post; BetaKit; Bloomberg; CBC; Global News; Gothamist; International Business Times; MIT Technology Review; Nearshore Americas; Nikkei Asian Review; NPR; The Economic Times of India; The Financial Times; The Globe and Mail; The Information; The New York Times; and The Washington Post. Harvard Business School published a case study on MobSquad last fall, and Harvard Business Review featured us multiple times in an article that appeared on the cover of their November/December 2020 edition. You can learn more about us on our website. You have an advanced degree (M.S. or PhD) in Computer Science, Engineering, Mathematics, Physics, or a comparable analytical field from an accredited institution You have over five years of experience working with deep learning frameworks (TensorFlow, Keras) You have over five years of experience with relevant languages (Python, Java) and libraries (scikit-learn, Pandas) You have over five years of experience developing unique algorithms You have strong experience creating and deploying machine learning models You have demonstrated knowledge of relevant libraries and operating systems (OpenCV, Linux) You have knowledge of SQL (MySQL, PostgreSQL) and NoSQL (MongoDB, Cassandra, HBase) databases You have strong attention to detail, translating to strength in data quality verification to enable clean data at all times You have work/project history reflective of a self-motivated professional who excels when given open-ended problems and broadly-defined goals, having an innate desire to build models and algorithms that reveal the patterns and relationships in data that can be leveraged to provide business value A full-time position that offers competitive compensation A benefits program delivered through our bespoke digital platform, giving you control, choice, and flexibility. We give you the ability to build your package of benefits covering health (e.g., medical, dental, vision), wellness (e.g., gym, workout gear, massage, transit), and RRSP (retirement savings) A downtown office location with first-rate amenities, surrounded by great restaurants and easily-accessible transit For international candidates, sponsorship for an immediate work permit, expedited permanent residency, and Canadian citizenship within four years 
ScrapedJobID500:
Strong familiarity with various machine learning & statistical techniques Proficiency in Python Masters/PhD degree or equivalent in a quantitative field 3 years of experience building models from data Experience working with relational data via SQL Ability to work in *nix environments Self-motivated, strong sense of ownership, and adaptable in a fast paced environment Ability to initiate and drive projects to completion with minimal guidance Strong written and verbal communication skills to describe results of analyses in a clear and effective manner Experience with big data technologies such as PySpark and Hadoop Software development experience Experience working with major cloud technologies (AWS, Azure, and GCP) Challenging Work - We love solving highly complex problems. And as the global leaders in our industry, we never stop innovating—our work is never "done. That's because across our teams and in all roles, every employee is empowered to bring their best ideas forward and to jump in and solve the problems they're passionate about. Great People - We take our work seriously, but we don't take ourselves too seriously! It's in our DNA to celebrate, laugh, and have fun. We are stronger, together, when we are open, honest, and above all, real. Every person is valued here and plays an important role in our shared success. Global Impact - As a global team spanning continents, boundaries, and cultures, every day we are inspired by the impact our work has on our colleagues, our customers, our communities, and the world at large. Diversity, Equity and Inclusion - Diversity, equity and inclusion are more than words to us. They are the guiding principles for building a culture where we celebrate each others' differences, continuously strive for equality and recognize that inclusion makes us stronger as individuals, a company and a global citizen. 
ScrapedJobID501:
As a ML engineer, you will design and build large scale ML systems that can process billions of products ML models for wrapper induction that require few training examples, NLP models for understanding free-texts Drive cross functional collaborations with partner teams working on shopping 3+ years of industry experience Hands-on experience on large scale machine learning systems (full ML stack from modelling to deployment at scale.) Hands-on experience with big data technologies (e.g., Hadoop/Spark) and scalable realtime systems that process stream data Nice to have: PhD in Machine Learning or related areas, publication on top ML conferences, Familiarity with information extraction techniques for web-pages and free-texts, Experience working with shopping data is a plus 
ScrapedJobID502:
Maintain an acute awareness of the industry and what the competitors are putting out. Investigate new options for the system from code to core. Coordinate with Senior Technical Leads regarding AI tech. Coordinate with team members to discover the best solution for the clients. Conceptualize new features that we could offer exclusively. Manage R&D Data Science Developers. 2+ years of Experience in Software Development Education: M.tech or Ph.D. in Computer Science/Engineering preferably with a focus on AI. Strong hold on Data structures and Algorithms. Experience with Anaconda/Python/Tensorflow. French Language skills. Hours: 30-40 hours/week. Wage: $85,000 - $100,000/year. 3 Weeks of Vacation. A great environment and the right tools to do great work. 
ScrapedJobID503:
State-of-the-art offices that are designed to maximize collaboration Flexible working arrangements Enriching challenges that provide opportunity for constant learning and advancement An environment which is leveraging technology to its highest potential Analyze financial news and build machine learning/NLP models for sentiment detection, volatility signals, and other information signals. Apply these models to automated market making for trading and risk management. Collaborate with other quantitative researchers and data scientists to create innovative solutions for the various problems in electronic options market making. Analyze terabytes of equity and options market data to derive actionable intelligence to improve trading performance. PhD in NLP, automated speech recognition, or other closely related field Strong programming skills and experience in a scripting language such as Python Strong interest in quantitative trading and finance Excellent communication skills and ability to interact with traders and technology Knowledge of C++ Exposure to quantitative finance Video dated October 2019. 
ScrapedJobID504:
Bachelor’s degree in Data Science, Financial/Accounting, Commerce or a related field and 3 years of recent, related experience*; OR an equivalent combination of education and experience may be considered. A valid BC Class 5 Driver’s Licence or equivalent. Recent, related experience must include a minimum of 3 years in each of the following: Audit and/or accounting experience, for example experience working with accounting principles, auditing standards, information technology and management auditing. Completing complex analysis of large volumes of raw data. A Chartered Professional Accountant (CPA) designation, or Certified Fraud Examiner (CFE) or Certified Internal Auditor (CIA) certification, in good standing. Currently enrolled in one of the above professional programs. Health sector experience. Willingness to conduct field work which includes travel within the province. 
ScrapedJobID505:
Research, explore, implement, and evaluate new machine learning models Implement and compare existing cutting-edge research works to solve business problems Test the model performance with business use cases Build prototype models Publish research papers Produce open-source software and packages Present AI solutions to the business sponsors PhD degree in machine learning or related field or PhD Student Research experience Python experience is preferred Technical and business communication in English Team and technical leadership 
ScrapedJobID506:
Identify business intelligence requirements, interpret, and establish viable data modelling to complete analytical and visualization outputs. Develop visualization tools using Power BI that follow best practices in selection and use of data visualizations to provide insights and support evidence-based decision making. Provide analysis, which may include descriptive statistics, forecasting and/or predictive models Create and maintain report documentation and user guides, ensuring requirements are current, updating manuals, as required and ensuring system users are familiar with manuals and updates. Demonstrate tact and superior customer service skills in interacting directly with key stakeholders and subject matter experts to gather requirements, validate data and provide end-user training in resulting visualization tools (e.g. dashboards, reports). Acting as a consultant, provide expert advice, coaching and feedback on the work of others as it relates to capturing, analyzing, reporting and understanding data and information organization. Work to improve data literacy across the organization. Focus on improving ability to access data & to understand potential insights from data. Support, follow and contribute to information governance and data standards established by the organization. Identify and document opportunities for improvement of data quality. Work in collaboration with decision support and clinical teams to determine root causes and business impacts. Bachelor’s degree is required in the field of computer science, information systems, computer programming, preferably in mathematics, statistical methods, data science, engineering or related field 1-3 years of experience in an analytic role (previous experience in a healthcare setting preferred). Proficiency using Power BI, or other data visualization technology. Excellent oral and written communication skills with demonstrated ability to effectively communicate complex ideas/processes in simple terminology to key stakeholders, including all levels of management. Strong quantitative, analytical, and problem solving skills. Strong ability to manage different stakeholder perspectives and resistance to change. Ability to influence and orient business executives and senior management audiences toward a common goal that is satisfying all stakeholders. Demonstrated experience with validating and auditing data and understanding data governance principles. Results oriented with the work ethic to work independently and undertake tasks needed to accomplish work objectives and deliver quality, consistent and timely results. Experience using SQL or any database query language. Knowledge of analytical tools and technologies (e.g. Python, R). Previous experience with Electronic Medical Records preferred. Proven ability to adapt to changing requests and competing priorities. Demonstrated attention to detail and maintaining high quality standards. Models and promotes core ethical practices while demonstrating Waypoint Values, and reflects an optimistic and positive attitude You must meet the requirements of our COVID-19 Immunization Policy by providing proof of full vaccination, or a request and receipt of an accommodation under the Ontario Human Rights Code, including a medical exemption. 
ScrapedJobID507:

ScrapedJobID508:
Acquire data from primary or secondary data sources and maintain databases/data systems. Compile and processing of data for organizational, hospital and Ministry- level reporting Prepare and submit reports and records relating to activities as appropriate and/or requested Maps data processes and identifies additional requirements to support and meet data requirements Facilitate report design processes to meet current and future data and reporting needs. Identify and define new process improvement opportunities. Address data inquiries and provide data content support, including partnering with colleagues to solve and respond to data challenges. Escalate data and content integrity issues on a timely basis and use discretion when resolving issues within the bounds of assigned duties. Support with the identification and development of policies and procedures related to data initiatives. Work collaboratively within a cross-functional team environment and seek input in identifying and defining business processes as related to data analytics. Support the ICS Team with larger analytics projects and ad-hoc requests Use statistical tools to interpret data sets, for operational, diagnostic, and predictive analytics efforts. Identify, analyze, and interpret trends or patterns in data sets. Assist in the daily organization of the department to maintain a high level of efficiency. Participate in quality activities and continuous improvement initiatives in keeping with the company's Quality Management System. Participate in ongoing internal and/or external continuing education activities. Travel to division locations throughout Ontario may be required. Required to work overtime as needed by projects. Adhere to Bayshore Policies and Procedures. Maintain confidentiality of client and corporate information and discusses same only with appropriate Bayshore personnel. Complies with all Canadian provincial and federal privacy legislation. All other duties as required. 3-5 years of experience in managing data. Clinical/Healthcare experience is preferred. Ability to identify, compile and process clinical and non-clinical data for quality reporting and process improvement. Ability to derive business and quality insights from data. Ability to foster collaboration and shared direction among diverse clinical and non-clinical teams, and stakeholders. Exceptional analytical and information-seeking skills that contribute to improved process management. Self-directed and highly motivated with excellent interpersonal and communication skills. Experience prioritizing competing demands in a fast-paced, multi-site, multi-disciplinary health care environment. Demonstrated critical thinking, problem solving, technical troubleshooting and analytical skills with specific ability to critically think across clinical, business and technology spheres. Knowledge/experience with data visualization methods and technologies using Excel and Power BI. Fluent and computer literate with computer systems such as Microsoft Office applications (MS Word, Excel, PowerPoint & Outlook). Technical Team Leadership Conceptual, Logical and Technical Database Design Solution Definition and Work Estimation Excellent problem-solving skills Excellent communication and presentation skills Strong interpersonal skills and team-based orientation 
ScrapedJobID509:
Run day-to-day activities of a dynamic team of machine learning scientists, to deliver novel, strategic AI-enabled solutions with diverse, industry-leading skills in distributed machine learning training workflows, edge AI, data engineering and tools both in the cloud and on-device. Drive the direction of Paravision’s architecture, data collection, analytics, infrastructure, tools, and learning systems. Review the team’s designs, algorithms, and code while also spending time developing your own. Read papers and attend top-tier conferences such as CVPR, ECCV, ICCV and Neurips. Lead the implementation of SOTA algorithms in computer vision + deep learning using modern frameworks such as Pytorch, Tensorflow and MXNet. Partner with internal stakeholders to ensure the teams' contributions align with company objectives in defining, architecting and building data ingestion systems and model training pipelines from experimentation to deployment, monitoring and continuous performance improvement. Perform full lifecycle of team management to attract, engage, retain, coach and performance manage the team of exceptional engineers (e.g., mentoring, recruiting, training and development, performance evaluation). Actively drive partnership with the Machine Learning team to release models that are top five in the world for accuracy and performance as measured by the NIST FRVT test. PhD in Computer Science or related field with research in machine learning. 5+ years of experience building machine learning or AI systems. 2+ years leading and/or managing technical teams. Expert skills with machine learning software packages (e.g., PyTorch, MXNet, Caffe, scikit-learn, TensorFlow). Expertise in software engineering standards and best practices. Deep understanding of mathematical foundations of Machine Learning algorithms. Experience working with large datasets. You love the idea of coaching and building leaders. You have a passion for enabling and motivating people to do their best work. Strong technical, analytical and quantitative skills with the ability to use data and metrics to back up assumptions, recommendations, and drive decisions. Demonstrated ability to understand and discuss technical concepts, manage trade offs, and evaluate opportunistic new ideas with internal and external partners. An entrepreneurial spirit and comfort working within a rapidly changing startup environment. A track record of creating diverse and inclusive environments and bring experience improving diversity, equity and/or inclusion in your current or past roles. A true passion for technology and thoughtful delivery of next-generation capabilities. Experience collaborating across a multi-national distributed team. Experience working with computer vision in design of APIs and SDKs. Experience working with Openvino, TensorRT, or other inference engines Competitive salary with meaningful equity compensation and excellent benefits. The opportunity to work with a group of highly talented and equally nice people while making a huge impact. Work-life flexibility - we value your contributions above all. A professional environment with a focus on teamwork. 
ScrapedJobID510:
Work with stakeholders throughout the company to source opportunities for creating data-driven products Regularly present and communicate insights to high-level business stakeholders Extract mission-critical insights from datasets Innovate and bring creative ideas to building mission critical customer facing products that depend on data science Work with senior business leaders to identify solutions and best practices Create scalable models that drive business decisions and enable our customers’ success Mentor team members in the areas of technical expertise and career building Develop tools to monitor models for evolving performance and accuracy Contribute to best practices around feature extraction, model development, and knowledge sharing among multiple data science teams Been in the Data Science game for some time. You either have a PhD and 3+ years of experience or your Masters and 5+ years of industry experience. Experience solving nebulous problems using a systematic, analytical approach Proven ability to architect data science solutions to complex problems and delivering solutions in customer facing products A solid understanding of machine learning and applied mathematics in the areas of statistics, linear algebra, optimization techniques, etc Strong programming skills in Python A strong command of SQL and working with multiple relational databases and data warehouses (Redshift, Postgres, Athena, Snowflake, etc…) Experience in end to end machine learning project life cycle The ability to communicate insights through visualizations using libraries such as matplotlib, seaborn, plotly, etc… Experience working with unstructured data Experience with deep learning frameworks such as TensorFlow and PyTorch Are scrappy when extracting useful insights with partial data A solid experience in working with software development teams and using source version control tools like Git Analyzing big datasets using tools such as Apache Spark Developing and deploying using Docker With some of the AWS services (e.g. EC2, S3, Sage Maker, Cloudwatch) On frameworks for in-production ML code (e.g. Kedro) With accessing data from other datastores in the AWS ecosystem such as ElasticSearch, S3, and DynamoDB The BEST team. Remote-first culture. International Meetups. Access to Jungle Scout tools & experts. Performance Bonus. Flexible Vacation. Comprehensive Health Benefits & Retirement Program. 
ScrapedJobID511:
Manage, grow and support a team of BI analysts Support key initiatives in the business by providing data, insights and recommendations Coordinate + collaborate with various teams within Logistics, Product, Data and others to deliver projects Consult with stakeholders on data and technical issues, providing guidance on technical implementation feasibility Build a strong community for all BI analysts around the toolset and best practices 8+ years' experience in analytics or a related role with specific Logistics -experience considered an asset 2+ years of managing teams in a direct line as well as overseeing project management Ability to collaborate with stakeholders across different organizations and geographies to manage change and deliver initiatives Delivering data-driven insights and outcomes clearly and communicating effectively with people of varying levels of data literacy and technical knowledge Comfortable translating business requirements/requests into a technical approach Experience with data and analytics tools such as SQL, Python, R, Google Cloud Platform, Amazon Redshift, etc. Experience visualizing data with common tools such as Tableau, Python, Google Sheets, Microsoft Excel, etc. Experience in design and development of machine learning and data science applications/products at scale considered an asset Experience with version control (ie. Git) and Data Pipeline creation and maintenance (ie. Apache Airflow) considered an asset Sound mathematical and statistical background required 
ScrapedJobID512:
Design, develop, and deploy advanced ML-based image processing algorithms Work closely with a team of software developers to design and develop medical image post-processing software Work closely with regulatory and quality assurance engineers to ensure development of quality software Work closely with scientific advisors and physicians to develop algorithms for solving clinical problems MSc or PhD in Engineering, Applied Mathematics or Computer Science Strong theoretical knowledge, including mathematical foundations of modern machine learning systems and techniques Strong programming skills in Python, TensorFlow and C++ Experience with macOS, Linux, and Windows command line interface Experience with high dimensional medical images considered an asset Experience with DICOM images (MR and CT) considered an asset Peer reviewed publications in top-tier ML or medical image analysis conferences/journals considered an asset Experience with version control tools and Agile development methodology considered an asset Experience with QT, OpenGL, and OpenCV considered an asset Experience in the medical imaging software industry considered an asset Competitive compensation Comprehensive health benefits on day one RRSP matching program Transportation allowance Flexible working arrangements Professional development and tuition reimbursement program Gratifying internal recognition/kudos programs Annual salary review – based on company and individual performance Fun, inclusive, ego-free environment where diversity and individual thoughts are encouraged and valued Company/team building events such as amusement park festivals, outdoor picnics, BBQs, etc. 
ScrapedJobID513:
Provide the Data Intelligence and Governance team with data analyses from researching systems and processes, profiling data via SQL queries, and validating data quality requirements. Identify and partner with data stewardship across the organization to operationalize the Data Governance framework. Champion data governance initiatives by promoting ideas into action; including developing and implementing data quality rules, communication, and adoption strategy. Oversee data quality management and data quality issue prioritization. Assist in developing data governance policies, processes, and documentation. Support corporate data quality initiatives through recommendation for solutions and leadership around data validation. Analyze and understand corporate data across data domains, on both source and target levels. Collaborate with other data analysts from cross-functional teams to address data quality issues and educate data stewardship on data governance principles. Identify new opportunities for data governance continually. You are proficient in data analysis (preferably within software development, data delivery, and data analytics settings). Have a post-secondary degree in Data Science, Computing, Mathematics or Healthcare Informatics (preferably master’s level). Have 5+ years of data analysis experience with increasing responsibility. Are highly knowledgeable in databases and adept in SQL. Have hands-on experience in data visualization tools such as PowerBI. Are experienced with CRM tools such as SalesForce and NetSuite. Are exceptional at rapport building and creative problem solving. Have strong organizational, planning, and prioritization skills. Are goal-oriented, positive, a self-starter, with strong analytical skills. Are a data detective with excellent communication, known for collaborating and your ability to communicate complex data findings to various audiences. Demonstrate a proven track record of delivering results while guiding and facilitating business partners in solving data quality issues. Able to work independently. 
ScrapedJobID514:
Responsible for the design, development, and maintenance of data pipelines and back-end services for data collection and related functions for large external and internal data sources. Manage Automated Unit and integration test suites Support and contribute to master data functions as required during critical junctures Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, Analytics and AI roadmaps, and ensure long term technical viability of new deployments. Infuse key analytics technologies where appropriate including but not limited to SQL Server, Azure Synapse, Azure ML, Azure Cognitive Services, Azure Data Factory, Big Data, Data Lake, Azure Databricks, Power BI Experiment and recommend new technologies that simplify or improve current data ingestion process A key relationship contact for all tools development suppliers including designers and third-party platform investments Indirect support and coaching for total company analytical initiatives and data science acceleration plans Support requests for both the individual and the team’s analysis Post-audit and compliance tracking for all projects and routines Support ad-hoc requests for deep dives and productivity projects Assist in analyzing data, fields, and overall hierarchy to support analytics projects and provide collaborative solutions Key item accountability within routines and rituals including project management, meeting ownership, documentation, cross-functional alignment, and measurement. Development of a continuous list of ongoing process improvement projects. Collaborative mindset Exceptional attention to detail and analytical thinking Strong ability to design effective and efficient data structures and schemas Strong ability for developing for continuous integration and automated deployments Problem solver that finds efficiencies through innovation Customer and Consumer first mindset Affinity for trial & error mentality A/B testing culture support Progress over perfection mentality with usability & simplicity at the forefront of decision making Performance driven with ability to meet deadlines in a fast-paced environment Willingness to learn with a team-oriented attitude Strong Aptitude for learning new technologies and tools Bachelor’s in computer science or related technical field or equivalent work experience 4+ years designing, building and maintaining end-to-end data systems Expert in wrangling large-scale data sets Strong ability to write high quality, maintainable rode in SQL, Python and spark Experience with Databricks, Snowflake a plus Hands-on Experience with leading commercial cloud platform: Azure preferred (services including: Blob storage, ADF, Azure Synapse etc.) Experience in scripting languages 
ScrapedJobID515:

ScrapedJobID516:

ScrapedJobID517:
Architecting, implementing, and stewarding end-to-end data infrastructure Building agent-based simulations of smart contracts and blockchain networks using our Python SDK Designing and optimizing incentive models for blockchain protocols and help discover potential attack vectors Build data models and visualizations of public blockchain data and simulation results that provide intuitive analytics to customers Understand product, risk, and business requirements and how to apply ML to solve our most challenging problems in impactful ways Automating and scaling simulation model deployment on cloud infrastructure Make business recommendations to the executive and cross-functional teams (e.g. cost-benefit, forecasting, experiment analysis) effectively through findings from quantitative information Driving best practices around security in data engineering Driving data literacy and data-driven decision making across functions 8-10 years of relevant experience Experience developing production quality software in Python, Go, or other high-performance languages Experience with scientific computing packages such as Numpy/Scipy, Pandas, etc.. Track record of designing, building, scaling and maintaining production services, and composing service-oriented architecture Experience with distributed computation frameworks such as Spark, Flink, TensorFlow M.S. or Ph.D. in STEM field, with experience building production Blockchain pipelines (development, deployment, inference and monitoring) at scale Smart contract development experience (e.g. Solidity) Experience with building Machine Learning infrastructure at scale 
ScrapedJobID518:
Build security tooling and automation for internal use that enable the Security team to operate at high speed and wide scale. Integrate SAST/DAST in CI/CD and operational pipelines. Conduct research of security tools that can be used in the organization and integrate them as needed. Collaborate with Grammarly team members on security scanning of company repositories. Facilitate developer productivity in security by helping developers fix bugs faster using automated tools. Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable. Is excited by internet security issues, automation, software engineering technologies, cloud architectures, and threat landscape concepts. Has at least 3 years of hands-on software development experience. Can deliver maintainable and high-quality code, preferably on Python or Go, JS. Is familiar with software development methodologies, processes, and tools including version control systems, package managers, and build tools (such as npm, pip, sbt, Gradle or Maven). Is familiar with modern DevOps practices and tools, especially Docker. Is a good communicator with the ability to collaborate effectively, empathetically, and proactively on a tightly integrated team. Has previous experience in networking or network security, cloud orchestration, or Security Operations. Has knowledge of cloud security best practices and vulnerabilities, infrastructure security (bare metal), OS, container, or general application security. Has prior experience in continuous security cycle implementation for web applications. Has experience in software supply chain security. Professional growth: We hire people we trust, and we give team members autonomy to do their best work. We also support professional development with training, coaching, and regular feedback. A connected team: Grammarly builds products that help people connect, and we apply this mindset to our own team. We have a highly collaborative culture supported by our EAGER values. We also take time to celebrate our colleagues and accomplishments with global, local, and team-specific events and programs. Comprehensive benefits: Grammarly offers all team members competitive pay along with a benefits package that includes superior health care. We also offer support to set up a home office, ample and defined time off, gym and recreation stipends, admission discounts, and more. Relocation support: We can help you relocate to Kyiv and make the experience smooth and easy. Grammarly provides a relocation bonus, legal and visa support, temporary housing, moving support and travel expenses, assistance in finding schools for your kids—and all other information you might need. 
ScrapedJobID519:
Build code and models to translate data into actionable insights Design and develop Machine Learning model within Field Services to improve Customer Experience and optimize Field Operations processes Track model performance using appropriate KPIs, metrics and techniques Deliver solutions with measurable results and benefits to the business overall and define key metrics for measuring success of the project Communicate results of analysis and models to stakeholders effectively and confidently Translating business imperatives into data centered questions to be able to quantify and evaluate them Bring in new sources of data by exploring data across Bell and externally Design and expand interactive dashboards Self starter with highly analytical problem solving skills Undergraduate of masters degree in Engineering, Computer Science, Physics, Mathematics, Operations Management/Research, Business or relevant field Experience in using Python and SQL (Hadoop, Microsoft SQL Server, Teradata, SAS, Oracle) to analyze data and gather valuable insights Experience in developing and modifying Hadoop (Spark, Scala, Impala), Python and SQL ETL Processes Knowledge of machine learning practices and experience applying them to real datasets Must be versatile and quick to learn new languages, packages and frameworks Strategic and creative thinker who is exceptionally adept with quantitative and qualitative analysis Ability to leverage insights and opportunities from data and metrics to build strategies and make recommendations Team player with excellent organization and interpersonal skills 
ScrapedJobID520:
Builds effective relationships with internal/external stakeholders. Leads/participates in the design, implementation and management of new analytics & reporting solutions. Designs, develops, and implements calculators and models for liquidity risk measures with innovative analytical solutions . Designs and produces regular and ad-hoc reports, and dashboards. Breaks down strategic problems, and analyses data and information to provide subject matter insights and recommendations. Structures and assembles data into multi-dimensions with various granularities (e.g., customers, products, transactions, financial instruments ). Monitors and tracks tool performance, user acceptance testing, and addresses any issues. Integrates information from multiple sources to enable more efficient processes, enhanced analysis and/or streamlined reporting. Builds reports and visualizations to effectively communicate data driven insights to users for a variety of audiences e.g. visualization solutions of data into reports, graphics, dashboards to illustrate facts, trends, and insights. Develops solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs. Supports development and execution of strategic analytics & reporting initiatives in collaboration with internal and external stakeholders. Develops tools and delivers training programs for use of reporting tools and self-serve analytics by non-analytical end users; may include delivery of training to audiences. Documents and maintain operational procedures and processes relating to analytical and reporting processes. Collaborates with internal and external stakeholders in order to deliver on business objectives. Exercises judgment to identify, diagnose, and solve problems within given rules. Works independently on a range of complex tasks, which may include unique situations. Broader work or accountabilities may be assigned as needed. Typically between 4 - 6 years of relevant experience and post-secondary degree in related field of study or an equivalent combination of education and experience. Knowledge and experience in data preparation, data analysis, and financial modelling and statistical tool sets including but not limited to Spotfire, Tableau, SQL, SAS, R, Python, MATLAB, SPSS, Spark – In-depth . Technical proficiency gained through education and/or business experience. Verbal & written communication skills - In-depth. Collaboration & team skills - In-depth. Analytical and problem solving skills - In-depth. Influence skills - In-depth. Data driven decision making - In-depth. 
ScrapedJobID521:
We are looking for an experienced BI Analyst with experience and skills across the BI spectrum to join our team to support and deliver various analytical dashboards/reports. Gather and document requirements, problems, and opportunities for key reporting needs. Assist BI Lead with development of reporting solutions within PowerBI and SSRS, and aid business teams in refining requirements. Adhere to IT project management standards and procedures, tracking and documenting the various tasks accordingly. Accommodate evolving requirements, risks and issues while meeting targets within reasonable timelines. Collaborate with the IT Infrastructure, Software Development, and other cross functional teams to accurately capture related datasets for reporting. Learn the functionality, operation and business process of internal software applications as it pertains to reporting objectives. Adopt an Agile approach when executing projects from inception to completion Prepare and release report documentation to guide users through report/dashboard definitions and navigation. Design, develop and deploy ETL solutions to capture data for report/dashboard ingestion. Structure data models, visualize information, and publish analytical dashboards/reports. Write SQL queries and formulate DAX calculations to facilitate data analysis, data sourcing and report development. Perform QA and coordinate solution UAT with stakeholders. Troubleshoot dashboard/report issues in a timely fashion and ensure high report/dashboard uptime. Partner with IT and business teams to execute data quality and cleansing exercises. Minimum 4 years of experience as a Business Intelligence Analyst/Developer, Data Analyst, Data Scientist or report developer. Post-secondary diploma or degree in Computer Science, Management Information Systems or a related field is preferred, however, a combination of professional certifications, recognized training and/or experience will be considered. Demonstrated experience with data science, statistical analysis or data mining (e.g. association rules discovery, clustering, classification and regression – predictive analytics) and programming languages such as R, Python would be an asset Candidates for this role must have SQL querying, data analysis and report development experience. Understanding of cloud-based platforms (Azure, Snowflake, others) would be an asset Minimum 5 years in SQL querying and development spanning stored procedures, functions, views, temporary tables, cursors, linked servers, SQL server agent jobs. ETL experience covering package development, data lineage and auditing, loop containers, dynamic SQL, parameter/variable transmission, integration services catalog. Script tasks and extraction of data using APIs would be advantageous. Proficiency formulating Data Analysis Expression (DAX) calculations. 4+ years proven experience or recognized training in Power BI/ SSRS report development including data modelling. Experience in other industry standard tools will also be considered. Familiarity with project documentation and tracking. Exposure to tools such as Team Foundation Server, DevOps and SharePoint. 2+ years experience in Agile methodologies and experience in project-oriented working environments. Minimum 4 years of experience working with the Microsoft BI stack, particularly SQL Server Integration Services (SSIS) SQL Server Analysis Services (SSAS) would be advantageous. Strong communication skills High performing and motivated individual who wants to make a difference Keen to grow one’s understanding of the various functions/operations of the business Business/service oriented, with the ability to create and maintain productive relationships. Influence and engage all levels of stakeholders and support change Strong analytical, problem-solving skills and attention to detail Effective organizational, time management and planning skills Experience working in a team-oriented, collaborative environment, as well as ability to work independently Aptitude for delivering report/dashboard training to small groups 
ScrapedJobID522:
You will be working on cutting edge problems in Deep Learning for Deeplite optimization software stack. Work on architecture-specific neural network optimization algorithms for high performance computing. Design and develop a lightweight and high-performance inference engine for CPUs and microcontrollers. In this role you will have opportunity to develop an inference engine running on many devices. Bachelors, Masters or Ph.D. or equivalent in Computer Science, Computer Engineering, or related field. 4+ years of relevant work or research experience in high performance computing and compiler optimizations. Excellent C/C++ programming and software design skills, including debugging, performance analysis, and test design. Excellent Python skills, and a dedication to writing clean, understandable, testable code with an eye towards maintainability. Experience with optimizing compiler, programming low-level hardware and microcontrollers. Development or research experience in a production compiler (preferably LLVM or TVM) Familiarity with ARM, RISC-V and/or x86 architectures is highly preferred Experience with deep learning runtime frameworks such as ARM-NN, CMSIS-NN, TensorRT, XLA, ONNX Runtime, OpenCL, MLIR is a huge plus 
ScrapedJobID523:
Create dashboards and reports to surface data for different stakeholders, and provide actionable insights supporting key projects and business decisions. Optimize and automate the reporting process to drive efficiency. Identifying opportunities for clients using data and knowledge of industry trends. Proactively look for opportunities to share and empower the Client Success team allowing them to self serve and promote a data-driven culture. You don’t report stats or send out reports – you tell stories backed up by Data. Using the right visualizations, create and share presentations of findings at multiple levels of stakeholders. Bachelor's degree or higher, preferably in a quantitative discipline or social sciences with quantitative research experience 3+ years of experience in web and data analytics Proficient in Tableau Advanced Excel skills Experience using Google Analytics Good understanding of relational database or cloud database and database structures Strong coordination and communication skills both verbal and written Ability and desire to develop processes and procedures where none exists Self-starter who has initiative and is eager to learn Proactive in finding information and solutions and a real problem solver 
ScrapedJobID524:
Drive innovation in our products by designing new capabilities based on advanced analytical techniques Develop prototypes and work with our software development teams to transform them into production level technology Design and implement scalable data pipelines that productionize your prototypes Generate value from a unique dataset that spans HR data across many enterprise level companies through research studies or by creating standardization technology Identify solutions to business problems, and opportunities to create value based on your experience in using statistical techniques Collaborate with stakeholders across the organization to support data-driven business solutions Must have a PhD or Master’s degree in Computer Science, Physics, Statistics, Mathematics or a similar field, as well as extensive experience in quantitative analysis and modelling; if only a Master’s degree is obtained, minimum 3 years’ experience working with different business stakeholders in a comparable work environment 1-2 years’ proven industry experience focusing on data science; experience working in a cloud/SaaS environment with experience on Jenkins and AWS Cloud Services will be strongly preferred Minimum 5 years’ experience working with advanced statistical techniques around hypothesis testing, regression analysis, and machine learning Strong problem solving skills, a passion for the scientific method, and a desire to keep the big picture in mind when connecting technology to business value Minimum 2 years of strong coding skills in Python; knowledge of Scala would be an added bonus Excellent written and verbal communication skills for cross-team collaboration and presenting ideas and results to stakeholders You roll up your sleeves You make it easy You are proud You never stop learning You play to win 
ScrapedJobID525:
Data analysis and pricing of new business quotes. Assist with the development of pricing models and tools. Assist with the development of SQL Server and MS Access databases. Consolidation, evaluation and reconciliation of MS Excel spreadsheets, text files and databases.
Data Quality Review Aid with experience studies for new business quotes. Use of R or Python software required along with MS Excel. Reconciliation and evaluation of data within SQL server or MS Access. Coordinate with external systems to integrate outputs/inputs of AXIS with databases.
Ad Hoc Requests: Assist with pricing model setup, automation of tasks within Excel and other statistical/data manipulations tasks not mentioned. Assist with Longevity pricing as required. Assist with Life Reinsurance modelling in Moody’s AXIS.
Position Requirements
Education Bachelor’s degree from actuarial, mathematical, statistical, data science/similar programs or Actuarial exams along with other bachelor’s degree.
Knowledge Understanding of Linear Regression. High-level knowledge of insurance, reinsurance or life contingencies strongly preferred.
Skills Good communication skills (oral and written). Very strong analytical and problem-solving skills. Ability to deal with other technical professionals (mathematical/actuarial). Highly proficient in MS-Office tools, especially MS-Excel and MS-Access. Experience with mortality forecasting algorithms preferred. Experience with either R, Python or other mathematical/statistical programming languages. Prefer working knowledge of data manipulation inside such languages. SQL and Database knowledge required, such as SQL Server, MS Access or others. Experience with MS Power BI, Tableau or similar is an asset.
Experience Previous work experience, including co-op or summer work term(s) preferred. 
ScrapedJobID526:
Design, implementation and evaluation of machine learning models for Medical Image Analysis (e.g. Generative Models, Vision Transformers, Multimodal Registration, Segmentation, Classification and Anomaly Detection). Writing production level code and deploying ML-powered applications for radiologists Lead junior engineers with technical decisions to deploy software, integrate them with new or existing services Lead and collaborate with experts from across the company to advance data science best practices Educate and guide others on modern applications of data science techniques You will work broadly with our AI team, radiologists, product managers, and support engineers to formulate the business problems as data science and AI problems, build prototypes and implement end-to-end analytics solutions. We are here to provide insights and methods to uplift the quality of the products and services we produce As a senior member of the team, you will have significant responsibility in mentoring team members and contributing to the improvement of team culture and development 4+ years experience in industry level of research MSc/PhD in quantitative discipline (Physics, Mathematics, Statistics, Biomedical/Electrical/Software Engineering, Computer Science) Experienced in Machine Learning and Computer Vision, as demonstrated by previous roles and/or a publication track record Proficient in Python, ML libraries (scikit-learn, TensorFlow, PyTorch) and Image Processing libraries (OpenCV, SimpleITK) Experience with Medical Image Analysis and/or relevant peer-reviewed publications Proven leadership abilities in an engineering environment in driving operational excellence and best practices You are a team player and check the ego at the door - we share a common goal and will work hard together to achieve it You can demonstrate patience and are able to naturally guide, mentor, and collaborate with team members and cross-functional departments Nice to have:
Familiarity with web development (e.g. Flask, Serverless) and deployment (e.g. Docker) and cloud services (e.g. AWS)
Experience with MRI image reconstruction Familiarity with web development (e.g. Flask, Serverless) and deployment (e.g. Docker) and cloud services (e.g. AWS) Experience with MRI image reconstruction An avenue to make a positive impact on people's lives and their health We believe in preventative healthcare for everyone, including our team - Prenuvo provides free, whole-body scans to each team member and/or your loved ones Growth opportunities are at the heart of our people journey, we’re doing big things with bright minds - there is no single path to success, it can be shaped along the way Building strong relationships is at the core of everything we do - our team gets together each week to connect, share, and socialize with “Beef Dip Wednesdays”, a tradition that began with our founder’s affinity for local delivered eats Daily health at Prenuvo means having space to take a break and refuel - we keep our break room stocked with coffee and healthy snacks Recognizing time away to restore is vital to our wellbeing - we have a flexible vacation policy and we will encourage you to use it We offer a comprehensive benefits package including health, dental, vision, including Mental Health coverage, and an Employee and Family Assistance Program to support you and your family 
ScrapedJobID527:
Responsible for refactoring Distribution Optimization algorithm written in Python using Object Oriented Programming Work with client stakeholders to understand key business problems, determine solution requirements, build statistical / ML / predictive models, and fine-tune for accuracy Successful compilation of results from various what-if scenarios using client’s data science platforms; support client’s Decision Science team to deliver the simulation solutions to the business teams were performed Ensure models are deployed and deliver projected business value Work as part of a global team to solve problems in a computationally efficient manner Model documentation – providing details where enhancements, bug fixes, or other modification 5-10 yrs of optimization background with an extensive knowledge and experience in OOP using Python Experience and knowledge on heuristic optimization and other optimization techniques Maintaining and supporting optimization models developed by other data scientists Creation of delta analysis for various what-if scenarios Ability to engage with the client stakeholders to understand business problems, ideate & converge on solution approach and develop analytical solutions Ability to work with global teams and communicate effectively Graduate degree in Operational Research, Data Science or Data Analytics or a relate quantitative field 
ScrapedJobID528:
Extract, consolidate, and analyze data from various data platforms; deliver insights and actionable next steps based on this data to help guide marketing and product decisions Build internal dashboards, spreadsheets and/or documents to track key performance metrics related to paid marketing and user acquisition Proactively work with agency partners and internal teams to optimize performance based on this tracking Manage paid user acquisition campaigns across mobile, PC, console and digital platforms. Coordinate with agency to set-up campaigns, report performance and work with our production team to identify product features that could support user acquisition strategies Manage mobile marketing agency to ensure campaigns are within budget and following strategic direction Manage in-game advertisers (i.e. Unity Ads, ironSource, Google, etc.) to optimize mobile ad revenue for rewarded videos, offerwalls and other placements Analyze creative performance for ad units to guide marketing and product teams in right direction Assist in creative development with art director, marketing and external agencies Collaborate with marketing, product, finance and sale teams Collaborate with product team to define how insights could have an impact on product features and propose best insight strategies based on product capabilities Identify market trends and insights, analyze competitive landscape, and brainstorm new and creative growth strategies Report to head of game division with dotted line to head of marketing Four (4) plus years of data analyst experience with mobile gaming or related company MS+ in Data Science, Analytics, Statistics, Computer Science or other quantitative discipline or BS in similar Skilled in creating visualizations Experience with large datasets and data cleansing Understanding of statistical concepts and applying them Highly organized, responsible and detail-oriented Ability to collaborate well cross-functionally Experience managing external vendors Financial industry experience/knowledge Developing predictive models Great employee benefits (Insurance package, sick days, etc) Possibility of advancement Dynamic and challenging work environment Training opportunities Team oriented culture Social events and gathering 
ScrapedJobID529:
Build the best cloud-based AI/ML solutions to power intelligent enterprise services Collaborate daily with a team of like-minded developers, product managers and quality engineers to produce quality software Work with product owners to understand detailed requirements and own your code from design, implementation, testing and delivery of high-quality solutions to our users 5+ years of related experience with a Bachelor's degree; or 3 years and a Master's degree; or a PhD without experience; or equivalent work experience Expertise in Java or Python, OOP, Design Patterns, time and space-efficient algorithms Experience building new products that use challenging algorithms Expertise in coding efficient, object-oriented, modularized and quality software Knowledge of core AI/ML techniques and algorithms Knowledge of unit testing, profiling, and code tuning 
ScrapedJobID530:
Identify and translate data into descriptive analysis with actionable insights by performing data cleansing and feature selection effectively Design and perform extensive statistical analyses to seek opportunities to improve current operations and financial modelling accuracy Develop A/B testing framework and test model quality Create and maintain interactive data visualization through data interpretation and analyses, integrating various reporting components from multiple data sources Build scenario simulation and other data visualization tools to inform business and operational decision-making processes Support and enhance of existing reports and dashboards based on evolving business needs Assess the effectiveness and accuracy of new data sources and data wrangling techniques Support ad-hoc analyses with decision-grade quality Assist in facilitating hands-on sessions in prioritizing user-stories, designing analytical approaches, running experiments, and assessing data product performance Prepare compelling, meaningful and memorable messaging and presentations to address business questions (both written and verbal) Have an open mind and a knack to collaborate effectively across internal and external partners to further capitalize on data assets Handle ambiguity and apply first principles with structured approaches to solving problems Apply design- and system-thinking concepts with an agile mindset to create and deploy incremental, viable data products by leveraging tools available in-house and in the open-source ecosystems Bachelor degree with exceptional academic standing, and/or master degree(s) in an analytical discipline such as: mathematics, applied science and engineering, physics, computer science, management analytics, data science 2+ years of professional experience in analytics or other quantitative disciplines 2+ years in VBA, SQL, Python/R…nice to have (Power BI, MS SSRS, Azure, and API design) Experience in modeling and analysis including statistical analysis, operations research, business analysis, data mining, and machine learning Experience in problem solving and analytical skills to develop creative, unique and pragmatic approaches and solutions to address complex problems Proven analytical and quantitative skills to back up assumptions, develop business cases, and complete root cause analyses Business domain knowledge in one or more of the following: Sales, Call Center Operations, Billing and Collections, Accounting and Finance Experience cleaning, transforming and visualizing large data sets working with various data formats such as unstructured logs, XML, JSON, flat files, audio, image is a plus Excellent verbal and written communications skills Experience working in a fast pace environment is a plus 
ScrapedJobID531:
Applies in-depth disciplinary knowledge, contributing to the development of new techniques and the improvement of processes and work-flows. Coordinates and contribute to the objectives of data science initiatives and overall business through leveraging in-depth understanding of how areas collectively integrate within the sub-function. Assumes informal/formal leadership role through coaching and training of new recruits. Significantly influences decisions, work, and performance of all teams through advice, counsel and/or facilitating services to others in the business. Conducts strategic data analysis, identifies insights and implications and make strategic recommendations, develops data displays that clearly communicate complex analysis. Mines and analyzes data from various banking platforms to drive optimization and improve data quality. Delivers analytics initiatives to address business problems with the ability to identify data required, assess time & effort required and establish a project plan. Consults with business clients to identify system functional specifications. Applies comprehensive understanding of how multiple areas collectively integrate to contribute towards achieving business goals. Consults with users and clients to solve complex system issues/problems through in-depth evaluation of business processes, systems and industry standards; recommends solutions. Leads system change process from requirements through implementation; provides user and operational support of application to business users Formulate and define systems scope and objectives for complex projects through research and fact-finding combined with an understanding of applicable business systems and industry standards. Impacts the business directly by ensuring the quality of work provided by self and others; impacts own team and closely related work teams. Considers the business implications of the application of technology to the current business environment; identifies and communicates risks and impacts. Drives communication between business leaders and IT; exhibits sound and comprehensive communication and diplomacy skills to exchange complex information. Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. 5-8 years experience using tools for statistical modeling of large data sets Ability to effectively use complex analytical, interpretive and problem solving techniques Demonstratedinterpersonal, verbal and written communication skills Bachelor’s/University degree or equivalent experience 
ScrapedJobID532:
Apply knowledge of programming, math, statistics, and machine learning to build solutions for recognizing patterns in the real-world data, organizing information, extracting entities and discovering relations between them, leading to prototype development and product improvement Use an analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data Work with engineers to translate prototypes into new products, services, and features and provide guidelines for large-scale implementation Extend, develop, program, and implement new algorithms University Degree in Computer Science University Degree in Computational Linguistics, Computational Biology, Statistics, or Applied Math, and 2+ years of industrial experience as Software Engineer/Developer PhD in AI or another quantitative field and 1+ year of hands-on experience programming machine learning based solutions to real-world problems MSc in AI or another quantitative field and 4+ years of hands-on experience programming machine learning based solutions to real-world problems 5+ years of total programming experience in industry or research Ability to write production-quality object-oriented code in at least one of the modern OOP programming languages (e.g. Python, JavaScript, Java, C++, Scala, C#) Basic knowledge of SQL, ability to write selects with joins An open mind; desire to learn the best language/technology to solve a given problem Deep understanding of machine learning theory and practice (feature engineering, regularization, hyperparameter tuning, ensemble methods, neural network architectures) Expertise in data analysis (experiment design, classification, regression, unsupervised methods) Knowledge of core computer science concepts such as data structures and algorithms, OOP, code profiling/optimization Detailed knowledge of at least one popular deep learning library, proven ability to implement in practice neural network architectures described in literature Proficiency with regular expressions and other deterministic methods for processing text as well as experience in practical NLP is a plus Ease with Linux Good English; a level of French sufficient for work-related discussions “Hacker” attitude: hunger for resolving enigmas, finding solutions to riddles and facing uncommon challenges Readiness to work in uncertainty regarding the resolution of a problem, the existence of means to resolve it and, sometimes, in the absence of precise objectives Autonomous and responsible; organized and structured in initiatives and work Detail-oriented and able to keep a global vision of the issues and their solutions Positive attitude, friendliness, and generosity 
ScrapedJobID533:
Ability to createcomplex, insightful interactive reports Ability to identify and develop KPIs and executive level dashboards Development of advanced Power BI solutions utilizing various data sources (on-premise / cloud) Knowledge of creating tabular model datasets for ad-hoc querying Aptitude for distilling complex data problems into easily understood visualization solutions Perform data analysis and source to target field mappings Excellent spoken and written communication skills Ability to work directly with clients to elicit requirements and iteratively develop reporting solutions Strong business analysis and data analysis skills In depth understanding of data warehousing, dimensional data modelling, and other core BI concepts 5+ years authoring Power BI reports and implementing industry best practices for visualizing data 3+ years designing and developing Tabular Modeling solutions utilizing tools such as Power Query, SSAS (Tabular), Azure Analysis Services, and Power BI Data Flows 5+ years writing complex SQL and T-SQL queries 3+ years authoring operational/paginated reports utilizing tools such as SSRS or Report Builder 2+ years with SQL Server Integration Services (SSIS) Experience authoring and facilitating custom training material to clients Azure cloud experience in particular Azure Data Factory, Azure Dake Lake, Azure SQL, and Azure Synapse Analytics Experience with other business intelligence reporting toolsets such as Cognos, Tableau, Qlik, etc. Experience developing and supporting SQL Server Analysis Services OLAP cubes Experience with common data science toolkits, such as Python, R, Weka, NumPy, MatLab, etc. Advanced Analytics (ML / AI) experience such as Classification models, k-NN, Naive Bayes, SVM, Decision Forests, etc. University or college degree, or equivalent experience Strong Business Analysis and Data Analysis skills Other systems development experience Technical background with proven trouble shooting skills Adept at delving into systems to find the true root cause for the issue at hand Strong organization and analytical skills with excellent attention to details Ability to work independently on multiple simultaneous tasks within a challenging fast paced team and customer-oriented environment. 
ScrapedJobID534:
Maintain an acute awareness of the industry and what the competitors are putting out. Investigate new options for the system. Coordinate with Senior R&D R&D regarding tech. Coordinate with team members to discover the best solution for the clients. Conceptualize new features that we could offer exclusively. 1+ years of Experience in Software Development Education: BSc or M.tech in Computer Science/Engineering preferably with a focus on AI. Strong hold on Data structures and Algorithms. Experience with Anaconda/Python/Tensorflow. French Language skills. Hours: 30-40 hours/week. Wage: $70,000 - $80,000/year. 2 Weeks of Vacation. A great environment and the right tools to do great work. 
ScrapedJobID535:
Influences the strategic direction of the brand by communicating data-derived insights and recommendations aligned to the needs of the business Builds and maintains patient flow and trend-based forecast models
Manages the forecasting process and gains alignment on forecast assumptions and scenarios with cross-functional partners
Work with global Takeda partners to design and refresh forecast models Manages the forecasting process and gains alignment on forecast assumptions and scenarios with cross-functional partners Work with global Takeda partners to design and refresh forecast models Creates and maintains dashboards and scorecards, primarily in Power BI, as well as insights presentations in PowerPoint
Defines key performance indicators in consultation with cross-functional partners to deliver meaningful and actionable findings
Creates Power BI dashboards both self-sufficiently and, where required, in partnership with vendors and commercial IT
Drives business unit adoption of insights and self-serve analytics Defines key performance indicators in consultation with cross-functional partners to deliver meaningful and actionable findings Creates Power BI dashboards both self-sufficiently and, where required, in partnership with vendors and commercial IT Drives business unit adoption of insights and self-serve analytics Support omni-channel analytics through delivery of reporting, insights and measurement Analyzes data to answer brand team questions and conducts self-driven exploratory analysis Effectively collaborates with Customer Excellence team members to deliver on salesforce effectiveness requirements including: territory design, targeting/call planning, resource allocation, incentive compensation and segmentation Develops and maintains a thorough understanding of the therapeutic area Partner with vendors on primary and secondary market research to understand customer journeys and current brand utilization as well as to guide future strategy Degree in applied sciences, statistics, mathematics, data science or medical sciences an asset High level of analytical skill and problem solving ability Proven ability to work both self-directed in a fast-paced, complex environment as well as collaboratively with both internal and external partners Demonstrated strategic and critical thinking Experience with quantitative reasoning and making evidence-based recommendations Experience in business intelligence and analytics, including:
Forecasting model development, execution and communication of outputs
Market insights synthesis, KPI creation and dashboard design
Sales force effectiveness (territory design, segmentation, salesforce sizing, incentive compensation) Forecasting model development, execution and communication of outputs Market insights synthesis, KPI creation and dashboard design Sales force effectiveness (territory design, segmentation, salesforce sizing, incentive compensation) Excellent Excel and Power BI capabilities
Python, SQL, R, language proficiency and experience with Databricks an asset Python, SQL, R, language proficiency and experience with Databricks an asset Strong communication and presentation skills, have the ability to communicate with impact the ‘so-what’ of complex analytics to non-technical audiences Excellent interpersonal skills, ability to build relationships across departments Ability to understand complex therapeutic areas and clinical/scientific data an asset Basic project management and ability to lead productive meetings with large groups Proficiency with Canadian pharmaceutical data sources such as IQVIA (previously IMS) and knowledge of Canadian pharmaceutical industry an asset Willingness to travel to occasional company meetings, including overnight trips in Canada, US, and Europe (<10%). Note for COVID-19: subject to company travel policies, currently all non-essential international and domestic travel is suspended until the end of 2021. 
ScrapedJobID536:
Working closely with other data scientists and developers in building and deploying various machine learning models for Global Relay's customers Being a subject matter expert on current speech transcription and speaker identification techniques Interacting with product managers on enhancements to our core products Executing all steps in the data science process from understanding business requirements to deploying models Producing reports detailing model performance 5+ years of experience with solving machine learning/speech recognition problems Experience working with very large data sets in an enterprise-wide application environment Knowledge of signal processing methods for audio processing and time series analysis An understanding of different neural network architectures as applied to speech recognition such as: Attention-based models, RNNs and CNNs Python, Bash and C++ experience Knowledge of common machine learning libraries such as: Scikit-learn, TensorFlow, PyTorch, HTK, Kaldi, Julius, Sphinx and others Strong organizational and communication skills MSc or PhD in a STEM or Linguistics subject Data collection and cleaning experience Data engineering skills Experience building acoustic or language models for speech recognition Experience with:
Natural language processing models
Kubernetes and micro services
Working in an agile development environment Natural language processing models Kubernetes and micro services Working in an agile development environment 
ScrapedJobID537:
Identify trends reaching meaningful conclusions that will advise strategic business decisions through the manipulation of large data sets Work closely and communicate effectively with Partners to understand requirements and formulate analytics solutions Design and implement analytics models and visualizations to provide impactful data insights Develop and maintain scalable data transformation code Evaluate new capabilities of the analytics platform, develop prototypes and assist in drawing conclusions about the applicability to our solution landscape Assist partners with data-related functional and technical issues Make use of statistical tools to interpret data sets, paying attention to trends and patterns that could be valuable for diagnostic and predictive analytics efforts Create appropriate documentation that allows others to understand the steps of the data analysis process and duplicate or replicate the analysis Engage with management to prioritize business and information needs Bachelor's degree or equivalent in Computer Science, Data Science or related quantitative field (Applied Mathematics, Engineering) At least 5 years demonstrated ability working with large-scale software systems Passionate about data and problem solving Proficiency in Python, R, and SQL with the ability to query and analyze data and understand data complexity, models and structures Solid experience working with large data sets on enterprise data platforms and performing tasks such as managing data transformations and machine learning models Good experience in Reporting and Visualization tools such as PowerBI, Tableau Solid understanding of Database Design and Data Warehousing concepts Demonstrated analytical skills, including mining, evaluation, analysis, and visualization Effective verbal and written communication skills. Should be able to adapt communication style to suit different audiences. Established interpersonal skills for work internally across departments, as well as with clients. Ability to work in a highly collaborative environment as well as independently with minimum supervision Knowledge of insurance / reinsurance Experience using Pyspark scripting 
ScrapedJobID538:
Apply established statistical methods and techniques to analyze and interpret data. Identify the appropriate method of statistical analysis and apply statistical techniques to interpret data. Compile and analyze data and interpret trends, fluctuations, and other changes that may emerge. Develop forms and procedures required for the collection and compilation of data. Devise and implement administrative procedures for the collection of data. Oversee the design and maintenance of databases, data collection forms, error checking methods, and related programs for collection, analysis, and reporting. Design database specifications and modify existing software packages to meet specific research project needs. Document new designs, codes, and modifications. Develop test cases and test system upgrades and enhancements. Write sections of scientific papers, funding proposals, grants, and abstracts. Identify and resolve database and software problems. Conduct data audits, compile results, analyze and summarize audit findings. Coordinate and manage the collection, delivery, entry, verification, analysis, and reporting of data. Provide advice regarding data collection and analysis required for research projects. Recommend modifications to processes related to data collection and data entry conventions and develop implementation plans. Apply specialized knowledge and scientific principles to review, critically appraise and interpret published literature. Research pertinent literature in a designed project area and analyze the applicability of the concepts. Review case report forms, determine possible protocol deviations, discrepant data, and inconsistent reporting. Facilitate meetings and prepare recommendations on statistical and reporting strategies. Exchange information with colleagues and statistical experts. Explain statistical approaches to others who do not have the equivalent knowledge in statistical methods. Develop and deliver presentations and training sessions. Safeguard the confidentiality of study data. Develop, maintain, and/or optimize open source data digitization pipelines that convert source documents into tidy datasets that are ready for epidemiological modelling and analysis Oversee and implement data management best practices, to ensure that digitized data are FAIR ( https://fairsharing.org ) Build quality assurance pipelines that can be used to detect and correct errors of data entry and processing, as well as detect cases for which the sources themselves likely contain errors Develop data pipelines that connect our historical data to existing online streams of current data Build and maintain an API for programmatic access to digitized data Build R and/or Python packages – sitting on top of this API – designed to take digitized data as inputs to modelling and analysis projects (e.g. time-series visualization, missing-value imputation) Develop and/or integrate with web applications – also sitting on top of the API – to provide data searching, visualization, and download capabilities without the need for coding Build a containerized open tool chain that provides a computing environment that is set up to access curated epidemiological data and connects it with a suite of open source analysis tools Unix/Linux command line Version control with git and GitHub Regular expressions Docker Python/Jupyter Javascript C/C++ Statistical modelling Epidemiological modelling Data visualization Human Resources Service Centre at 905-525-9140 ext. 222-HR (22247), or Faculty of Health Sciences HR Office at ext. 22207, or School of Graduate Studies at ext. 23679 
ScrapedJobID539:
Participate in client meetings and assist in identifying client needs; help to recommend solutions from among EA’s data, software and advanced marketing capabilities to meet those needs. Design and build analytical files and analytical frameworks for client projects. Analyze, interpret and communicate the results of the analytical solution. In conjunction with the model development team participate in the development and validation of predictive models. Summarize data in tables and charts, interpret the data, looking for relevant insights and write reports in support of client objectives. Prepare and present Powerpoint presentations of research results including extensive use of data visualization. Manage projects from start to finish, managing timelines while maintaining a high level of quality. Work closely with other staff in Client Advocacy, Client Services, Standard Research, Custom Research and Sales to meet client requirements. Other duties as required. Education - Post-secondary degree in Geography, Business or related field Experience - Minimum of 2-4 year of relevant experience in Data Science Technical Skills – Possesses programming skills to allow for self-sufficiency in handling data (Alteryx, SQL, SAS, SPSS). Expertise in all Microsoft applications (Word, Excel, Powerpoint). Must be comfortable working with large quantities of data. Intermediate to advanced skills in Excel and Tableau are required. Analytical Skills – Effectively researches and synthesizes complex or diverse information; uses intuition and experience to complement data and designs work flows and procedures. Judgment - Displays willingness to make timely decisions, including appropriate people in the decision-making process and exhibits sound and accurate judgment; supports and explains reasoning for decisions Planning/Organizing - Prioritizes and plans work activities effectively. Ability to multi-task. Teamwork - Balances team and individual responsibilities; Exhibits objectivity and openness to others' views, giving and welcoming feedback. Puts success of team above own interests and demonstrates ability to build morale and group commitments to goals and objectives. Supports everyone's efforts to succeed. Innovation - Displays original thinking and creativity and meets challenges with resourcefulness. Generates suggestions for improving work. Presents ideas and information in a manner that gets others' agreement. Communication Skills – Able to clearly communicate ideas and expectations. Effectively listens for understanding and asks questions for clarification. Presents ideas effectively in both verbal and written form. Interpersonal Skills – Approachable and easy to talk to. Relates well to all kinds of people in the organization. Able to effectively build rapport with others. Uses diplomacy and tact. Maintains composure and shows an ability to resolve conflicts and gain agreement. Client Focus – Dedicated to meeting the expectations and requirements of clients and acts with the client in mind. Establishes effective relationships and gains and maintains the trust and respect of clients. Presentation Skills – Able to create and deliver informative, compelling presentations that capture and keep the audience’s attention – both in person and via Teams. Uses a strong voice, consistent eye contact, and exudes a confident presence. Observes the reactions of the audience and adjusts tone, pace, style and content to address any issues. 
ScrapedJobID540:
Prototype, develop and deploy CV models that find the best placement opportunities with a focus on video classification, action recognition, image-audio consistency and video analytics. Build and maintain production-ready CV code that analyzes thousands of hours of video content. Research state-of-the-art solutions for video content understanding and apply them to our products. Build new products and workflows in collaboration with TripleLift's Product and Engineering teams Ship reliable, scalable, efficient, and elegant code Hands-on experience with deep learning algorithms like CNN, RNN, GAN or VAE. Demonstrated experience with Tensorflow/Pytorch/MXNet/Keras. Deep understanding of computer vision, image processing, computational photography and 3D geometry. Mathematical knowledge of linear algebra, optimization, statistics and probability. 3+ years of experience with OpenCV/Dlib/Scikit or other computer vision processing library 3+ years of experience with FFMPEG or other video processing tools Experience shipping production code Strong communication skills, particularly in conveying technical concepts in a manner that is easy for clients and non-technical partners to understand Ability to work under intense pressure and multitask in a fast-paced start-up environment M.S., or Ph.D in Computer Science or equivalent experience 
ScrapedJobID541:
Responsible for server side applications Analysis, Design & Development. Collaborate with business partners on the trading floor to create performant applications that deliver real time insights on millions of data points. Responsible for creating high throughput applications leveraging existing Citi Big data framework, Part of an innovative team pursing boundaries to create innovative data visualization solutions. Ability to take initiative to research, learn and recommend emerging technologies. Be part of a dynamic group working towards a common goal. Work with developers onshore, offshore and matrix teams to implement a business solution Proficiency in Java or Python. Experience with customer analytics. Relish tackling new challenges, paying attention to details, and growing professionally. Basic shell commands and shell scripting. Adapts machine learning and deep learning technologies to the finance products Strong familiarity with machine learning and statistical techniques Knowledge and experience of distributed computing Knowledge of advanced statistical techniques and concepts. Extensive hand-coding expertise in Core Java development Experience with PySpark/Pandas and related data analytics libraries Adapts machine learning and deep learning technologies to the finance products Experience with messaging systems like Kafka & EMS (Solace, Tibco) Experience in Hadoop framework with good understanding of HDFS, Hive, HBase, Spark 
ScrapedJobID542:
Demonstrate the ability to work independently and collaboratively with other groups and functions Be a self-starter and can-do team player who is willing to roll-up the sleeves and do whatever is needed to move projects forward Have the ability to innovate and embrace the Aviva values of Commitment, Community, Confidence and Care Be results-oriented and demonstrate a sense of urgency and accountability for business issues Develop and deploy new risk analytics models that enhance business understanding and drive proactive decision-making Develop, enhance and manage data pipelines Analyze data and produce interactive visualizations to present to various business stakeholders Build harmonious relationships with business stakeholders to ensure that integrated, high quality and long-term tools/solutions are provided Continuously innovate to bring cutting-edge technology in a meaningful and seamless way to achieve the company’s strategic objectives 1+ years of experience in general insurance industry including predictive modelling and working with large datasets . Experience in developing non-linear models within a machine learning framework is preferred. Cross-functional skills that allow you to straddle the worlds of data scientists and actuaries, to bring innovation to model-acceptance processes, model-monitoring practices and end-to-end automation Programming and problem-solving skills to develop, test, validate, and maintain robust tools/models (Python experience in particular) Bachelor’s degree in Computer Science, Actuarial Science, Data Analytics, Statistics, Finance, or other related field or equivalent experience Competitive rewards package including base compensation, eligibility for annual bonus, retirement savings, share plan, health benefits, personal wellness, and volunteer opportunities. Exceptional Career Development opportunities. We’ll support your professional development education. 
ScrapedJobID543:

ScrapedJobID544:
Post-secondary education in a related field. An understanding of low-level implementation of neural networks. Excellent C/C++ programming and software design skills, including debugging, performance analysis, and test design. In-depth understanding of computer processor architecture. Development or research experience with deep learning runtimes/compilers and related ecosystem, such as TensorFlow, PyTorch, MXNet, ONNX Runtime, TVM. Development or research experience in a deep learning runtime/compiler is a huge plus Ability to write custom kernels in a production runtime/compiler (such as ONNXRT, TVM, TNN, etc.) Curiosity and willingness to continually learn new things and propose new ideas. Experience of low-level algorithm implementation for faster computation, knowledge, and experience with fast computation libraries like BLAS, cuDNN etc. is a strong plus. 
ScrapedJobID545:
People Leader: You will hire, train, motivate, assign responsibilities, and hold people accountable. You will oversee a team of 8+ analysts and engineers and will design the future structure of the team. You will compare actual versus expected deliverable at high frequencies, and exchange actionable feedback. Data Platform Vision: Articulate a strategic vision for your team covering the business plan, technology, tools, and operations, and align that with various other teams across the company. Enforce best practices and workflows that improve the use of data across the organization Data-driven Culture: you will be an ambassador for our data-driven culture, taking data and using it to answer business questions and drive strategy & decision making Solution Architecture: you will gather and help shape requirements for business initiatives and translate those requirements into designing and building solutions that scale and can be leveraged across applications Project Management: you will lead data projects from start to finish, showing your ability to manage scope, work with ambiguity and manage stakeholders Data Engineering Health: You will promote the health (integrity, reliability, cost) of our data platform with code reviews, technical mentorship, tech talks (internal + external) and expansion of best practices Experimentation Framework: Build upon the framework already in place to support our product team in creating AB testing to drive hypothesis-driven innovation You enjoy managing people and are very good at it. That means you’ve had several direct reports for at least 2 years. You’ve demonstrated the ability to develop a team including hiring, coaching and mentoring of team members, but can be hands on when needed You have extensive experience working with management teams and using data to influence company direction You have worked as an analytics lead and/or data engineering lead in a fast-paced environment (ideally both!) You are outstanding at pulling, worked with large sets of complex data and transforming them into structures that are easy to understand You understand that some systems need to be built to scale, and others need to be built fast. You can make those tradeoffs and explain them simply to stakeholders Extensive experience operating large scale data pipelines and databases. You have worked with and designed modern data architecture (Snowflake, dbt, Airflow, Looker) and fluency in SQL, Python or R among others You are a problem solver with strong project management skills who can ruthlessly prioritize different business initiatives Work with a group of ultra-smart hard-working talent coming from companies such as Google, Uber, & Facebook Join a results-driven organization where performance is measured by your output and not the number of hours you work Be part of a 100% transparent culture where every employee has access to board decks, strategy, and financials Work on projects that have instant impact, with most engineers pushing code to production within their first week Every day you will be helping our customers save money, earn rewards, and experience more of what life has to offer, making this a very rewarding and meaningful career Flexible working hours with complete work-from-home freedom Guilt-free unlimited vacation policy with great employee travel discounts using SnapTravel Competitive salaries, equity options, full benefits from day one, wellness budgets and paid L&D Generous EI top-up, parental leave, additional vacation and a flexible return-to-work plan Continued growth with a generous employee L&D budget and Diversity & Inclusion events Guilt-free paid stress days and mental health support 
ScrapedJobID546:
Work as a member of the Digital Accelerator with a fusion team of highly talented Data Scientists, developers and opportunity managers, to unlock substantial value from operations Work closely with the business teams to understand their goals, business problems and assist in identifying potential analytical and data science solutions and feasibility Support the full range of problem solving activities including data wrangling, ETL pipeline development, rapid scoping level / exploratory data analysis, proof of concept solutions as well as end-to-end execution plans for scaling proven models and deploying into an operational environment Ensure your models and analytics are tested with the end users and iterate to deployable adoptable solutions Communicate key metrics and results to stakeholders, as you progress through delivery leveraging visualization tools as appropriate for effective story telling Continue model / tool support in operational phases, including model performance monitoring and retraining Mentor and guide junior members of the team through the modeling and problem solving process Keep up to date with the latest advances in the data science field and actively participate in data science communities Share and grow data science knowledge across Imperial Conduct peer reviews with the data science team to ensure high-quality products Help mature ML Ops framework and adoption Work closely with the platform and data infrastructure team to ensure data science needs are properly considered in architecture and data pipelines are robust 5+ years work experience in advanced analytics and data science solving business problems Degree in machine learning, computer science, statistics, mathematics, physics, engineering, economics, operations research or related quantitative field Proven track record completing and deploying data science solutions in an industrial operating environment Broad array of ML and AI skills (supervised, unsupervised, reinforcement learning and mathematical optimization) Strong Python programming skills, additional benefit for Pyspark and Databricks experience Ability to explain data science solutions and concepts to the end users Strong mentorship skills, and enthusiasm for sharing knowledge Ability to effectively iterate and communicate results to stakeholders and team members using appropriate visualization and communication tools Preference for domain knowledge in energy and mining industrial processes 8 hour shift Monday to Friday Calgary, AB: reliably commute or plan to relocate before starting work (required) advanced analytics and data science: 5 years (preferred) ML and AI skills: 5 years (preferred) Python programming skills: 1 year (preferred) Pyspark and Databricks: 1 year (preferred) mentorship skills: 1 year (preferred) energy and mining industrial: 1 year (preferred) No 
ScrapedJobID547:
You will own the production Feature Store and Model Serving infrastructure. Develop self-service tools for data scientists that support feature engineering pipeline, model testing and deployment. Develop distributed training infrastructure (autoML) for faster training of models. Develop tools to monitor ML models in production, monitoring drift and performance. You may lead a team and will own key portions of department OKRs that help maximize team productivity. Overall, you will be responsible for delivering business value at scale via Machine Learning. 2+ years experience working in a DevOps or data engineer role using cloud-based infrastructure such as GCP (preferred), AWS or Microsoft Azure 4+ Software development experience and strong design skills Expert in Python, Flask/Django and one high performance language like C++ Exposure to machine learning concepts and interest in learning more. Familiarity with Kubernetes or other container orchestration tools in a production setting. Familiarity with workflow orchestration tools such as Airflow. Experience automating deployments in GCP (preferred), AWS or Azure. Up to date with what's under the hood of some of the advanced ML infra tools available. Bachelor's Degree /MS/ PHD or Equivalent Relevant Experience Required Experience building AutoML. Experience implementing algorithms from research papers and building models. Track record of creating excellent slack emojis and memes. Mission Driven - Some companies use AI to serve better digital ads and trade stocks, we seek to make our communities safer and more resilient Top Compensation - Competitive compensation package We are 100% Distributed - work from almost anywhere Your health matters to us, so we offer 100% employer-paid premium option Remote worker monthly reimbursement Co-working space reimbursement Wellness reimbursement Educational Allowance Weekly lunch stipend 
ScrapedJobID548:
Favoriser la croissance des revenus en développant, déployant et testant des algorithmes et des stratégies de tarification optimales dans le portefeuille d'unités de Sonder. Diriger les initiatives de Data Science pour résoudre les problèmes fondamentaux de gestion des revenus tels que. Comment développer des stratégies de tarification sur notre large éventail de marchés ? Comment identifier et fixer des prix optimaux pour les différents segments de clientèle ? Comment allouer les stocks de manière optimale pour capturer la demande à travers les différents canaux (vente, groupe, vente en gros et canaux directs aux consommateurs) ? Comment fixer les prix et allouer les stocks en fonction des différentes durées de séjour afin de maximiser l'utilisation des calendriers et la marge sur coûts variables Comment tester et mesurer l'efficacité de notre stratégie de prix ? Définir et mettre en œuvre un ensemble rigoureux de mesures de tarification et de méthodologies d'expérimentation. Encadrer, superviser et conseiller les collègues juniors de l'équipe Data Science. Collaborer avec les équipes d'ingénierie, d'analyse et de tarification pour mettre en œuvre et rendre opérationnelles diverses solutions de tarification. Collaborer avec d'autres fonctions telles que les ventes, la distribution et les marchés pour définir la stratégie de revenus, les objectifs et les garde-fous de tarification. MS ou PhD en économie/économétrie, recherche opérationnelle, finance quantitative, informatique, mathématiques, ingénierie, statistiques ou domaine quantitatif connexe. Minimum 3 ans d'expérience dans l'application de techniques et de principes de science des données à des problèmes commerciaux. Une expérience préalable dans l'optimisation des prix dans un secteur connexe (hôtellerie, compagnies aériennes, billets) est un atout majeur. Expérience de travail avec des équipes de produits et d'ingénierie dans des entreprises à forte croissance pour résoudre des problèmes, identifier des tendances et des opportunités, produire des recommandations. Minimum 3 ans d'expérience avec Python et SQL Excellentes compétences en communication - capacité à expliquer votre travail et son impact sur l'entreprise à tous les types de partenaires commerciaux. Vous avez une grande énergie, une passion pour les données, le souci du détail et une attitude positive. Une rémunération compétitive Plan d'options sur actions généreux Assurance médicale, dentaire et visuelle Les membres de l'équipe exonérés bénéficient de congés payés. Les membres de l'équipe non exemptés accumulent des congés payés. Crédits annuels gratuits et remises pour rester à Sonders Une entreprise avec une grande vision, un environnement de travail dynamique et une équipe de collègues intelligents, ambitieux et avec lesquels il est agréable de travailler ! Drive revenue growth by developing, deploying and testing optimal pricing algorithms and strategies across Sonder's portfolio of units Lead Data Science initiates to solve fundamental revenue management problems such as How do we develop pricing strategies across our wide range of markets How do we identify and price optimally across different customer segments How do we optimally allocate inventory to capture demand across channels (sales, group, wholesale and direct to consumer channels) How do we price and allocate inventory across different lengths of stay to maximize calendar utilization and contribution margin How do we test and measure the effectiveness of our pricing strategy Define and implement a rigorous set of pricing metrics and experimentation methodologies Mentor, oversee and advise junior Data Science team colleagues Partner with Engineering, Analytics and Pricing Ops team to implement and operationalize various pricing solutions Partner with other functions such as Sales, Distribution and Markets to define revenue strategy, targets and pricing guardrails MS or PhD in Economics/Econometrics, Operations Research, Quantitative Finance, Computer Science, Math, Engineering, Statistics or related quantitative field Minimum 3 years experience applying Data Science techniques and principles to business problems Prior experience in pricing optimization in a related industry (hospitality, airlines, tickets) is a big bonus Experience working with Product and Engineering teams at high growth companies to solve problems, identify trends and opportunities, productionize recommendations Minimum 3 years of experience with Python and SQL Great communication skills – ability to explain your work and the impact on the business to all types of business partners High-energy self-starter with a passion for data, attention to detail, and a positive attitude Competitive compensation Generous stock option plan Medical, dental and vision insurance Exempt team members have paid time off. Non-exempt team members accrue paid time off. Annual free credits and discounts to stay in Sonders A company with a huge vision, a dynamic work environment, and a team of smart, ambitious and fun to work-with colleagues! 
ScrapedJobID549:
Design, implement, and deploy machine learning algorithms. Manage machine learning algorithm lifecycle. Coordinate data collection and annotation efforts. Work with real-time data and content coming from various data sources. Manage machine learning data pipelines. Design tests for machine learning algorithm effectiveness and performance monitoring. Design tools and interfaces for interactive machine learning and teaching. Research and development on cutting-edge machine learning technologies. Graduate degree in Computer Science with a strong background in machine learning required. Strong problem-solving abilities, solid background in algorithms and data structures required. Strong programming skills in Python and Scala required. Experience in other programming languages (eg. Java, R, Haskell) a plus. Solid knowledge of machine learning tools (eg. scikit-learn, tensorflow, keras, pytorch, Spark MLlib) required. Experience with distributed and streaming data technologies (eg. Hadoop, Spark, Kafka) required. Experience with building and deploying API's with Docker and Kubernetes required. Experience with natural processing tasks (eg. named entity recognition, language modeling, vector representations) required. Experience with Elastic Search, Lucene a plus but not required. Experience with ranking algorithms a plus but not required. Experience with interactive machine learning (eg. active learning, reinforcement learning, machine teaching) a plus but not required. 
ScrapedJobID550:
Requirements: PhD in computer or biomedical engineering, computer science, medical physics, or a related field with a research focus on biomedical image processing/medical image computing, machine learning, and/or computer vision Demonstrated record of high-performance scientific programming with python and/or C++ Demonstration of personal ownership and technical leadership Ability to work in small and large teams, highly adaptable to changing strategies and responsibilities Great interpersonal communication, creative thinking, and problem-solving ability Demonstrated record of high-quality publications in the field Demonstrated analytical, verbal, and scientific writing skills CV Cover letter Three references Technical paper 
ScrapedJobID551:
Data analysis and pricing of new business quotes. Assist with the development of pricing models and tools. Assist with the development of SQL Server and MS Access databases. Consolidation, evaluation and reconciliation of MS Excel spreadsheets, text files and databases.
Data Quality Review Aid with experience studies for new business quotes. Use of R or Python software required along with MS Excel. Reconciliation and evaluation of data within SQL server or MS Access. Coordinate with external systems to integrate outputs/inputs of AXIS with databases.
Ad Hoc Requests: Assist with pricing model setup, automation of tasks within Excel and other statistical/data manipulations tasks not mentioned. Assist with Longevity pricing as required. Assist with Life Reinsurance modelling in Moody’s AXIS.
Position Requirements
Education Bachelor’s degree from actuarial, mathematical, statistical, data science/similar programs or Actuarial exams along with other bachelor’s degree.
Knowledge Understanding of Linear Regression. High-level knowledge of insurance, reinsurance or life contingencies strongly preferred.
Skills Good communication skills (oral and written). Very strong analytical and problem-solving skills. Ability to deal with other technical professionals (mathematical/actuarial). Highly proficient in MS-Office tools, especially MS-Excel and MS-Access. Experience with mortality forecasting algorithms preferred. Experience with either R, Python or other mathematical/statistical programming languages. Prefer working knowledge of data manipulation inside such languages. SQL and Database knowledge required, such as SQL Server, MS Access or others. Experience with MS Power BI, Tableau or similar is an asset.
Experience Previous work experience, including co-op or summer work term(s) preferred. 
ScrapedJobID552:
Manage our infrastructure: Work with Marketing Technology, ML Platforms, & engineering to design, build, maintain and optimize our data management and machine learning architecture. Build our feature engineering pipeline: Work with machine learning scientists to build data processing pipelines supporting data analysis and machine learning tasks, and automate feature engineering pipelines in production. Handle ML integration: Develop software to deliver and integrate machine learning product capabilities into our platform. Get our models into production: Work with data scientists, Marketing Technology, and ML Platforms to deploy machine learning models in production. Maintain a high-quality product: Develop processes and frameworks to ensure data and model quality. Perform code reviews and testing to ensure software quality is high and requirements are met. Develop reusable building blocks for quantitative models, leveraging high parallel, distributed machine learning and advanced data analysis techniques (e.g. 'Feature Engineering' , ‘Model Training DAG’, ‘Model Scoring DAG’, ‘Hyperparameter Optimizer DAG’, 'Monitoring Model Performance DAG', etc…). Leverage our work in order to increase adoption across our business partners, to drive real business value. Build and maintain strong partnership with business and engineering teams. 4+ years of software engineering experience or advanced degree in quantitative field w/ material exposure to coding (e.g. mathematics, economics, computer science, physics, neuroscience, operations research etc.). Experience developing data science / machine learning-driven products Interest in and have done work in statistical modeling and machine learning A good understanding of data warehousing, data modeling and data architecting The knowledge to work with machine learning scientists and facilitate translation of proof-of-concept models into production-strength systems Strong understanding in model inferencing lifecycle, monitoring, feedback loop and data capture in real time at scale Ability to ramp up quickly on our tech stack which includes GCP, Kubernetes, Airflow, Kafka, Pandas, Scikit Learn, Pytorch, Python, and Java. A Bachelor’s Degree in Computer Science or a related field 
ScrapedJobID553:
Work with key stakeholders throughout the organization to identify opportunities for leveraging available data to drive customer experience and network performance improvements. Leverage large data sets to build predictive models to identify opportunities to drive network performance improvements and reliability to improve the customer experience. Develop processes and tools to perform analytics, monitoring and analyze model’s performance and accuracy. Explore new capabilities and technologies to drive innovation and automate reports and prototype dashboards to provide insights at scale, solving for analytical needs. Conduct data analysis to make business recommendations (cost-benefit, invest-divest, forecasting, impact analysis). Presenting the insights, algorithms, and visualizations to wider audience. Use the expert knowledge of statistical analysis, data mining techniques, machine learning to develop data driven algorithmic models to describe and measure the performance of Rogers’s core services (internet, video, wireless, voice). Assess the effectiveness and accuracy of new data sources and data gathering techniques Support the influence and impact across the enterprise in promoting the analytics strategic direction Development of the annual operating plan, forecasts, and budgets Initiative Proactively identifies present and future obstacles, issues, and opportunities. Takes actions to address such obstacles. Innovation Motivated to improve organizational performance through the introduction of new ideas, methods, processes, products, or services. Develops new ways of looking at a situation. Degree in Engineering, Computer Science, Data Science, or related disciplines Experience with distributed data/computing tools: Azure HDInsight(Spark, Hadoop, MapReduce), Azure web services(Databricks, Data Factory, Synapse/Snowflake) and Splunk Knowledge of query Languages: HiveQL, SQL, SSPL, Python, R, etc. Experience with visualization tools: Splunk or PowerBI Knowledge of advanced statistical and analytical techniques and concepts (regression, properties of distributions etc.) Ability to work with little supervision but strong collaboration team collaboration skills Must have excellent writing, presentation, and communication skills and ability to get along with people Passionate about technology, data science, analytical models, machine learning, quantitative modelling, software development and automation A mindset of creativity, innovation, and energetic drive to succeed Strong ability to prioritize and handle multiple tasks while meeting tight deadlines, goals and targets in a fast-paced work environment Understanding of Telecommunication networks is an asset. Our people are at the heart of our success Our customers come first. They inspire everything we do We do what’s right, each and every day We believe in the power of new ideas We work as one team, with one vision We give back to our communities and protect our environment 
ScrapedJobID554:
You are enthusiastic about making a significant difference in the lives of your customers through your work. You are passionate about software development and take security seriously. You love building beautiful applications that are easy to understand and use. You care deeply about the quality and accuracy of your reports, and design your reports for easy verification. You are a continual learner, love new ideas and have a natural curiosity to keep improving. You understand the value of timely releases to market, and know when not to budge on software quality. Promote QHR’s “Blue Culture” framework to foster a collaborative, positive and efficient workplace, Contribute to the organization’s positive image both internally and externally, Perform other duties consistent with the position, as reasonably directed by your manager. Bachelor's degree preferred 3+ years of experience in Business Intelligence or Data Science Background in data warehouse design, data mining, and report generation In-depth experience in database management systems, Online Analytical Processing (OLAP) and Extract-Transform-Load (ETL) methodologies and frameworks. Experience with BI technologies (e.g. Jasper Server, Power BI, Tableau) Strong communication and presentation skills SQL Server, PostgreSQL, or other database systems Software Programming and/or Testing Healthcare data and/or reporting 
ScrapedJobID555:
Develop highly scalable capabilities with natural language processing, machine learning, data regression, and rules-based models, and expose the results of these efforts through APIs and/or persisting the data for later consumption Measure and improve efficiency and effectiveness of the customer experience and internal processes, and help clearly identify and communicate areas for improvements Be aware of industry trends in the data, analytics, NLP, and ML space, and help with identifying applicable technologies Work collaboratively with, learn from, and share knowledge with the rest of the Analytics and Audit team Help the team tell stories with data through reporting and custom data visualizations to drive key business decisions Collaborate effectively with the Design and Product teams to understand product requirements Work closely with testing to ensure we're delivering high quality solutions Work in a true DevOps environment and work closely with operations to deploy advanced solutions Collaborate effectively with high profile customers on an as needed basis Continue to improve the thriving engineering culture across all tech functions Must have customer focus, world-class quality, and effective communication with a focus on decisive, fast-moving solutions, quick and constructive resolutions to conflicts, and a "no barriers" mentality Serve as an evangelist for the team and overall culture, both internally and externally Bachelors or higher degree in Computer Science, Mathematics, or another technical field. 3-5 years of engineering management experience in a technology environment. Highly proficient with Python 3 and Jupyter notebooks Experience telling stories with data and data visualizations
Tableau, SteamLit, Plotly Dash, matplotlib, etc. Tableau, SteamLit, Plotly Dash, matplotlib, etc. Very comfortable reading and writing complex SQL queries Experience with building natural language processing (NLP) solutions; spaCy v3+ preferred
Experience with building custom NLP processing pipelines and training new models Experience with building custom NLP processing pipelines and training new models Experience in building machine learning models and exposing them through APIs; PyTorch and FastAPI preferred Familiarity with distributed Python tools such as Ray and Dask Comfortable with Typescript or willing to learn Table stakes are VS Code and git Experience with DevOps and MLOps
Kubernetes and Docker Kubernetes and Docker Experience with any of Tableau, Redis, PostgreSQL, or Snowflake Experience in an established mid-sized growth stage company or a fast-moving start-up in the areas of data analytics or real-time data processing Medical, Dental and Vision coverage Retirement benefits Employee Assistance Program Healthy Living Rewards Program Generous Time Off Allowance Volunteering Time Off Education Assistance Program 
ScrapedJobID556:
Bachelor's degree in the field of Science, Technology, Engineering, Math or equivalent practical experience. Experience reading or debugging code in one or more of the following: Java, C, C++, Python, Shell, Perl, JavaScript. Experience in advocating for customer issues or needs. Experience with distributed, columnar and/or analytic oriented databases or distributed data processing frameworks. Experience with open source distributed storage and processing utilities in the Apache Hadoop family and/or workflow orchestration products. Experience with machine learning technologies, including developing and/or training models or implementing solutions which rely on invoking such models. Experience in data analytics, warehousing, ETL development, data science or other Big Data applications. Understanding of basic web technologies. Understanding of TCP/IP concepts, Unix/Linux basic administration and commands. Excellent troubleshooting, attention to detail, and communication skills in a fast-paced setting. Manage the customer’s problem through effective diagnosis, resolution, or implementation of new investigation tools to increase productivity for customer issues on Google Cloud Platform products. Develop an in-depth understanding of Google's product technology and underlying architectures by troubleshooting, reproducing, determining the root cause for customer reported issues, and building tools for faster diagnosis. Act as a consultant and subject matter expert for internal stakeholders in engineering, sales, and customer organizations to resolve technical deployment obstacles and improve Google Cloud. Work as part of a team of Engineers/Consultants that globally ensure 24-hour customer support. This will include a need to sometimes work non-standard work hours or shifts. Understand customer issues and advocate for their needs with cross-functional teams, like product and engineering, to find ways to improve the product and drive high-quality production. 
ScrapedJobID557:
You will partner closely with our Ads Product & Engineering team, which is the core driver of revenue for the company. You'll play a key role in developing Ads product strategy and roadmap. You'll play with petabytes of data full of user and advertiser interactions to develop a deeper understanding of Reddit's ads ecosystem. In addition, you will work side by side with a world-class org of Engineering, ML, Search, Data Science, Data Warehouse, and Analytics practitioners who work together to create a variety of capabilities for Reddit to be more successful in its decision-making and product development. In this process, you will be exposed to a variety of new techniques in experimentation, statistical frameworks, machine learning, deep learning, and causal inference. Analyze conversations and behaviors across Reddit's 10,000 interest-based communities, and convert them into insights and product recommendations. Understand Reddit advertising and help the company improve Ads Revenue while simultaneously improving ROAS (Return on Ads Spend) for advertisers and ads quality for users. Conduct product/feature analyses, opportunity sizing, experimentation (A/B testing) and build dashboards/visualizations to assess product health. Organize data by designing table schemas, data pipelines, aggregations, alerts and general data infrastructure for the Ads Organization. Collaborate with various cross-functional stakeholders, including Product Managers, Engineers, Designers, UX Researchers, Data Engineers and Data Warehouse Engineers to lead projects related to organizing and analyzing data. Be an integral part of the Data Org, leveraging and contributing to the vibrant knowledge base, shared across a community of world-class data experts. 5+ years of experience in data analytics or related quantitative role 2+ years of experience in the digital advertising space Demonstrated ability to influence and guide product strategy with data Demonstrated ability to take ambiguous problems and solve them in a structured, hypothesis-driven, data-supported way Desire to mentor other data scientists and share best practices to elevate the data science practice at Reddit Strong ability to communicate and discuss complex topics with technical & non-technical audiences Proficiency with relational database (e.g., SQL) and statistical analysis/programming languages (e.g., R / Python) Proficiency with dashboarding tools (e.g. Mode Analytics, Tableau, Looker) 
ScrapedJobID558:
Web Development Bootcamp Cohorts Introductory Program Cohorts Junior Developers Junior Data Scientists Cyber Security Minimum 1 years of professional experience in Software Development, Cyber Security, or Data Science. Experience in a range of popular technologies in Web Development, Cyber Security and/or Data Science.
Web Development: Javascript, React, Ruby/Rails, NodeJS, PostgreSQL
Data Science: Python, Java, R
Cyber Security: Linux and Windows, Javascript, Python Web Development: Javascript, React, Ruby/Rails, NodeJS, PostgreSQL Data Science: Python, Java, R Cyber Security: Linux and Windows, Javascript, Python A strong understanding of open source development workflows using tools such as Github Any experience in teaching, mentoring, or tutoring is an asset. 
ScrapedJobID559:
A team player, fostering collaboration and creativity in an open and honest environment Passionate about talent development and data delivery projects A visionary with a curious mind, you have an interest in collaborating in the delivery of data initiatives and the ability to link your expertise with business needs to create value Comfortable working in constantly evolving complex environments and multidisciplinary teams An agent of change, motivated and able to question the status quo An excellent communicator, adept at negotiating and decision-maker Mobilizer, organized and results oriented A bachelor’s degree in Information Technology, Software Engineering or any equivalent combination of training and experience Minimum 10 years of software development experience in the data and analytics space Minimum 5 years of experience managing resources and projects. A strong understanding of technologies, project delivery and continuous integration and delivery processes Experience delivering products in Agile/Scrum mode in software development Experience working with project management tools such as MS Project, Clarity or similar tools. Excellent ability to manage priorities and resource capacity. An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID560:
Synthesize business needs and create business/functional design documents which can be used to build analysis and data models Client-facing skills which will include providing quantitative analyses, recommendations and presentations to clients Assess data for validity and work on required data preparation with attention to detail and alignment to business requirements Translate data into analytical outputs that enables our clients to answer fundamental questions that are central to their business success. Develops, implements, and supports methodologies, standards, and tools for analysis and data science work. Partners with insights and analysis team leads from the Digital Intelligence team as well as Digital Marketing team within Cardinal Path to help deliver quality insights as required Build cooperative, productive relationships with clients and vendors by utilizing excellent communication skills, while also interacting effectively internally and externally. Participation and development of data science and analytic products while identifying key areas for improvement of products and services. Research, prototype, and explore future, non-standard analytics approaches that push the limits of current analysis output. Bachelor’s degree in a technical field of study (Applied Statistics, Business Analytics, Operations Research, Computer Science, or relevant quantitative field) with a minimum of 3 years’ experience as an Analyst / Data Scientist or a Master’s degree with a minimum of 2 years’ experience as an Analyst / Data Scientist Proficiency with classical statistical modelling methods and machine learning techniques to solve complex business problems Strong Python skills for model design and development Proficiency with SQL and an experience working with cloud environments Experience visualizing and presenting data and analytics findings Self-motivation, creativity and ability to work independently in meeting deadlines Exceptional written and verbal communication skills and is comfortable working with remote teams Understanding of performance marketing metrics and channels Previous experience with web analytics tools such as Adobe Marketing Cloud, Google Analytics, etc. Previous experience with marketing and media analytics including database marketing techniques, digital attribution and media mix modelling Familiarity with analyzing data for digital marketing and ecommerce, as well as all other non-digital aspects of a business 
ScrapedJobID561:
Conduct research as required for continuous improvement business use case development and analysis; Assist the team with the development of Key Performance Indicators (KPI)reports, deriving measurements for scorecards, analyzing current practices and targeting areas for improvement; Collaborate with team members in the creation & tracking of business use cases, identifying trends, and recommendations for business efficiency gains; Develop presentations, spreadsheets, and documentation to support team members; Assist in the creation and application of data science tools and techniques that can be applied to decision support in as real time as possible; Assist in documenting department processes across functions, supporting team members in process analysis, rationalization and improvement recommendations; and Apply creative skills to ensure data is transformed into applicable business information. A current student in the Bachelor of Commerce degree program focused in Business Analytics/Science; A student who has completed three years of study and is currently enrolled in a Co-op program at a recognized University; Strong computer skills in Microsoft Office including Word, PowerPoint, SharePoint and Excel; Experience in use of Power BI, Tableau, Python, R and other analytical tools is considered an asset; Exceptional creativity and problem solving skills with ability to see the “Big Picture”, supporting integration and cross functional work efforts; Effective communication and interpersonal skills to interface with team members and customers to promote positive customer outcomes; Strong analytical and problem solving abilities in serving a wide variety of functions; and Strong financial, organizational, time management, written communication skills. 
ScrapedJobID562:
8+ years of hands-on industry experience building supervised and unsupervised learning models A Masters or PhD in Artificial Intelligence, Computer Science, Mathematics or Statistics. Strong background in Machine Learning, statistical inference or similar. Building predictive models is your game. You have knowledge about regression, deep neural networks, cross validation, naive bayes, feature extraction, feature engineering, overfitting, etc. Strong programming skills. Hands-on machine learning experience with Python and toolkits like PyTorch or TensorFlow. Track record of building, shipping and maintaining machine learning models in a highly ambiguous and fast paced environment. Track record of defining new data science techniques and best practices that improve the ML model performance. Track record of designing and architecting large scale experiments and analysis which impact multiple teams and adjacent focus areas. Experience with Deep Learning and associated frameworks is a plus. Experience with data processing infrastructure such as Spark, Hadoop, SQL, Amazon Web Services and/or Google Cloud Platform is a plus. Experience supporting product or growth teams Experience in the SaaS industry Experience working with executive leadership, across departments/teams Preference for candidates with experience at our current stage and beyond (over 10,000 customers, high growth, lots of change and building internal processes) 
ScrapedJobID563:
Design and develop reproducible ML pipelines and scalable ML systems; Deliver software and models for ML development projects following an agile methodology with teams that can include Vector Applied ML Specialists, Applied ML Scientists, professional staff, researchers, students, and sponsors; Design and implement reference architectures for ML systems for training as well serving workloads that apply ML research to real-world problems using public and private datasets; Design, develop and contribute to open-source software that applies ML research techniques to common problems; Research and extend open source MLOps tools and frameworks that address the full life cycle of end-to-end machine learning systems; Mentor sponsor engineers and student researchers on industry collaboration projects that apply ML research to shared problems, mentoring on engineering best practices, and assisting with operational issues; Develop prototypes and proofs of concept; Report and present MLOps best practices and outcomes for team efforts including demos, status, and results; and, Other duties as assigned. Bachelor's degree in computer science, mathematics, electrical engineering, or related discipline; Master’s degree preferred 3+ years of experience in software engineering 1+ years experience in MLOps Experience applying building ML systems for training and inference Good understanding of CI/CD/CT as it relates to machine learning lifecycle Demonstrated experience in machine learning and/or statistics Demonstrated analytical skills to identify signal in data and feasibility of prediction Expert Knowledge and experience with Python for ML and DevOps. Experience with C++, Java or Scala is preferred Experience working on teams that land high quality software successfully in production is preferred Experience with MLflow, Airflow, Seldon core and Kubernetes is preferred Understanding of model maintenance, retraining and evaluation frameworks is a plus Experience in leading open-source deep learning software frameworks (PyTorch, Tensorflow, and CUDA) is preferred User interaction/design expertise with Human-Computer Interaction (HCI) engineering considered an asset 
ScrapedJobID564:
Supports internal business partners globally by executing tasks outlined in the Global Data Operations Service Catalogue as well as the North America Portfolio Support Service Catalogue. Sets up, maintains, reviews, and validates security masters, brokers, and various reference data elements. Delivers production support tasks accurately and in a timely manner that meets established SLAs. Participates in the data reconciliation processes amongst various internal and external systems. Takes ownership, with some guidance (if needed), on complex escalated position, cash, coupon payment, and security master related reconciliation breaks requiring non-standard research and problem-solving abilities. Maintains an overall understanding of the assigned investment strategy (i.e. cash weights, financial instruments within the portfolio, cash management, etc.) Responsible for cash management support by calculating / verifying current day and net investable cash in multiple currencies for portfolio managers and resolve discrepancies within established deadlines. Participates in the analysis of the characteristics of new instruments to determine the associated data requirements and support procedures across all relevant systems. Participates in Product Shelf changes (e.g. new fund launch, new institutional mandates, portfolio manager change, fund name change, etc.) related activities within Support Services. Liaises with other functions to ensure the integrity of portfolio related data (position, cash, security master, pricing, corporate action, FX, derivatives, etc.) via reconciliation resolution oversight, coordination, and escalation globally. Acts as the escalation point for critical reconciliation breaks Contributes to the production of management reports and executive-level commentaries University degree in Accounting, Finance, Math or business area of concentration or equivalent experience MBA is an asset Certify Financial Analyst (CFA) or Professional accounting designation (CMA, CGA, CA, CPA) is an asset Minimum 3 years' financial services industry experience in a data analysis capacity Strong knowledge of investment products and global security markets is required Knowledge of market data services such as Bloomberg and Reuters is required Must have previous knowledge and work experience with data management applications (e.g. CADIS, Eagle PACE), order management systems (e.g. Charles River, Aladdin), portfolio administration applications (e.g. Eagle STAR, FMC), fund accounting applications (e.g. PAS, Eagle STAR), reconciliation tools (e.g. TLM), and data warehouse platforms (e.g. Eagle PACE) Must have a solid understanding of the end-to-end investment services processes, including but not limited to trade entry, trade process, settlement, security master set up/maintenance, valuation, corporate action processing, fund accounting and reconciliation resolution. Demonstrated ability to process and assimilate data and information into meaningful management and reporting information. Strong interpersonal, conflict resolution, written and verbal communication skills Customer focus and with a keen interest in providing superb services to clients. Strong organization skills and detail orientation, with an ability to understand the big picture and work under pressure with tight deadlines. Strong research, analytical as well as problem-solving skills. Aptitude for mathematical calculations and the ability to analyze detailed numerical data. Good Microsoft Office skills – in particular Excel, Access, Word, PowerPoint, Project, and Visio. Aptitude for learning new technology and adapting to rapid changes Rotating support coverage is required for international markets that are open during statutory holidays Participate in Business Recovery testing on an as-needed basis as defined by the manager Overtime, off-hours support, and travel may be required Staggering shift work is required on a rotational basis and as defined by the manager to provide global business coverage Current hours of business coverage for the North America Team (subject to change to fit global operations coverage needs): Mondays to Thursdays: Eastern Time 7:00a.m. – 8:00p.m, Fridays: Eastern Time 7:00a.m. – 6:00p.m, Sundays: Eastern Time 4:00p.m – 8:00p.m. Temporarily due to COVID-19 
ScrapedJobID565:
Have a University degree in Information Science, Data Science, Computing, Business or a related field. Are experienced in data governance (preference to candidates with experience in a fundraising context). Are experienced with data analytics, including experience with analytics tools such as R, Python, SQL, PowerBI, and Tableau. Are an expert in change control and process implementation? Have 3-5 years experience with Blackbaud products, especially Raiser’s Edge. Have high level of business acumen coupled with technical knowledge, and experience managing automation. Are a quick study when it comes to the adoption and mastery of software and technology? Oversee and create a data governance framework that describes how data in RE is to be entered, accessed, and used. Champion the strategy for BI, data warehouse & Information systems based on the goals and objectives of the Foundation. Develop Information systems strategy and operational objectives by gathering information, studying business functions; studying system capabilities, evaluating output requirements, formats and designing modifications. Develop and ensure that the policies and procedures outlined in the data governance framework are implemented by the BIIT Team and Data Stewardship Committee Lead a Data Stewardship Committee that has recurring meetings to discuss progress towards data stewardship objectives and requests for data and analytics. Identify opportunities to strengthen data integrity, improve the data environment and through investment in relevant strategic initiatives and data infrastructure. Deliver reports on business operations (such as fundraising, campaigns, and events) and data quality indicators. Conduct analytics to explore and discover patterns, meaningful relationships, anomalies and trends in data to identify opportunities to leverage predictive analytics to improve business operations using relevant platforms and dashboards Lead the execution of user testing efforts, and delivery of BI solutions, modifications and publishing progress reports, functional hierarchy, business rules, interface designs and definitions, issues resolution mechanisms and data mapping. Maintain user confidence, data privacy and protect operations by keeping information confidential and compliant to applicable privacy and cyber laws. Conduct gap analysis between application and stated customer requirements and collaborate with database team, developers to estimate project and business impact. Provide quarterly executive updates on Data and Analytics (processes, practices and technologies) initiatives in place aimed at improving business management and optimization. Supervise and mentor the IST team assigned to you and oversee the work of the team Oversee risks on all information systems, applications, databases, online tools and constantly scan and evaluate to mitigate any risks, upholding the security, privacy and confidentiality of all information systems, applications, tools and databases. Identify investment requirements to improve, support and maintain technical services and best practice information systems user experience for the Foundation. Develop and maintain End-User policies and procedures, ensuring best practices. Coordinate with various business units and management regarding end-user computing to effectively support business functions. Maintain data integrity of the system through use of data integrity scripts and ongoing training, improve and build on data auditing and validations to enhance data accuracy and reliability of information used for decision making. Think critically about strategy as well as be comfortable making suggestions to improve any area of the business Have strong interpersonal skills, ability to work well in a team, build off the ideas of others, and be open to constructive feedback on their work Work closely with leadership in the creation and delivery of best practice donor data management systems. Act as an Ambassador throughout the Community, positively representing the Hospital and the Foundation Assist in the preparation of an annual plan of measurable goals and strategies to maximize the fundraising initiatives and campaigns Casual dress Company events Hybrid working from home/office arrangements Competitive benefits package and pension 
ScrapedJobID566:
Access to social volunteer and recreational programs, via our many Employee Resource Groups (ERGs) Opportunities for career development through active internal mobility and our innovative training program: Canada Academy A brand new workspace, flexible, comfortable and easily adaptable to your needs: remote work opportunities, standing desks, innovation lab., open meeting rooms and spaces Leadership, building up the Analytics & Insight brand within and outside HR Manage, build, and develop the Data Analysts and Employee Data Management teams, driving efficiencies and automation along with reinforcing data quality throughout our Information System Build a date-driven and analytics culture by communicating and democratizing the concepts and value of analytics to the broader HR and executive communities and collaborating with other analytics authorities across the organization Position the team as an expert advisory to support HR strategy and decision-making. Develop close ties with HR Leadership and other HR COEs (Learning & Development, Talent Acquisition, Benefits, Payroll …) to identify and build sophisticated analytics solutions Identify and build the skillsets within the team and where relevant, propose a development plan for HR Promote and champion a culture of innovation Business Intelligence and analytics Produce analysis and sharp visualizations through business analytics and intelligence technologies such as PowerBI to help make informed decisions. Identify and use multiple data sources, analyze and present results – interpret data and derives significant patterns or points of attention, provide recommendations and insight based on key trends and knowledge of business challenges. Design, develop and maintain standardized dashboards, metrics, KPIs and reports including with PeopleSoft. Provide summary level and detailed reports incrementally and on an ad-hoc basis; examples include overtime reports, time-off management, headcount reports, payroll reports Co-create solutions with our Enterprise Data Management team to ensure scalable solutions are delivered Train and coach HR teams on how to interpret data and metrics and make the best use of the reports and dashboards Help team enhance scope of Data Science activities: e.g. Developing Forecasting, Multi-Variate models, Regression/Correlation analysis, Machine learning, AI, etc. Demonstrate a continuous learning curve and open mind-set to bring in innovative ideas. Project management Keep track of the pipeline confirmed priorities, ensure features are developed, reviewed, thoroughly tested, and implemented as per user requirements. Comprehensive assessment of business needs to build a precise understanding of requirements, propose solutions, and execute as per plan. Project contribution at all stages of development, monitor and coach team Database Management/HR Workflow Maintain data integrity, create and utilize reports and data queries to authenticate integrity of employee information, resolves differences between Finance and Human Resources systems, and assist with reconciling data between PeopleSoft and other internal compensation systems, including Payroll Participate in auditing and maintenance of employee records, including HR status updates, terminations, and new hires Additional missions may include Participate in alternative systems research and RFPs Support and assist new product implementation both within Human Resources and outside the department. Bachelor’s degree or higher in Computer Science, Information Technology, Data Science, Math, Engineering, Finance or similar field 4 - 6 years of experience in analytics, business intelligence, or similar roles. Strong applied mathematical, statistical, and analytical skills to design and interpret descriptive and predictive statistics Experience in data mining, text analytics, data collection strategies Excellent verbal and written communication skills with an ability to convey ideas and effective story-telling through data, reports and dashboards. Client-focused, ability to effectively collaborate and communicate with the respective HR and Business stakeholders; Strong analytical and problem solving skills with high attention to detail and accuracy. Strong ability to adapt and re-assess priorities for short and medium term, while being able to drive the holistic long term roadmap Experience with HRIS Systems is an asset but not mandatory as trainings can be organized Outstanding operational and organizational skills in addition to detailed oriented work Ability to work under pressure to meet deadlines Self-starter, proactive in seeking information and approaching business problems with creativity Able to work well independently and in a team environment Experience working in a large, complex organization is an advantage Proficient with PowerBi, Tableau, or similar business intelligence and analytics tools. Coding knowledge and experience in several languages: for example, R, Python, Java, MS Excel/VBA, , etc. Experience with database programming languages including SQL Knowledge of Business Objects Experience in one or more of the ETL platforms such as KNIME, Alteryx Experience with data sources and reporting tools; HCM PeopleSoft 
ScrapedJobID567:
Masters in Computer Science, Statistics, or Data Science Expertise in Python Excellent communication skills Excellent leadership skills Excellent problem-solving skills Experience creating production-quality models Machine Learning/Deep Learning Experience Data Science experience with building one or more: Recommender systems, NLP(chatbot, NER, classification), Computer Vision(object detection, segmentation, classification, OCR, ICR), Reinforcement learning, Time Series forecasting 7+ years of experience with machine learning projects 4+ years of experience with leading machine learning projects 
ScrapedJobID568:
Monday to Friday machine learning: 1 year (preferred) Temporarily due to COVID-19 
ScrapedJobID569:

ScrapedJobID570:
2-3 years experience in an analytics role MS degree in math/stats/research/social sciences preferred (advanced degree completion may be considered for job experience). Experience with multivariate statistics (e.g. regression, factor analysis, correspondent analysis, discriminant analysis, drivers analysis) is required. Experience with SPSS, SAS and/or R; Experience with Text analysis, working with different data sources/types (e.g. social data, qual survey data) is desirable. Would be a plus Programming experience in Python, VB, Data visualization Experience with SPSS Modeler. 
ScrapedJobID571:
Have at minimum, an undergraduate in related fields: business, analytics, economics, statistics, mathematics, or computer science Advanced skills in BI tools for tools like PowerBI, Qlik and Tableau Ability to transform business requirements into dashboard and BI processes and visuals Be able to perform statistical programming in R or Python. Knowledge of running embedded scripts into dashboards Understand the fundamentals of data types, analytics, machine learning and have the passion to learn deeper into the subject Be interested in consulting and technology Be proficient at presentation skills and conducting meetings Be a team player, be organized, be punctual Have Master’s level education in relevant fields Has advanced experience in insight delivery and ML using Power BI (Cognitive Services, PyCaret) Have a coding background with emphasis on data science applications and methodologies Admitted into a customized education program that will focus on personal and professional growth of the individual Working in a very challenging and fast paced environment that will require you to push yourself intellectually Working with the founder directly in open concept downtown Toronto office Attend analytics, data science, AI and industry conferences and workshops, developing your own network Flexible workhours and work from home arrangements 8 hour shift Yes 
ScrapedJobID572:
Are you ahead of the curve, agile, curious and creative? Do you enjoy analyzing data to better understand when objectives are achieved? Do teamwork and challenges motivate you? Do you want to work on major projects for the Bank and have a real impact? Serve as a client data expert, develop in-depth knowledge of client and marketing data, and work closely and continuously with the various stakeholders Help manage the marketing data ecosystem, including recurring production Help define business rules and prepare datasets using reporting tools to make them available, thereby simplifying proactive decision making (e.g., dashboard, analysis, report, model, database) Participate in the migration of marketing activities to big data environments Use effective visualizations to present results, performance and trends Make recommendations based on trends, observe objectives and key indicators, identify areas of risk and opportunity Carry out specific analyses and present the results clearly and concisely A bachelor’s degree and 5 years of relevant experience or a master’s degree and 3 years of relevant experience Advanced proficiency in SAS and SQL Knowledge of PowerBI tools Proficiency in R and/or Python, an asset Knowledge of big data environments (Snowflake, Hadoop and Spark), an asset Bilingualism, spoken and written (English and French) Strong communication skills and ability to explain concepts in plain language Proactive and diligent Strong ability to develop in an environment undergoing transformation Health and wellness program, including many benefits Flexible group insurance Defined benefit pension plan Employee Share Ownership Plan Employee and family assistance program Preferred banking services Volunteer program Telemedicine Virtual sleep clinic 
ScrapedJobID573:
Over 10 years of experience, proven innovation, technical leadership and expertise in ML PhD or Master in machine learning, computer science Extensive patent and academic publications Serves as subject matter expert in specific domain such as NLP or ASR Recognized as a thought leader within the industry/research community An accomplished technical contributor looking to hone your craft and influence the work of others Contributor to highly referenced ML research or open source ML tooling Highly skilled in Python and Pytorch Define and lead ambitious, novel, high-impact ML research projects that result in product innovations and research publications Become a leader of the technical direction for Ada’s ML technologies Accelerate the growth of your ML teammates through guidance, feedback, and leading by example Identify opportunities for improving our existing products and innovating towards the next ones Competitive salary and generous stock option plan Unlimited vacation Wellness account Extended health coverage Dental/optical/travel insurance Life insurance Employee and family assistance plan Flexible work schedule Digital first, fully remote with WFH budget In-house social worker Paid parental leave for Canadian and U.S. residents Development opportunities 
ScrapedJobID574:
Research and implement state of the art machine learning techniques to solve real world problems; Work in collaboration with Researchers, Machine learning specialists, Vector team members and Vector affiliates to build demos, minimum viable products (MVP) and prototypes; Provide advice regarding building machine learning applications and ML product roadmaps Provide oversight for Vector-led or co-led efforts to prepare and open source specific datasets for machine learning research; Serve as the an AI Engineering team representative to research computing and HPC team; Serve as an expert and facilitate identification of experts among the Vector research community for external stakeholders (e.g., health and other sectors) to advise on machine learning research trends and applications; and, Other related duties as assigned. A degree in computer science or computer engineering with a research focus on machine learning Strong software engineering and coding skills, with the ability to write high-performance and production-level code Demonstrated expertise in building systems for applying machine learning algorithms for solving business challenges Demonstrated experience applying machine learning research to novel problems and data sets Strong knowledge and experience of Python Experience with large scale machine learning operations such as distributed training, parameter and architecture tuning of deep learning models Experience using deep learning software frameworks (PyTorch, Tensorflow, JAX, or CUDA) Demonstrated experience with SLURM and bash programming is a plus Experience with high-performance-computing and GPU execution model is a plus Experience with CI/CD and software development life-cycles is a plus 
ScrapedJobID575:
A passionate business focused Data Analytics Consultant to join our team of specialists focused on supporting our Customers on their journey with Data and Analytics Analyze & Understand
Understand the customer perspective and project / business requirements
Analyze, understand, document the customer environment, their data assets and business processes
Determine best use of Business Intelligence within the customer’s environment, team and culture
Working with clients to identify data issues and opportunities Understand the customer perspective and project / business requirements Analyze, understand, document the customer environment, their data assets and business processes Determine best use of Business Intelligence within the customer’s environment, team and culture Working with clients to identify data issues and opportunities Create Qlik Analytics Solutions
Develop end-user business oriented dashboards, self-service analytics and reports
Translate business requirements into Qlik dashboards, reports and analytical solutions
Help customers gain better business insights and improve their operational, tactical and strategic processes Develop end-user business oriented dashboards, self-service analytics and reports Translate business requirements into Qlik dashboards, reports and analytical solutions Help customers gain better business insights and improve their operational, tactical and strategic processes Deliver Qlik Solutions
Manage end to end project from a Project Management perspective
Deliver, present, review the Qlik Solution and ensure customer satisfaction
Create and document business/technical specifications and validate the application results
Conduct end users trainings to make sure that there is successful adoption of the solution Manage end to end project from a Project Management perspective Deliver, present, review the Qlik Solution and ensure customer satisfaction Create and document business/technical specifications and validate the application results Conduct end users trainings to make sure that there is successful adoption of the solution Inspire
Assist the customer in nurturing their BI culture, identify opportunities for customer to evolve in their BI Journey
Identify opportunities to speed up business decisions and increase operational efficiencies with Data
Inspire team members and colleagues with constant technology innovation and research Assist the customer in nurturing their BI culture, identify opportunities for customer to evolve in their BI Journey Identify opportunities to speed up business decisions and increase operational efficiencies with Data Inspire team members and colleagues with constant technology innovation and research 7+ years working as an analyst in a midsize or large organization 5+ years working with data and/or analytics platforms (e.g. Qlik, Tableau, PowerBI or Excel) 3+ years in delivering User Training 3+ years in Project Management 1+ years in Data Science (eg. Python, R, Matlab, …) or similar technologies Experience with Qlik Products is desired although not required Knowledge of programming, databases, networking and operating systems Outstanding communication and interpersonal skills Outstanding problem solving and analytical skills Extreme passion for customer engagement through storytelling and/or formal training Natural empathy for customers goals and objectives (your customer's success is your success) Unique work culture based on enthusiasm and passion for people and technology Competitive base salary based on experience and qualifications Performance bonus and benefits plan 
ScrapedJobID576:
Develop production ready and high performance machine learning code, working most of the time in projects dealing with Natural Language Processing tasks. Work cross functionally with our Research team to assess and validate machine learning models, code and hyperparameters. Collaborate with our development team to ensure our system is highly performant, stable, and robust to failure. Create and maintain official machine learning regression tests and tooling. Demonstrated experience implementing machine learning algorithms, probabilistic techniques, or deep learning. Strong production experience in Java, C/C++, Go or Python Familiarity with frameworks like Tensorflow, PyTorch, Theano, Keras, Caffe(2), or CNTK. As well as key machine learning applications in NLP such as Classification or Sequence Labeling. An understanding of modern software development practices. Experience with Linux and DevOps is a huge plus. We’ve got a dream team. Zuva is filled with smart, curious, independent, and self-motivated people. Together, we make up a culture that values diversity of thought, creative thinking and fun. There is room to grow. We work on challenging problems. It’s hard (in a good way) and it gives ample opportunities for growth. We also believe in the power of learning. We provide an annual learning budget to all Kirans, as well as regular learning sessions hosted by internal and external experts. The future is flexible. While we’re all remote right now, we have a number of fully remote team members around the world. Covid-19 has reminded us that our health and well-being come before anything, which means you have flexibility when it comes to designing your work day. It also means that we have a flexible vacation policy that allows you to take time off when you need it. We’ve always got your back. Literally. Got a knot in your back? We have a comprehensive health and benefits plan for you and your family, as well as access to Employee Assistance Programs. We’ve also implemented and are continuing with “company shut-down days” that we started since last year. These provide an opportunity for everyone to step back and recharge at the same time. Proven Technology and Design. Machine learning is driving a new industrial revolution, and we have a product with proven technology and clients who are excited about our product! Moreover, we care about great design and a great customer experience. 
ScrapedJobID577:

ScrapedJobID578:
Proven track record in the research, data science and engineering around building and shipping machine learning or statistical models that scale to high volumes of data (billions of data points) Excellent grasp of Python and advanced SQL Excellent knowledge of MLOps processes and tooling for moving models from training to production and debugging complex systems Strong understanding of modern machine learning techniques and their mathematical concepts Experience with sklearn, SparkML, pandas, NumPy or similar packages Experience with deep learning packages, including Tensorflow, PyTorch, or Keras Working knowledge of large-scale distributed systems and related technologies such as Spark, Elasticsearch, Kubernetes etc. Familiarity with cloud platforms (we use AWS here) and automation technologies (e.g., Kubernetes, Jenkins, Chef, etc.) is a plus Knowledge of GNN, RL, Recommender Systems and NLP techniques including embeddings, transfer learning, attention mechanisms is a plus Familiarity with the information/cyber security domain is a plus Work closely with engineering and product teams to scientifically frame the business problems and come up with the underlying mathematical models Perform exploratory data analysis to gain deeper understanding of the data Develop tools and algorithms for generating synthetic data sets Develop and test statistical and machine learning models for efficacy and operational impact Write production quality code and work with other software engineering teams to deploy models into production Support deployed models as a subject matter expert Be creative and engineer novel features and methods to push beyond our current capabilities Equity for all employees Paid paternity and maternity leave Training and career development programs 
ScrapedJobID579:
Work in a team environment using Agile practices Utilize Test Driven, Paired Programming and Continuous Integration development methods Innovate new ideas to evolve our applications and processes Acquire, analyze, transform and move large, complex datasets Participate in the design and development of our deep learning, ML and NLP solutions Understand NLP concepts like: Named Entity Recognition (NER), Sentiment Analysis, Data Tokenization, Lexical Semantics, Relationship Extraction, etc. Understand ML fundamentals: loss functions, classification and regression models, feature engineering, hyperparameter optimization, and model validation Master's or Bachelor’s degree in Computer Science, Data Science, Mathematics, (or related field of study) 2+ years of experience building algorithms and applying machine learning solutions to business problems Software engineering skills: version control, build pipelines, object-oriented programming. Hands on experience with big data systems like Hadoop, Spark, AWS EMR, Azure HDInsights, etc. Industry knowledge creating ETLs to extract, translate and load large datasets Relational and NoSql database systems experience Experience with AWS environments. ML frameworks: TensorFlow, Torch, Caffe, or Theano. Python, Scala, Java or .NET. Oracle, MySQL, PostgreSQL or MongoDB Hadoop/AWS EMR, Apache Spark AWS product knowledge (e.g. EC2, VPCs, Lambda, API Gateway, etc.) AWS Console, CLI and SDK experience Infrastructure as code: Terraform, CDK, or CloudFormation Git version control 
ScrapedJobID580:
Manage, grow and support a team of BI analysts Support key initiatives in the business by providing data, insights and recommendations Coordinate + collaborate with various teams within Logistics, Product, Data and others to deliver projects Consult with stakeholders on data and technical issues, providing guidance on technical implementation feasibility Build a strong community for all BI analysts around the toolset and best practices 8+ years' experience in analytics or a related role with specific Logistics -experience considered an asset 2+ years of managing teams in a direct line as well as overseeing project management Ability to collaborate with stakeholders across different organizations and geographies to manage change and deliver initiatives Delivering data-driven insights and outcomes clearly and communicating effectively with people of varying levels of data literacy and technical knowledge Comfortable translating business requirements/requests into a technical approach Experience with data and analytics tools such as SQL, Python, R, Google Cloud Platform, Amazon Redshift, etc. Experience visualizing data with common tools such as Tableau, Python, Google Sheets, Microsoft Excel, etc. Experience in design and development of machine learning and data science applications/products at scale considered an asset Experience with version control (ie. Git) and Data Pipeline creation and maintenance (ie. Apache Airflow) considered an asset Sound mathematical and statistical background required 
ScrapedJobID581:

ScrapedJobID582:
Advise on the best technologies and frameworks to monitor performance for the team's and client's needs. Show your analysis through presentations and communication with technical and non-technical people. Develop performance measuring frameworks to track goals, user needs and work with KPIs. Work with marketing software and tools such as Google Analytics, Google Tag Manager, Google Search Console, Adobe Analytics, Hubspot, Salesforce Marketing Cloud, Facebook Ads, Google Ads, and LinkedIn Ads. Oversee the analytics, data layer, and tag management solution for accurate and efficient data capture. Help conceptualize, design, build and automate reports/dashboards that provide insights into client audiences. Manage ongoing audience data and KPI reporting on a weekly/monthly/quarterly basis, delivering insights and recommendations to both business and content teams. Provide data-driven feedback and actionable insights to our content teams regarding content/topic performance onsite & off-platform (social media, blog, video, etc..) As needed, work with developers for tracking needs and implementation 1-3+ years of experience working with or close to marketing data 1-3+ years of experience working directly with Google Analytics data Proven ability to manage, understand, discuss, and work with analytics accounts, goals, properties, dashboards, reports, segments, and custom channel/content groupings Experience using visualization tools, in particular Google Data Studio - expertise in Tableau a bonus Hands-on experience with Google Tag Manager; experience and expertise in web tagging concepts and the ability to lead tagging strategy highly desired A high degree of comfort with Excel and/or Google Sheets spreadsheet concepts A degree in marketing or statistics Entrepreneurial ability to diagnose web data tracking issues and propose solutions Ability to work with a fluid team at a fast pace Interest in statistical programming/query languages (R, Python, SQL) Understanding of data science processes and ability to implement these in an Agile environment Excellent communication skills and ability to simplify advanced statistical concepts for a layman audience Strong understanding of advertising data and advertising concepts HTML, Javascript, and other web development expertise Working knowledge of APIs, data connectors, and other pipelines Experience with UX/testing technologies such as Hotjar, Google Optimize An understanding of SEO and technical SEO concepts, search data CRM and email software marketing data Prior experience with project/workflow management software (we use Asana) 
ScrapedJobID583:
Collaborate closely with the Data team improving internal processes. Help marketing and development teams to identify trends and opportunities. Develop advanced learning algorithms and statistical models to solve critical problems and help deliver incredible player experiences. Architect, implement, deploy, and maintain data science intensive applications. Synthesize data from various sources and extract useful information that will lead to improving the player experience, player retention, game design and effective marketing strategies. Extract and organize data into a reliable user-friendly form and present it to the interested and affected parties on the team. Follow up with additional analysis once initiatives have begun to determine success or need for continued improvements. Assist in designing and building business intelligence tools for data mining and reporting. Suggest improvements in tools and techniques to help scale the team. Conduct ad hoc data analysis based on current team needs and management priorities. Mentor other Data scientists with the team. Excellent organizational, communication and interpersonal skills Bachelor’s degree in a technical or quantitative discipline (Mathematics, Economics, Statistics, Computer Science, MIS, other) Minimum 3 years of tried and true statistical analysis and data mining experience A passion for video games and understanding of gaming culture Experience in the gaming industry, specifically Free to Play gaming is a plus In-depth knowledge of Postgres SQL, Mongo DB, Python Notebooks Experience in defining/designing/building/managing a data warehouse is a plus Strong quantitative analysis techniques and qualitative methods, as well as predictive modelling Demonstrated success presenting complex research data (both qualitative and quantitative) in a clear and compelling manner that inspires action Excellent organizational, communication and interpersonal skills Self-starter who can manage their time effectively and has the interest of integrating into a team of passionate, highly intelligent game developing ninjas Competitive salary with bonus opportunities Excellent benefits and paid time off Matching RRSP plan Employee Assistance Program (EAP) Professional development and career support Fitness and parking/transit subsidies Daily lunches prepared onsite by our in-studio Executive Chef and professional kitchen staff All-day snacks and drinks, sleep pods, massage chairs, cold brew, dog therapy days and more 
ScrapedJobID584:
Consults with internal business leaders, identifies opportunities/challenges, and brings analytics driven insights/solutions to solve business problems. Helps determine advanced analytics priorities and sequencing of projects to optimize business goals. Works closely with business leaders in change management as an outcome of model delivery. Leads, develops, manages, and delivers projects of diverse scope. Codifies processes/techniques/tools into best practices for other data scientists. Oversees the work of more junior data scientists. Participates in code and model review of other data scientists. Works with Customer Experience, Human Center Design, Operations, and IT teams to bring model outputs to life to support business processes, and end users. Provides thought leadership including researching new analytics methodologies, tools, and data Innovates and finds creative ways to source data to support modeling efforts, utilizing structured and unstructured data using Big Data technologies and NLP Actively involved in recruiting data science professionals and manages data science co-ops An advanced degree in Computer Science, Mathematics, Engineering, Statistics, or other quantitative discipline Minimum 5 years of commercial experience solving high impact business problems using data science Experience leading initiatives across the entire advanced analytics lifecycle from business problem through to deployment Practical experience with big data processing frameworks, and platforms such as Azure, Databricks, Spark, Hive, PCF Excellent communication skills – able to translate complex data science concepts to technical and non-technical stakeholders. Masterful storyteller able to galvanize others to act. Agile thinker with a bias for action, able to remove roadblocks fast. Track record of implementing models into production with business value. 
ScrapedJobID585:
An experienced Data Scientist with a passion for digging deep and finding trends that others may miss You can release high-quality, production-ready products. This requires rapid iterations, robust debate, and technical skills. The better you are at writing code, the more efficiently we can release a product that's used daily to make critical decisions. Seen as an active contributor in the team problem-solving-process – you aren't afraid to share your opinions in a low-ego manner You enjoy solving challenging problems, all while having a blast with equally passionate and talented team members You are comfortable and enjoy working with data. This requires a high level of mathematical and statistical literacy and an intense interest in applying quantitative analysis to real-world problems You can extract meaning from data. Our product lives and dies based on the accuracy of our data-driven advice You are intellectually honest, not fooled by randomness, and obsessive about details You are well versed in techniques such as statistical analysis, exploratory analysis, and predictive analysis Rapidly design and implement machine learning and data products that our enterprise customers and internal teams will use to make informed data-backed decisions Design and implement the data and analytics products that are leveraged by our enterprise customers Provide data insights back to the organization in an accessible and end-user friendly manner Collaborate with software engineers, data engineers, and fellow scientists to create the best solutions for our customers internally and externally Work closely with stakeholders and contribute your suggestions to build optimal solutions Implement algorithms with modern software development and delivery techniques Remain up-to-date with the latest trends in data science and bring that knowledge to life in our products and analysis Be flexible to handle other duties as assigned Bachelor's degree in Computer or Data Science, Applied Mathematics, or a similar technical field of study, or equivalent practical experience Minimum of 5 years of experience as a Data Scientist, Data Engineer, or Machine Learning Engineer 3-5 years of experience with Python/Java and SQL as it pertains to Data Analytics / Data Mining Deep familiarity with BI/Data tools such as Tableau, Spark, Snowflake, etc. Familiarity with Kubernetes, C#, Docker, Apache Kafka a plus! Strong background in Machine Learning a must. Focus on recommendation systems, natural language processing (NLP), Bayesian estimation, or reinforcement learning would be a plus. Generous vacation policy, paid holidays, and paid parental leave Competitive Medical, Dental and Vision Plans Downtown Toronto Office in the Entertainment District- easy walk to TTC and Union Station Work from home flexibility Seismic Cares volunteer program #OneSeismic culture that celebrates wins, encourages autonomy, ownership, and transparency 
ScrapedJobID586:
Be a member of Fortisandbox team Own design, implementation, and maintenance of machine learning solutions Do research into existing deep learning methods and how they best fit cybersecurity needs Write reports, blogs, and patents Have an opportunity to be creative and explore new methods while supervised by team manager Collaborate with QA team to troubleshoot customer issues related to AI Masters or PhD degree in computer science, software engineering or related discipline At least 2 years of experience implementing applied machine learning products Hands on skill with implementing data pipelines, handling large data sets, interface with SQL databases Proficiency in Python, C++, and object oriented concepts Practical understanding of machine learning algorithms like decision trees, Bayesian inference, linear regression, deep learning, graph convolutional networks, recursive neural networks Strong communication skills Practical familiarity with Docker, Kubernetics Experienced with developing in Linux and Windows environment Reverse engineering skills when applied to reversing windows PE files, Office documents, etc. Familiar with sandboxing technologies 
ScrapedJobID587:
Manage client relationship and key stakeholders Collaborate with client to align business requirements with data science systems and process solutions that ensure client’s overall objectives are met Collaborate and work closely with cross-functional antuit.ai and the domain experts to design and deliver the solution Create meaningful presentations and analyses that tell a “story” focused on insights, to communicate the results and ideas to key decision makers in antuit.ai and client companies Monitor, track, and report project progress to internal and external key stakeholders Lead and mentor a global services team of technical and analytical experts who deliver value to our customers both in the CPG and Retail world Develop and manage processes, systems, and KPIs for delivery excellence Advise on implementation strategies and best practices Develop, implement, and oversee the execution of implementation projects Ensure high quality proactive communication with our customers Provide non-technical support during the "go-live" period. Take hands-on role with our customers and team members, helping navigate challenging situations to achieve positive results for all parties Provide input to the product roadmap based on customer needs and experiences Master’s degree or Bachelor’s degree with relevant industry experience will be considered in lieu of advanced degree. Strong project management and organizational skills 5+ years of experience in CPG/retail particularly in forecasting 5+ years of experience with implementing Demand Planning, Sales Planning, or Advanced Planning solutions. 2+ years of experience with AI/ML solutions Relevant solutions consulting and implementation experience with other leading supply chain planning solutions such as Oracle, Blue Yonder / JDS, SAP, or similar. Strong business analysis skills, understanding and usage of statistical algorithms, SCM concepts, awareness of tactical planning on overall supply chain required. Must have excellent communication and interpersonal skills to interact with a wide variety of internal and external personnel, with emphasis on follow-through and reporting. Understand and adhere to Information Security policies, guidelines and procedure, practice them for protection of organizational data and Information System. Take part in Information Security training and act accordingly while handling information. Report all suspected security and policy breach to Infosec team or appropriate authority (CISO). 
ScrapedJobID588:
Support research scientists in their day to day technical tasks Engineer features that can help identify cognitive impairment or mental health disorders from speech and text Develop and implement data analysis methods and techniques; deploy and integrate them to our production environment Develop, implement, and deploy machine learning model prototypes Improve research-related processes by applying relevant tools, maintaining and improving the Docker environments, etc. An understanding of software engineering best practices (eg. write clean, modular, well-documented code; refactor code for efficiency; create unit tests to test programs; etc.) An understanding of machine learning engineering best practices, tools, and techniques Experience conducting code reviews A minimum of 2-3 years industry experience working with data, coding, and scripting (Python) Experience with a number of ML techniques and frameworks, e.g. data normalization, sampling, linear regression, decision trees, deep neural networks, text tokenization etc. (pandas, numpy, scipy, scikit-learn, pytorch, spacy, huggingface) Experience with doing machine learning R&D in a production environment, excellent knowledge of model evaluation metrics and best practices (Docker, Amazon AWS, etc) Experience with natural language processing and/or speech processing Excitement and interest in working with research scientists in the machine learning for health space An ability to work quickly, and a mindset conducive to getting things done An ability to work with a fair amount of autonomy Experience in a fast growth, startup environment Competitive compensation with equity options. Health and dental insurance. Generous work from home policy. 4 weeks vacation. Winter holiday week off. Half-day Fridays in July and August. Office is a 2-minute walk from Yonge & Bloor which is home to many restaurants, amenities and transit options. 
ScrapedJobID589:
Deep experience with at least one cloud vendor and how to train neural network architectures on them. Fundamentally understand the options for distributed tensorflow (or equivalent frameworks) Able to develop in Python Functional knowledge of C++ Experience working through python library dependency issues Knowledge of machine learning and deep learning tools and frameworks such as Tensorflow, Pytorch, scikit-learn, etc Fundamentals of Unix and Modern Distributed Systems design Excellent oral and written communication skill Ability to work in a global team Distributed frameworks, e.g., Dask, Spark Experience with Infrastructure as Code (Terraform, Ansible, Cloudformation etc.) Video dated October 2019. 
ScrapedJobID590:
HOOPP Pension Plan (Defined Pension) Retirement Planning Program Generous vacation days for permanent and long-term contracts Work-life balance Career Planning Program Learning and Professional Development Program Flexible benefits program from your first day on the job for permanent and long-term contracts Strong problem solving skills, with an emphasis on developing products and services to support stakeholder business decisions. Strong organizational skills with a demonstrated ability to manage multiple tasks and priorities. Strong interpersonal and presentation skills are essential, including the ability to communicate (both orally and in writing) complex ideas in simple terminology. Proven ability to work as part of a team, and to work with minimal supervision. Teaching experience in higher education is an asset. Experience with federal, provincial, or hospital healthcare datasets is an asset. Familiarity with AWS, Google Cloud, or Microsoft Azure is an asset. Understanding of Canada's federal and provincial healthcare systems is an asset. Fluency in English required, bilingualism is an asset Undergraduate degree in Mathematics, Statistics, Biostatistics, Economics, Computing Science, Data Science, or related field or equivalent experience. Graduate degree is an asset. A minimum of three years’ experience in data engineering and/or data science, including either (1) data architectures and pipelines or (2) statistical and machine learning. Relevant tools and techniques may include SQL, Air Flow, gradient boosting, and neural networks, etc. Extensive working experience with Python or R to manipulate data and draw insights from datasets. Experience with SAS is an asset. une structure salariale concurrentielle un régime d'avantages sociaux flexible dès le premier jour de travail l'adhésion au régime de retraite HOOPP un programme de planification de la retraite un équilibre travail-vie personnelle un programme de planification de carrière des programmes d'apprentissage et de perfectionnement professionnel Solides aptitudes pour la résolution de problèmes, plus particulièrement en ce qui concerne l’élaboration de produits et de services visant à soutenir les décisions opérationnelles des intervenants. Excellentes aptitudes pour l’organisation et capacité manifeste à gérer de multiples tâches et priorités. Entregent et excellentes aptitudes pour la présentation, dont la capacité à vulgariser des concepts complexes (de vive voix et par écrit), essentiels. Capacité manifeste à travailler au sein d’une équipe et avec un minimum de supervision. Expérience de l’enseignement universitaire, un atout. Expérience d’ensembles de données sur les services de santé à l’échelle fédérale, provinciale ou des hôpitaux, un atout. Connaissance d’AWS, de Google Cloud ou de Microsoft Azure, un atout. Compréhension des systèmes de santé fédéral et provinciaux au Canada, un atout. Maîtrise de l’anglais essentielle; maîtrise du français, un atout. Diplôme de premier cycle en mathématiques, en statistique, en biostatistique, en économie, en informatique, en science des données ou dans un domaine connexe, ou expérience équivalente. Diplôme d’études supérieures, un atout. Au moins 3 années d’expérience en ingénierie des données ou en science des données, y compris (1) en architectures et pipelines de données ou (2) en apprentissage statistique et automatique. Les techniques et les outils pertinents peuvent inclure SQL, Airflow, le renforcement de gradient et les réseaux neuronaux. Vaste expérience de l’utilisation de Python ou de R pour manipuler des données et tirer des conclusions des ensembles de données. Expérience de SAS, un atout. 
ScrapedJobID591:
Partner with the Business Lead to develop and promote the DMA research services and innovation capabilities to support business development activities with established and prospective academic and industry partners; encourage and facilitate industry interactions, including research engagements. Promote engagement of services provincially, nationally, and internationally across the bioscience community with institutional partners, collaborators, and external clients. Lead the Data Management and Analytic team by managing the employee career cycle through activities such as: recruitment, retention and separations, orientation, and onboarding, coaching and performance feedback, supporting professional growth, training, and development, managing performance, and addressing disciplinary matters. Manage the implementation of programs, activities, and systems to support the delivery of optimal services to both internal and external researchers, partner organizations, collaborators, and clients. Define and implement consistent data capture, management and access policies across GIFS and subsidiary programs and platforms (e.g., OPAL, Engineering Biology, Cell Biology, Plant Growth Facilities) to ensure long-term stewardship and data integration and enable data analytics and data repurposing across GIFS. Define and implement Machine Learning to accelerate the Design-Build-Test- and Learn cycle at GIFS. Define and implement consistent data capture, management and access policies across programs GIFS leads such as P2RIC, CERC and Bangladesh. Define the opportunity and establish cloud-computing resources to support computational needs for GIFS data analytic pipelines. Exploit economies of scale in hardware acquisitions, software licensing, and systems administration by consolidating data and computational resources across GIFS. Create, optimize, and manage workflows to meet internal and external requests, focusing on high-quality, high throughput. As the subject matter expert in bioinformatics lead the interdisciplinary application of information technology tools for collecting, analyzing, storing, and visualizing biological data applied to agriculture. Lead by example with a commitment to continuous improvement and GIFS values. Establish and manage lab processes, including but not limited to, electronic lab notebook, data and metadata management, data analytics and large-scale data warehousing infrastructure such as a laboratory-information-management-system. Negotiate and monitor fee for service agreements in partnership with the GIFS Business Development Office. Work with the Business Development team in identifying funding opportunities; provide technical review and support for developing co-funding for industry-sponsored research, grant submissions and funding opportunities to support the growth of the Platform and GIFS. Collect, analyze, and synthesize data related to overall performance. Facilitate communication among clients, the research community, and key stakeholders. Identify strategic alliance partners and develop long-term, sustainable relationships. Foster and promote a culture of innovation by dedicating time for innovation within the platform. Participate in the Scientific Executive Committee (SEC) and help in defining, supporting, and implementing scientific and strategic direction for the Institute. Other accountabilities as assigned. Minimum of five (5) years of hands-on experience in bioinformatics and machine learning applied to next-generation sequencing data, engineering biology and cloud computing. Minimum three (3) years of experience in the technical management of operations in a life sciences laboratory. Experience in using advanced genomic, computational and/or data science approaches to study biological phenomena in a range of eukaryotic organisms. Research leadership in areas at the intersection of genome biology, computational biology, biostatistics, data management and cloud computing will be prioritized. Experience with project management, product development, and/or innovation projects, ideally in the ag biotechnology ecosystem. Experience leading and developing teams. Experience with research funding models and processes. Industry-focused business development and/or marketing experience along with a strong understanding of both academic and industry environments is highly desired. Demonstrated experience and skill in building relationships with diverse constituencies and negotiating commercial agreements. The ideal candidate will have direct experience in the bridging research to industry and the ability to bring the results of scientific research to the marketplace. Innovative problem solver capable of overcoming challenging and complex issues in a fast-paced environment and growing market. Excellent oral and written communications skills, including the ability to convey complex technical ideas to non-specialist audiences. Ability to manage multiple projects simultaneously and work effectively within a high achieving team environment. Sound judgment, discretion, diplomacy, and professional integrity. Excellent interpersonal skills with the ability to establish and maintain professional relationships that support exceptional collaboration. Ability to gather, analyze, and present information with attention to detail. Ability to work effectively in a diverse working environment. 
ScrapedJobID592:
Construire un modèle de tarification pour les nouveaux programmes en vue de leur lancement Construire un modèle de prévision pour anticiper la rentabilité des comptes Soutenir la stratégie de prix de Dialogue Optimiser notre structure de coûts avec l'aide des services de produits et des opérations Augmenter l'utilisation de l'analyse de données en libre-service des fonctions financière et de mise en marché Développer des modèles de tarification personnalisés pour les partenaires et les clients 3 ans d'expérience en tant qu'ingénieur(e) analytique, scientifique de données ou analyste de données Maîtrise de SQL et de Python ou R De l'expérience dans le traitement massivement parallèle d'entrepôts de données (Snowflake, Redshift, BigQuery) De l'expérience dans l'établissement de modèles d'entrepôts de données (DBT est un atout) Un atout : de l'expérience avec Looker, Metabase, Tableau, Snowplow Un régime de rémunération flexible, comprenant un programme d'unités d'action assujetties à des restrictions, un régime d'incitatifs à court et à long terme et un régime d'avantages sociaux financé à 100 % pour nos employés à temps plein Accès illimité à tous les programmes de Dialogue pour vous et les membres de votre famille immédiate Une équipe de personnes brillantes, travaillantes et attentionnées qui contribueront à avancer votre carrière Une politique de congés généreuse, comprenant 4 semaines de vacances pour les employés à temps plein ainsi que 9 journées bien-être Un horaire de travail souple et une approche hybride en matière de télétravail afin de vous offrir toute la flexibilité dont vous avez besoin Un bureau nouvellement conçu et primé pour son architecture au cœur du Vieux-Montréal Build pricing model for new programs in preparation of their release Build predictive model to forecast account profitability Support Dialogue's pricing strategy Optimize our cost structure with product and operations Increase self-serve analytics usage within the finance and go-to-market functions Develop custom pricing models for partners and enterprise clients 3 years of experience as an analytics engineer, data scientist or data analyst Proficient in SQL and Python/R Experience with MPP data warehouse (Snowflake, Redshift, BigQuery) Experience developing data warehouse models (DBT is a plus) A plus: experience with Looker, Metabase, Tableau, Snowplow A flexible compensation package, including a restricted stock units (RSU) program, short-term and long-term incentive plans, and a 100%-funded benefits for our full-time employees Unlimited access to all of Dialogue's programs for you and your immediate family members because we care about you A team of bright, hard-working, and caring individuals that will contribute to your growth A safe space where sharing your ideas and vision are encouraged and that will allow you to influence company direction A generous time-off policy, including 4 weeks of vacation for full-time employees and up to nine (9) wellness days A flexible work schedule and a hybrid approach to remote work to allow for all the flexibility you may need A newly designed and architectural award-winning office in the heart of Old Montreal 
ScrapedJobID593:
Establish Machine Learning Strategy: Collaborate with Product, Data, and Software teams to establish actionable strategies related to the implementation of ML at DarkVision. Set priorities and deadlines: Work alongside Project Management to define key priorities and establish deadlines. Supervise & Grow the Machine Learning team: Manage and grow DarkVision's Machine Learning Engineering team, overseeing goals and performance in the following areas: Deep Learning Algorithm Research Machine Learning Pipeline Development and Deployment Monitoring and continuous improvement of ML models Help lead our research partnerships: Build and leverage relationships with universities to partner on AI/ML projects, measuring effectiveness and relaying progress to the leadership team. Smart, keen, quick, and strong desire to learn new things Able to discern when ML is warranted instead of utilizing a conventional solution At least 3 years of experience in managing cross functional teams Demonstrated ability in developing end-to-end deep learning projects Define ML experiments to ensure agile development Bachelor or Master's in Software Engineering, Computer Science or Equivalent. AWS services like Sagemaker, Batch, Lambda. Training models with imbalanced datasets. Organizing enterprise data into structured datasets for ML and visualization teams Computer vision and edge deployment experience Competitive salary or higher (Top $ for top talent) Full benefits package. Competitive vacation allotment Flexible work environment. Well-Funded: We are backed by Koch Industries - North America's largest privately held company and are actively working with top-tier operators across North America. 'A' Players: Our team is made up of talented, intelligent, and hardworking people. If you're an 'A' player, you'll enjoy the intellectually stimulating, challenging and respectfully competitive atmosphere. Growing Quickly: We are in the process of launching several new product lines and as a result have more than doubled our headcount over the last year. Lots of Opportunities: We are transitioning into a much larger organization and will soon be expanding into a 52,000 sq ft facility in Vancouver. We have recently opened a larger Calgary office and have expanded into the US, starting with a new office in Houston, TX. 
ScrapedJobID594:
Conduct design and development to build and optimize deep learning software and hardware to accelerate deep learning on FPGAs. Design, develop and optimize for deep learning training and inference frameworks. Transform computational graph representation of neural network model. Optimizing code for FPGA computing hardware backends. Interacting with deep learning researchers and experience with deep learning frameworks. Problem Solving skills. Written/verbal communication skills. The candidate must have a Master's degree in Electrical Engineering, Computer Engineering, Computer Science or a related field. FPGA, Verilog, C/C++ and/or Python. Algorithms development. 
ScrapedJobID595:
Translating key business objectives into insight rich experiments that drive marketing ROI Ensuring execution (i.e., list creation) is done efficiently and with excellence Designing campaign results can be actioned by providing high value campaign reporting Work in a consultative role to provide "value-added" insights in the form of analysis, interpretation and advice of campaign reporting Your success will be predicated on your ability to forge strong partnerships, communicate effectively, deliver on-time, and continuously strive for increased efficiency. Design/execute/measure high impact direct to consumer marketing experiments Continuously improve campaign design and delivery by leveraging any and all analytical tools/techniques at your disposal Execute with excellence Manage your project pipeline to ensure agreed upon timelines can be met Proactively provide analytical guidance to key stakeholders, based on deep understanding of the businesses, to understand and enhance marketing ROI Maintain a culture of risk management and control, supported by effective processes and sound infrastructure Familiarity with direct marketing principles (Predictive Models, Experiment Design, A/B testing, Sample Size calculations, Net Performance Measurements, etc.) Good knowledge of everyday banking products and transactions Technical and detail oriented Knowledge of how campaigns are created by leveraging customer data from internal data warehouses through the use of programming tools such as Unica and SAS A project management mindset to help deliver on time to specifications Team player while able to work independently Pragmatic decision maker blending a mix of intellect, experience and street smarts A profit driven mindset 1-2+ years of relevant experience in a direct marketing, consulting, analytics, or agency-side role in financial services/telecom (or other high volume direct marketing industries) Significant experience with IBM Campaign (Unica) Knowledge of SQL and SAS; knowledge of databases and data structures; knowledge of vendors and file format requirements Experience designing and executing successful direct marketing experiments, including channel tests Familiarity with concepts such as "next best offer" and "always-on" an asset Degree in business, science, statistics, engineering, or other quantitative discipline Track record of delivering successful initiatives on time and on budget 
ScrapedJobID596:
The ideal candidate will be familiar with the following technical skills Python or R for Data Science. Reproducible Data Science Workflows in Python or R. Machine Learning and Deep Learning Principles. Statistical Modelling Data Analytics and Business Intelligence (Techniques and Tools like PowerBI) Big Data Technologies (Spark, Hive etc). Cloud Technologies (AWS Experience preferred). Foundational Computer Science Skills are nice to have. >3 years of professional experience in Data Science Have worked in Agile development environment. >1 year of leading/managing a team Have worked in a Data Science or Analytics consulting, setting for >3 years. Experience in the following domains would be an advantage:
Telecom
Life Sciences
Technology Telecom Life Sciences Technology Bachelors required Masters preferred Agile Certified Nice to have Responsible for the timely delivery of quality results to the client. Regularly meet with and build relationships with key client stakeholders. Identify and capitalize on opportunities for upselling and cross-selling. Responsible for adequately resourcing the engagement including backfilling of rotating resources. Responsible for ensuring all consultants are documenting their work and roles as per company and client requirements. Develop Level of Effort Estimates and other related collateral as required by client. Manager is responsible for ensuring teams are running effective daily scrum meetings. Manager is responsible for ensuring projects are delivered on time and within budget Responsible for triaging with the consultants work items to align with client expectations. Select the correct PM format (Scrum/Kanban/ScrumBan) and ensure all team members are well coached on the working style. Ensure timely regular reports are generated and shared with internal stakeholders and clients. Mentor consultants on soft and hard skills required for role. Develop Performance Plans for each consultant. Develop learning plans for consultants. Ensure clean handoff of consultants to other managers in event of transition. Perform weekly 1-1 check ins with consultants. Manage and measure consultant performance. Involved in selling technical solutions to current and prospective clients. Developing deliverables for SoWs and LOE's in tandem with the Sales team. Cataloging Consultant work and ensuring Blogs, Case Studies and other material are being generated that can be used to enhance sales and marketing efforts. Will act as evangelist for ProCogia in the community -getting involved in Meetups and attending relevant conferences. Generate go-to-market service offerings Be involved in initiatives to enhance ProCogia's reputation as leaders in the Data Solutions space (e.g. Blogs, Articles, White Papers, Podcasts etc). As a hiring manager, you will be responsible for designing interview setup for open roles as well as assisting in the creation of job advertisements. Triage incoming interview requests and assist in scheduling interview rounds. Improve the quality of interview screening through the development of reusable interview collateral and the mentoring of less experienced consultants on their interview techniques. Involved in internal initiatives to improve existing processes and identify gaps and create new processes. With the management team set plans and directions for the organization. Communicate direction setting information from ProCogia leadership and the customer leadership. Manage the organization budget. 
ScrapedJobID597:
Monday to Friday Yes 
ScrapedJobID598:
To help the Data Lab families accelerate the completion of their AI projects by contributing to the implementation and execution of a strategy of opening up to the outside world that must allow access to all players in the Quebec, Ontario, Canadian and in some cases global innovation ecosystem. From the world of startups to the academic world, including solution providers and companies tackling problems similar to those of the Lab, the candidate must develop an excellent understanding of the roadmaps of the Data Lab's families in order to propose to them the collaborators who will have the greatest impact in the realization of their projects. To act as Senior AI Business Analyst for the climate risk project portfolio. Help define and deliver the Data Lab’s strategy of opening up to the outside world. Develop an excellent understanding of the teams’ roadmaps and propose collaborators to accelerate their achievement. Organize and structure the documentation and results of the different collaborations. Contribute to the definition of the portfolio of climate risk projects, support the projects as a Senior Business Analyst and represent them in our different lines of business. Act as an intermediary between the Data Lab, IT, users and different levels of management. Facilitate working sessions with experts from different fields and different project stakeholders. University degree in a related field or relevant experience At least 5 years of experience as a business analyst in an IT environment, including 2 in an AI context Highly developed analytical skills facilitating problem solving Support, coaching and consulting skills Knowledge of the company, the insurance industry and business processes are important assets Team player Bilingual (English/French) Have knowledge of applied artificial intelligence, its capabilities and limitations. Be involved for at least 2 years in the local or national innovation ecosystem. Be familiar with geospatial or climate science and ideally have accomplished some AI projects in these fields. An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID599:
30 days - Learn about the product (project goals, requirements, constraints, key stakeholders), familiarize with existing code and data, learn about a statistical or machine learning model that is used on our products. Implement tests for this model. 60 days - Full assessment of quality and correctness for one product. Analyze risks and develop a plan of attack. Learn about the infrastructure for machine learning R&D and improve on its automated testing features. 90 days - Full assessment of quality and correctness for an additional product. Analyze risks and develop a plan of attack. Take ownership of a significant feature of the infrastructure for machine learning R&D. Help productionize machine learning models Machine learning models in our products are production-quality Infrastructure for machine learning R&D is significantly improved, helping scientists develop, test, and verify models more quickly Multiple ADI products have their statistical and machine learning models assessed, have sufficient coverage of automated tests, and are regularly manually tested Model accuracies have reasonable correctness, and their errors are also reasonable Tests and quality is documented, including edge cases that are known to deteriorate quality Deep experience in test automation with Python applications Experience working with machine learning frameworks, such as numpy and pandas Experience in AWS, Docker, and API testing Making complex decisions Resourcefulness Focusing on performance Collaborates Courage Instills trust Being open Being flexible and adaptable 
ScrapedJobID600:
Ensure proper data set up and management in Mattel systems Perform audits regarding data integrity for key parameters like pricing, sourcing information Perform quantitative and qualitative analysis of internal data including: demands, inventory, level of excess. Provide ad hoc analysis to meet business needs. Collaborate and support with the Demand Planning process Measure and communicate the KPI’s on regular basis Work with Sales, Marketing, and Planning to provide full transparency on key aspects of the business Provide monthly metrics reporting on net change from previous month’s supply, invalid items, programs, forecast accuracy, etc. and the resulting operational impact Set up mechanisms/new ways to detect and highlight critical forecast changes (i.e. short avails), continuously propose ways to avoid unshippables. Prepare information required for monthly demand meetings Develop reporting tools to improve the planning processes and support business decisions Create data dashboards, graphs and visualizations and continue our drive for data automation through visualization platforms like Tableau or Thoughtspot Mine and analyze large datasets, draw valid inferences and present them successfully to management using a reporting tool. Produce regular weekly / monthly business summaries that increase knowledge and insights into our impact at the point of purchase Highly audience aware and engaged, equally able to consolidate large quantities of data and insight into short form hard hitting content as with getting into highly granular depths of detail. Proactively interrogate external data and insights resources to contextualize Mattel performance and inform and challenge key stakeholders Utilizes tools to create simpler, faster, better reporting Solid interpersonal and communication skills – able to communicate effectively across all organizational levels and all functional areas, understanding and presenting the viewpoints of others Sound business judgment – able to interpret issues and recommend actions to best support group, division, and corporate goals Strong analytical skills – able to coordinate diverse information, identify relevant data, recommend, and implement corrective actions Able to identify and address process improvements and share expertise with others Ability to influence and achieve expected results independently by establishing effective cross-functional & cross-culture relationships High level of organizational and time management skills. Advanced/expert proficiency with Excel and VBA Extensive knowledge of Access will be an asset Extensive knowledge and usage of Mattel’s systems and Cognos will be an asset Exceptional problem solving & analytical ability Ability to perform in a demanding ,dynamic, highly visible organization 1+ years in a supply chain role is an asset Working knowledge of a demand planning tools We collaborate: Being a part of Mattel means being part of one team with shared values and common goals. Every person counts and working closely together always brings better results. Partnership is our process and our collective capabilities is our superpower. We innovate: At Mattel we always aim to find new and better ways to create innovative products and experiences. No matter where you work in the organization, you can always make a difference and have real impact. We welcome new ideas and value new initiatives that challenge conventional thinking. We execute: We are a performance driven company. We strive for excellence and are focused on pursuing best in class outcomes. We believe in accountability and ownership and know that our people are at their best when they are empowered to create and deliver results. 
ScrapedJobID601:
Ensure proper data set up and management in Mattel systems Perform audits regarding data integrity for key parameters like pricing, sourcing information Perform quantitative and qualitative analysis of internal data including: demands, inventory, level of excess. Provide ad hoc analysis to meet business needs. Collaborate and support with the Demand Planning process Measure and communicate the KPI’s on regular basis Work with Sales, Marketing, and Planning to provide full transparency on key aspects of the business Provide monthly metrics reporting on net change from previous month’s supply, invalid items, programs, forecast accuracy, etc. and the resulting operational impact Set up mechanisms/new ways to detect and highlight critical forecast changes (i.e. short avails), continuously propose ways to avoid unshippables. Prepare information required for monthly demand meetings Develop reporting tools to improve the planning processes and support business decisions Create data dashboards, graphs and visualizations and continue our drive for data automation through visualization platforms like Tableau or Thoughtspot Mine and analyze large datasets, draw valid inferences and present them successfully to management using a reporting tool. Produce regular weekly / monthly business summaries that increase knowledge and insights into our impact at the point of purchase Highly audience aware and engaged, equally able to consolidate large quantities of data and insight into short form hard hitting content as with getting into highly granular depths of detail. Proactively interrogate external data and insights resources to contextualize Mattel performance and inform and challenge key stakeholders Utilizes tools to create simpler, faster, better reporting Solid interpersonal and communication skills – able to communicate effectively across all organizational levels and all functional areas, understanding and presenting the viewpoints of others Sound business judgment – able to interpret issues and recommend actions to best support group, division, and corporate goals Strong analytical skills – able to coordinate diverse information, identify relevant data, recommend, and implement corrective actions Able to identify and address process improvements and share expertise with others Ability to influence and achieve expected results independently by establishing effective cross-functional & cross-culture relationships High level of organizational and time management skills. Advanced/expert proficiency with Excel and VBA Extensive knowledge of Access will be an asset Extensive knowledge and usage of Mattel’s systems and Cognos will be an asset Exceptional problem solving & analytical ability Ability to perform in a demanding ,dynamic, highly visible organization 1+ years in a supply chain role is an asset Working knowledge of a demand planning tools We collaborate: Being a part of Mattel means being part of one team with shared values and common goals. Every person counts and working closely together always brings better results. Partnership is our process and our collective capabilities is our superpower. We innovate: At Mattel we always aim to find new and better ways to create innovative products and experiences. No matter where you work in the organization, you can always make a difference and have real impact. We welcome new ideas and value new initiatives that challenge conventional thinking. We execute: We are a performance driven company. We strive for excellence and are focused on pursuing best in class outcomes. We believe in accountability and ownership and know that our people are at their best when they are empowered to create and deliver results. 
ScrapedJobID602:
Work with Data Scientists to prepare data/features for Machine Learning modeling, which includes data exploration, data cleansing and feature engineering Enhance data collection procedures by assessing the effectiveness and accuracy of data sources and data gathering techniques. Support data science teams in data extraction and preparation from multiple sources including files, data base tables, Azure Connected Data Platform, modelling the data for use for Advanced Analytics and business dashboards. Logical and physical data modeling of data to align with Business Intelligence/Advanced Analytics initiatives and Canada Life modelling standards for meta data, and the management of the data models using modeling tools (such as Erwin, Collibra). Adhere to all company data and analytics policies and standards. Define and manage application security setup using Active Directory/Azure security, including access audit and access clean-up. Build insights: complete data analysis and discovery to better understand the data and the story it is telling to drive actionable results. Loves teamwork and collaboration, collaborates daily with the core Analytics squad and business. Open to learning and sharing with others across the company, including senior leadership and community of practice participation. Recommend improvements to data engineering and governance practices across our company. Master or above degree in computer science, engineering, data science, mathematics, or related fields. Proven experience as an ML engineer or similar roles. Excellent analytical and problem-solving skills. A strong proficiency in querying and manipulating large data sets for analytical purposes using SQL-like languages (Hive / Hadoop experience preferred). Proven proficiency in Python and R coding, including basic mathematical computing libraries such as NumPy, machine learning fundamentals, and data science fundamentals. Working experience and knowledge of Cloud data platform considered an asset. Excellent communication and presentation skills and strong organization skills. Agile, practical, customer service-oriented mindset (doesn’t over complicate processes). Generally curious and excited to learn new things. 
ScrapedJobID603:
Partner with stakeholders, process specialists and users to elicit and document business requirements. Elicit requirements using interviews, document analysis, requirements workshops and workflows. Translate requirements into effective logical and physical designs using dimensional modeling techniques. Design, develop, implement and support enterprise-reporting solutions and provide ad-hoc data analysis. Design, develop and maintain reports, dashboards and analytical tools. Conduct and/or support testing activities, as appropriate, throughout the lifecycle of the business intelligence systems. Support end users in application usage and administration through consultation, training and documentation as needed. A post-secondary degree or diploma in a relevant field (i.e. business, information technology, data science, etc.); or a relevant certification (CBIP, CBAP, etc.); or a combination of relevant experience and education. Prior experience in building and deploying enterprise business intelligence reports or dashboards is an asset. Prior experience working with the IBM Cognos; or Microsoft PowerBI reporting tools is an asset. Prior experience in performing basic data queries using SQL is an asset. Knowledgeable in enterprise business intelligence and data mining. Very strong attention to detail. Ability to adapt quickly to new technologies and changing business requirements. Ability to quickly troubleshoot problems that may arise. Must be a strong team member and have the ability to work independently or as part of a team. Excellent verbal and written communication skills. Professional image with ability to form good partner relationships across functions. Advanced knowledge of all Microsoft Office products. Strategic, intellectually curious thinker with focus on outcomes. Day shift 
ScrapedJobID604:
In this role you will participate in Pre-Silicon SW development of end-to-end machine learning-based solutions for camera and computer vision applications running on AMD Edge platforms Work with engineering teams cross technical functions, geographical regions and time zones, involving various facets of computer vision machine learning product Work closely with HW and SW teams and get your hands on a broad range of activities from solution design, software development, to optimization and deployment for Edge platforms Work closely with Pre-silicon teams (simulation, emulation, etc.) to bring-up SW stack on platform. Work closely with architecture teams to provide timely feedback and direction on various architectural design decisions Measure, analyze, and optimize power and performance for both application and system software/hardware stack Determine and implement unit testing and system level testing strategies Proven experience with software engineering and C, C++ programming Experience with Machine Learning/Deep Learning frameworks like Tensorflow, Pytorch Experience with Pre-Silicon SW development. Experience with ASIC design process preferred. Good understanding of deep learning concepts like CNN, RNN/LSTMs Strong background in computer vision, computer system architecture, and algorithm design Effective communication skills, strong collaboration to join a global organization working cross geographical regions and time zones Experience with end-to-end software application development flow – from design to development to integration and testing Experience in developing computer vision algorithms using OpenCV and/or Deep Learning approaches Experience with system software (driver/OS level) on Android/Linux/Windows environment Experience of profiling and optimization techniques for software and system stacks Validated debugging and analysis skills, for root causing sophisticated issues at both application and system level Experience with GPGPU compute like OpenCL, DirectX Compute Experience with camera architecture, camera APIs and other camera algorithms Experience in development of any of the deep learning compiler frameworks like TVM, Glow or XLA; or other LLVM-based compilers 
ScrapedJobID605:
Partner closely with business leaders across the organization to understand current and future business Guide the future direction of data strategy and processes, including intake, sources, database design Transform data and information into insights that inform high-level strategy and tactical decision-making Be a champion for a data driven culture, lead a team of cross-functional analysts and support and train Develop and execute a plan to maximize self-service capabilities for internal users and customers. Proactively communicate and collaborate with internal and external customers to ensure information Oversee internal and external application/tool development, integration and support. Where required, Liaise with HSB US, UK and Munich Re during forecasting business needs and requirements. Implement a formal data governance approach and increase the maturity of the enterprise data Influence and effect business process changes to support an efficient and cost-effective business Masters or bachelor’s degree in Analytics, Business Intelligence, Data Science, Economics, 7+ years as an analyst, data scientist or data engineer preferably in the Property and Casualty insurance Strategic mindset with demonstrated experience in implementing data frameworks and driving Expert communication skills and ability to influence varying audiences and business partners, Experienced people leader with focus on coaching and mentoring cross functional team members, Knowledge of (re)insurance & products, financial metrics used in insurance and industry data sources, Strong teamwork skills in order to collaborate and build strong relationships with co-workers and internal Project management skills including to plan, organize, motivate, and manage resources to achieve Decision making skills and able to solicit and objectively consider input from appropriate sources, and Agility with ability to adapt approaches that are appropriate for each and new situations, 
ScrapedJobID606:
Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems. | Conceptualiser et s'approprier l'architecture de données pour plusieurs projets à grande échelle, tout en évaluant les compromis coûts-avantages de la conception et de l'exploitation au sein des systèmes. Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve. | Créer et contribuer à des cadres qui améliorent l'efficacité de l'enregistrement des données, tout en travaillant avec l'infrastructure de données pour trier les problèmes et les résoudre. Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights visually in a meaningful way. | Collaborez avec les ingénieurs, les gestionnaires de produits et les scientifiques des données pour comprendre les besoins en matière de données, en représentant visuellement les principales données de manière significative. Define and manage SLA for all data sets in allocated areas of ownership. | Définir et gérer les accords de niveau de service pour tous les ensembles de données dans les domaines de propriété attribués. Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership. | Déterminer et mettre en œuvre le modèle de sécurité en fonction des exigences en matière de confidentialité, confirmer que les mesures de protection sont respectées, traiter les problèmes de qualité des données et faire évoluer les processus de gouvernance dans les domaines de propriété attribués. Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains. | Concevoir, construire et lancer des collections de modèles de données et de visualisations sophistiqués qui prennent en charge plusieurs cas d'utilisation dans différents produits ou domaines. Solve our most challenging data integration problems, utilizing optimal ETL patterns, frameworks, query techniques, sourcing from structured and unstructured data sources. | Résoudre nos problèmes d'intégration de données les plus difficiles, en utilisant des modèles ETL optimaux, des cadres, des techniques d'interrogation, à partir de sources de données structurées et non structurées. Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts. | Contribuer à la maîtrise des processus existants en production, en optimisant le code complexe grâce à des concepts algorithmiques avancés. Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts. | Optimiser les pipelines, les tableaux de bord, les cadres et les systèmes pour faciliter le développement des artefacts de données. Influence product and cross-functional teams to identify data opportunities to drive impact. | Influencer les produits et les équipes interfonctionnelles pour identifier les opportunités de données afin de générer un impact. Mentor team members by giving/receiving actionable feedback. | Encadrer les membres de l'équipe en donnant/recevant des informations concrètes. 5+ years experience in the data warehouse space. | Plus de cinq ans d'expérience dans le domaine des systèmes de stockage de données. 5+ years experience in custom ETL design, implementation and maintenance. | Plus de cinq ans d'expérience dans le domaine des systèmes de stockage de données. 5+ years experience with object-oriented programming languages. | Plus de cinq ans d'expérience dans les langages de programmation orientés objet. 7+ years experience with schema design and dimensional data modeling. | Plus de sept ans d'expérience dans la conception de schémas et la modélisation de données dimensionnelles. 7+ years experience in writing SQL statements. | Plus de sept ans d'expérience dans l'écriture d'instructions SQL. Experience analyzing data to identify gaps and inconsistencies. | Expérience de l'analyse des données pour identifier les lacunes et les incohérences. Experience managing and communicating data warehouse plans to internal clients. | De l'expérience dans la gestion et la communication des plans d'entrepôt de données aux clients internes. BS/BA in Technical Field, Computer Science or Mathematics. | Licence dans un domaine technique, en informatique ou en mathématiques. Experience working with either a MapReduce or an MPP system. | Expérience de travail avec un système MapReduce ou MPP. Knowledge and practical application of Python. | Connaissance et application pratique de Python. Experience working autonomously in global teams. | Expérience du travail autonome au sein d'équipes internationales. Experience influencing product decisions with data. | Expérience de l'influence des données sur les décisions relatives aux produits. 
ScrapedJobID607:
Develop data-driven physical predictive models within R&D and manufacturing Work on all aspects of the analytics solution development from building efficient data pipelines to implementing leading-edge inferential methods Deploy scalable solutions for large datasets • Develop high-performance software solutions, primarily with the Python data-science stack, and using compiled languages such as C/C++, Fortran, C#, Java Work in collaboration with project management to deliver effective and timely solutions Interact regularly with research groups within Corning Stay abreast of new developments in the field of physics-informed machine learning, with a constant eye on how these innovations can be applied to our problems Participate in presenting new results and research innovations internally and externally Cultivate and grow ties with academia Mentor new hires and interns Strong background in numerical modeling and emerging machine learning and deep learning methods applied to numerical modeling in mechanical engineering, chemical engineering, materials science and applied physics. Experience demonstrated through industrial work, academic research projects or compelling open-source project contributions. Deep understanding of one or more numerical modeling domains, including but not limited to: computational fluid dynamics and heat transfer, solid mechanics, computational materials science, computational electromagnetics, molecular dynamics, agent-based modeling, cellular automata. Strong interest, and preferably demonstrated background, in emerging machine learning approaches to enable and accelerate numerical simulation of physics and chemistry. Strong programming background in one or more languages such as C/C++, Fortran, Python, C#, Java. Excellent communication skills – both oral and written. Graduate-level training in numerical simulation in mechanical / chemical / electrical / civil / materials engineering, applied math, applied physics. Strong hands-on experience with the Python data science stack (Python core, NumPy, SciPy, Pandas, Matplotlib, scikit-learn and deep learning frameworks such as Tensorflow or PyTorch). Experience with High Performance Computing, including General Purpose GPUs, would be a strong asset. Experience in writing clean and maintainable code is critical. Working as part of a team using source management frameworks such as GIT is an asset. Autonomous (Self-starter) Creative Detail-oriented and precise Team player Organized 
ScrapedJobID608:
Overseeing the development of software to clean and investigate large, messy data sets of numerical and textual data Networking with various teams to explore internal and external data sources and APIs to help uncover new trends and improve analysis Designing and contributing to highly scalable data pipelines, tools, and products to enable the analyst community to fully leverage the power of AWS Working with your team to analyze large swaths of data in order to optimize various business programs Managing and developing talent to drive a highly performant and engaged team Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, you’re not afraid to blurt out your disruptive idea. You know how the latest tech works, yet you are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. Crafty: You know how to get things done. You can navigate a large organization, motivate people, and influence your peers. Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Inspiring: You have a passion for developing people and take great pride in your management system. You know how to deliver through others while paving the way for their growth. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook and all the monitors you want! You can travel to a relevant conference of your choice annually - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours, dress code and environment Bachelor’s Degree in a quantitative field At least 5 year of experience in open source programming languages for large scale data analysis (Python, Scala, or Java) At least 5 year of experience with version control system like Git and GitHub. At least 5 year of experience with relational databases and programming in SQL At least 2 years in lead positions (managing people/owning products/architecting and driving an agenda) Master’s Degree or PhD Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) Experience with CICD tools Experience with Machine Learning workflows 5+ years experience in Python 5+ years’ experience with SQL 3+ years in lead positions (managing people/owning products/architecting and driving an agenda) 
ScrapedJobID609:
Diagnose problems and develop compelling, data-driven recommendations Partner with Product, Engineering, and Data Science teams to design solutions to operations problems, influence product roadmaps, and solution new products/processes Manage the development, reporting, and visualization of metrics for the entire Risk organization Maintain, develop and manage various data pipelines and ETLs Improve risk solutions through third party evaluation and integration with a focus on improving the seller experience Design and develop executive presentations for Square's leadership and board members A BS/BA in Statistics, Mathematics, Operations Research, Management Science, Computer Science, or a related technical field, OR BS/BA in Criminal Justice, Economics, Business, or a related business field 4 or more years of relevant experience (or masters and 2+ years) Proficient in SQL Intermediate knowledge on Python (Numpy, Pandas, Matplotlib etc.) Experience with designing and creating data visualizations (e.g. Looker) The ability to answer unstructured questions and bring projects to conclusion A strong passion for Square's mission [Bonus] Experience and interest in risk, trust & safety, payments, or spam prevention [Bonus] Experience with scripting and data analysis programming languages (e.g. Python, R, etc) [Bonus] Experience using statistics and machine learning [Bonus] Consulting / project management experience Healthcare coverage Retirement Plans Employee Stock Purchase Program Wellness perks Paid parental leave Paid time off Learning and Development resources 
ScrapedJobID610:
Customer focus Results and Accountability Innovation Transparency and Integrity Mastery Inclusiveness Sense of urgency Collaboration and Teamwork 
ScrapedJobID611:

ScrapedJobID612:
real-time visibility on how Ubisoft titles are played; and an understanding of the habits and preferences of the people playing them. Design, develop, and optimize extremely efficient and reliable data pipelines to prepare data for the Machine Learning use cases. Work closely with our clients/partners, internal Data Scientists and Developers on diverse data pipelines (batch and stream processes). Play a key role in the creation and improvement of our new Feature Sore solution, aimed to be the central point of interactions for the Data Scientists and everything happening on the platform. Synch up with your team to discuss work-in-progress, ideas, and blockers; plan and prioritize; overcome issues; etc. Be a key member of the team, participate in the decisions and implementations to improve the platform’s quality. Stay current on technological advancements to help develop yourself, the platform and position Ubisoft as a leader of the domain. Minimum 4 years of data engineering design/development experience in building very large data products, ideally in an AI/ML environment. Experience working with Spark and Kafka streams, plus other big data technologies (e.g. Flink, Hadoop, Hive, Athena, etc.) Solid programming knowledge in multiple languages (SQL, Python, Java, Scala...). Previous experience using cloud technology, ideally AWS (S3, EMR, DynamoDB, SageMaker...) Understanding of microservices architecture and REST APIs. Knowledge of CI / CD and associated best practices. Good understanding of ML concepts (Features, models...). Strong communication and collaboration skills. A constant desire to grow and learn and to see teammates succeed together. Experience building and interacting with REST APIs ingesting/serving large amount of data. Already worked on implementing and maintaining a Feature Store. Familiarity with industry standards such as Airflow. Knowledge of Kubernetes, Docker and other DevOps/MLOps technologies. Experience with designing and deploying Data Science/ML solutions in the cloud. An understanding of the video game industry. 
ScrapedJobID613:
to be located in Toronto or Waterloo Offices Use your creativity and curiosity to develop and deploy new analytical tools to help the business in their decision-making Uncover issues and trouble shoot existing tools and data processes, discover the fix and bring the solution to the team Learn our current tools and run reports to be visualized for leaders. Help leaders understand the story behind the numbers Apply data science methodologies to improve the consistency and accuracy of data Requests for more or different information, leading to report development, data checking and visual presentation of the requests Work collaboratively within your team to achieve the best results, communicate and share insights and best practices University degree in computer science, software engineering, data science, statistics, or a related discipline 1-3 years of professional work experience in a data analysis-related position Strong communication (verbal/written) and organizational skills Highly analytical, demonstrated ability to develop creative solutions to complex problems Strong proficiency in using the R programming language for data wrangling and analysis (knowledge of Python also an asset) Strong programming skills and efficient use of Microsoft applications (e.g., Excel, Access, VBA) Knowledge of SAS & SharePoint is an asset Competitive salaries Flexible work schedules Bright, open workspaces and smart casual dress code Three national employee resource groups focused on inclusion and the experience of immigrants to Canada, the LGBTQ+ community, and women in leadership Onsite health and wellness programs Spirit days and a company-wide social committee enhance our employee experience Annual Economical Appreciation Week features team events and fun surprises 
ScrapedJobID614:
Work with various business units within Mattamy to define problems and requirements Select the appropriate data analytics techniques and data assets to address the business requirements Provide requirements and guidance for data ingestion and data processing to the Data Engineering team Present the outcome of the data analytics solution to the business units in a manner that a broad audience will understand Ensure all appropriate services levels and quality objectives are met Be the expert of all the key data assets of the Mattamy business and perform necessary research of external commercial data and open data that can enhance the outcome of analytics projects Evaluate new data analytics techniques, services, and tools as necessary Provide guidance and coaching to other data analytics citizens across the organization and promote a data driven culture within Mattamy Bachelors’ Degree in Computer Science, Math, Statistics, related field or equivalent working experience Minimum 4 years’ relevant experience in advanced data analytics Expert knowledge and experience with modern analytics tools such as R, Python, SAS or Matlab Experience with interactive dashboard tools such as Tableau, PowerBI Proficiency in Microsoft Office tools including Outlook, Word, Excel, PowerPoint Experience using modern cloud-based data lake technologies such as Azure, Cloudera or Google Demonstrated success collaborating with businesses and non-technical teams to provide insights from data Strong ability to communicate and collaborate effectively with business groups, leadership, and project teams Excellent analytical, organizational, planning and time-management skills Ability to effectively manage multiple priorities simultaneously and can be proactive in responding to business needs Self-directed, an ability to work independently and facilitate training as needed Knowledge and experience in the land development and builder industry in Canada and/or the US Previous experience in the financial services and/or mortgage lending industry Previous experience working in a multi-client/multi-division and cross-functional matrixed environment Previous experience in coaching junior data analysts or citizen data analysts 
ScrapedJobID615:
Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. AWS Cloud (certification is an asset) AWS services like AWS glue or other AWS services Python programming language. Big Data technologies (like a Spark, hive/HDFS, PySpark, Hadoop) SQL and NoSQL databases, including Postgres and Cassandra. Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. AWS cloud services: EC2, EMR, RDS, Redshift Stream-processing systems: Storm, Spark-Streaming, etc. Object-oriented/object function scripting languages: Java, C++, Scala, etc. 
ScrapedJobID616:
Support research scientists in their day to day technical tasks Engineer features that can help identify cognitive impairment or mental health disorders from speech and text Develop and implement data analysis methods and techniques; deploy and integrate them to our production environment Develop, implement, and deploy machine learning model prototypes Improve research-related processes by applying relevant tools, maintaining and improving the Docker environments, etc. An understanding of software engineering best practices (eg. write clean, modular, well-documented code; refactor code for efficiency; create unit tests to test programs; etc.) An understanding of machine learning engineering best practices, tools, and techniques Experience conducting code reviews A minimum of 2-3 years industry experience working with data, coding, and scripting (Python) Experience with a number of ML techniques and frameworks, e.g. data normalization, sampling, linear regression, decision trees, deep neural networks, text tokenization etc. (pandas, numpy, scipy, scikit-learn, pytorch, spacy, huggingface) Experience with doing machine learning R&D in a production environment, excellent knowledge of model evaluation metrics and best practices (Docker, Amazon AWS, etc) Experience with natural language processing and/or speech processing Excitement and interest in working with research scientists in the machine learning for health space An ability to work quickly, and a mindset conducive to getting things done An ability to work with a fair amount of autonomy Experience in a fast growth, startup environment Competitive compensation with equity options. Health and dental insurance. Generous work from home policy. 4 weeks vacation. Winter holiday week off. Half-day Fridays in July and August. Office is a 2-minute walk from Yonge & Bloor which is home to many restaurants, amenities and transit options. 
ScrapedJobID617:

ScrapedJobID618:
Lead a team of passionate data scientists focused on modeling members’ fitness performance and providing weight recommendations Develop algorithms to sense, understand, and derive insights on human motion while exercising via computer vision, pose detection, and more. Review the team’s designs, algorithms, and code while also spending time developing your own Lead the initiative to fully leverage the world's largest and best fitness data set Collaborate closely with fitness experts on training methodologies; Validate and innovate on new more effective training methodologies using a data-driven approach Work closely and collaborate with front-end and back-end teams to take the team’s work to production Drive the direction of Tonal’s architecture, data collection, analytics, infrastructure, tools, and learning systems Leverage your creativity to identify innovative opportunities for new data-driven features Advanced degree in engineering, scientific, or mathematical field 5+ years data science experience 2+ years leading and/or managing technical teams Knowledge of machine learning and signal processing algorithms Working experience with data filtering and cleansing techniques Strong knowledge of Python and SQL Working knowledge of software development, including RESTful APIs Team player with high integrity Open to feedback and constantly striving to learn and improve High degree of self-awareness 
ScrapedJobID619:
Overseeing the development of software to clean and investigate large, messy data sets of numerical and textual data Networking with various teams to explore internal and external data sources and APIs to help uncover new trends and improve analysis Designing and contributing to highly scalable data pipelines, tools, and products to enable the analyst community to fully leverage the power of AWS Working with your team to analyze large swaths of data in order to optimize various business programs Managing and developing talent to drive a highly performant and engaged team Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, you’re not afraid to blurt out your disruptive idea. You know how the latest tech works, yet you are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. Crafty: You know how to get things done. You can navigate a large organization, motivate people, and influence your peers. Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Inspiring: You have a passion for developing people and take great pride in your management system. You know how to deliver through others while paving the way for their growth. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook and all the monitors you want! You can travel to a relevant conference of your choice annually - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours, dress code and environment Bachelor’s Degree in a quantitative field At least 5 year of experience in open source programming languages for large scale data analysis (Python, Scala, or Java) At least 5 year of experience with version control system like Git and GitHub. At least 5 year of experience with relational databases and programming in SQL At least 2 years in lead positions (managing people/owning products/architecting and driving an agenda) Master’s Degree or PhD Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) Experience with CICD tools Experience with Machine Learning workflows 5+ years experience in Python 5+ years’ experience with SQL 3+ years in lead positions (managing people/owning products/architecting and driving an agenda) 
ScrapedJobID620:
Partner with product and publishing teams in the creation, tracking and exploration of KPIs that monitor the performance of supported projects. Use a hypothesis-driven approach to design and construct exploratory analysis. Develop dashboards and visualizations to track these core Indicators across a variety of games and products. Own data acquisition and reporting pipelines. Work with the Data Engineering team to develop ETL solutions and ensure data integrity. Support remote game teams with reporting and data validation. Develop complex SQL queries to ask questions of large/complex datasets. Partner with the Marketing, Publishing, Development, Legal, and Finance teams. 4+ years performing analysis, providing insights and constructing visualizations. Game analytics experience, mobile app development or related consumer product experience. B.S. or M.S. in Economics, Statistics, Mathematics, Computer Science, or similar. Experience performing root-cause analysis on all data and processes to answer specific business questions and identify opportunities for improvement. Experience performing A/B testing. Experience communicating complex quantitative concepts and solutions to stakeholders and partners Advanced SQL skills. Expertise in data visualization/BI tools (MixPanel, Google Data Studio, Tableau, etc). Able to partner with cross-functional (product, marketing, development) teams to understand their needs and priorities with multiple perspectives to guide product performance improvement. Solid communication skills with the ability to interact at all levels of management. 
ScrapedJobID621:

ScrapedJobID622:
Work with data scientists to understand the core concept of ML pipelines in production, and responsible for the FIT/SIT/UAT tests. Ongoing monitor and support in production Machine Learning scoring/application pipelines. Manage issues with production incidents, problem items and service request for provisioning/security and change for operational enhancements. Work with a Data & Analytics Technology Enablement team to support the creation of Azure ML workspaces and test ML environment for Advanced Analytics and required operational procedures. Adhere to all company data and analytics policies and standards. Support data scientists that utilize the Azure Machine Learning (ML) Environment. Support data science teams in the set-up/transition and ongoing support of Azure Machine Learning “applications”. Establish and support ongoing development, and production support processes associated with analytics model consumption in production in Azure landscape. Define and manage application security setup using Active Directory/Azure security, including access audit and access clean-up. Construct and manage application monitoring and coordinating any corrective actions required for Advanced Analytics applications in production. Author and curate Advanced Analytics application documentation. Build insights: complete data analysis and discovery to better understand the data and the story it is telling to drive actionable results. Loves teamwork and collaboration, collaborates daily with the core Analytics squad and business. Open to learning and sharing with others across the company, including senior leadership and community of practice participation. Recommend improvements to data engineering and governance practices across our company. 3+ years of applied Cloud platform operation experience (Azure ML experience is an asset). 5+ years experience in R and Python. Working knowledge/experience in Docker container management and maintenance ML applications. Experience in managing Azure ML pipeline and understanding the concepts of ML model is a plus. Excellent communication and presentation skills and strong organization skills. Agile, practical, customer service-oriented mindset (doesn’t over complicate processes). Generally curious and excited to learn new things. 
ScrapedJobID623:
Mentor researchers and ML engineers Own the research and machine learning product roadmap Create vision for novel machine learning products Align stakeholders towards proposed product vision Conduct research for ML use cases and applications Build initial ML prototypes and models Conduct systematic experiments across multiple models and hyperparameter combinations Create or augment datasets Clean, process, analyze and visualize data and model performance Keep up-to-date with new research literature and state-of-the-art machine learning and deep learning approaches Complete understanding of machine learning lifecycle from conception to production Depth and breadth of state-of-the-art approaches in science Image-based (feature extraction etc.) Machine Learning / Deep Learning Prior experience in conducting academic or industry research Creative problem solving Design and develop ML prototypes and models Practical and theoretical understanding of machine learning and deep learning concepts, deployment, and continual improvement of ML products Mentorship & management of research team Program management alongside product and project managers Geomatics experience a bonus Minimum BSc in Electrical Engineering, Physics, Mathematics, Computer Science, or an equivalent technical degree; MSc or PhD preferred Machine Learning experience required, including Image Segmentation; Geomatics a plus 3-5 years management experience in a research or engineering environment Python/Octave SQL Machine learning: Scikit-learn/Fast.ai / AllenNLP / OpenCV / HuggingFace / etc Deep learning: TensorFlow / PyTorch / MXNet / JAX / Chainer / etc. Linux Cloud: AWS/Azure/GCP 
ScrapedJobID624:
Works with Sales and Customer Advisory teams to develop an understanding of clients’ current business strategies, requirements, and opportunities. Prepares and delivers presentations, demonstrations, and proof of concepts to customers. This could include:
Preparing and manipulating structured and unstructured data for data discovery and mining from multiple disparate resources.
Building and deploying analytic models, to support decision makers with data driven insights that address immediate business problems and objectives.
Creating informative visualizations that intuitively display large amounts of data and/or complex relationships; translates data analytics into coherent reports and presentations for internal and external customers with varying degrees of technical knowledge. Preparing and manipulating structured and unstructured data for data discovery and mining from multiple disparate resources. Building and deploying analytic models, to support decision makers with data driven insights that address immediate business problems and objectives. Creating informative visualizations that intuitively display large amounts of data and/or complex relationships; translates data analytics into coherent reports and presentations for internal and external customers with varying degrees of technical knowledge. Works with Customer Advisory team (Technical / Solution Architects) to craft a target solution architecture for the proposed SAS solution(s). Maintains and develops relevant knowledge levels of technical and industry trends to identify impacts and opportunities created by these trends. Supports partner development & enablement, as well as partnered sales opportunities. Provides support at marketing events, trade shows, user group meetings, and academic program activities. 5+ years’ experience across a diverse set of industries (Government experience would be a plus). Bachelor's degree, preferably in Business, Computer Science, or other quantitative field. High levels of proactivity, creativity, curiosity, self-motivation, and thirst for knowledge. Goal oriented, competitive. Data Science hands-on experience in using combination of techniques (e.g. statistics, machine learning, deep learning, natural language processing, computer vision, forecasting, optimization, etc.) to understand the data and build predictive models to answer real-world questions. Experience with or knowledge of the following would be a distinctive advantage:
Programming in SAS and Open Source like R or Python.
AI & ML on cloud platforms like Microsoft Azure, AWS (Amazon), GCP (Google) Programming in SAS and Open Source like R or Python. AI & ML on cloud platforms like Microsoft Azure, AWS (Amazon), GCP (Google) Excellent communication and presentation skills. Bilingual (English/French) is a plus. Ability to travel. You’re curious, passionate, authentic and accountable. These are our values and influence everything we do We love living the #SASlife and believe that happy, healthy people have a passion for life, and bring that energy to work. No matter what your specialty or where you are in the world, your unique contributions will make a difference. Our multi-dimensional culture blends our different backgrounds, experiences, and perspectives. Here, it isn’t about fitting into our culture, it’s about adding to it - and we can’t wait to see what you’ll bring. 
ScrapedJobID625:
Bachelor’s degree in computer science or relevant field. 5+ years of work experience as a software developer or engineer within a product development environment (Software and/or SaaS). 2+ years of industry experience in applied machine learning or deep learning. Proficiency in C# (or Java), SQL, Python, AWS and experience with ML frameworks. Strong knowledge of machine learning techniques. Experience with integrating applications and platforms with cloud technologies (AWS). Experience designing, building, and deploying statistical and machine learning models using frameworks. MS, or PhD degree in Computer Science or related field, or equivalent practical experience. Experience leading machine learning engineering teams of 1 – 5 people. Research and select the right ML tools and technology set required to solve various business problems. Identify relevant business problems and build prototype/proof-of-concept solutions employing state-of-art methods in a variety of areas including natural language processing, clustering, and recommendation systems. Develop a long-term sustainable technical architecture to complement our product development technology (C#, SQL Server, Python, AWS). Serve the team by participating in, and guiding the design, development and implementation of operational standards that result in highly available, scalable, and reliable customer experiences. Engage varying degrees of stakeholders, including other development teams, compliance groups, product management, and external audiences. Keep team members motivated and engaged while maintaining a positive atmosphere. Work with Product Management to guide the overall direction of our ML powered features and integrate them into the Product suite. Identify and propose innovative opportunities for deploying ML capabilities in the product. Facilitate and coordinate an understanding at the portfolio level of cross-project dependencies to ensure smooth integration at completion. Actively contribute to, execute, and monitor the teams process improvement efforts. Ad hoc duties as required. Software
Experience In at least 5 years of experience with/in Software Development
Experience In at least 3 years of experience with/in Machine Learning Experience In at least 5 years of experience with/in Software Development Experience In at least 3 years of experience with/in Machine Learning 
ScrapedJobID626:
Writing SQL to clean, transform, investigate, and augment large, complex database tables Working closely with business partners to make sure our business strategy is as data driven as possible Designing rich data visualizations to communicate complex ideas to customers or company leaders Ensure data and intent integrity by automated data quality verification pipelines Supporting and consulting with the business to propagate data management best practices Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, and you’re not afraid to blurt out your disruptive idea. You know SQL and are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. A Wrangler: You know how to programmatically extract data from a database or an API, bring it through a transformation or two, and convert into a human-readable form (Matplotlib, QuickSight, Tableau, etc.). Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook With Manager approval, you can travel to a conference of your choice annually (senior+) - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours and casual environment At least 1 year of experience with relational databases and programming in SQL At least 1 year of experience with version control systems like GitHub. Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) At least 1 year of experience in open source programming languages for large scale data analysis (Python or Scala) 
ScrapedJobID627:
BS degree and 6 years of relevant experience or MS degree and 4 years of experience Hands-on professional experience with applying machine learning and other data science techniques to mitigate threats at scale in a production environment 2+ years of work experience in applying data science to physical security, network security, or fraud related problems Industry experience using database languages, such as SQL, and common data science software development and statistical analysis tools (e.g., Python, R, Scikit-learn) Demonstrated technical leadership in data science and/or machine learning (e.g., tech lead, data science leader, led analytic development effort, etc.) Experience leading and coaching junior data scientists to improve their skills and effectiveness MS or PhD in a STEM field Experience extracting large sets of data, and designing ETL flows Experience designing and deploying large scale analytic processing solutions using Spark, Scala, etc. Strong sense of ownership combined with collaborative approach to overcoming challenges and influencing organizational change Meets/exceeds Amazon’s leadership principles requirements for this role Meets/exceeds Amazon’s functional/technical depth and complexity for this role 
ScrapedJobID628:
Diagnose problems and develop compelling, data-driven recommendations Partner with Product, Engineering, and Data Science teams to design solutions to operations problems, influence product roadmaps, and solution new products/processes Manage the development, reporting, and visualization of metrics for the entire Risk organization Maintain, develop and manage various data pipelines and ETLs Improve risk solutions through third party evaluation and integration with a focus on improving the seller experience Design and develop executive presentations for Square's leadership and board members A BS/BA in Statistics, Mathematics, Operations Research, Management Science, Computer Science, or a related technical field, OR BS/BA in Criminal Justice, Economics, Business, or a related business field 4 or more years of relevant experience (or masters and 2+ years) Proficient in SQL Intermediate knowledge on Python (Numpy, Pandas, Matplotlib etc.) Experience with designing and creating data visualizations (e.g. Looker) The ability to answer unstructured questions and bring projects to conclusion A strong passion for Square's mission [Bonus] Experience and interest in risk, trust & safety, payments, or spam prevention [Bonus] Experience with scripting and data analysis programming languages (e.g. Python, R, etc) [Bonus] Experience using statistics and machine learning [Bonus] Consulting / project management experience Healthcare coverage Retirement Plans Employee Stock Purchase Program Wellness perks Paid parental leave Paid time off Learning and Development resources 
ScrapedJobID629:
Manage a team of data scientists and data ETL developers in the implementation of new statistical or mathematical methodologies for specific models or firmware issues/performance analysis. Interact with Geotab’s big data infrastructure using cloud-based data warehouses (i.e. Google BigQuery) and various programming languages (i.e. SQL, Python). Research and develop statistical and machine learning models for data analysis. Mine and analyze company data, especially raw device data to drive optimization and improvement of product development, and business strategies. Collaborate with firmware teams and stakeholders from other departments to identify requirements and define metrics of success for the team to work on. Assist with device troubleshooting and provide meaningful insights using BigQuery data and develop useful data analysis tools to improve efficiencies. Lead the strategies of the A/B testing for GO product quality and firmware quality for the department. Test performance of data-driven products, and ensure the quality and integrity of the data products, including tables, dashboards and monitors that the team provided. Ensure data quality and integrity. Develop and implement strategies with the team to assess the effectiveness and accuracy of new data sources and data gathering techniques. Work with stakeholders throughout Geotab to identify opportunities for leveraging company data to drive business solutions. Provide expert project leadership and guidance to the team as SME. Work as a project manager to provide roadmap for products and projects that the team is working on. Work as a product owner to clarify the requirements from stakeholders continuously and guide the development to the right direction. Oversee the activities and performance of direct reports. Provide direction, coaching, and mentorship to the team. Engage in the development of the team by coaching, providing feedback, identifying areas of growth, and training opportunities. Collaborate and support employees during the performance management process, meeting KPAs, and career development planning. Support Geotab global strategic initiatives. 5-8 years experience as a Data Scientist/Analyst or similar role. Experience in writing SQL queries. Experience in programming in Python. Knowledge of data ETL pipeline, data management and visualization techniques. Affinity for statistical analysis and predictive modeling. Experience working within a technical or engineering organization, with knowledge of the high-technology industry is an asset. High accuracy and meticulous attention to detail. Strong project management skills; able to identify needs, develop effective solutions, and manage projects through to completion. Must stay relevant to technology and have the flexibility to adapt to the growing technology and market demands. Leadership experience in a team-oriented workplace. Success with coaching and development of employees. Hand-on experience in Agile development style. Strong analytical skills with the ability to problem solve to well-judged decisions. Strong team-player with the ability to engage with all levels of the organization. Technical competence using software programs, including but not limited to, Google Suite for business (Sheets, Docs, Slides). Entrepreneurial mindset and comfortable in a flat organization. 
ScrapedJobID630:
Ideate and execute on ML projects that add transformational AI capabilities to the people analytics space Drive innovation in our products by designing new capabilities based on advanced analytical techniques Develop prototypes and work with our software development teams to transform them into production-level technology Design and implement scalable data pipelines that productionize your prototypes Generate value from a unique dataset that spans HR data across thousands of organizations and millions of employees through research studies or by creating standardization and predictive technology Identify solutions to business problems, and opportunities to create value based on your experience in using statistical techniques Collaborate with stakeholders across the organization to support data-driven business solutions Must have a PhD or Master’s degree in Computer Science, Physics, Statistics, Mathematics or a similar field, as well as extensive experience in quantitative analysis, modelling and machine learning Minimum 6 years industry experience working in data science with focus on people analytics or in data science in a software company Experience working in a cloud/SaaS environment with Jenkins and AWS Cloud Services will be strongly preferred Experienced working with advanced statistical techniques around hypothesis testing, regression analysis, and machine learning Strong problem solving skills, a passion for the scientific method, and a desire to keep the big picture in mind when connecting technology to business value Expert level coding skills in Python and experience with common ML libraries; knowledge of Scala would be an added bonus Proven track record of working with multiple stakeholders and shaping business goals into innovative technology solutions Excellent written and verbal communication skills for cross-team collaboration and presenting ideas and results to stakeholders You roll up your sleeves You make it easy You are proud You never stop learning You play to win 
ScrapedJobID631:
Improve and develop deep learning models to revolutionize user acquisition advertisement for mobile gaming Drive Unity's user acquisition product in close collaboration with other data scientists, product managers, and engineers Initiate and define new business opportunities and products based on data insights Convey ideas and assist execution Background in deep learning, from concepts to implementation Production experience of machine learning systems Proven focus on delivering business value Good coding skills and engineering practices, familiar with agile software process and data-driven development Work with the tech stack of Python/TensorFlow/Kubeflow/Airflow/GCP ecosystem or equivalent Experience in scaling of Machine Learning algorithms (BigQuery, Spark) Experience in mobile advertisement or gaming Experience in container technologies (Docker, Kubernetes) Développer et améliorer des modèles d'apprentissage profond destinés à révolutionner la publicité liée à l'acquisition d'utilisateurs pour les jeux sur mobile Diriger les projets d'acquisition d'utilisateurs de Unity en étroite collaboration avec les scientifiques des données, les chefs de produits et les développeurs issus d'autres équipes Lancer et définir de nouvelles possibilités commerciales et de nouveaux produits sur la base des données recueillies Communiquer les idées des uns et des autres et assister à l'exécution. Une expérience en matière d'apprentissage profond, depuis la conception jusqu'à la mise en œuvre Expérience de la production de systèmes d'apprentissage machine Priorité confirmée à la production de valeur commerciale Bonnes compétences dans les domaines du codage et des meilleures pratiques d'ingénierie, connaissance des processus logiciels agiles et du développement piloté par les données Travailler avec la pile technologique Python/TensorFlow/Kubeflow/Airflow/Google Cloud ou équivalent. Expérience des systèmes d'apprentissage machine à grande échelle (BigQuery, Spark) Expérience dans la publicité et les jeux sur mobile Expérience en matière de technologies de conteneurs (Docker, Kubernetes) 
ScrapedJobID632:
Currently pursuing a quantitative degree in Computer Science, Statistics, Mathematics, Econometrics or a related field. Demonstrated familiarity or interest in machine learning, statistical analysis, or data mining through previous internships, personal/ academic projects, hackathons, and/or publications. Experience with object-oriented programming in Python Ability to confidently communicate ideas to an audience of peers and managers. Comfortable and effective working independently and as a member of a cross-functional team. Must be eligible to work 4 months commencing January 2022. Must be eligible to work 4 months commencing January 2022. One or more work terms in a machine learning or software engineering related role. A year of experience using machine-learning or data engineering libraries/frameworks in python (scikit-learn, TensorFlow, pyspark). General familiarity with cloud application development and the tools required for building cloud-native data applications (Kubernetes, Docker, Spark, S3). Co-op or internship program enrollment is preferred. 
ScrapedJobID633:
Design, undertake and analyze data to determine patterns and insights that can optimize data ingestion and data presentation. Support the delivery of AI projects in designing and implementing the data pipelines/data streaming. Implement AI models in accordance with project requirements and AI data engineering standards Develop and implement datasets and databases with machine learning tools to solve real time business problems Educate the organization both from IT (including vendors) and the business perspectives on data ingestion and data streaming tools, processes and best practices. Support the maturation of AI platforms, modules, and services that address cross-enterprise opportunities through market research and proof-of-concepts. Establish strong relationship with vendor partners to ensure strong delivery, innovation and ongoing improvement in receiving high value services. Develop, construct, test and maintain architectures, such as databases and large-scale processing systems Ensure architecture will support the requirements of the data scientists, the stakeholders, and the business. Discover opportunities to acquire new data from other systems Develop and improve data set processes for data modeling, mining, and production. Employ a variety of languages and tools to marry systems together Recommend and implement ways to improve data reliability, efficiency, and quality. Collaborate with stakeholders including the Product owner, data science, and design teams to assist with data-related technical issues and support their data infrastructure needs. Create data tools for analytics and data scientist team members that assist them in building and optimizing the products that help business achieving their goals. Work with data and analytics experts to strive for greater functionality in data systems. Provide technology or services ownership direction on all matters related to a key functional area - to associated functional lead and peers Provide technology specific financial inputs related to both data engineering tool set costs and monthly data consumption costs. Responsible for working with stakeholders related to a key functional area to ensure synergistic collaboration and attain shared goals Responsible for ensuring consistency of data engineering tools and processes across projects/products." Participate in Management and Operational Committees according to cadence, as required Provide business and technical inputs to Business Governance and Operational Management Committees, as appropriate" Responsible for handling high amount of technology complexity and drive autonomous decision making, as it relates to adoption of technology best practices Responsible to drive technology vision and continuous improvement objectives for a functional area Demonstrate significant technical depth to handle strategic technology priorities 3-5 years of IT experience with a minimum of 1 year working with Machine Learning and Cloud technology such as Microsoft Azure. + A proven track record in deploying AI models using best-in-class MLOP's toolsets to monitor Model performance and make the necessary adjustments as required to optimize performance. Certifications in Machine Learning, Deep Learning are an asset A relevant University degree/technical certification, and/or relevant experience commensurate to the role Adaptability and Flexibility - The ability to keep functioning effectively when under pressure and/or experiencing rapidly changing or uncertain conditions, and to maintain self-control in the face of hostility or provocation. Openness to different and new ways of doing things; willingness to modify one's preferred way of doing things Accountability and Credibility - Takes responsibility for the results and future direction of the organization. Demonstrated concern that one be perceived as responsible, reliable, and trustworthy Customer Orientation - Demonstrated concern for satisfying one's external and/or internal customers Results Orientation - Focusing on the desired end result of one's own or one's unit's work; setting challenging goals, focusing effort on the goals, and meeting or exceeding them Forward Thinking - Anticipating the implications and consequences of situations and taking appropriate action to be prepared for possible contingencies Fostering Teamwork - As a team member, the ability and desire to work cooperatively with others on a team. As a team leader, interest, skill, and success in getting groups to learn to work together cooperatively Analytical Thinking - Approaching a problem by using a logical, systematic, sequential approach Interpersonal Effectiveness - The ability to notice, interpret, and anticipate others' concerns and feelings, and to communicate this awareness empathetically to others Candidates must be eligible to work in the country of interest, at the time any offer of employment is made and seeking any required work permits/visas or other authorizations which may be required is the sole responsibility of the candidates applying for this position. Mandatory Covid-19 Vaccination Required as of October 31st, 2021 
ScrapedJobID634:
Prepares and maintains multiple customer mailing lists based on predetermined criteria; coordinates mailers in the offers system, assigns targeted players to the appropriate offer(s); creates bar codes, valid dates, offer descriptions, etc. Assists in the development of automated dashboards and reports using modern BI tools Resolves customer account issues related to marketing programs, DM eligibility, tier scores, duplicate accounts or mail code discrepancies; may liaise with casino staff or customers directly Supports the tracking & reporting of results of each marketing campaign in terms of effectiveness and event participation (e.g. revenue generation, redemption percentage) Assists with marketing analytics activities and reports on all A&P (Advertising and Promotion), DM (postal mail, email, telephone) and online initiatives to better understand and identify opportunities to enhance program performance Coordinates and implements initiatives to ensure management of effective marketing databases; ensures data is accurate and current Ensures compliance with all data management policies and procedures including Crown Corporation partners Liaises and communicates effectively with all appropriate business units Develops and cultivates strong working relationships with all stakeholders: guests, management and employees Ensures compliance with licensing laws, health and safety and other statutory regulations Performs other duties as assigned or directed Undergraduate degree in either Marketing, Statistics, Business Analysis, Data Science, Mathematics, Business Administration, Hospitality Management or an equivalent combination of education and experience. Knowledge of SQL is a plus, but willingness to learn and use SQL is a must. Experience with modern BI tools is a plus. Knowledge or experience in casino or hospitality industry is an asset. 
ScrapedJobID635:
Ideate and execute on ML projects that add transformational AI capabilities to the people analytics space Drive innovation in our products by designing new capabilities based on advanced analytical techniques Develop prototypes and work with our software development teams to transform them into production-level technology Design and implement scalable data pipelines that productionize your prototypes Generate value from a unique dataset that spans HR data across thousands of organizations and millions of employees through research studies or by creating standardization and predictive technology Identify solutions to business problems, and opportunities to create value based on your experience in using statistical techniques Collaborate with stakeholders across the organization to support data-driven business solutions Must have a PhD or Master’s degree in Computer Science, Physics, Statistics, Mathematics or a similar field, as well as extensive experience in quantitative analysis, modelling and machine learning Minimum 6 years industry experience working in data science with focus on people analytics or in data science in a software company Experience working in a cloud/SaaS environment with Jenkins and AWS Cloud Services will be strongly preferred Experienced working with advanced statistical techniques around hypothesis testing, regression analysis, and machine learning Strong problem solving skills, a passion for the scientific method, and a desire to keep the big picture in mind when connecting technology to business value Expert level coding skills in Python and experience with common ML libraries; knowledge of Scala would be an added bonus Proven track record of working with multiple stakeholders and shaping business goals into innovative technology solutions Excellent written and verbal communication skills for cross-team collaboration and presenting ideas and results to stakeholders You roll up your sleeves You make it easy You are proud You never stop learning You play to win 
ScrapedJobID636:
Lead the development of machine learning products from inception to launch to support Collaborate with cross-functional, agile teams of data engineers, ML engineers, and product managers in solving business problems Build, automate, and maintain machine learning pipelines for training machine learning models on distributed systems Use a production-first mindset to consult on project feasibility through prototyping with respect to performance, time, quality and cost Advanced knowledge of ML models: deep learning, reinforcement learning, NLP, and others Hands-on experience and expertise with different AI/ML frameworks such as Keras, Pytorch, TensorFlow, SparkML, Scikit-Learn Advanced Python development skills with excellent code design (OOP, Algorithms, and Data Structures) Experience with SQL and database systems such as Oracle, SQL Server, Teradata Skilled communicator with a proven record of leading projects across disciplines Degree in a discipline such as: Data Science, applied math, applied science / engineering, economics/econometrics, management science / operations research, or related area Experience with CI/CD pipelines Experience with development and deployment of recommender systems Hands-on experience defining and operationalizing ML models into operational systems Experience with distributed data and computational resources such as Hadoop, HDFS, Docker, Dask 
ScrapedJobID637:
Mining the most interesting examples from the vast sensor data and metadata generated every day by Nuro's vehicles Developing manual and ML-assisted labeling workflows to annotate those examples with excellent quality and low cost Validating the annotations with both automated and manual checks Exposing APIs to enable rich queries and experimentation on the resulting datasets Design and implement tools to search through large amounts of image and other data to uncover the most interesting training examples. Architect data and annotation processing pipelines that manage petabytes of data with excellent performance and fault tolerance. Develop applications that empower operation specialists to visualize and annotate large volumes of lidar/camera data with superhuman speed and accuracy. Define metrics to understand dataset quality, coverage, and diversity. Develop dashboards and visualizations to highlight issues proactively. Collaborate with operations teams (both in-house and outsourced) to understand operation specialists' needs and deliver easy-to-use products. Collaborate with ML engineers from mapping, perception, prediction, and planning teams to understand the onboard system architecture and how training data fits in. You are experienced with backend engineering in a language such as C++, Python, or Go. You put a premium on clear and concise communication. You collaborate effectively with colleagues from a wide range of disciplines and backgrounds. You feel comfortable navigating situations with many stakeholders and requirements to consider. You hold a Bachelor's or Master's Degree in computer science, software engineering, a related field, or equivalent practical experience. 
ScrapedJobID638:
Develop, test, and deploy code Maintain an existing code database Test and debug software and hardware related issues Keep your eye out for opportunities to improve our products A degree in Computer Science/Engineering or related field. 1+ programming experience in Python with strong grasp of software engineering standard methodologies such as code-reusability, modularity, use of repos, etc. 1+ years of applied experience in ML, NLP, and Deep learning. Have an understanding of SDLC, machine learning concepts, and NLP tasks such as classification, feature engineering, information extraction, structured prediction, sentiment analysis, and topic modelling. Knowledge of packages such as Pytorch, Keras, Scikit Learn, Pandas, Tensorflow, and NLTK. Conceptual understanding in a data-driven software engineering environment and how to leverage data to make business decisions. A track record in building and maintaining high quality, robust and maintainable code. Understanding of Data Warehouse concepts, ETL strategies and best practices. An appetite for problem solving with a creative and resourceful approach to finding the right solution for the job. Strong communication and collaboration skills
﻿ You are a self-motivated and outgoing person who can work closely with business and IT stakeholders. You understand the relationship between data and business outcomes and can focus on long term strategies for data. Proficiency with PostgreSQL, Teradata, Hadoop and AWS is an asset. You have experience working as part of an Agile Team. Competitive rewards package including base compensation, eligibility for annual bonus, retirement savings, share plan, health benefits, personal wellness, and volunteer opportunities. Exceptional Career Development opportunities. We’ll support your professional development education. 
ScrapedJobID639:
In this role you will participate in developing system level end-to-end machine learning-based solutions for camera and computer vision applications running on AMD platforms Work with engineering teams cross technical functions, geographical regions and time zones, involving various facets of computer vision machine learning product Work closely with HW and SW teams and get your hands on a broad range of activities from solution design, software development, to optimization and deployment for Edge platforms Work closely with architecture teams to provide timely feedback and direction on various architectural design decisions Measure, analyze, and optimize power and performance for both application and system software/hardware stack Determine and implement unit testing and system level testing strategies Solid years experience with software engineering and C, C++ programming Experience with Machine Learning/Deep Learning frameworks like Tensorflow, Pytorch Good understanding of deep learning concepts like CNN, RNN/LSTMs Strong background in computer vision, computer system architecture, and algorithm design Effective communication skills, strong teamwork to join a global organization working cross geographical regions and time zones Experience with end-to-end software application development flow – from design to development to integration and testing Experience in developing computer vision algorithms using OpenCV and/or Deep Learning approaches Experience with system software (driver/OS level) on Android/Linux/Windows environment Experience of profiling and optimization techniques for software and system stacks Proven debugging and analysis skills, for root causing complex issues at both application and system level Experience with GPGPU compute like OpenCL, DirectX Compute Experience with camera architecture, camera APIs and other camera algorithms Experience in development of any of the deep learning compiler frameworks like TVM, Glow or XLA; or other LLVM-based compilers 
ScrapedJobID640:
Develop an outstanding and engaged software development team, from recruiting talent to implementing initiatives fostering engagement and resource development. Implement and continuously improve our tools and processes to increase the teams’ autonomy and efficiency, provide the necessary training and coaching. Manage projects mainly having AI components, with an understanding of the organization’s strategies, priorities and constraints. Work closely with the Product Owner to define the scope and overall objectives of the project, as well as the product increments, while providing leadership and vision. Ensure that the solution will meet the client’s expectations, Intact standards in terms of security and governance, that the impacts and infrastructure requirements will be well identified and that the solutions will be optimized. Develop and manage the integrated plan, budget, resources plan and dependencies in a context of Agile/scrum development. Coordinate activities/dependencies with the different project teams. Ensure proactive and effective communication at all levels and mobilize the teams. Produce and communicate project KPIs, manage risks and propose mitigation measures. Anticipate problems and difficult situations and take action to resolve them A team player, fostering collaboration and creativity in an open and honest environment Passionate about talent development and innovative projects A visionary with a curious mind, you have an interest in collaborating in the delivery of AI initiatives and the ability to link your expertise with business needs to create value Comfortable working in constantly evolving complex environments and multidisciplinary teams An agent of change, motivated and able to question the status quo An excellent communicator, adept at negotiating and decision-maker Bilingual Mobilizer, organized and results oriented A bachelor’s degree in Information Technology, Software Engineering or any equivalent combination of training and experience Minimum 10 years of software development experience Minimum 5 years of experience managing resources and projects. A strong understanding of technologies, project delivery and continuous integration and delivery processes Good command of AI and machine learning concepts is considered as an asset Experience delivering products in Agile/Scrum mode in software development An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID641:
Design, implement, and deploy machine learning algorithms. Manage machine learning algorithm lifecycle. Coordinate data collection and annotation efforts. Work with real-time data and content coming from various data sources. Manage machine learning data pipelines. Design tests for machine learning algorithm effectiveness and performance monitoring. Design tools and interfaces for interactive machine learning and teaching. Research and development on cutting-edge machine learning technologies. Graduate degree in Computer Science with a strong background in machine learning required. Strong problem-solving abilities, solid background in algorithms and data structures required. Strong programming skills in Python and Scala required. Experience in other programming languages (eg. Java, R, Haskell) a plus. Solid knowledge of machine learning tools (eg. scikit-learn, tensorflow, keras, pytorch, Spark MLlib) required. Experience with distributed and streaming data technologies (eg. Hadoop, Spark, Kafka) required. Experience with building and deploying API's with Docker and Kubernetes required. Experience with natural processing tasks (eg. named entity recognition, language modeling, vector representations) required. Experience with Elastic Search, Lucene a plus but not required. Experience with ranking algorithms a plus but not required. Experience with interactive machine learning (eg. active learning, reinforcement learning, machine teaching) a plus but not required. 
ScrapedJobID642:
Work in close partnership with I&A and commercial partners to execute the business analytics agenda using a methodical approach that conveys to stakeholders what business analytics will deliver. Work with best-in-class external partners to leverage analytics tools and processes to bring insights to action Develop custom models/algorithms to uncover signals/patterns and trends to drive long-term business performance Work in close partnership with I&A and commercial partners to execute the business analytics agenda using a methodical approach that conveys to stakeholders what business analytics will deliver. Work with best-in-class external partners to leverage analytics tools and processes to bring insights to action Develop custom models/algorithms to uncover signals/patterns and trends to drive long-term business performance Knowledgeable and highly proficient in using retailer, consumer data, shopper insights and analytics to develop compelling growth plans with BI tools like Nielsen data/applications. Excel, Tableau, PBI, Panel, etc. Drive to help the business realize current opportunities and the curiosity to continuously uncover new opportunities High proficiency in base business tools (Excel/PowerPoint), with expertise in data modelling with data visualization tools In-depth knowledge in analyzing and creating visualizations of large amounts of data Experience in presenting to commercial and leadership teams Strong knowledge and usage of market segmentation models Proven track record in persuasively influencing and aligning key business stakeholders in a highly matrixed organization Able to partner well with marketing, sales and external agencies Strong working knowledge of the Canadian CPG industry and retail environment 
ScrapedJobID643:
Bring your expertise to customers to build Data Quality framework and implement data quality solution based on industry standards. Work with cross-functional stakeholders including IT representatives, business leaders and analytics and data management community to understand data quality challenges and identify solutions for remediation. Prepare the plan, lead small development and testing team and mentor junior colleagues to deliver quality and on-time solution in Agile/Hybrid Agile methodology. Minimum 5 years of relevant hands-on experience in Informatica Data Quality (IDQ) and Informatica Data Explorer (IDE) tools Experience in admin activities associated with configuring IDQ and IDE Good knowledge of at least one Address Validation and Cleansing tool (AddressDoctor / Informatica Address Verification, Trillium, etc.) Proficiency in at least one ETL tool (Informatica Power Center, Data Stage, SAP BODS, etc.) Good knowledge of DBMS concepts, SQL, PL/SQL, and Java (desired). Experience in integrating ETL tools with Informatica Data Quality Hands-on experience in integrating IDQ with downstream and upstream applications through a batch/real-time interface Working knowledge in fine tuning match/merge process and troubleshooting performance issues in IDQ Good knowledge of data quality concepts, data quality trends and other tools in market. Skills in data profiling and data analysis Ability to work with leaderships to architect, estimate and respond to IDQ related pursuits Experience in leading a team in a project or a module Effective communication and presentation skills Expertise in developing scorecards and statistics related to data quality Experience in leading requirements gathering and developing solution architecture for IDQ initiatives. If you believe you have what it takes to be a successful member of our team, please apply now. We know your career is important to you and it's important to us, too. This role is just the first step of a highly successful career we can help you build. The time is right for you to join Deloitte. Get your career off to great start. What impact will you make? Experience in handling client interactions at different phases of the projects. Well versed with onsite/offshore model and its challenges You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster. You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful. You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work. 
ScrapedJobID644:

ScrapedJobID645:
Novel ISP algorithm design, analysis, implementation, verification and improvement. Convert and optimize a software algorithm into a vendor-neutral FPGA implementation using VHDL and Xilinx/Altera toolchains. Analyze design trade-offs between general purpose (CPU/GPU/ARM/SIMD Vector processor) and custom compute platforms (FPGA). Document the architecture and design requirements. Model data-flows and make architectural trade-offs based on schedule and system limitations. Contribute to integration of blocks into larger system-on-a-chip (SoC) environments. Collaborate with other researchers and engineers to develop concepts that advance the entire product pipeline. Keep up-to-date with active research by participating in conferences. Masters or PhD degree in Electrical Engineering or Computer Engineering, or equivalent experience. 8+ years of experience in digital FPGA design methodologies and simulation. 5+ years of experience in camera pipeline architectures and associated algorithms. Experience in advanced real-time image processing algorithms & implementations (e.g. Compression, Warping, Demosaicing, Auto-White-Balance, Auto-Exposure, Tone-Mapping, Stereo-Vision, ToF). A solid understanding of algorithm design and analysis and its implementation on FPGA hardware. Expert in all stages of the FPGA design process: e.g simulation, timing closure, and in-system debugging. Programming experience in C/Matlab/Python/tcl for algorithmic design exploration and testing. Programming experience in VHDL/Verilog for production FPGA development shipped in volume. Experience with top down high-level-model to HW mapping. Experience in Machine Learning algorithms & implementations. Knowledge of industry trends and disruptive technologies. Understanding of CPU/GPU/ARM/SIMD Vector processor architectures and their trade-offs. 
ScrapedJobID646:
Travail significatif qui favorise le perfectionnement professionnel Possibilité de travailler dans l’industrie technologique et de s’y épanouir Environnement de travail axé sur la collaboration Faire partie d’une équipe à haut rendement Effectuer des analyses sur de grands ensembles de données, extraire des informations et communiquer avec divers intervenants dans le but d'améliorer le rendement global de l'entreprise. Développer des outils de gestion de données pour appuyer la prise de décision de la haute direction. Créer des outils et des tableaux de bord pour faciliter la communication d'informations avec des indicateurs de rendement clés pertinents pour différents intervenants. Exploiter l'IA, les statistiques avancées et les techniques d'exploration de données pour trouver des données commerciales clés. Établir des partenariats avec des scientifiques des données et des stratèges en IA pour améliorer les modèles de science des données. Collaborer avec les chefs de produits numériques pour explorer de nouvelles idées ou améliorations de produits. Établir des rapports pour mesurer les progrès des principales initiatives. Effectuer des validations et détecter les problèmes d'intégrité des données. Améliorer le cadre de gouvernance des données. Partager vos connaissances avec l’équipe et initier des activités de partage des connaissances Être un agent de changement et un promoteur de la mentalité agile Contribuer au milieu de travail collaboratif et stimulant Communiquer avec la communauté d'intelligence artificielle de Montréal et d'ailleurs pour trouver de nouvelles possibilités de collaboration et pour injecter de nouvelles idées dans notre pipeline Niveau élevé d'exactitude, souci du détail et capacité à apprendre de nouveaux outils et technologies rapidement Aptitude manifeste à intervenir sur des idées et des possibilités avant qu'on ne vous le demande ou d'y être contraint par des événements. Aptitude à exercer une souplesse et à fonctionner de façon indépendante dans un environnement agile. Aptitude à formuler des problèmes et des concepts complexes pour un public de gens d'affaires. Grand sens de l'organisation et capacité à travailler sous pression. Attitude positive envers l'acceptation de défis et de mandats additionnels. Expérience de conceptualisation et de mise en œuvre d'entrepôts de données avec un accent sur la préparation de données. Excellentes aptitudes en communication verbale et écrite en anglais. Le français est un atout. Excellentes compétences techniques et analytiques avec un minimum de trois ans d'expérience en tant qu'analyste d'entreprise ou des données. Baccalauréat en informatique ou en systèmes d'information de gestion, ou expérience équivalente. Bilinguisme requis Aptitude à créer des requêtes SQL, à utiliser Jira, PowerBI, Confluence et Sharepoint. Être capable de nettoyer et d'analyser de grands ensembles de données avec les technologies de données appropriées (p. ex., Python, SAS, R). Avoir acquis une solide expérience en prise de décisions fondées sur des données analytiques et opérationnelles, en analyse de données, et en statistiques. Excellent sens de l'analyse avec la capacité de découvrir des tendances dans les données et de comprendre des relations de données particulières. Expérience du développement de solutions d'expérience client (tableaux de bord, indicateurs de rendement clés, carte de pointage). Avantages sociaux : entièrement flexibles pour que vous puissiez choisir ce qui est important Retraite : Régime de retraite à prestations déterminées et régime enregistré d’épargne-retraite (REER) collectif Avantages financiers : Régime d’actionnariat et nombreux rabais d’entreprise Programmes personnels et familiaux : Plan de bien-être physique et prestations de maternité complémentaires Équilibre travail-vie personnelle : Horaires flexibles et « vendredis californiens » toute l’année Plaisir au travail : Activités sociales et communautaires tout au long de l’année! Meaningful work that drives professional development Ability to enter and grow within the technology industry Work in a collaborative environment Be part of a high-performance team Perform analysis on large data set, extract insights and communicate various stakeholders with the objective of improving the overall business performance. Develop data management tools to support data-driven decision from Senior Management. Create tools and build dashboards to facilitate reporting with relevant KPIs for different stakeholders. Leverage AI, advanced statistics and Data Mining techniques to find key business insights Partner with Data Scientists and AI Strategists to improve Data Science models Collaborate with Digital Product Managers to explore new product ideas or enhancements Build reporting to measure progress in key initiatives Perform validation and detect data integrity issues. Enhance the data governance framework. Share knowledge with team members & participate in various learning-sharing activities Contribute to the collaborative and stimulating work environment Be a change agent & Agile mindset promoter Be connected to the industry to know tendencies and suggest innovative ideas High level of accuracy, attention to detail and ability to learn new technologies and tools quickly Demonstrated strength in taking action on ideas and opportunities before being asked or forced to by events Ability to exercise flexibility and operate independently in an agile environment Ability to articulate complex problems and concepts to a business audience Strong organizational skills and able to work under pressure Positive attitude towards accepting additional challenges and assignments Experience in data warehouse design and implementation with an emphasis on data preparation Excellent English written and verbal communication skills. French an asset. Excellent technical and analytical skills with a minimum of 3 years’ experience as a business and/or data analyst Bachelor's degree in Computer Science, Management Information Systems or equivalent experience Bilingualism required Proficiency creating SQL queries, Use of PowerBI or other data visualization tools Comfort cleaning and analyzing large data sets with appropriate data technologies (e.g., Python, Databricks, SAS, R) Strong experience in analytical business decision-making, data analytics, and statistics Strong analytical skills with the ability to discover patterns in data and figure out puzzling data relationships Experience in developing customer experience solutions (dashboards, KPI, scorecard) Benefits: fully flexible for you to choose what is important Retirement: Defined Benefits Retirement Plan & Group Registered Retirement Savings Plan (RRSP) Financial Perks: Employee Stock Purchase Plan & numerous corporate discounts Personal and Family Programs: Physical Wellness Plan & Supplementary Maternity Plan Work-Life Balance: Flextime & California Fridays all year Fun at work: social and community events all-year round! 
ScrapedJobID647:
Understand current state architecture, identify future needs and requirements and develop future state architecture Propose solutions to modernize the data and analytics environment in order to improve efficiency and provide consistent access to critical data Create data and analytics roadmap and build annual data and analytics technology plan Translate business needs into technology requirements and define data standards and principles Define the data architecture framework, standards and principles, including modeling, metadata, security and reference data Develop reference architecture and identify and document data flows Identify business priorities and ongoing improvements, while ensuring data products are meeting business needs Support strategic initiatives to ensure that the organization is adhering to data standards and data management best practices Facilitate the execution of the data and analytics roadmap and vision for information delivery and management, including the enterprise data warehouse, big data, BI & analytics, content management and data management Provide expertise to project teams for successful project implementation. Support solution architects to architect and deliver solutions Research new technologies, data modeling methods and information management systems to determine which to incorporated into the organization’s data architectures Bachelor's Degree in Computer Science or Information Management. Master's Degree in Data Science preferred Data Management Professional or TOGAF certification is an asset 8+ years of experience architecting, designing and developing large scale data solutions utilizing a mixture of database platforms 8+ years of progressive information management solutions and end-to-end development life-cycle support (waterfall and/or agile) Previous experience in capital intensive industries and prior exposure to a business or non-IT related role is considered an asset Experience with emerging technologies and translating new trends into potential use cases Background in data technologies built on traditional (RDMBS) and non traditional (NoSQL) platforms Experience in working in multiple, large, cross-functional teams or projects, and influencing senior level management and key stakeholders Knowledge of all components of holistic data architecture, business re-engineering principles and processes, and basic knowledge of financial models and budgeting Advanced understanding of enterprise and data architecture methodology, standards, processes and service delivery Ability to translate business requirements into data architecture solutions and services Senior or expert level knowledge in Active Directory, Azure AAD, PaaS, IaaS, SaaS, predictive modeling, AI modeling, data warehousing, data lake, data factory, AWS, enterprise content management, collaboration systems In-depth understanding of data modelling principles (e.g., relational, graph) Understanding of event driven architecture, and associated schemas, and technologies, e.g., KSQL Experience gathering and analyzing system requirements Understanding of how data architecture enables corporate strategy and can be applied for each Business Unit and Function Ability to collaborate with the business to understand their vision and strategy and translate that into effective enterprise change 
ScrapedJobID648:
Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. AWS Cloud (certification is an asset) AWS services like AWS glue or other AWS services Python programming language. Big Data technologies (like a Spark, hive/HDFS, PySpark, Hadoop) SQL and NoSQL databases, including Postgres and Cassandra. Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. AWS cloud services: EC2, EMR, RDS, Redshift Stream-processing systems: Storm, Spark-Streaming, etc. Object-oriented/object function scripting languages: Java, C++, Scala, etc. 
ScrapedJobID649:
Scale and manage a growing team of data engineers, data analysts, and business intelligence developers Serve as the organizational leader and designer for the corporate data and analytics strategy, having high visibility and interaction with the Executive Team Collaborate with engineering and product development teams to optimize our current offerings; This includes building an aligned strategy with continuous improvement for data capturing and management, setting the data engineering and quality strategy that will support our company’s goals, and communicating the technical vision to executive leadership and non-technical stakeholders Architect our data collection, management, and storage platforms Be a champion for a data-driven culture, lead a team of cross-functional analysts and support and train staff in data systems and reporting Enable cross-collaboration teams to access our various data sources through business application and visualization tools Build and optimize the development of our predictive models and machine-learning algorithms Build a world-class reporting and insights platform that enables the business to operate with a data-driven approach A work ethic that demonstrates dedication and commitment to Bold’s mission and belief in our BUILDERS Code 5+ years experience in a hands-on analytics/data science role and 3+ years experience developing relevant strategies or consulting Advanced degree in a quantitative field such as statistics, engineering, mathematics, or computer science Expert SQL and strong proficiency in Python and R; Experience with DLP, Relational databases, Google Analytics, BigQuery, and Looker Experience managing and leading a team and fostering their growth through 1:1s, coaching, and setting clear expectations Track record of developing and delivering a highly functioning analytics platform enabling performance insights which drive strategic business decisions Experience with overseeing data aggregation, machine learning techniques, data visualization, and experimentation architecture Experience overseeing/developing model experimentation and optimization in a production environment The ability to effectively communicate analytical insights to a non-technical audience Track record of solving analytical problems creatively, with clear outcomes and a strong sense of accountability 
ScrapedJobID650:
Access to social volunteer and recreational programs, via our many Employee Resource Groups (ERGs) Opportunities for career development through active internal mobility and our innovative training program: Canada Academy A brand new workspace, flexible, comfortable and easily adaptable to your needs: remote work opportunities, standing desks, innovation lab., open meeting rooms and spaces Leadership, building up the Analytics & Insight brand within and outside HR Manage, build, and develop the Data Analysts and Employee Data Management teams, driving efficiencies and automation along with reinforcing data quality throughout our Information System Build a date-driven and analytics culture by communicating and democratizing the concepts and value of analytics to the broader HR and executive communities and collaborating with other analytics authorities across the organization Position the team as an expert advisory to support HR strategy and decision-making. Develop close ties with HR Leadership and other HR COEs (Learning & Development, Talent Acquisition, Benefits, Payroll …) to identify and build sophisticated analytics solutions Identify and build the skillsets within the team and where relevant, propose a development plan for HR Promote and champion a culture of innovation Business Intelligence and analytics Produce analysis and sharp visualizations through business analytics and intelligence technologies such as PowerBI to help make informed decisions. Identify and use multiple data sources, analyze and present results – interpret data and derives significant patterns or points of attention, provide recommendations and insight based on key trends and knowledge of business challenges. Design, develop and maintain standardized dashboards, metrics, KPIs and reports including with PeopleSoft. Provide summary level and detailed reports incrementally and on an ad-hoc basis; examples include overtime reports, time-off management, headcount reports, payroll reports Co-create solutions with our Enterprise Data Management team to ensure scalable solutions are delivered Train and coach HR teams on how to interpret data and metrics and make the best use of the reports and dashboards Help team enhance scope of Data Science activities: e.g. Developing Forecasting, Multi-Variate models, Regression/Correlation analysis, Machine learning, AI, etc. Demonstrate a continuous learning curve and open mind-set to bring in innovative ideas. Project management Keep track of the pipeline confirmed priorities, ensure features are developed, reviewed, thoroughly tested, and implemented as per user requirements. Comprehensive assessment of business needs to build a precise understanding of requirements, propose solutions, and execute as per plan. Project contribution at all stages of development, monitor and coach team Database Management/HR Workflow Maintain data integrity, create and utilize reports and data queries to authenticate integrity of employee information, resolves differences between Finance and Human Resources systems, and assist with reconciling data between PeopleSoft and other internal compensation systems, including Payroll Participate in auditing and maintenance of employee records, including HR status updates, terminations, and new hires Additional missions may include Participate in alternative systems research and RFPs Support and assist new product implementation both within Human Resources and outside the department. Bachelor’s degree or higher in Computer Science, Information Technology, Data Science, Math, Engineering, Finance or similar field 4 - 6 years of experience in analytics, business intelligence, or similar roles. Strong applied mathematical, statistical, and analytical skills to design and interpret descriptive and predictive statistics Experience in data mining, text analytics, data collection strategies Excellent verbal and written communication skills with an ability to convey ideas and effective story-telling through data, reports and dashboards. Client-focused, ability to effectively collaborate and communicate with the respective HR and Business stakeholders; Strong analytical and problem solving skills with high attention to detail and accuracy. Strong ability to adapt and re-assess priorities for short and medium term, while being able to drive the holistic long term roadmap Experience with HRIS Systems is an asset but not mandatory as trainings can be organized Outstanding operational and organizational skills in addition to detailed oriented work Ability to work under pressure to meet deadlines Self-starter, proactive in seeking information and approaching business problems with creativity Able to work well independently and in a team environment Experience working in a large, complex organization is an advantage Proficient with PowerBi, Tableau, or similar business intelligence and analytics tools. Coding knowledge and experience in several languages: for example, R, Python, Java, MS Excel/VBA, , etc. Experience with database programming languages including SQL Knowledge of Business Objects Experience in one or more of the ETL platforms such as KNIME, Alteryx Experience with data sources and reporting tools; HCM PeopleSoft 
ScrapedJobID651:
Contribute to the design and implementation of our NLP Enhance and improve MIMs ML models Enhance and improve MIMs ML Ops Pipeline Research and POC for state-of-the-art technologies Provide a statistic analysis of customer questions and conversations Master’s or Ph.D. in Computer Science/Engineering or related field required Strong experience working with Python, Numpy and Pandas Expert knowledge of NLP tasks such as classification, NER, and topic modeling A good understanding of Machine Learning fundamentals Experience with TextCNN, LSTM, seq2seq, Attention, BERT, GAN models Experience with TensorFlow, Keras, PyTorch, Scikit-learn Experience with NLP libraries NLTK, spaCy, etc. Proven experience in large projects supporting 100K+ users. Skills in Linux environment, shell script, git, and docker. Production Environment experience is an asset Team player Excellent verbal and written communication skills (English/French). Be highly proactive, self-motivated, and detail-oriented. 
ScrapedJobID652:
Influence how we build a mission-driven, high-throughput data science and analytics organization, and contribute to our collaborative culture Establish data rigor, data integrity, accuracy, responsiveness and execution cadence across all data science and analytics programs Build frameworks and tools to automate ad-hoc and post-hoc analysis requests Help Machine Learning team with exploratory data analysis for enabling semantic search, fraud analytics, spam detection models, document optimization and analysis to support applied machine learning across all product initiatives Create and implement machine learning models to support Course Hero products Mine structured and unstructured data platforms to understand customer attributes, user journeys, engagement with the products, and growth opportunities for our business Design and analyze A/B tests and propose innovative A/B testing techniques to help us learn about our millions of users Propose strategic initiatives and goals to help our functional partners to achieve their goals and drive growth Effectively communicate data findings to internal and external team members 5+ years of working experience in data science or analytics Deep understanding of statistics and probability, quantitative sciences, data analysis, natural language processing, text mining, econometrics, and distributed data processing Skilled in predictive modeling, statistical modeling, data mining, numerical simulation, stochastic modeling, time series analysis, and portfolio modeling Quantitative experience in B2C markets Track record of delivering decision support models and quantitative analysis with actionable insights Hands-on technical skills in Python, SQL, Map/Reduce, RegEx, and Linux scripting Experience with big data platforms such as Hadoop, MapReduce, Spark, Hive, and Pig MS or PhD degree in a scientific or quantitative field Experience mentoring or managing other data scientists Familiar with Search Engine Optimization (SEO) Knowledge and experience working with Google Analytics, Tableau, Amplitude, and Treasure Data Experience working in education or e-commerce domain Competitive salary Full private medical coverage (medical, dental, vision) Retirement savings program Paid Parental Leave Education Reimbursement Quarterly team events and outings Team lunches Social responsibility program (volunteer hours and donation matching program) Front row seat to Master Educator lectures – check out our Lecture Series videos 
ScrapedJobID653:
You will be working on cutting edge problems in Deep Learning for Deeplite optimization software stack. Work on architecture-specific neural network optimization algorithms for high performance computing. Design and develop a lightweight and high-performance inference engine for CPUs and microcontrollers. In this role you will have opportunity to develop an inference engine running on many devices. Bachelors, Masters or Ph.D. or equivalent in Computer Science, Computer Engineering, or related field. 4+ years of relevant work or research experience in high performance computing and compiler optimizations. Excellent C/C++ programming and software design skills, including debugging, performance analysis, and test design. Excellent Python skills, and a dedication to writing clean, understandable, testable code with an eye towards maintainability. Experience with optimizing compiler, programming low-level hardware and microcontrollers. Development or research experience in a production compiler (preferably LLVM or TVM) Familiarity with ARM, RISC-V and/or x86 architectures is highly preferred Experience with deep learning runtime frameworks such as ARM-NN, CMSIS-NN, TensorRT, XLA, ONNX Runtime, OpenCL, MLIR is a huge plus 
ScrapedJobID654:
Developing NLP systems that help us structure and understand biomedical information and patient records Using a variety of structured and unstructured data sources Imagining and implementing creative data-acquisition and labeling systems, using tools and techniques like crowdsourcing and novel active learning approaches Working with the latest NLP approaches (BERT, Transformer) Training your models at scale (Horovod, Nvidia v100s) Employing and iterating on scalable and novel machine learning pipelines (Airflow on Kubernetes) Reading and integrating state of the art techniques into Fathom's ML infrastructure such as Mixed Precision on Transformer networks 2+ years of development experience in a company/production setting Experience with deep learning frameworks like TensorFlow or PyTorch Industry or academic experience working on a range of ML problems, particularly NLP Strong software development skills, with a focus on building sound and scalable ML A real passion for finding, analyzing, and incorporating the latest research, technologies and techniques directly into a production environment Good intuition for understanding what good research looks like, and where we should focus effort to maximize outcomes Developed and improved core NLP components and not by just 'grabbing things off the shelf' Led large-scale crowd-sourcing data labeling and acquisition (Amazon Turk, Crowdflower, etc.) 
ScrapedJobID655:
Develop a deep understanding of the markets in each country and their data and analytical needs. Provide guidance to internal collaborators on advanced analytics Co-lead GAA's capability/product strategy, synthesizing business needs and advanced analytics expertise into capability/product roadmaps. Lead the development and deployment of strategic capabilities/products built around advanced analytics that create tangible business value. Coordinate across CoE roles and other business functions (sales, marketing, IT, external vendors, etc.) required to efficiently and effectively deliver new analytics capabilities/products Coordinate across markets the development of analytics capabilities to improve commonalities and efficiencies Collaborate with the Data & Insights Specialist on business adoption, and embedding analytics into business processes Find opportunities to evolve analytics capabilities/products and to use them across countries and brands Instil a culture of continuous improvement to refine and enhance existing capabilities. Monitor the external environment to stay up to date on leading advanced analytic capabilities, both within and outside of pharma, which can be applied within the organization. Oversee multiple capability related projects across different countries and markets. Extensive hands-on experience in application of advanced analytics and statistical methods on large and disparate datasets preferably in the context of Omnichannel marketing, specifically: Statistical Analysis and Modelling: (e.g. Design of Experiments, Time Series Analysis, Regression Analysis, Bayesian methods, etc), Machine Learning and Artificial Intelligence Extensive experience in deploying (and maintaining) production-grade advanced analytics capabilities. This includes not only the delivery of solutions but also the building of the business ecosystem (processes, organizational structure, change management, etc.) necessary. Strong organizational skills and time management; ability to manage diverse range of simultaneous projects. Strong leadership and interpersonal skills with demonstrated ability to work collaboratively with a significant number of business leaders and cross-functional business partners. Strong communication and influencing skills. Pharma commercial domain understanding. Experience with omnichannel analytics Experience with Agile methodology within an IT/business environment. Strategic and critical thinking with the ability to engage, build and maintain credibility with Commercial Leadership Team. Quantitative Master's or PhD degree from an accredited college or university is required in one of the following or related fields: Engineering, Operations Research, Management Science, Economics, Statistics, Math, Physics, Computer Science or Data Science. Cambridge, UK Gothenburg, Sweden Gaithersburg, US 
ScrapedJobID656:
Diagnose problems and develop compelling, data-driven recommendations Partner with Product, Engineering, and Data Science teams to design solutions to operations problems, influence product roadmaps, and solution new products/processes Manage the development, reporting, and visualization of metrics for the entire Risk organization Maintain, develop and manage various data pipelines and ETLs Improve risk solutions through third party evaluation and integration with a focus on improving the seller experience Design and develop executive presentations for Square's leadership and board members A BS/BA in Statistics, Mathematics, Operations Research, Management Science, Computer Science, or a related technical field, OR BS/BA in Criminal Justice, Economics, Business, or a related business field 4 or more years of relevant experience (or masters and 2+ years) Proficient in SQL Intermediate knowledge on Python (Numpy, Pandas, Matplotlib etc.) Experience with designing and creating data visualizations (e.g. Looker) The ability to answer unstructured questions and bring projects to conclusion A strong passion for Square's mission [Bonus] Experience and interest in risk, trust & safety, payments, or spam prevention [Bonus] Experience with scripting and data analysis programming languages (e.g. Python, R, etc) [Bonus] Experience using statistics and machine learning [Bonus] Consulting / project management experience Healthcare coverage Retirement Plans Employee Stock Purchase Program Wellness perks Paid parental leave Paid time off Learning and Development resources 
ScrapedJobID657:
Undergraduate in Computer Science or related field (master's degree is a plus). More than 2 years' experience with the following skills Hands on experience with Deep Learning frameworks like PyTorch, TensorFlow. Proficiency in programming languages like Python and C/C++ Fundamentals of deep learning (CNN) Experience with runtime environments (OpenVINO, ONNX runtime, TVM etc.) would be a huge plus. Experience with deep learning model compression, speedup related project is a huge plus Experience building systems based on machine learning and/or deep learning (Experience with embedded boards is a plus) Customer facing skills. 2 years of industry experience working with clients for technical collaboration. Willingness to work on multiple projects concurrently. Strive in a highly innovative and collaborative environment. Opportunity to advance state-of-the-art software in the fields of DNN model compression, AutoML, Neural Architecture Search (NAS) and more! Have a major impact – what you build will translate directly into the customer’s needs. Open and inclusive culture. 
ScrapedJobID658:
To work with some of the best professionals in the business - for a firm that values individual intellect as much as teamwork State-of-the-art offices that are designed to maximize collaboration Flexible working arrangements Enriching challenges that provide opportunity for constant learning and advancement An environment which is leveraging technology to its highest potential Bachelor's degree required, Ph.D. desire Development experience in Python or R (C, C++, Java, etc. is a plus) Track record of publications in competitive venues is highly desired Deep understanding of statistical learning methods Strong communications and organizational skills 4+ years of applicable research experience Video dated October 2019. 
ScrapedJobID659:
You'll build frameworks & strategies to shape how we integrate data, tracking and analysis into everything we do — from quick social campaigns to larger activations — then iterate on them to improve. Revolutionize our data storytelling — in writing, in graphics / video, on social media & more. Act as a thought leader internally, as you evangelize & educate around best practices in creating data-backed frameworks. You will apply structure in the way that we measure our marketing campaigns and initiatives to ensure that we are optimizing for performance. Take lead in drawing insights from raw data sets in order to create new, exciting ways connect with our community and new fans. You are capable of applying your skills across a variety of use cases; inflexible specialists need not apply. We believe in processes and the power of planning, but you will often have to roll with the punches and prioritize the most impactful tasks on the fly. You've got a track record of working in Business Intelligence, with a history of driving business impact with data-driven analysis & presentation. You've got deep technical expertise in data systems, especially Google Cloud Console, Query, Excel, Tableau, PostgreSQL. If you have Python & R experience, too, that's even better. You've got an artistic bent, and know how to create compelling visuals using data. 
ScrapedJobID660:
Be the Subject matter expert in all things Treasure Data. Equipped with solid knowledge of our Cloud-based Customer Data platform, you will provide the technical and analytics expertise to customers towards a successful, scalable implementation of production-ready Dashboards and Analytics solutions. Help our customers extract the maximum value from their data by building ETL pipelines that will feed into dynamic Dashboards, covering Use Cases for Marketing Campaign Analytics, Customer Data Insights, and more, which will allow business users to get valuable insights and solve complex real-world business problems. Ensure Reporting and ETL pipelines are scalable, efficient, well-documented, and easily customizable to different types of data and business use cases. Guide customers and prospects in best practices for implementation and architecture of their Reporting use cases on the Treasure Data platform. Help research the latest technologies and Data Science/ Statistical methods for building dynamic Dashboards and work with our ML team on developing and productizing new Reporting Solutions around the ML models built for customers. 10 % travel may be required as part of this job subject to travel restrictions A strong background in data & technology and a good understanding of Marketing Analytics and the Martech/Adtech Industry are a plus. Experience building ETL pipelines on large volumes of data using a combination of API methods and SQL (bonus points for Python). Understanding of popular Data Science methods and Machine Learning models such as Regression, Classification, Recommendation Systems, Clustering a plus, etc. Comfortable working on team projects and collaborating via version control tools such as GitHub and GitLab. Have strong customer communication and presentation skills as well as the ability to dive into technical topics and know-how, to successfully work as a trusted advisor to ensure the success of prospects and customers. Engagement with developers, business analysts, and IT confidently and succinctly and understand how they want to work with data. When it comes to delivering disruptive solutions to age-old problems, you are the expert. This can be demonstrated by a track record of happy, referenceable customers who appreciate your technical acumen and your diligence. This is a hands-on role – be ready to jump in and use the product from your first day. Have an existing portfolio of projects that demonstrate your ability to successfully build ETL pipelines and power dynamic Dashboards (custom formula calculations, global and local filter management, multiple joints on a one-to-one, one-to-many, and many-to-many relationships, dashboard refresh rate management, etc.). Have a good understanding of Digital Marketing and Marketing Technologies and the KPI metrics and Insights important to Marketing Teams and other decision-makers. Have experience working for a Marketing Agency or with a variety of brands directly to help them extract and visualize important KPIs and Customer Insights Have experience working with Big Data technologies (such as MySQL databases, Hadoop, MapReduce, Hive/Pig, Apache Spark, MongoDB, etc) Have experience in Digdag, Fluentd, Hivemall, or Embulk. Have wide industry experience across Automotive, retail, media, and entertainment, retail, telco/media markets, or E-commerce. 
ScrapedJobID661:
Develop large scale shopping recommendation algorithms Build data pipelines to do data analysis and collect training data Train deep learning models to improve quality and engagement of shopping recommenders Work on backend and infrastructure to build, deploy and serve machine learning models Develop ML algorithms to balance different objectives and model long term values Drive the roadmap for next generation of shopping recommenders 3+ years working experience in the area of applied Machine Learning Interest or experience working on a large-scale search, recommendation and ranking problems Interest and experience in doing full stack ML, including backend and ML infrastructure Experience with big data technologies MapReduce/Hadoop/Hive/Presto/Spark Expert in Java, C++ or Python Ph.D. in an area of Machine Learning Experience with large scale Whole page Optimization, Search or Recommendation algorithms Domain expertise in Shopping Shopping is cross-cutting, touches all aspects of Pinterest, so a wide variety of ML problems Largely green-field so lots of opportunity Huge impact - shopping is one of the major expansion areas for Pinterest 
ScrapedJobID662:
Apply knowledge of programming, math, statistics, and machine learning to build solutions for recognizing patterns in the real-world data, organizing information, extracting entities and discovering relations between them, leading to prototype development and product improvement Use an analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data Work with engineers to translate prototypes into new products, services, and features and provide guidelines for large-scale implementation Extend, develop, program, and implement new algorithms University Degree in Computer Science University Degree in Computational Linguistics, Computational Biology, Statistics, or Applied Math, and 2+ years of industrial experience as Software Engineer/Developer PhD in AI or another quantitative field and 1+ year of hands-on experience programming machine learning based solutions to real-world problems MSc in AI or another quantitative field and 4+ years of hands-on experience programming machine learning based solutions to real-world problems 5+ years of total programming experience in industry or research Ability to write production-quality object-oriented code in at least one of the modern OOP programming languages (e.g. Python, JavaScript, Java, C++, Scala, C#) Basic knowledge of SQL, ability to write selects with joins An open mind; desire to learn the best language/technology to solve a given problem Deep understanding of machine learning theory and practice (feature engineering, regularization, hyperparameter tuning, ensemble methods, neural network architectures) Expertise in data analysis (experiment design, classification, regression, unsupervised methods) Knowledge of core computer science concepts such as data structures and algorithms, OOP, code profiling/optimization Detailed knowledge of at least one popular deep learning library, proven ability to implement in practice neural network architectures described in literature Proficiency with regular expressions and other deterministic methods for processing text as well as experience in practical NLP is a plus Ease with Linux Good English; a level of French sufficient for work-related discussions “Hacker” attitude: hunger for resolving enigmas, finding solutions to riddles and facing uncommon challenges Readiness to work in uncertainty regarding the resolution of a problem, the existence of means to resolve it and, sometimes, in the absence of precise objectives Autonomous and responsible; organized and structured in initiatives and work Detail-oriented and able to keep a global vision of the issues and their solutions Positive attitude, friendliness, and generosity 
ScrapedJobID663:
Create solutions through the use of advanced statistical analysis, data mining, and data visualization techniques ensuring tasks are completed on time Designs, implements, and evaluates advanced statistical models and approaches for application in the business’s most complex issues Performs ad-hoc data mining and exploratory statistics tasks on very large data-sets related to the business’s strategies Prepares reports and presentations that will give insights into ongoing/completed work Cleansing of large unstructured data and enabling analytical capability in order to query the data and address various business needs Uses unstructured and disjointed datasets for the purpose of independently generating actionable business insights as well as creating manageable analytical processes Collaborates with senior data scientists to communicate obstacles and findings to relevant stakeholders in an effort to improve decision-making and drive business performance Comes up with superb illustrations and visualizations of data communicating results as measures of the business’s impact Team player, cooperating with others in the data analytics team and sharing information and knowledge, in solving complex business issues Seeking advice from others when learning Coordinating and monitoring specific team tasks when requested Documents completed work so that anyone will be able to understand and implement it Will work in researching and building analytics capabilities in transportation domain by communicating with engineering team Researches open source data relevant to transportation Assists in video labeling and building libraries which are focused on performing analysis relevant to transportation Must be enrolled in a graduate program (preferably in Civil/Transportation/Traffic Engineering) and eligible to work full-time (40 hours/week) Strong knowledge of road systems, pavement design, transportation planning, asset management, traffic analysis Able to think and function independently with minimal supervision Strong programming skills and experience working with tools such as Excel, R, Python, ArcGIS, SQL Server Management Studio, Azure MLS, Azure DevOps, Git Must have completed either academic coursework or MOOCs related to programming Academic/professional experience in but not limited to libraries such as Pandas, NLTK, Scrapy, BeautifulSoup, Numpy/Scipy, Sklearn/H2O, OpenCV, TensorFlow/PyTorch and/or Keras Good understanding of Dataframe Manipulation, Web Scraping, Natural Language Processing Machine Learning, Deep Learning concepts, techniques, and algorithms with a specialization in at least one of the listed concepts (Image/Video Processing – preferred) Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications Ability to troubleshoot complex issues Strong organizational and communication skills Confident but friendly and approachable 
ScrapedJobID664:
Responsible for refactoring Distribution Optimization algorithm written in Python using Object Oriented Programming Work with client stakeholders to understand key business problems, determine solution requirements, build statistical / ML / predictive models, and fine-tune for accuracy Successful compilation of results from various what-if scenarios using client’s data science platforms; support client’s Decision Science team to deliver the simulation solutions to the business teams were performed Ensure models are deployed and deliver projected business value Work as part of a global team to solve problems in a computationally efficient manner Model documentation – providing details where enhancements, bug fixes, or other modification 5-10 yrs of optimization background with an extensive knowledge and experience in OOP using Python Experience and knowledge on heuristic optimization and other optimization techniques Maintaining and supporting optimization models developed by other data scientists Creation of delta analysis for various what-if scenarios Ability to engage with the client stakeholders to understand business problems, ideate & converge on solution approach and develop analytical solutions Ability to work with global teams and communicate effectively Graduate degree in Operational Research, Data Science or Data Analytics or a relate quantitative field 
ScrapedJobID665:
Develop and maintain scalable and reusable data pipelines and APIs on cloud services such as AWS, to support all systems for all things ML related Develop and maintain logical and physical data models that support needs that are currently defined while being adaptable to future needs Work with business teams across the organization to understand their data-driven goals Bachelor’s degree in Computer Science or Engineering, or related field or relevant experience Experience building scalable data pipelines and databases on cloud services such as AWS Strong programming background. Python preferred. Experience building and integrating with 3rd party restful APIs Experience working with SQL, NoSQL databases (such as DynamoDB, MongoDB), and data warehouses (such as Snowflake, Redshift) Exposure to Docker, Kubernetes, Airflow, Spark an asset Familiarity with agile tooling to efficiently build as a team: Git, Jira, Confluence, etc. Experience working in Agile Scrum and Kanban environments Experience with infrastructure-as-code Excellent communication skills and stakeholder management Familiarity with data management capabilities (data registration, data quality, privacy and security.) and ability to learn advanced data management toolsets Be part of a collaborative, progressive and high-performing team, building revolutionary products that matter. Generous benefits, including a company match RRSP program. Continued professional development opportunities through programs such as Six Sigma. A modern workspace centrally located in Toronto’s thriving downtown core, easily accessed by transit and a few minutes’ walk from Union Station. Flexible time-off options 
ScrapedJobID666:
Develop a high performing technical team focused on data science and engineering Lead multiple initiatives simultaneously Provide learning and growth opportunity to the team based on the manager’s technical proficiency in data science, computer science or engineering and coach the next generation of leaders. Oversee development of data science products, models and other data driven outputs while also contributing in a technical capacity when necessary. Ensure strong collaboration with all relevant stakeholders, technical teams and users across the organization. Straddle the worlds of insurance professionals, data scientists and engineers to prioritize data driven solutions. Work closely with business partners to understand day-to-day challenges and key areas of opportunity for innovation and growth using data Engage directly with users, empathize with their experience and use data to inform decisions. Define team strategy and future roadmap and encourage the use of data science solutions across different departments. At least 7 years of experience working in a Computer Science or Data Science or engineering driven organization or team, including at least 1 year in a managerial role. Undergraduate or graduate degree in Computer Science, Data Science or Engineering or other related field or equivalent experience Deep agile development experience and preference for ability to work as a scrum master or product owner Experience in applying data science and/or computer science in the P&C insurance space preferred. Demonstrable experience leading technical professionals in managerial or senior technical roles. Ability to independently plan and manage core responsibilities for self and direct reports. Proficiency in at least one programming language, preferably Python. A proficiency sufficiently strong enough to teach. Excellent communication skills and comfort communicating complex ideas in appropriate terms for senior leadership and non-technical users. Strong ability to influence stakeholders and defining the next best action. Strong analytical skills, with the ability to understand problems and develop solutions for and with key business areas Ability to identify limitations and deficiencies in the technical deliveries Multidisciplinary candidates are preferred. Competitive rewards package including base compensation, eligibility for annual bonus, retirement savings, share plan, health benefits, personal wellness, and volunteer opportunities. Outstanding Career Development opportunities. We’ll support your professional development education. A collaborative culture 
ScrapedJobID667:
Design, test, and implement logic & processes to balance DC (country/channel, east/west) inventory that leverages our One Inventory network design across all global regions Deliver transfer automation and develop new tools that incorporate future demand forecasts and reconcile bottoms-up need with tops-down targets Define logic to maximize Retail and Ecom inventory availability while optimizing fulfillment cost and DC capacities Provide insights and recommendations to leadership on business operations by leading opportunity analysis, problem research, and metrics design Conduct deep dive analytics projects, integrating various data sets and utilizing advanced analytics concepts Develop, implement, and maintain interactive reporting solutions for monitoring and analyzing business performance, using BI software Design tools to deliver insights faster and influence decision making using scripting languages like R and Python Refresh existing tools and data sets to empower the business teams to answer their own questions and develop a culture of self-serve analytics and data-driven decision making 4+ years retail experience in a related function (inventory management, merchandising, supply chain) 4+ years data analytics and reporting experience (SQL, Python, PowerBI, Excel) University degree in business, inventory management, supply chain/logistics, or related field University degree in data science and analytics Proven excellence in identifying and communicating business insights to cross functional partners and management Acknowledges the presence of choice in every moment and takes personal responsibility for their life. Possesses an entrepreneurial spirit and continuously innovates to achieve great results. Communicates with honesty and kindness, and creates the space for others to do the same. Leads with courage, knowing the possibility of greatness is bigger than the fear of failure. Fosters connection by putting people first and building trusting relationships. Integrates fun and joy as a way of being and working 
ScrapedJobID668:
Extended health care On-site parking Monday to Friday Bachelor's Degree (preferred) Temporarily due to COVID-19 
ScrapedJobID669:
To help the Data Lab families accelerate the completion of their AI projects by contributing to the implementation and execution of a strategy of opening up to the outside world that must allow access to all players in the Quebec, Ontario, Canadian and in some cases global innovation ecosystem. From the world of startups to the academic world, including solution providers and companies tackling problems similar to those of the Lab, the candidate must develop an excellent understanding of the roadmaps of the Data Lab's families in order to propose to them the collaborators who will have the greatest impact in the realization of their projects. To act as Senior AI Business Analyst for the climate risk project portfolio. Help define and deliver the Data Lab’s strategy of opening up to the outside world. Develop an excellent understanding of the teams’ roadmaps and propose collaborators to accelerate their achievement. Organize and structure the documentation and results of the different collaborations. Contribute to the definition of the portfolio of climate risk projects, support the projects as a Senior Business Analyst and represent them in our different lines of business. Act as an intermediary between the Data Lab, IT, users and different levels of management. Facilitate working sessions with experts from different fields and different project stakeholders. University degree in a related field or relevant experience At least 5 years of experience as a business analyst in an IT environment, including 2 in an AI context Highly developed analytical skills facilitating problem solving Support, coaching and consulting skills Knowledge of the company, the insurance industry and business processes are important assets Team player Bilingual (English/French) Have knowledge of applied artificial intelligence, its capabilities and limitations. Be involved for at least 2 years in the local or national innovation ecosystem. Be familiar with geospatial or climate science and ideally have accomplished some AI projects in these fields. An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID670:
As part of the development of the development and implementation the governance processes, understand stakeholder requests, define objectives, develop detailed project plans, develop strategies to mitigate and quantify risks. Support the development and implementation the governance processes to validate and syndicate changes to reference data across Oracle / SAS Modules that are approved by business. Understand business processes and systems as well as the various data flows, develop them if necessary, and establish new mapping tables, while ensuring their consistency and precision, in connection with conversion, integration, the mapping, transformation and analysis of financial data. Capture and track the measures and metrics related to the governance of data and report out any anomalies. Support the establishment of data quality management best practices, standards, guidelines & processes and ensure adherence across the organization through regular audits. Contribute to strong data analysis and solutioning in the data governance domain enabling stakeholders to manage, control and leverage quality information within and across business units and functional domains. This includes maintaining various dashboards, capability metrics and provision of reporting to identify trends, potential issues, support solutioning. Perform security and maintenance of EDMCS. Execute the loading of reference data into Oracle for new and existing dimensional data, execute create and change requests. Work with technical lead teams regarding customization and integration of finance applications. Interface and co-ordinate with the applicable functional business units to action changes to the master data files. With the team, act as an advisory role to the business team on future process models, product launches, support of acquisitions, changes in organizational structure. Execute requests for mass maintenance of reference data to ensure the appropriate standards and governance rules are maintained. Perform on-going 52-109 controls related to the data management and reporting (access, security, change management etc.). Act as support or back-up to the development and automation of reports defined as part of the current project. Bachelor's Degree in Accounting/Finance or equivalent experience. CPA Certified Public Accountant (asset). Experience and knowledge of integration / conversion and mapping of financial data. Experience in master data management strategies, data governance and/or data steward or equivalent experience (an asset). 3 to 4 years of relevant experience. Experience with 52-109/SOX controls Excellent oral/written communication skills. Strong analytical and problem-solving skills. Strong negotiation skills and ability to persuade, influence and motivate from a wide variety of functional background. Demonstrated ability to manage multiple priorities. An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID671:
Combination of graduate education (MS or PhD) and academic research lab experience in Deep Learning, Machine Learning, or similar computationally intensive degree 2+ yrs of professional ML experience as a technical leader and major contributor on projects with other MLEs and cross-disciplinary contributors involved. Experience in running ML/DL projects from discovery to delivery is highly valued. 3-5+ yrs professional experience (industry or research lab) related to ML or software engineering. Expertise with Python (strong emphasis on keras, TF, pytorch, sklearn, opencv) Strong software experience with SQL, version control, APIs. Experience in CI/CD involved in deploying, maintaining, and monitoring ML or Data products. Special interest will be given to any of ML Ops, Graph-based data structures, advanced search/recommendations, scaling large scale ML production systems to marketplace-sized requirements. Good scripting, functional, and vectorized scientific programming skills in python. Good exploratory data analysis and reporting skills Comprehensive benefits offerings for benefits eligible Teammates. Unique culture that truly values each and every Teammate. Career development and Future Growth Opportunities. 
ScrapedJobID672:
Work hand in hand with our sites, the broader IT team, and a large range of Nutrien subject matter experts to develop and manage a variety of high priority projects requiring their specific expertise Assist in the development of hardware and software architecture for IT and enterprise OT deployment Acquire knowledge of the Potash business to enable understanding of where data analytics and advanced computer technologies can help us improve our operations and safety Acquire and maintain a strong working knowledge of existing systems utilized within the potash business unit Utilizing a structured methodology, find or develop solutions to support the mining operations Develop solid solution designs utilizing a variety of proven methodologies including agile and algorithmic approaches Develop digital solutions for visualization, navigation, and automation of Mining equipment Create, modify, integrate, test, and sustain solutions deployed in our technology stack using sensor integration, computer vision or numerous other data science techniques Develop test and support procedures for hardware and software systems Identify Technical challenges in Visualization and Automation of mining equipment. Explore and evaluate potential solution for them Maintain a working understanding of process control systems including products from Emerson and Rockwell (PLCs, HMIs, etc) Utilize software solutions and integrations with other enterprise systems including but not exclusive to the following: AWS architecture, AWS services (including Redshift), Python, C++ and ROS Assist the Next Generation Potash team in development, deployment and support of potash IT and OT systems to further progress towards our strategies Be primarily based in Saskatoon with potential to work for short periods of time at our operating mines in Saskatchewan (based on the project) 2 Year Technical Diploma/Degree 7-10 years of combined experience working with IOT, integrations, computer vision, data analytics or robotic / remote control systems (preferably in a mining or industrial environment) 2 years of experience working in operational control systems with a good understanding of networking and cyber security concerns as it relates to the topic 5 years experience of managing projects and project teams Strong verbal and electronic communication skills – The senior data scientist will be in constant contact with internal employees, and at times contractors and vendors, and require these skills to provide prompt, effective service Problem Solving skills – Excellent hardware/software troubleshooting skills relating to the computer and data science Experience in developing and end to end hardware and software solutions Ability to work efficiently on their own, or as a member of a group Valid driver’s license 
ScrapedJobID673:
Develop the state of the art NLP applications with ML for knowledge engineering and expert search & recommendation. Build a scalable graph solution to meet business needs. Build a scalable data engine, NLP pipelines, and ML algorithms for Knowledge Graph. Apply NLP, ML, and graph computing technologies to improve business processes and operational efficiency. Create, design and optimize ML pipelines incorporating the relevant latest technologies and best practices. Research publicly available or open source labeled datasets and build a pipeline to extract, transform, and load data for ML. Work with Product, Design, and Engineering teams to commercialize AI capabilities and integrate them into products. Masters/PhD degree in a quantitative or computational field such as Data Science, Machine Learning, Computer Science, Statistics, Mathematics, and Engineering. Relevant work experience in data engineering, data/text mining, and building data pipelines. Must have prior experience developing business solutions with NLP, ML, and Graph technologies. Deep expertise in graph building, graph processing, graph querying, and graph analytics. Familiarity with Graph ML (e.g., graph embedding and graph neural networks). Strong Python programming skills with a broad range of NLP and ML libraries (e.g, NLTK, Spacy,BERT, OpenAI GPT-2, Scikit-learn, TensorFlow, PyTorch, Keras) in collaboration environments (e.g. Jupyter Notebook, PyCharm). Experience using AWS Analytics & Machine Learning tools. Proven ability to architect ML models and lead model development lifecycle: fetch, clean, and prepare data, train and evaluate model, deploy to production, monitor, and adjust as needed. Track record of delivering data science components that are part of successful commercial software or data products. Competitive remuneration package in a rapidly-expanding growth stage global company Comprehensive medical insurance coverage Generous leave policy, including a ‘work remote policy’ The opportunity to travel and work around the globe with our international clients and growing number of offices (Hong Kong, Shanghai, Singapore, Mumbai, Hyderabad, Manila, Ho Chi Minh, New York City, Toronto) Lynk employees are prohibited from trading Restricted Securities (defined as any security whose performance is linked to a single company) on any Personal Trading Account. All future new joiners, if they receive a conditional offer to join Lynk, will be required to undergo a background check. Lynk is an equal opportunities employer 
ScrapedJobID674:
Define and design Viamo's data solutions:
Working with Viamo's cross-functional product teams to understand product monitoring and programme evaluation requirements, and translate these into technical data specifications. (For example, this could mean helping a new product team formulate and refine the metrics they use for learning about user behaviour and product performance. )
Working with Viamo's clients to discuss their data needs and recommend optimal solutions based on existing data product capabilities.
Define best practice for needs analysis and end-to-end data product development process.
Ensure the quality and accuracy of data products which are built, working with dashboard designers and data engineers to troubleshoot and iterate.
Recommend best practice in terms of data visualisation techniques
Coach product teams in data analysis methods and approaches
Plan the strategy and process to produce monthly and quarterly impact reports for each product crew, country managers, the exec team, and board. Working with Viamo's cross-functional product teams to understand product monitoring and programme evaluation requirements, and translate these into technical data specifications. (For example, this could mean helping a new product team formulate and refine the metrics they use for learning about user behaviour and product performance. ) Working with Viamo's clients to discuss their data needs and recommend optimal solutions based on existing data product capabilities. Define best practice for needs analysis and end-to-end data product development process. Ensure the quality and accuracy of data products which are built, working with dashboard designers and data engineers to troubleshoot and iterate. Recommend best practice in terms of data visualisation techniques Coach product teams in data analysis methods and approaches Plan the strategy and process to produce monthly and quarterly impact reports for each product crew, country managers, the exec team, and board. Ad-hoc exploratory data analysis:
Query Viamo data to answer specific questions about the performance of the Viamo product ecosystem to help improve products.
Run exec level reports in a timely and accurate manner, liaising with key stakeholders to improve access to information and clarify issues.
Help define company wide monthly reporting metrics Query Viamo data to answer specific questions about the performance of the Viamo product ecosystem to help improve products. Run exec level reports in a timely and accurate manner, liaising with key stakeholders to improve access to information and clarify issues. Help define company wide monthly reporting metrics Assist with best practices in terms of data governance:
Map access levels across the different tools that form the Data Platform as per guidelines
Work with the Director of Infrastructure and Security, and with Viamo's Data Protection Officer, to ensure that data processing complies with our robust privacy and data protection commitments. Map access levels across the different tools that form the Data Platform as per guidelines Work with the Director of Infrastructure and Security, and with Viamo's Data Protection Officer, to ensure that data processing complies with our robust privacy and data protection commitments. Support the Data and Insights product team in planning the product roadmap:
There is significant scope to improve on current best practice and ample opportunity to work across departments to evolve data assets and use of data.
Recommend ways of increasing efficiency of internal processes through automation and increased access to data
Recommend approach towards unified approach to product measurement in line with Viamo's ambitions of creating a platform to bring together end users and paying partners through the product ecosystem
Recommend any further resourcing or technology gaps Viamo has in terms of realising its ambitions
Recommend new technical methods of data analysis based on their specific database management expertise There is significant scope to improve on current best practice and ample opportunity to work across departments to evolve data assets and use of data. Recommend ways of increasing efficiency of internal processes through automation and increased access to data Recommend approach towards unified approach to product measurement in line with Viamo's ambitions of creating a platform to bring together end users and paying partners through the product ecosystem Recommend any further resourcing or technology gaps Viamo has in terms of realising its ambitions Recommend new technical methods of data analysis based on their specific database management expertise Guide product teams to plan data structures, processing, metrics definition, visualization, and data governance as they innovate new products Lead on the requirements gathering and data specification processes, working closely with data engineers, dashboard implementers, and product specialists to understand the data needs of Viamo and our partners Work confidently and independently with our global teams as part of the Data and Insights product team Reports to the Director of Technical Product Management. Experience of 8+ years in any combination of: social enterprise, INGO, mobile network operator, Over 5 years of experience working as a data analyst/ data scientist Experience working remotely Ability to collaborate at multiple levels with a product team (including product management, design, and engineering roles): from discussing general market/customer needs, to roadmap planning, to specific technical requirements, down to low-level query details and technical optimization Expertise in database management languages (MySQL, BigQuery Standard SQL, etc) Experience in dashboarding software (Google Data Studio, Tableau, PowerBI etc) Strong technical problem solving skills, proven ability to troubleshoot and debug Strong communication skills with technical and non-technical team members A proven ability to systematically approach tasks and to manage multiple, at times changing priorities and expectations A passion for helping people in emerging markets through technology Experience working with user engagement data Experience of coaching teams in best practices in approaches and methodologies in data science Degree in computer science, data science, or similar Experience using a data visualisation tool to prototype dashboards Experience of AWS and Google Cloud Platform infrastructure Experience in using Machine Learning Understanding of the implications of GDPR and other data privacy regulation on data storage and use Experience of working with a data warehouse solution (eg. BigQuery, Redshift, Snowflake etc) Experience using ETL tools 
ScrapedJobID675:
Apply advanced statistical and machine learning techniques to build models for underwriting, pricing, and claims management. Design, test, build, and maintain the backend infrastructure to manage the machine learning model lifecycle. Collaborate closely with team members on developing machine learning systems from prototyping to production. Help us drive innovation by enabling new risk assessment paradigms and distribution models. Ensure data quality and integrity. Work with existing data science groups at Munich Re to develop model management best practices. Undergraduate Degree in Computer Science, Engineering, Statistics, or Applied Mathematics, plus 3 years' experience OR Graduate Degree in Computer Science, Engineering, Statistics, or Applied Mathematics, plus 1 year of experience. Ability to write robust code for deployable services in Python; working knowledge of SQL (familiarity with multiple languages considered an asset). Experience working through the modeling lifecycle including gathering data, design, recommendations, testing, implementation, communication, monitoring, and retraining. Experience with cloud computing platforms (e.g., Microsoft Azure, AWS, GCP). Experience with software engineering best practices including Git, Docker, CI/CD, test driven development, and code review. Familiarity with big data technologies (e.g., Apache Spark, Airflow, etc.), natural language processing and deep learning frameworks (e.g., TensorFlow, PyTorch) is an asset but not required. Strong communication skills to explain complex ML systems to business leaders. Capacity for abstraction and an aptitude for high-level software design. Thrives in a dynamic environment and can successfully deliver on multiple assignments under tight deadlines. 
ScrapedJobID676:
You will develop novel machine learning methods and algorithms that solve complex problems, including but not limited to, object detection, semantic segmentation, instance segmentation, depth estimation, optical flow, etc. Develop scalable and robust data pipelines that are able to process petabytes of data for model training, and deploy models in production Work fast and smart, and collaborate well with other awesome team members to deliver high-quality perception solutions that power the next generation of mobile robots Recent experience in state-of-the-art deep learning models for computer vision tasks on camera, lidar, radar Strong ML fundamentals and has demonstrated experience building and expanding model architectures Strong SWE fundamentals and has demonstrated SWE experience in both high and low-level languages (Python and C++) Strong research capabilities, track record of publishing papers at top conferences on relevant topics Bonus: Experience in deploying models in real time environments. Optimizing architectures to explore the accuracy vs. compute tradeoff Bonus: Experience working with productizing ML models and the infrastructure supporting model development (data, large scale training, eval, etc) 
ScrapedJobID677:
Formulate hypotheses and run a variety of A/B tests to determine the best strategies to implement into our products. Work with external partner studios to create balance changes and features that will improve target metrics. Evaluate and explore opportunities in our games and operations, through detailed querying and analysis of our data. Be a key bridge between data, game design, and the business through the creation of reports and dashboards, helping to illustrate the ongoing story told by our data. Build partnerships with each team member, sharing the tools and insights that predict and improve retention and monetization within our products. Continuously improve, maintain, and develop our analytics tools and predictive models for our games. A bachelor's degree in mathematics, statistics, computer science, economics, or a related quantitative field and/or a graduate degree in data science or business analytics. At least four years prior experience as a data analyst/scientist, preferably in the F2P mobile gaming space. Expert level knowledge of SQL (e.g., window functions), Tableau (or similar), and proficiency with at least one scripting language (e.g., R, Python). Ambition to own and take ownership of the reporting and analysis functions for our games. The ability to tell a convincing story with data. An innate curiosity and ability to mine large complex data sets and build predictive models that lead to meaningful conclusions. Previous experience A/B testing and calculating statistical significance within a big data context (e.g., bootstrapping, permutation testing). Strong written and oral communication skills. Prior management experience is a huge plus. Hungry, humble, and smart and can use these three pillars to impact you and those around you. A mobile game fanatic. You are on top of the latest games, trends, and what’s happening in live events. Entrepreneurial, self-motivated, and have the attitude to get things done. A risk-taker, and gain your biggest learnings through them. Empathic, compassionate, and curious. Solution-oriented and data-driven. Comfortable in an environment where priorities and plans can change rapidly. 
ScrapedJobID678:
A graduate degree in data management, statistics, economics, social sciences, or a related discipline. Minimum of three (3) years with progressive level of responsibility in a management capacity, including direct supervision and development of staff, in database management, information synthesis, business analytics, data quality and reporting. A combination of education and experience will also be considered. Proficiency with information and data management software is an asset. Demonstrated ability to translate complex information into clear, simple analysis. Understanding of processes for integrating data from multiple sources. Knowledge of statistics and experience analyzing large datasets (STATA, SPSS, Excel). Familiarity with common data science technologies. Knowledge of evaluation methodologies and the ability to transform performance management frameworks into data collection and reporting systems. Working knowledge of data management systems, especially Efforts to Outcomes™ or another Homeless Management Information System. Understanding of FOIP, HIA, PIPA, OCAP and related privacy legislation, policy, and practice. Working knowledge of the non-profit sector, especially organizations involved in homelessness and housing in Edmonton. Understanding of business processes associated with not-for-profits and government, as well as management of contracted services. Excellent communication skills, both verbal and written. Excellent leadership and interpersonal skills, able to engage with stakeholders of diverse and at times competing for interests to work towards achieving a common agenda. Demonstrated ability to lead and develop teams. Ability to link quantitative data to qualitative, wholistic evidence. Support the Director, Planning & Systems Integration and Senior Leadership Team with an evidence-based decision-making approach for organizational performance, business planning and Plan updates. Support all data and analytics projects including the bi-annual Homeless Count process and Sector Emergency Response Planning. Ensure appropriate development and use of data and system tools to support a high level of performance, community outcomes and inform decisions to continuously improve the execution of programs and projects. Ensure reports and dashboards are timely, accurate, easy to understand and share insights on key performance indicators that will enable leadership to make proactive and informed decisions. Lead analysis to support other departments and partners in improving performance, ensuring accountability, and identifying and addressing gaps. Provide guidance on the translation of knowledge gained from data analysis, evaluation, and research into formats appropriate for relevant stakeholder audiences. Work collaboratively with various and diverse community stakeholders in the implementation and advancement of the Plan and meeting the objectives of the annual Homeward Trust work plan. Develop and maintain strong relationships with stakeholders in the community, government, Indigenous, academic, and private sectors. Work closely with staff, funded agencies, and system stakeholders to develop data systems, policies, processes, and protocols to ensure data collection at the agency level can be used for performance management, outcomes measurement, and system planning. Provide leadership and guidance to Database Administrators and Analysts, ensuring optimal performance of duties and teamwork with departments and stakeholders. Acts as the conduit between a highly specialized technical team, and the management/ executive level. Must be able to communicate information effectively between the two levels. Lead in all reporting – preparing regular activity reports, policy summaries, and implementation monitoring frameworks for relevant committees, including gathering information from relevant stakeholders. Effectively coordinate the gathering of information and build clear and digestible executive reports and dashboards for Homeward Trust Senior Leadership Team, Board of Directors, and funders, providing impactful insights and recommendations. Manage operational budget and liaise with vendors and service providers to ensure the efficient acquisition of data-related technology with ongoing reporting and reviews. Champion the promotion of best practices and bolster data strategy, capacity, and governance in Homeward Trust and the broader community sector, acting as a demonstrated leader both locally and nationally. Facilitate effective mechanisms for internal and external information sharing consistent with the information and privacy legislation, policy, and practice. Prepare responses to information requests, including securing permissions for data release and gathering information from Homeward Trust departments and external stakeholders. Other duties will be assigned, as necessary. Understand the higher-level purpose of Homeward Trust’s work through research and understanding of the organization’s alignment to the initiatives of all levels of government and the Plan. Build strong, trusting, and collaborative relationships with the Director, Planning & Systems Integration, CEO and Senior Leadership Team. Develop and lead a strong team of Database Administrators and Analysts. Develop strong, transparent, and collaborative relationships with stakeholders in the community, government, Indigenous, academic and private sectors. Lead a Review and recommended strategies surrounding research tools required for projects including the bi-annual Homeless Count process. Develop and advocate recommendations for data policy and data collection tool enhancements. Must pass criminal record check including vulnerable sector clearance. Must follow Covid-19 Safety Protocols and Procedures. 
ScrapedJobID679:
Conduct research as required for continuous improvement business use case development and analysis; Assist the team with the development of Key Performance Indicators (KPI)reports, deriving measurements for scorecards, analyzing current practices and targeting areas for improvement; Collaborate with team members in the creation & tracking of business use cases, identifying trends, and recommendations for business efficiency gains; Develop presentations, spreadsheets, and documentation to support team members; Assist in the creation and application of data science tools and techniques that can be applied to decision support in as real time as possible; Assist in documenting department processes across functions, supporting team members in process analysis, rationalization and improvement recommendations; and Apply creative skills to ensure data is transformed into applicable business information. A current student in the Bachelor of Commerce degree program focused in Business Analytics/Science; A student who has completed three years of study and is currently enrolled in a Co-op program at a recognized University; Strong computer skills in Microsoft Office including Word, PowerPoint, SharePoint and Excel; Experience in use of Power BI, Tableau, Python, R and other analytical tools is considered an asset; Exceptional creativity and problem solving skills with ability to see the “Big Picture”, supporting integration and cross functional work efforts; Effective communication and interpersonal skills to interface with team members and customers to promote positive customer outcomes; Strong analytical and problem solving abilities in serving a wide variety of functions; and Strong financial, organizational, time management, written communication skills. 
ScrapedJobID680:
Clearly communicate project statuses with leaders and project teams Engage in quality assurance processes to create a high standard of accuracy Ensure exception and error handling techniques are used Use understanding of business rules to enhance logic used in reporting and analysis Seek out new technology and processes to improve team ability and reach Verbally and visually present reporting and analysis findings to leaders and stakeholders of various levels Submit work for quality assurance with a low number of errors Prioritize multiple projects within own work stream to deliver with little impact to timelines Manage relationships with data source providers for issues and support Consistently incorporate reconciliation in published reports and datasets Prove or disprove relationships between variables (causal) Forecast business measures with confidence and accuracy Assist with development planning with other team members Take on and seek out opportunities to mentor and coach Champion best practices in quality and reliability Over 8 years relevant industry experience within a telecom, client services or technology environment Undergraduate degree in a field linked to data engineering, business analytics, applied mathematics, computer science, IT, computer applications, or related field Ability to create reporting and analysis solutions that are delivered within scope, expected timelines and of high quality Demonstrated solid critical thinking and problem-solving skills Expert ability to identify issues and make difficult decisions, knowing when to escalate when required Strong ability to develop strategic relationships across the organization in a collaborative and foster trust from others Committed to personal and team excellence and ability to operate in a dynamic and constantly changing environment 
ScrapedJobID681:
Collaborating with key stakeholders to understand the data landscape, business process value streams in the context of the evolution, transformation of Lead-to-Cash systems Translating business problems into concrete data analyses, models, migration scope, sequence, requirements. Creating artifacts like data mapping, lineage, dependency and data inventory; contributing to data dictionary and catalogue. Upholding data principles and standards and contributing to a good data governance Contributing to data security, classification, and compliance (SOX, GDPR…) Working with a team of developers, tech leads in building, testing, reconciling and implementing data transformations. Analyzing data in current systems, building procedures for data cleansing, and reconciliation. Supporting Architectural Principles and NFRs related to data accuracy, scalability, traceability, reusability, reliability, security(PII) and simplicity Collaborating with Project Managers to plan, identify risk factors and regularly communicate progress. Influencing decision regarding Data tools, technology, approaches Background in participating in successful, complex data projects, including migrations, in the context of M&A and Digital Transformation Strong business acumen and ability to translate business needs into data requirements Strong expertise in data analysis and data profiling Ability to communicate with Product Managers, Business Stakeholders, Developers Experience in data models and data flows of leading SaaS Lead-to-Cash systems like Salesforce, Netsuite, Hubspot, Zuora, Workday etc Excellent data analysis, mapping skills. Advanced SQL skills. (Asset: Experience with BigQuery and GCP) Strong experience in SQL/Python scripting (Nice to have: Exposure to iPaaS solutions like Mulesoft, API, message queues, event driven integration) Experience in SDLC including Agile, CI/CD, Cloud environments (AWS, GCP) Good knowledge of data management, data integration, data quality and database development techniques Ability to apply Data Governance principles (Lineage, Quality, Metadata) Strong analytical and problem-solving skills. Ability to stay positive and motivated while under pressure. Bachelor degree in Business Technology Management, Finance, Statistics, Mathematics or any other related fields Opportunity to learn and expand your skill set in data and technology, forge wonderful relationships and make your mark within the diverse and inclusive Lightspeed family, a true Canadian tech success story Join a recently created data team and help us move to the next level Amazing benefits & perks, including equity for all Lightspeeders Constant development of both your data skill-set and business acumen with limitless growth opportunities Lightspeed share scheme (we are all owners) Unlimited Paid Time Off Policy Comprehensive Medical, Dental, and Life Insurance RRSP Contribution $500 Health & Wellness Credit Paid leave and assistance for new parents Mental Health Online Platform, and counselling & coaching services LinkedIn Learning License 
ScrapedJobID682:
BS/MS Degree in Data Science, Engineering, Computer Science or similar. 5+ years proven experience in Project Leadership of cross functional initiatives. 5+ years experience in Data Infrastructure / Data Science / Cloud Environment Fluent and current on analytics tools and data architecture trends with an eye on market/technical conditions and future direction. Project management experience of data in cloud environments (AWS experience an asset) Verbal and written communication skills with the ability to present and sell solutions/concepts to other architects and to business users and stakeholders. Data project project implementation experiences that involve both on-prem, cloud, and edge computing. Pharmaceutical, manufacturing, and/or GXP compliance industry data experience preferred. Experience in a professional services / consulting firm or role is an asset. Strong Project Management understanding. Technology and data savviness, passionate on scale and interconnectivity while maintaining an innovative and curious mindset Self driven and proactive, comfortable to deliver as a team leader, team member and individual contributor Ability to effectively communicate and influence others across ALL levels of the organization in order to drive transformational change Financial and Business Acumen including business case development Knowledge of: SCRUM, Agile Methodologies, Change Management, Project Management. Proficient in authoring, editing and presenting both business and technical documents. Ability to elicit requirements and communicate clearly with non-technical individuals, development teams, and other ancillary project members. Excellent problem-solving skills. Mobility: Ability to travel up to 10% 
ScrapedJobID683:
Understands and translates business and functional needs into machine learning problem statements Translates complex machine learning problem statements into specific deliverables and requirements Designs and develops scalable solutions that leverage machine learning and deep learning models to meet enterprise requirements Works closely with data scientists and data engineers to develop machine learning algorithms Works closely with UX designers and product teams to improve the product user experience Translates machine learning algorithms into production-level code Collaborates with development teams to test and deploy machine learning models Creates metrics to continuously evaluate the performance of machine learning solutions Maintains and improves the performance of existing machine learning solutions Ensures adherence to performance standards and compliance to data security requirements Keeps abreast with new tools, algorithms and techniques in machine learning and works to implement them in the organization Proficiency in machine learning algorithms such as multi-class classifications, decision trees, support vector machines and deep learning Strong understanding of probability and statistical models (generative and descriptive models) Advanced programming skills with C/C++, Python, Java or R Ability to run experiments scientifically and analyze results Ability to effectively communicate technical concepts and results to technical and business audiences in a comprehensive manner Ability to collaborate effectively across multiple teams and stakeholders, including analytics teams, development teams, product management and operations More than two years of experience in developing and deploying enterprise-scale machine learning solutions. Experience training and deploying models using cloud-based infrastructure. Experience with Microsoft Azure Cognitive Services is desirable. Experience with microservices architecture, Docker and Kubernetes is desirable Bachelor's degree in data science, applied mathematics, computer science or otherwise research-based field; Master’s degree preferred 
ScrapedJobID684:
Synthesize business needs and create business/functional design documents which can be used to build analysis and data models Client-facing skills which will include providing quantitative analyses, recommendations and presentations to clients Assess data for validity and work on required data preparation with attention to detail and alignment to business requirements Translate data into analytical outputs that enables our clients to answer fundamental questions that are central to their business success. Develops, implements, and supports methodologies, standards, and tools for analysis and data science work. Partners with insights and analysis team leads from the Digital Intelligence team as well as Digital Marketing team within Cardinal Path to help deliver quality insights as required Build cooperative, productive relationships with clients and vendors by utilizing excellent communication skills, while also interacting effectively internally and externally. Participation and development of data science and analytic products while identifying key areas for improvement of products and services. Research, prototype, and explore future, non-standard analytics approaches that push the limits of current analysis output. Bachelor’s degree in a technical field of study (Applied Statistics, Business Analytics, Operations Research, Computer Science, or relevant quantitative field) with a minimum of 3 years’ experience as an Analyst / Data Scientist or a Master’s degree with a minimum of 2 years’ experience as an Analyst / Data Scientist Proficiency with classical statistical modelling methods and machine learning techniques to solve complex business problems Strong Python skills for model design and development Proficiency with SQL and an experience working with cloud environments Experience visualizing and presenting data and analytics findings Self-motivation, creativity and ability to work independently in meeting deadlines Exceptional written and verbal communication skills and is comfortable working with remote teams Understanding of performance marketing metrics and channels Previous experience with web analytics tools such as Adobe Marketing Cloud, Google Analytics, etc. Previous experience with marketing and media analytics including database marketing techniques, digital attribution and media mix modelling Familiarity with analyzing data for digital marketing and ecommerce, as well as all other non-digital aspects of a business 
ScrapedJobID685:
Data Management Study Point of Contact (DMSPoC) To provide end to end data management services and project management of studies Single point of contact for project for a portfolio of clinical trials that are part of a clinical trial program (e.g., covid trials) Attend meetings with project clinical study team and track – progress across study portfolio, proactively identify risks and plan mitigations, trends for data management services Manage a data management team at project comprising of project study lead data manager (SLDMs), data reviewers and programmers Accountable to manage and deliver project slas for the portfolio of studies Attend meetings with project study lead data manager (SLDM), provide inputs, for documents and activities during setup phase of the study Reviews project plan for study during various stages and provides guidance to SLDMs to track activities against the project plan Provide necessary guidance to SLDMs on resource estimation for the study and ensuring right resources are available for the study based on requirement Provide intervention if needed with off-shore team Program management of studies managed by project SLDM Risk identification and mitigation for any deliverables along with close out of studies Ensure compliance to sops and trainings Point of contact for oversight data manager Bachelor’s degree or higher, ideally in a life sciences subject Data management experience – minimum 5 yrs Must have exposure to end to end data management activities across all the three phases of setup/conduct and close out Excellent communication skills and stakeholder management Fluent with ich gcp & cdisc requirements People management experience will be added advantage Veeva experience and exposure to oncology trials will be preferred Data management experience – minimum 5 yrs, Project management experience – minimum 2 yrs People management experience – minimum 1 yr Monday to Friday Temporarily due to COVID-19 
ScrapedJobID686:
Completion of PhD in an area related to computer vision, signal processing, or machine learning Postdoctoral experience in computer vision, signal processing or machine learning Demonstrated ability to thrive in a multidisciplinary research environment Fluent in written and spoken English and demonstrated excellence in scientific writing Demonstrated exceptional analytical, communication and visualization skills A cover letter expressing your long-term research vision and career goals, and detailing how you are a good fit for the position; A CV; The contact information (full address, email and phone number) for three references. 
ScrapedJobID687:
Enable bringing analytics to the airline and airport baggage industry Work internally and externally to model and analyze our customers data to provide easy-to-understand metrics Build automation for data capture from disparate systems for import into a data lake Develop visualizations in Power BI Be an expert in everything Power BI related Passion for Data Science Previous experience with Microsoft Power Bi or a similar tool Excellent teamwork skills Proven ability to work with cross-functional teams Excellent written and verbal communication skills College diploma or University Degree in a relevant field of study Knowledgeable in Microsoft SQL Server and Azure DAX/R/Python and other scripting languages familiarity Microsoft Power Platform and JNet knowledge an asset 
ScrapedJobID688:
Access to a wealth of global experience, resources and healthcare data from which to draw on to build innovative solutions Motivated, insightful colleagues who have a solid grounding in all aspects of the pharmaceutical and healthcare industries Ownership and responsibility for delivering product, company and market analyses to Canadian-focused client stakeholders that will shape recommendations to our multinational pharmaceutical clients and other healthcare stakeholders A learning environment, with structured access to global experts and leaders in analytic methods designed for life sciences An entrepreneurial environment providing significant growth opportunities Access to IQVIA’s senior leadership who will mentor and guide you on your career goals and personal objectives A supportive and friendly environment focused on client, business and individual success Takes lead role in proposal development to ensure actionable, on-target and timely proposals are provided to clients. Primary owner of client engagements with ultimate responsibility for client satisfaction and delivering high levels of quality/added value. Manages client interface and project team to achieve efficient and effective project delivery. Serves as a solutions-based expert, internally and externally, by applying consultative problem-solving skills. Plays a significant role in cross-functional account planning and strategy with IQVIA’s Account Teams, IQVIA Technologies and our Real World Solutions experts. Meets or exceeds assigned revenue targets by developing and delivering insightful, value-added solutions that align to client priorities and strategic needs. Responsible for significant and tangible client impact from all engagements. Seeks out and identifies new revenue opportunities at existing and potential clients – ensuring a continuous flow of business from client engagements. Identifies issues of importance to the industry and works with Centre of Excellence (CoE) and Geographic Leaders to develop actionable commercial offerings. Maintains in-depth and current knowledge of client’s strategies, business issues and relationships with client’s senior management. Remains current on industry, client and competitive trends and directions in order to anticipate and identify new business challenges and issues at clients. Contributes to the enhanced awareness of IQVIA’s Human Data Science capabilities in the Canadian marketplace, e.g. through speaking engagements, client meetings, publications etc. Proactively continues to strengthen subject matter expertise through on the job experience, participation in conferences and symposiums and other forums for professional knowledge sharing. Assumes people-management responsibilities for junior team members. Proactively mentors, coaches, and shares subject matter expertise with others to elevate our capabilities to deliver world-class solutions for clients. Participates in recruiting, onboarding, and training project managers. Collaborates with other Principals and the Executive on shaping organizational culture and creating an environment which supports career progression for all members of the team. At least 10 years of experience in the pharmaceutical or consulting industry, with Master’s degree preferred. In depth and long-standing relationships with client companies, especially at a senior level. Deep expertise in one of the Consulting team’s areas of expertise, but demonstrates the ability and knowledge to work across multiple areas of expertise. Demonstrated experience in leading cross-functional teams in the execution of projects of significant size and scope. Possesses exemplary business development skills. Has broad knowledge of the pharmaceutical industry. In-depth understanding of client and IQVIA data assets and core offerings. Works effectively with others in and across the organization to accomplish team goals. Knowledge of consulting methods, tools and techniques. Knowledge and understanding of the marketplace and professional/trade associations key people and companies. Demonstrated strategic thinking, planning and change management skills. Excellent interpersonal and networking skills. Values people’s opinions and encourages knowledge sharing. High level of energy, drive and enthusiasm. Able to manage complex relationships and juggle priorities. Ability to sell profitable consulting engagements. Demonstrates strong client relationship and influencing skills. Functional area expertise is required, with core areas including the following:
Commercial model design
Customer Segmentation/Targeting, Sales Force Sizing (including Call Planning), Territory Alignment, Channel Management
Market Assessments, defining drivers of success, product potential, and forecasting
Patient-level analytics to support Lines of Therapy, Adherence and Compliance studies
Primary market research to support brand launch and/or to track brand performance
Omnichannel go-to-market strategies and models Commercial model design Customer Segmentation/Targeting, Sales Force Sizing (including Call Planning), Territory Alignment, Channel Management Market Assessments, defining drivers of success, product potential, and forecasting Patient-level analytics to support Lines of Therapy, Adherence and Compliance studies Primary market research to support brand launch and/or to track brand performance Omnichannel go-to-market strategies and models 
ScrapedJobID689:
to be located in Toronto or Waterloo Offices Use your creativity and curiosity to develop and deploy new analytical tools to help the business in their decision-making Uncover issues and trouble shoot existing tools and data processes, discover the fix and bring the solution to the team Learn our current tools and run reports to be visualized for leaders. Help leaders understand the story behind the numbers Apply data science methodologies to improve the consistency and accuracy of data Requests for more or different information, leading to report development, data checking and visual presentation of the requests Work collaboratively within your team to achieve the best results, communicate and share insights and best practices University degree in computer science, software engineering, data science, statistics, or a related discipline 1-3 years of professional work experience in a data analysis-related position Strong communication (verbal/written) and organizational skills Highly analytical, demonstrated ability to develop creative solutions to complex problems Strong proficiency in using the R programming language for data wrangling and analysis (knowledge of Python also an asset) Strong programming skills and efficient use of Microsoft applications (e.g., Excel, Access, VBA) Knowledge of SAS & SharePoint is an asset Competitive salaries Flexible work schedules Bright, open workspaces and smart casual dress code Three national employee resource groups focused on inclusion and the experience of immigrants to Canada, the LGBTQ+ community, and women in leadership Onsite health and wellness programs Spirit days and a company-wide social committee enhance our employee experience Annual Economical Appreciation Week features team events and fun surprises 
ScrapedJobID690:
Monday to Friday Yes 
ScrapedJobID691:

ScrapedJobID692:
You will be responsible for extracting and analysing data from our various data sources, drawing actionable insights to enable decision making Applying a mix of qualitative and quantitative analysis techniques you will produce insights that help us improve the customer experience of our products, which include regulated medical devices You will own your research findings and present them to major stakeholders and key decision makers ensuring you deliver a clear message that product, safety, and other relevant teams can act upon Inspecting and measuring customer experience performance and taking relevant actions Discuss with all stakeholders their on-site tracking and reporting needs. Create reports based on stakeholder requirements and automate processes wherever possible Liaise with the Customer Experience and Medical Safety Teams to ensure all customer issues are captured, analysed, and triaged for action Provide regularly customer insights to the wider Marketing team Improve analytical tools/technologies to facilitate a world-class customer experience Identify and recommend new 3rd party tools to integrate with the core architecture Working experience in UX/UI analysis with previous experience across products, verticals or brands Technical skills and ability to get, clean up, crunch and visualise data. Experience with SQL, Python and Tableau (or other BI tools) is a big advantage. Good understanding of the customer life cycle, customer satisfaction metrics and how to develop customer performance across the organisation Top analytical skills — you approach data with the right questions, recognising trends Excellent presentation skills — comfortable presenting to a broad audience of stakeholders and confident to defend your findings in a discussion Ideal but not essential, a graduate in a quantitative/social science subject or similar Ideally some experience working within the healthtech, SaMD, or wider healthcare sector Self-starter, energetic, enthusiastic, take the initiative and work independently but also to socialise ideas and develop collaborative solutions. 
ScrapedJobID693:
Act as an HXM system administrator, advisor, subject matter expert and technical mentor for the PnC team and other Admin Users. Identify areas to improve systems processes, functionality and workflow while maximizing technological capabilities to reduce manual processes and create more effective use of the HXM and other PnC systems Provide technical insights, advice, and analysis on any PnC systems or software evaluations, reviewing vendor options, features, and modules and making recommendations on the best solutions Manage the implementation of new PnC systems and technologies, including documentation of current / future – state processes, coordination of stakeholders and tasks, data mining, testing and training, and other related project activities Facilitate a strong partnership between People and Culture and system user communities to increase usage and self-service, including leading training and education sessions or creating content for systems course development Respond to employee inquires/questions with a 'service-first' mindset Conduct business analysis to define, design, document, test, and deploy features that propose viable solutions or improved processes to achieve current state requirements as well as the ability to scale for future requirements Anticipates clients long term needs by establishing a clear sense of their organizational and business unit strategies. Delivers and provides additional information beyond client expectations. Provide data analysis, offer insights and identify trends to the business, including the senior leadership team Provide oversight on data governance, including systems and dashboard architecture and maintenance Build custom reporting and dashboards to respond to People and Culture team and business requests Accountable for high level of data integrity, auditing, and enforcing data validation processes within the HXM Design, map out and document new workflows and business processes with a 'Better, Smarter, Faster' mentality Manage upcoming system releases, testing and reviewing for possible issues and correcting any negative impacts Compile weekly/monthly/quarterly reporting packages and dashboards Manage time away from work balance and liability reporting Help project manage PnC's Employment Equity initiative and manage employee data collection in HXM, equity reports, and support any related Diversity & Inclusion activities and reporting analysis needs Communicates a clear vision for project initiatives and helps to translate vision into specific actions. Actively employs critical thinking towards anticipating trends in the external and internal environment by developing proactive plans to address or prevent future factors. Assist with regular operational reporting Document and maintain various processes Manage ad hoc People and Culture projects as requested 5-7 years of relevant experience working in a fast-paced, high-tech environment Experience administering and configuring an HRIS/HXM Experience with SharePoint, PowerBI (or Dashboard software), SQL and XML preferred Experience implementing an HXM an asset Advanced knowledge of Excel and proven ability to work with other MS Office tools Understands relational database concepts and can query and transform data dynamically using complex queries and scripting Strong analytical and problem-solving skills with an aptitude for working with data Excellent attention to detail; understands the importance of data integrity Excellent communication skills and ability to collaborate with and influence key stakeholder groups Proven ability to identify process efficiencies and drive continuous improvement initiatives Strength in organizing and coordinating multiple activities and projects at one time, while effectively managing disruptions and changing priorities Ability to independently exercise decision making authority over technical tasks and recommend system functionality to meet business requirements. Business acumen and curiosity Self-starter with proven initiative and a collaborative approach Flexible work hours Health and wellness programs Collaborative work environment Dog friendly office Snacks and food trays! Foosball and Ping-Pong tables Showers on site Centrally located in downtown, close to restaurants and pubs, easily accessible by public transit 
ScrapedJobID694:
Awesome work-from-home policy with quarterly in-person meetings around the world Competitive salaries for quick-learners and fast-paced individuals You will have the ability to gain career experience beyond strict job requirements, with decision-making power to be the master of your own projects Resources for self-improvement including courses, software, workshops, and conferences We are committed to hiring great people from diverse backgrounds, not just because it’s the right thing to do, but because it makes our company stronger Develop Reinforcement Learning algorithms to provide safe and efficient train operations Design and build environments to simulate realistic rail operations that perform with high accuracy to live environments Productize machine learning algorithms to operate in a production environment Communicate with a team of front-end and back-end developers to integrate solutions via APIs Determine methodology for using current software in an ATO setting Drive continuous product development and contribute to direction of technological development Maintain a high-level of communication between managers and development team Conduct formal presentations to other team members, managers, and in public Contribute to various aspects of a growing company Be an ambassador of technological advancement and revolutionized transportation Grow personal connections to the industry to understand trends and opportunities Proven experience delivering machine learning algorithms in an operational setting At least 3 years of relevant work experience (Preferred) Master’s degree in Machine Learning, Computer Science, Engineering or related (Bonus) Experience in the rail industry (Double Bonus) Experience in Autonomous Train Operations Strong working knowledge of statistical techniques (distributions, regressions, error bounds, etc.) Experience with Python, ML libraries such as Keras, TensorFlow, PyTorch, pandas, and more… Experience with git version control, agile methodology, MS 365, and other common software tools Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and common CS algorithms Professional communication abilities in English Driven, self-motivated, and detail-focused individuals Clear and concise communicators Passion for career growth and continuous learning Organized in work habits, schedules, timelines, documentation and correspondence Remote work with quarterly in-person meetings (location is voted on every quarter) Incentives offered such as Employee Stock Options and yearly bonuses 
ScrapedJobID695:
This is an on-site position - not remote. Work from home as appropriate. Bachelor’s in computer science or equivalent 5 years’ software development experience 2+ years' experience running medium to large/complex projects with multiple internal / external dependencies Expertise in working with at least one deep learning framework, such as PyTorch, TensorFlow, Caffe Experienced in working with ETL pipelines Experienced in cloud providers such as GCP or AWS Strong analytical and problem solving skills Ability to understand and execute on the company’s mission and values Maintain a high degree of ethical standard and trustworthiness Strong technical written and oral communication skills 7+ years’ software development experience Proficient in Python A track record for delivering Machine Learning projects for a product Excellent written and verbal communication skills Strong and proactive communication, natural curiosity. Ambition to apply skills to a wide variety of fields Be able and open to pick up new skills, work with 3rd party technologies and devices 
ScrapedJobID696:
Writing SQL to clean, transform, investigate, and augment large, complex database tables Working closely with business partners to make sure our business strategy is as data driven as possible Designing rich data visualizations to communicate complex ideas to customers or company leaders Ensure data and intent integrity by automated data quality verification pipelines Supporting and consulting with the business to propagate data management best practices Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, and you’re not afraid to blurt out your disruptive idea. You know SQL and are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. A Wrangler: You know how to programmatically extract data from a database or an API, bring it through a transformation or two, and convert into a human-readable form (Matplotlib, QuickSight, Tableau, etc.). Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook With Manager approval, you can travel to a conference of your choice annually (senior+) - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours and casual environment At least 1 year of experience with relational databases and programming in SQL At least 1 year of experience with version control systems like GitHub. Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) At least 1 year of experience in open source programming languages for large scale data analysis (Python or Scala) 
ScrapedJobID697:
A team player who can work within an integrated team of product managers, designers, and developers. Expert critical thinking and problem-solving skills with a keen eye to apply machine learning solutions to solve interesting customer problems. Effectively translate requirements into feasible machine learning solutions. Develop, drive, and execute the long-term vision and strategy for content understanding and machine learning platforms. Ensure the development of consistent high quality data products. Standardize data quality measurements by establishing metrics, building tools and processes. Work with external vendors and aid build vs buy decisions. Work closely with data privacy and data security teams at Medchart to help guide the data privacy policies and comply with data protection regulations. Research state-of-the-art methods in language modelling and related natural language. processing problems, data extraction, and other machine learning problems. Prototype novel methods and productionize promising methods. Build Medchart’s machine learning pipeline. Live our company values of humble, hungry, and care BS, MS or Ph.D. in Computer Science or related field 3+ years of professional or academic experience in machine learning 5+ years of experience building clean, maintainable, and well-tested code. You are adept at machine learning algorithms. Proven ability to apply, debug, and develop machine learning models for real-world applications (especially NLP) Accomplished problem solver, able to think both creatively and methodically. Able and eager to learn about the latest technologies and ML best practices. Effective communicator who can translate complex technical concepts into simple ideas depending on the audience. Hands-on experience on large scale machine learning systems (full ML stack from modelling to deployment at scale.) Hands-on experience with big data technologies (e.g., Hadoop/Spark). Hands-on experience with medical data. Health and Lifestyle benefit spending accounts Results-oriented work environment Frequent wellness initiatives Currently in a work from home environment with offices in Toronto, Waterloo, and Dallas A positive, diverse, and growth-oriented team environment 
ScrapedJobID698:
Participating in requirements gathering / analysis, and solution documentation of large scale data transformation / feature engineering and loading routines Construction of robust data transformation / feature engineering and loading routines Working collaboratively with the data science team to engineer and integrate features from foundational data that are suitable for solving modelling problems Coming up with and conducting unit and integration test cases for data transformation and loading pipelines Assessing correlations and suitability for modelling of transformed data Curiosity with global regulatory regimes and anonymization frameworks and how they effect analytics and modeling outcomes Investigating and implementing ways to improve data reliability, efficiency, and quality Working creatively to understand, wrangle, and integrate diverse / unstructured data sources Collaborating with stakeholders including the product owners, data science, and design teams to assist with data-related technical issues and support their data infrastructure needs Bachelor’s degree in computer science, engineering, business, finance or a related area of study Upto 5 years experience in a similar role Excellent analytical and problem-solving skills Extreme attention to detail Familiarity with the modelling / analytics process, assessing the usefulness of data within that process Deep knowledge of SQL, “Big data” data pipelines, and architectures Experience with enterprise data modelling and architecture Experience working with big data tools like Apache Spark Experience working with large data sets, data pipeline and workflow management tools, and stream-processing systems Experience with data lineage concepts & related tools Experience with data cleansing, data masking for PII Experience implementing automated data quality validations within ETL pipelines Strong knowledge of Cloud environments (Unix/Windows, Virtualization, Containers, Data Management, CI/CD Management) Background in programming in Python, C, C++, or Java Experience with waterfall and agile methodologies Experience with, or willingness to develop and exercise skills in the areas of enterprise content management, web-based software applications, and application integration Ability to work cross-functionally with IT infrastructure and database administrator teams on project implementations Knowledge of Jira and Confluence Experience with OpenText Magellan Good written and verbal communication skills Able to build a sense of trust and rapport with the team and partners A self-starter attitude, a strong desire to learn as you go, and the belief that you can make a meaningful contribution to your immediate team, the business users that you serve, and to the organization 
ScrapedJobID699:

ScrapedJobID700:
Oversee operation, maintenance and continuous development of corporate reporting systems Conduct business requirements analysis, design and prototyping, and collaborate with consultant on development of modules of the corporate BI platform Effectively promote business acumen and performance management throughout the organization by creating training materials, holding training sessions and change management of new analytics Actively participate in Data Governance Council as administrator of data governance programs, and providing thought-leadership on data governance practices Support Finance department with analytics to support budget forecasting and financial reporting systems, as required Collaborate with Game Data Analytics on shared initiatives Support Executive Producers and game teams with analytical support if required Continuously optimize the company’s BI platform while implementing best practices from across the analytics industry Create detailed presentations for senior executives and partners in Finance to report on trends and events, and inform decision making Ad-hoc analysis and reporting on key business initiatives Bachelor’s degree in Business, Marketing, Computer Science or a related field, complimented by relevant experience in other fields that results in balanced knowledge between technology and business Deep hands-on knowledge and experience with data systems and tools, exhibiting a regimented method of information system development. Experience with Google Cloud Services and Google Big Query is an advantage Experience with analytics tools (such as Tableau, Power BI, etc.); experience with Sisense is an asset Strong proficiency with Microsoft Excel, PowerPoint, Word. Experience with Google Suite is an advantage Strong verbal and written communications skills, ability to create a compelling narrative Strong natural curiosity and ability to dissect problems to root causes Strong UX/UI focus; able to empathize with the end-user and design tools with usability and comprehensibility Ability to gather business requirements, design and develop BI solutions A basic understanding of statistics and data visualization techniques Operational discipline with solid project management and change management skills Experience with people management and influencing cross-functional teams Strong organizational and time management skills Strong attention to detail, especially when it affects end-user behaviour Experience within the video game industry is an asset 
ScrapedJobID701:
Analysis and Data Modelling: Using both the Tableau reporting suite and SQL, model and interpret large volumes of data, identify trends and extract business insights. In addition, assist with documenting data sources, relationships between data entities and methods of calculation and measurement while understanding stakeholder needs. Business Analysis and Requirement Gathering: Liaise between Engineering and various functional departments to create, define and document business requirements, models and functional specifications. Moreover, meet with decision makers, system owners and end users to define operational requirements, system or reporting goals as well as identify and resolve system or reporting issues. Communication: Communicating insights to relevant stakeholders clearly as well as helping other teams with their data related inquiries. Data Visualization: Create, maintain, enhance and automate various dashboards and reports that provide insights into user and operational behaviour. Project Management: Aide Data Engineering Manager with day-to-day project management activities including Kanban/ Jira Board maintenance, roadmap creation and project constraint (scope, time and budget) management. Data-Governing Steward: deploy frameworks and tools guided by data governance principles including: data catalogues, data dictionaries and master data management. Formal training in software engineering, computer science or computer engineering with at least 3 to 5 years of experience working in a Data Analyst capacity Advanced knowledge and experience working with Tableau – ex. Level of Detail, window functions, data blending, parameters, levels of filtering, etc. Experience working with analytical (OLAP, HTAP, etc.) databases (Snowflake, BigQuery, etc.) Command of analytical SQL (ex. Window Functions & Frames, Group Sets, Cubes, Rollups, etc.) Knowledge of Data Governance principles including a proven ability to build and deploy data catalogues, data dictionaries and/ or meta/master data management Established experience with AWS Cloud Services including: EC2, EBS, S3, KMS Key Management, Landing Zone Proficiency with at least two object-oriented/object function scripting languages including Java, Scala and Python Understanding of the SAP ecosystems: SAP ECC, SAP FICO, SAP BW and BPC Comfortable working in a ‘self-serve’ autonomous capacity (i.e. retrieving and modeling your own data when required). Experience gathering stakeholder requirements with a demonstrated ability to get to the bottom of specific business rationale Clear and concise written and verbal communication skills Ability to thrive in fast-paced environment with tight deadlines 
ScrapedJobID702:
Advise on the best technologies and frameworks to monitor performance for the team's and client's needs. Show your analysis through presentations and communication with technical and non-technical people. Develop performance measuring frameworks to track goals, user needs and work with KPIs. Work with marketing software and tools such as Google Analytics, Google Tag Manager, Google Search Console, Adobe Analytics, Hubspot, Salesforce Marketing Cloud, Facebook Ads, Google Ads, and LinkedIn Ads. Oversee the analytics, data layer, and tag management solution for accurate and efficient data capture. Help conceptualize, design, build and automate reports/dashboards that provide insights into client audiences. Manage ongoing audience data and KPI reporting on a weekly/monthly/quarterly basis, delivering insights and recommendations to both business and content teams. Provide data-driven feedback and actionable insights to our content teams regarding content/topic performance onsite & off-platform (social media, blog, video, etc..) As needed, work with developers for tracking needs and implementation 1-3+ years of experience working with or close to marketing data 1-3+ years of experience working directly with Google Analytics data Proven ability to manage, understand, discuss, and work with analytics accounts, goals, properties, dashboards, reports, segments, and custom channel/content groupings Experience using visualization tools, in particular Google Data Studio - expertise in Tableau a bonus Hands-on experience with Google Tag Manager; experience and expertise in web tagging concepts and the ability to lead tagging strategy highly desired A high degree of comfort with Excel and/or Google Sheets spreadsheet concepts A degree in marketing or statistics Entrepreneurial ability to diagnose web data tracking issues and propose solutions Ability to work with a fluid team at a fast pace Interest in statistical programming/query languages (R, Python, SQL) Understanding of data science processes and ability to implement these in an Agile environment Excellent communication skills and ability to simplify advanced statistical concepts for a layman audience Strong understanding of advertising data and advertising concepts HTML, Javascript, and other web development expertise Working knowledge of APIs, data connectors, and other pipelines Experience with UX/testing technologies such as Hotjar, Google Optimize An understanding of SEO and technical SEO concepts, search data CRM and email software marketing data Prior experience with project/workflow management software (we use Asana) 
ScrapedJobID703:
Are you passionate or interested in learning about maritime shipping & logistics? Are you entrepreneurial at heart and want to be a part of a family owned company? Are you a people person who cares for others? Are you a dedicated and committed individual who believes in continuously evolving? Build and manage data warehouse system using best methodology suited for respective business areas Develop tabular and multidimensional models that are compatible with warehouse standards Build high performance data marts and Analysis Services reporting models Develop visual reports, dashboards, and KPIs scorecards using Power BI desktop Connect data sources, importing data and transforming data (ETL) for business intelligence Implement row level security on data and understand application security layer models in Power BI Build DAX and MDX queries in Power BI desktop to support advanced calculations Adapt in development, publishing, and scheduling Power BI reports as per Business requirements Understand business requirements and develop data models accordingly by taking care of the resources Manage assigned projects, develop project plans, monitor performance Design methodology and project documentation Have knowledge and experience in prototyping, designing, and requirement analysis Have knowledge and skills for secondary tools such as Microsoft azure, SQL data warehouse, PolyBase, Visual Studio, PowerShell, PowerApps, Power Automate etc. Integrate PBI reports into other applications using embedded analytics like PBI service (SAAS) or by API automation Bachelor’s degree in computer science or information system and a minimum of 5 years of work experience in a similar field A minimum of 2-4years experience in data preparation, data gateways, and data warehousing projects A minimum of 2-4 years’ experience working/acquaintance with Microsoft Business Intelligence Stack having Power BI, SSAS, SSRS, SSIS A minimum of 2-4 years’ experience with Structured Query Language (SQL) Excellent listening, communication, interpersonal, and presentation skills Excellent analytical, critical, and problem-solving skills Familiarity and experience with PowerShell, JavaScript, CSS, and other Java script library Team player with professional attitude Experience in advanced analytics and data science using Python and R is an asset Experience with other BI tools (Tableau, Qlik, Oracle BI, IBM Cognos, Crystal Report etc.) is an asset Shipping experience is an asset 100% health and dental benefits coverage RRSP coverage with MSC Canada matching a portion of employee contribution Tailored training program opportunities for employee development Employee mentorship, leadership and assistance opportunities An employee referral incentive program Community Involvement Gym facility Health & Wellness Program 
ScrapedJobID704:
Partner with the Business Lead to develop and promote the DMA research services and innovation capabilities to support business development activities with established and prospective academic and industry partners; encourage and facilitate industry interactions, including research engagements. Promote engagement of services provincially, nationally, and internationally across the bioscience community with institutional partners, collaborators, and external clients. Lead the Data Management and Analytic team by managing the employee career cycle through activities such as: recruitment, retention and separations, orientation, and onboarding, coaching and performance feedback, supporting professional growth, training, and development, managing performance, and addressing disciplinary matters. Manage the implementation of programs, activities, and systems to support the delivery of optimal services to both internal and external researchers, partner organizations, collaborators, and clients. Define and implement consistent data capture, management and access policies across GIFS and subsidiary programs and platforms (e.g., OPAL, Engineering Biology, Cell Biology, Plant Growth Facilities) to ensure long-term stewardship and data integration and enable data analytics and data repurposing across GIFS. Define and implement Machine Learning to accelerate the Design-Build-Test- and Learn cycle at GIFS. Define and implement consistent data capture, management and access policies across programs GIFS leads such as P2RIC, CERC and Bangladesh. Define the opportunity and establish cloud-computing resources to support computational needs for GIFS data analytic pipelines. Exploit economies of scale in hardware acquisitions, software licensing, and systems administration by consolidating data and computational resources across GIFS. Create, optimize, and manage workflows to meet internal and external requests, focusing on high-quality, high throughput. As the subject matter expert in bioinformatics lead the interdisciplinary application of information technology tools for collecting, analyzing, storing, and visualizing biological data applied to agriculture. Lead by example with a commitment to continuous improvement and GIFS values. Establish and manage lab processes, including but not limited to, electronic lab notebook, data and metadata management, data analytics and large-scale data warehousing infrastructure such as a laboratory-information-management-system. Negotiate and monitor fee for service agreements in partnership with the GIFS Business Development Office. Work with the Business Development team in identifying funding opportunities; provide technical review and support for developing co-funding for industry-sponsored research, grant submissions and funding opportunities to support the growth of the Platform and GIFS. Collect, analyze, and synthesize data related to overall performance. Facilitate communication among clients, the research community, and key stakeholders. Identify strategic alliance partners and develop long-term, sustainable relationships. Foster and promote a culture of innovation by dedicating time for innovation within the platform. Participate in the Scientific Executive Committee (SEC) and help in defining, supporting, and implementing scientific and strategic direction for the Institute. Other accountabilities as assigned. Minimum of five (5) years of hands-on experience in bioinformatics and machine learning applied to next-generation sequencing data, engineering biology and cloud computing. Minimum three (3) years of experience in the technical management of operations in a life sciences laboratory. Experience in using advanced genomic, computational and/or data science approaches to study biological phenomena in a range of eukaryotic organisms. Research leadership in areas at the intersection of genome biology, computational biology, biostatistics, data management and cloud computing will be prioritized. Experience with project management, product development, and/or innovation projects, ideally in the ag biotechnology ecosystem. Experience leading and developing teams. Experience with research funding models and processes. Industry-focused business development and/or marketing experience along with a strong understanding of both academic and industry environments is highly desired. Demonstrated experience and skill in building relationships with diverse constituencies and negotiating commercial agreements. The ideal candidate will have direct experience in the bridging research to industry and the ability to bring the results of scientific research to the marketplace. Innovative problem solver capable of overcoming challenging and complex issues in a fast-paced environment and growing market. Excellent oral and written communications skills, including the ability to convey complex technical ideas to non-specialist audiences. Ability to manage multiple projects simultaneously and work effectively within a high achieving team environment. Sound judgment, discretion, diplomacy, and professional integrity. Excellent interpersonal skills with the ability to establish and maintain professional relationships that support exceptional collaboration. Ability to gather, analyze, and present information with attention to detail. Ability to work effectively in a diverse working environment. 
ScrapedJobID705:
Proven track record in the research, data science and engineering around building and shipping machine learning or statistical models that scale to high volumes of data (billions of data points) Excellent grasp of Python and advanced SQL Excellent knowledge of MLOps processes and tooling for moving models from training to production and debugging complex systems Strong understanding of modern machine learning techniques and their mathematical concepts Experience with sklearn, SparkML, pandas, NumPy or similar packages Experience with deep learning packages, including Tensorflow, PyTorch, or Keras Working knowledge of large-scale distributed systems and related technologies such as Spark, Elasticsearch, Kubernetes etc. Familiarity with cloud platforms (we use AWS here) and automation technologies (e.g., Kubernetes, Jenkins, Chef, etc.) is a plus Knowledge of GNN, RL, Recommender Systems and NLP techniques including embeddings, transfer learning, attention mechanisms is a plus Familiarity with the information/cyber security domain is a plus Work closely with engineering and product teams to scientifically frame the business problems and come up with the underlying mathematical models Perform exploratory data analysis to gain deeper understanding of the data Develop tools and algorithms for generating synthetic data sets Develop and test statistical and machine learning models for efficacy and operational impact Write production quality code and work with other software engineering teams to deploy models into production Support deployed models as a subject matter expert Be creative and engineer novel features and methods to push beyond our current capabilities Equity for all employees Paid paternity and maternity leave Training and career development programs 
ScrapedJobID706:
Degree or Diploma in Computer Science, Software Engineering, Computational Statistics or equivalent degree or experience. MS or PHD in Computer Science, specializing in Machine Learning is desirable. Minimum 3 years of relevant experience with statistical computing in R or Python. (Experience with modern R packages and technologies such as dplyr, tidyR, data.table, shinyR preferred). Minimum 3 years of experience with Machine Learning algorithms and Probabilistic Modelling. Strong background in statistics, preferably Bayesian Statistics — experience with Bayesian Inference using Statistical Languages for MCMC such as Stan, JAGS, WinBugs is a big plus. Experience with SQL and SQL Server. Experience with .NET Framework and C# is preferable. Experience using cloud computing platforms such as EC2 (AWS). Domain experience in on-line gaming and entertainment industry, Financial Markets (such as Stock Exchange, Options, Bonds, Forex, etc.), or other types of 2-sided markets. Experience with Neural Networks or Deep Learning on large problems – a plus. Experience with Hadoop, Map Reduce or High Performance Computing – a plus. An environment passionate about growth and learning Competitive salary with bonus Fitness subsidy program Free beverages in the office Workplace that is conveniently located along the Yonge/Sheppard line 
ScrapedJobID707:
Machine learning et statistiques : élaboration de modèles explicatifs et prédictifs d'aide à la décision (algorithmes d'apprentissage supervisé et non supervisé, économétrie, prévision, diagnostic quantitatif, ...) Recherche opérationnelle : assistance à la conception et à la mise en oeuvre de solutions d'optimisation sous contraintes et de modèles de simulation Big Data : connaissances algorithmiques pour le traitement de grand volume de données et non structurées Le développement ou le renforcement de nos offres au travers de formations, de groupes de travail, de diffusion de support internes et externes... La politique de publication (blogs sectoriels, études, parution presse...) Le développement commercial en contribuant à la définition des besoins et en participant aux actions commerciales. Toute personne âgée de plus de 18 ans et de moins de 28 ans à la date d’inscription peut prétendre à un Volontariat International. Le départ en mission s’effectue au plus tard le jour de votre 29ème anniversaire. Au-delà, aucune dérogation n’est accordée. Vous devez être de nationalité française ou européenne (ressortissant des Etats membres de l'Espace Economique Européen qui regroupe les 27 Etats membres de l’Union européenne, la Norvège, l'Islande, le Lichtenstein) ou monégasque. Vous devez être en règle avec les obligations de service national du pays dont vous êtes ressortissant. Vous devez jouir de vos droits civiques et justifier d’un casier judiciaire vierge. 
ScrapedJobID708:
Work within and coordinate with a small team to analyze, implement, and optimize DirectML-TensorFlow and PyTorch for machine learning models. Collaborate with ISV, library, compiler, driver, and hardware engineers to influence strategic decisions to achieve the highest performance for DirectML. Innovate new algorithmic improvements that exploits the strengths of the hardware architecture to deliver the best possible machine learning performance. 4+ years of relevant experience in Machine Learning and/or GPU programming Experience in deep learning frameworks (e.g. TensorFlow, Keras, PyTorch, Caffe, ONNX, etc) and familiarity with CNN/LSTM model architectures Knowledge of CPU and GPU architecture and experience in GPGPU programming technologies Experience advocating for technical solutions in a collaborative team environment Excellent communication and collaboration skills Experience with writing GPU shaders (CUDA, OpenCL, HLSL) is a plus Experience with DirectML APIs (or other backend high performance compute libraries) is a plus Experience with Direct3D is a plus PhD/MS in Computer Science or related disciplines 
ScrapedJobID709:
Apply software engineering techniques to the creation of prototypes and reliable and high-performance tools for game development teams. Work closely with product teams to create complete packages that meet production quality criteria (robustness, documentation, completeness, and performance). Develop and maintain frameworks, libraries, and development tools to facilitate the use of machine learning tools in production. Provide support to production team members by communicating the capabilities and limitations of their products. Contribute to efforts to promote machine learning techniques throughout the company by creating training content and participating in outreach initiatives. Identify opportunities to improve products and make them sustainable. A degree in computer science or software engineering (or related training) At least 3 years of experience in software development or other relevant experience Excellent knowledge of Python programming language Excellent knowledge of machine learning concepts and practices Excellent knowledge of at least one machine learning framework (such as TensorFlow or PyTorch) Good knowledge of big data development and NoSQL and SQL data modeling Good knowledge of data transportation, transformation, storage, and integrity concepts and practices Experience with Git Knowledge of data pipeline alerting and monitoring systems Knowledge of public Cloud services (AWS, Azure, GCP) Knowledge of Docker and Kubernetes considered Your CV, highlighting your background, experience, and skills. 
ScrapedJobID710:
Play an integral role in our delivery practice as we execute on enterprise level client engagements through our various industry specializations Engage directly with clients and drive the implementation and successful end user experience of analytics solutions; execute on engagements and collaborate with the client and delivery team to ensure that any applicable milestones and deliverables are met on time and on budget Design and develop industry-specific data models for client projects in industries such as Natural Resources, Finance, Manufacturing and Distribution, and Retail Work with other engineers to enhance data models and improve data query efficiency; create complex data queries to facilitate ad hoc and exploratory analytics Build real-time data capture and transformation functionality across all products and build out technology stack for Business Intelligence and Data Warehouse Clean data: review for data inconsistencies and identify opportunities to improve data collection process; Wrangle/Munge data: transform or map data from one raw data form into another format with the intent of making it more appropriate and valuable for analytics Develop, construct, test and maintain architectures such as databases and large-scale data processing systems; design, construct, install, test and maintain highly scalable data management systems Employ a variety of languages and tools (e.g. scripting languages) to marry systems together Build or recommend data visualization tools and business intelligence tools such as interactive dashboards and automated reports, to enable leaders to make swift, fact-based decisions Remain up to date of development technologies, both current and future in order to deliver state-of-the-art Analytics solutions for our customers You demonstrate BDO's core values through all aspect of your work: Integrity, Respect and Collaboration You understand your client’s industry, challenges, and opportunities; client describe you as positive, professional, and delivering high quality work You identify, recommend, and are focused on effective service delivery to your clients You share in an inclusive and engaging work environment that develops, retains & attracts talent You actively participate in the adoption of digital tools and strategies to drive an innovative workplace You grow your expertise through learning and professional development. Post-secondary education in engineering or computer science or equivalent work experience Good experience working with Azure Databricks, Azure Data Factory and Azure Data Lake Strong attention to the quality of work delivered (attention to detail) Able to adapt quickly to changing client requirements Experience with the Microsoft SQL Server Analytics stack including: Core SQL, SSIS, SSRS, SSAS, Programming experience in Python Experience working with SQL and NoSQL databases Knowledge of Continuous Integration and Source Control systems (e.g. Gradle, Maven, Bamboo, TeamCity, Git) Data Visualization experience in Power BI, Tableau, or similar Experience using the Apache Hadoop ecosystem (Spark, Data Lake, Hive, HDFS, Impala) to tackle "big data" problems Exposure to data science, machine learning or statistics Some experience using Docker Knowledge of ETL, ELT, Lambda and Kappa data architectures We enable you to engage with the firm's strategic plan, and be a key contributor to the success and growth of the firm. We help you be the best professional you can be in our services, industries and markets. Achieve your personal goals outside of the office and make an impact on your community. 
ScrapedJobID711:
Understand Ubisoft's requirements and participate in the technical design of the proposed solutions; Design, develop, test and maintain ETL flows and related data warehouse models/objects/systems; Automate data processing and set up a qualitative follow-up; Actively participate in the post-production support of ETL developments (troubleshooting, optimization and others); Ensure that documentation is produced for all development deliverables; Make proposals on how to improve and maintain existing workflows; Collaborate with other developers, architects and business analysts, as well as Agile roles such as product owners and Scrum Master; Actively participate in knowledge transfer of tasks to the support team. Proven experience as a data scientist or ETL developer in a data ecosystem, with specific expertise in ETL development, working with large volumes of data, if possible, with Informatica; Good knowledge of data warehousing, preferably with SnowFlake; Ability to optimize complex SQL queries - use of indexes, partition analysis; Knowledge of any cloud data warehouse, cloud environment (AWS, GCP, Azure) and Hadoop stack (HDFS, Hive, Spark) and other big data technologies is a plus; Self-motivated, willing to learn/experiment with new technologies, and who demonstrates initiative and problem-solving skills while working in a collaborative environment where customer satisfaction is at the core of what we do; Excellent interpersonal communication skills in French and English are required both verbally and in writing. 
ScrapedJobID712:
Prepares labour and material estimates for ship maintenance and repair, conversions, and new constructions. Estimates requests based on accurate evaluations of owner-supplied specifications, terms and conditions, detailed or outline specifications, drawings, sketches, or following verbal instructions. This involves soliciting pricing from suppliers, consulting with shipyard personnel, contractors, regulatory bodies, and trades, and applying general and specific knowledge of the work to be performed gained from experience and analysis, to determine man-hour and material requirements and calculate the overall costs for the project. Provides management with summaries for estimated labour and material and overviews of work content, including work requiring special consideration regarding complexity, time requirements, and non-availability of products or services. Develops and maintains reports derived from key organizational data to support future estimating work, as well other business divisions. Optimizes and standardizes all stages of the data analysis process, from extraction through to modelling & visualization. Builds data set requirements, metrics, data/report definitions and establishes reporting governance processes. Identifies, connects, and maintains access to shipyard data sources (PowerBI dataflows, IFS, ShipConstructor, E1, Primavera). Collects, interprets, analyzes, and transforms various types of data into relevant metrics and reports for end users. Validates data sources, transformations, and analysis against reference data to ensure quality, accuracy, and completeness of derived reports. Supports Estimators, Resource Planners and Program Controllers in the application and interpretation of data, for use in estimates/budget calculations. Performs risk analysis on estimates by allocating risk profiles to cost elements and running simulations to identify the level of confidence. Builds and maintains cost estimate models to accurately calculate and classify project costs according to the given work breakdown structure. Uses estimating software to aid the calculation of estimates and to meet estimate reporting requirements. Store and maintain past project data in the estimating database (CostFact database) to support future project cost calculations. Develops and releases Yard performance reports to Operations and Upper Management on weekly and monthly basis. Post-secondary Diploma or Degree from a recognized technical institution or university in Engineering or a relevant field is preferred. An equivalent combination of education and/or work experience will be considered. A minimum of 10 years’ experience in the marine industry or 5 years’ experience in a shipyard environment is needed. Minimum 7 years of experience with business analytics, statistical analytics, KPI development and metrics reporting, preferably in a Program & Project Management environment with quantitative, financial or metric analysis on multiple large-scale data warehouses is required. Excellent communication skills in the English language, both verbal and written, including knowledge of correct marine terminology. Proven ability to prepare accurate estimates. Able to read technical drawings and interpret contract and tender documentation requirements. Knowledge of applicable rules and regulations in the marine industry. Familiarity with all shipyard trades and knowledge of marine equipment and systems. Excellent analytical skills to gather, analyze and validate data, including applying statistical methods. Exhibited ability to prepare estimating Cost Models, reports, and analyses. Advanced Excel knowledge (including the use of macros) is required. Experience with Business Intelligence tools such as Power BI or SAP BI is needed. Experience with risk analysis techniques and software tools (such as Oracle Crystal Ball) is required. Experience in using cost estimating software/tools (such as CostFact) is required. Strong core Microsoft Office application skills are required. Proficiency with query languages such as SQL, or programming languages such as C#, Python, R, or JavaScript is an asset. 
ScrapedJobID713:
Lead a team that applies state of the art data science and machine learning techniques to personalize customer service experience and resolutions across self-service and agent-assisted interactions Drive significant business growth by collaborating with business, product, engineering teams to identify and solve high-impact ML problems in Customer Service balancing trade-offs between Customer Lifetime Value, Happiness and Cost Lead development of frameworks to translate noisy customer feedback into quantitative signals that can be leveraged to help the organization set operational targets that are customer-friendly and cost-efficient, and create a feedback loop for proactive incident prevention Lead development of multi-KPI optimization systems that can explore and exploit in accordance with rapid growths in business, shifts in supply chain landscape, and evolution towards a differentiated customer service experience Manage a portfolio of existing initiatives and evolve them to be scalable, platform-oriented data science products Lead the design and development of intelligent products that leverage a wide variety of data sources to improve customer and agent experience Master’s degree in Computer Science, Engineering, or related fields; PhD preferred 6+ years of experience leading multi-disciplinary technical teams of scientists, analysts and engineers of varied levels of experience. Track record of developing and managing high-performing teams Thorough command of general data science and machine learning techniques Relevant experience designing and implementing customer-facing systems that are scalable, fast, and resilient Track record of delivering large cross-functional projects and managing multiple stakeholders with competing priorities Good understanding of experimental techniques for the design of A/B tests to measure the impact Communication skills that can influence across organizations and at all levels 
ScrapedJobID714:
Bring your expertise to customers to build Data Quality framework and implement data quality solution based on industry standards. Work with cross-functional stakeholders including IT representatives, business leaders and analytics and data management community to understand data quality challenges and identify solutions for remediation. Prepare the plan, lead small development and testing team and mentor junior colleagues to deliver quality and on-time solution in Agile/Hybrid Agile methodology. Minimum 5 years of relevant hands-on experience in Informatica Data Quality (IDQ) and Informatica Data Explorer (IDE) tools Experience in admin activities associated with configuring IDQ and IDE Good knowledge of at least one Address Validation and Cleansing tool (AddressDoctor / Informatica Address Verification, Trillium, etc.) Proficiency in at least one ETL tool (Informatica Power Center, Data Stage, SAP BODS, etc.) Good knowledge of DBMS concepts, SQL, PL/SQL, and Java (desired). Experience in integrating ETL tools with Informatica Data Quality Hands-on experience in integrating IDQ with downstream and upstream applications through a batch/real-time interface Working knowledge in fine tuning match/merge process and troubleshooting performance issues in IDQ Good knowledge of data quality concepts, data quality trends and other tools in market. Skills in data profiling and data analysis Ability to work with leaderships to architect, estimate and respond to IDQ related pursuits Experience in leading a team in a project or a module Effective communication and presentation skills Expertise in developing scorecards and statistics related to data quality Experience in leading requirements gathering and developing solution architecture for IDQ initiatives. If you believe you have what it takes to be a successful member of our team, please apply now. We know your career is important to you and it's important to us, too. This role is just the first step of a highly successful career we can help you build. The time is right for you to join Deloitte. Get your career off to great start. What impact will you make? Experience in handling client interactions at different phases of the projects. Well versed with onsite/offshore model and its challenges You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster. You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful. You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work. 
ScrapedJobID715:
Clearly communicate project statuses with leaders and project teams Engage in quality assurance processes to create a high standard of accuracy Ensure exception and error handling techniques are used Use understanding of business rules to enhance logic used in reporting and analysis Seek out new technology and processes to improve team ability and reach Verbally and visually present reporting and analysis findings to leaders and stakeholders of various levels Submit work for quality assurance with a low number of errors Prioritize multiple projects within own work stream to deliver with little impact to timelines Manage relationships with data source providers for issues and support Consistently incorporate reconciliation in published reports and datasets Prove or disprove relationships between variables (causal) Forecast business measures with confidence and accuracy Assist with development planning with other team members Take on and seek out opportunities to mentor and coach Champion best practices in quality and reliability Over 8 years relevant industry experience within a telecom, client services or technology environment Undergraduate degree in a field linked to data engineering, business analytics, applied mathematics, computer science, IT, computer applications, or related field Ability to create reporting and analysis solutions that are delivered within scope, expected timelines and of high quality Demonstrated solid critical thinking and problem-solving skills Expert ability to identify issues and make difficult decisions, knowing when to escalate when required Strong ability to develop strategic relationships across the organization in a collaborative and foster trust from others Committed to personal and team excellence and ability to operate in a dynamic and constantly changing environment 
ScrapedJobID716:
A team player, fostering collaboration and creativity in an open and honest environment Passionate about talent development and data delivery projects A visionary with a curious mind, you have an interest in collaborating in the delivery of data initiatives and the ability to link your expertise with business needs to create value Comfortable working in constantly evolving complex environments and multidisciplinary teams An agent of change, motivated and able to question the status quo An excellent communicator, adept at negotiating and decision-maker Mobilizer, organized and results oriented A bachelor’s degree in Information Technology, Software Engineering or any equivalent combination of training and experience Minimum 10 years of software development experience in the data and analytics space Minimum 5 years of experience managing resources and projects. A strong understanding of technologies, project delivery and continuous integration and delivery processes Experience delivering products in Agile/Scrum mode in software development Experience working with project management tools such as MS Project, Clarity or similar tools. Excellent ability to manage priorities and resource capacity. An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID717:
Enrolled in a Ph.D. degree or equivalent in engineering, computer science, machine learning, statistics, physics, or related fields. Experience in designing experiments and statistical analysis of results. Experience in understanding and ability to implement algorithms using both toolkits and self-developed code. Experience with Java, C++, or other programming language, as well as with R, MATLAB, Python, or similar scripting language. Familiar with the core undergraduate curriculum of computer science. Technical fluency; comfort understanding and discussing architectural concepts and algorithms, schedule tradeoffs and new opportunities with technical team members. Publications at top-tier peer-reviewed conferences or journals. Excellent critical thinking skills, combined with the ability to present your beliefs clearly and compellingly in both verbal and written form. 
ScrapedJobID718:
The application of quantitative skills (Mathematics & Statistics) and methodological approach to ensure a disciplined approach to analysis and data mining Ability to create algorithms, apply 'scoring' of data Lead the Data Science team responsible for developing advanced analytical solutions to support key business goals Coach and develop team members as necessary to develop and maintain high standard of output Engage with senior stakeholders to understand and translate key business challenges into analytics solutions, leveraging ML approaches where appropriate Develop effective model management processes and performance framework to enable operational ML solutions In collaboration with Enterprise Analytics partners develop a multi-year AI/ML strategic roadmap focused on driving transformational results through analytics Minimum 10+ Years of Job Related Experience Extensive experience in advanced analytics and data science, managing and leading analytics teams Financial services experience preferred Advanced degree or certification in Data Science, Analytics, Mathematics or Statistics preferred Deep expertise with analytical tools such as SAS, MATLAB and cloud technologies such as AWS Sagemaker Advanced Experience with coding and scripting languages such as Python, R, SQL Advanced experience with ML and deep learning algorithms, methods, platforms and processes Understanding of machine learning theory and predictive modeling lifecycle Knowledge of Data Management, Data Governance, and technical architecture required to enable advanced analytics capabilities 
ScrapedJobID719:
Attract the best AI, data science, and data engineering talent and make TI synonymous with innovation, analytical excellence, and agility. Partner with senior T&O leaders to develop data-driven strategies to drive operational excellence of infrastructure and applications with RBC Deliver insights to help shape strategy across a wide spectrum of application and technology infrastructure areas, including Cloud, Distributed Hosting, Networking, End User Compute, and Middleware Platforms Lead data research and development of AI/analytics solutions to improve: End-user experience, Cost Forecasting, Resource Forecasting, Change Management, Problem Management, Incident Reduction, and MTTR reductions Deliver Data Products necessary to enable Operational/SRE Practices across RBC Oversee planning and execution of analytics data infrastructure roadmap Provide guidance and thought-leadership on analytical best practices to team members and T&O partners Translate analytic insights into concrete, actionable recommendations for TI operational or TI product improvement 6+ years of experience in the data field and software development 5+ years of experience managing teams 3+ years of experience in design and building scalable data platforms and data solutions Drive the interaction with internal and organizational partners to define, design, and develop solutions to AI, analytics and AIOPS Agile way of working (Scrum, Kanban, SafeAgile) Strong knowledge of design, development, and implementation experience utilizing data science methodologies (CRISP-DM). Strong knowledge of the data science/data engineering toolchain (e.g. MLfLow, Jypiter notebook, DataIKU, Azure MLOps, etc.) Applied knowledge of traditional, private, and public cloud data platforms (AWS, Azure, and SaaS). Financial planning and management Working knowledge of ITSM processes and general knowledge infrastructure technology stacks (Network, Storage, Compute, etc.) Understanding of SRE practices Observability and monitoring for infrastructure and applications technologies DevOps practices and tools (Jenkins CI/CD, GitHub, etc.) Leaders who support your development through coaching and managing opportunities Ability to make a difference and lasting impact Work in a dynamic, collaborative, progressive, and high-performing agile team A world-class training program in financial services Opportunities to tackle challenging innovative work Opportunities to take on progressively greater accountabilities 
ScrapedJobID720:
Strategic Leadership: Develop business strategies that will drive growth, profitability, and competitive success for Capital One in the face of shifting consumer and regulatory demands People Management: Coaching and mentoring associates with a goal of developing and retaining talent at Capital One. Lead an inclusive work environment, where teamwork, diversity and belonging are essential. Product: Develop and implement new product and pricing strategies for various lending products; lead product level modeling/analytics Marketing: Develop direct-to-consumer marketing strategy and initiatives to support business growth objectives. Help build targeted insights to inform the design and development of new customer experiences, as well as breakthrough technology and concepts designed to deliver on new go to market strategies Credit Risk: Support step-change improvements in credit performance by connecting drivers of future consumer credit trends to historical behaviour, creating risk models, and testing hypotheses using rigorous monitoring and analysis End-to-End Delivery: Able to partner with teammates in process management, technology, data science and others in order to not just imagine great strategies on paper, but deliver them to market with quality Strong people leadership: Ability to build and leverage the capabilities of a high-performing team, as well as business partners across the enterprise. They should foster innovation, drive critical decisions, hold business partners accountable, and be able to consistently deliver results. Analytically oriented: Experience in analytical problem-solving. Conceptual thinking skills must be complemented by a strong quantitative orientation, given that a large part of the business is based on rigorous analytics. Have demonstrated an aptitude in learning and growing their technical skills (e.g. Excel, SQL, and/or Python). You don’t hesitate to get into the complex details of a problem and do the work alongside your team. Strategically minded: A thoughtful decision maker who is able to bring actionable and grounded recommendations to senior leadership. Able to identify and synthesize business challenges and opportunities, and solve for them using analysis to make strategic or tactical recommendations. Influential communicator: Ability to communicate complex ideas both verbally and in writing, coupled with strategic influencing skills and the ability to drive agreement through intellect and interpersonal skills. Results oriented: Focuses on driving impact both short and long term, and are able to drive and execute an agenda end-to-end from conception through to in-market delivery within an uncertain and fluid environment. Are not just about making recommendations, but getting stuff done. A team player: Helps us achieve more than the sum of our parts by collaborating effectively with others and encouraging an inclusive culture with diverse teammates. Have a successful track record of thriving in an entrepreneurial and dynamic environment. Previous consulting experience is a plus. A bachelor’s degree or higher At least 4 years of experience in analysis Demonstrated leadership experience (direct or indirect people / team leadership.) A degree preferably in Commerce, Finance, Marketing, Economics, Business Administration, Engineering, Mathematics, Computer Science, Statistics or a related field A master’s degree 2+ years of experience in a related field such as consulting or financial services 1+ years of experience of direct people management 
ScrapedJobID721:
gives back to the community has leadership that inspires, coaches and mentors allows you to speak up and be heard AND ... likes to have FUN? Live and breathe Big Data and analytics systems such as Apache Spark and Big Query Utilize hybrid cloud-based infrastructure (Google and AWS) to collect and process massive volumes of data; Build data processing pipelines to mine location-based insights, create audience segments and integrate them with a myriad of DMP and DSP systems; Research and build Machine Learning solutions to solve some of our prediction problems Transform ML solutions into scalable production grade systems Brainstorm and create powerful visualizations that makes data accessible and understandable; Evaluate database solutions and help to define the architecture and design of data delivery systems; Contribute with development best practices and experiment with new ideas; Work collaboratively with cross-functional teams to identify creative solutions for data targeting, and plan and execute key products from concept to production Master’s Degree or equivalent in computer science / software engineering, preferably focused on data mining, machine learning, or related quantitative fields; Deep knowledge of SQL, MapReduce and other Big Data languages and processing frameworks; Experience designing and coding data pipelines in Python or Java; Experience writing reliable, scalable and clean code, while applying software engineering best practices Understanding of statistical and predictive modelling and machine learning approaches Accomplished in the use of data analysis and machine learning packages such as pandas, jupyter and scikit-learn/Spark ML; Big plus if you have knowledge of the advertising domain and its technology stack You have a passion for keeping up with the constant state of rapid evolution in the data world! You are a creative & innovative thinker You are entrepreneurial and take initiative, finding and executing great ideas with minimal resources You are a visionary! Someone who wants to leave a lasting impact on business You are excellent at communicating within a team and with clients You thrive under pressure and have no problem meeting deadlines Remote Work Environment #ChooseOurOwnAdventure . Read more about our remote work environment here! Summer Hours ️ Wellness Program Lunchtime virtual gym sessions? Count me in! Course Reimbursement Program – We want you to keep learning, so we can too! Personal Days in addition to Vacation days An extra day off during the month of your birthday - our gift to you! Open and transparent communication, including bi-weekly All Hands Meetings with our CEO Pelmorex Learning Academy includes offerings like French, Leadership (for people leaders and non-leaders alike), yoga, mindfulness Your mental health is important to us! We partner with Inkblot for virtual counseling sessions Free online doctor visits with Maple Online Healthcare Personal Spending Account - Full-Time employees will receive $500 per year While we encourage 1:1 conversations, we recognize that not everyone is comfortable with speaking up. We have an anonymous reporting platform (Speakfully) to ensure everyone’s voice is heard Weather is inclusive, we will be too. We have an IDEAS (Inclusion, Diversity, Equity, Awareness, Solidarity) team committed to making this happen! 
ScrapedJobID722:
Mentor researchers and ML engineers Own the research and machine learning product roadmap Create vision for novel machine learning products Align stakeholders towards proposed product vision Conduct research for ML use cases and applications Build initial ML prototypes and models Conduct systematic experiments across multiple models and hyperparameter combinations Create or augment datasets Clean, process, analyze and visualize data and model performance Keep up-to-date with new research literature and state-of-the-art machine learning and deep learning approaches Complete understanding of machine learning lifecycle from conception to production Depth and breadth of state-of-the-art approaches in science Image-based (feature extraction etc.) Machine Learning / Deep Learning Prior experience in conducting academic or industry research Creative problem solving Design and develop ML prototypes and models Practical and theoretical understanding of machine learning and deep learning concepts, deployment, and continual improvement of ML products Mentorship & management of research team Program management alongside product and project managers Geomatics experience a bonus Minimum BSc in Electrical Engineering, Physics, Mathematics, Computer Science, or an equivalent technical degree; MSc or PhD preferred Machine Learning experience required, including Image Segmentation; Geomatics a plus 3-5 years management experience in a research or engineering environment Python/Octave SQL Machine learning: Scikit-learn/Fast.ai / AllenNLP / OpenCV / HuggingFace / etc Deep learning: TensorFlow / PyTorch / MXNet / JAX / Chainer / etc. Linux Cloud: AWS/Azure/GCP 
ScrapedJobID723:
Influence how we build a mission-driven, high-throughput data science and analytics organization, and contribute to our collaborative culture Establish data rigor, data integrity, accuracy, responsiveness and execution cadence across all data science and analytics programs Build frameworks and tools to automate ad-hoc and post-hoc analysis requests Help Machine Learning team with exploratory data analysis for enabling semantic search, fraud analytics, spam detection models, document optimization and analysis to support applied machine learning across all product initiatives Create and implement machine learning models to support Course Hero products Mine structured and unstructured data platforms to understand customer attributes, user journeys, engagement with the products, and growth opportunities for our business Design and analyze A/B tests and propose innovative A/B testing techniques to help us learn about our millions of users Propose strategic initiatives and goals to help our functional partners to achieve their goals and drive growth Effectively communicate data findings to internal and external team members 5+ years of working experience in data science or analytics Deep understanding of statistics and probability, quantitative sciences, data analysis, natural language processing, text mining, econometrics, and distributed data processing Skilled in predictive modeling, statistical modeling, data mining, numerical simulation, stochastic modeling, time series analysis, and portfolio modeling Quantitative experience in B2C markets Track record of delivering decision support models and quantitative analysis with actionable insights Hands-on technical skills in Python, SQL, Map/Reduce, RegEx, and Linux scripting Experience with big data platforms such as Hadoop, MapReduce, Spark, Hive, and Pig MS or PhD degree in a scientific or quantitative field Experience mentoring or managing other data scientists Familiar with Search Engine Optimization (SEO) Knowledge and experience working with Google Analytics, Tableau, Amplitude, and Treasure Data Experience working in education or e-commerce domain Competitive salary Full private medical coverage (medical, dental, vision) Retirement savings program Paid Parental Leave Education Reimbursement Quarterly team events and outings Team lunches Social responsibility program (volunteer hours and donation matching program) Front row seat to Master Educator lectures – check out our Lecture Series videos 
ScrapedJobID724:
Take a hands-on role in several projects, including the Fundamental Review of the Trading Book (FRTB), data solutions for capital optimization, and data quality control processes. Prototype new approaches and enhance existing methodologies to advance market data management and data quality control. Develop production level code and collaborate with IT team for integration into daily bank processes. Assist team members for various ad-hoc analyses, data methodology, documentation, reporting, preparation of materials. Execute model runs on a regular basis for reporting and perform corresponding analyses. Communicate with model developers, trading desks, risk teams, and business lines to enhance data quality control and data management for capital optimization Become an active member of the team including our D&I initiatives and communities. Solid quantitative background and problem-solving skills with a keen interest in Data Science, Finance, Economics, Market Risk, Derivatives Pricing, Risk management or Regulations. Advanced degree in a mathematics, economics, or scientific discipline (e.g., Mathematics, Finance, Statistics, Physics, Engineering, Biology, Economics, etc.). Master’s degrees or PhDs are a bonus. Experience in code development in Python or other formal programing will be important to support day-day activity. Effective communication (written and oral), specifically the ability to summarize complex ideas in simple terms; you enjoy working in collaborations. The opportunity to join a forward-thinking company surrounded by a collaborative team of innovative thinkers. A rewarding career path with diverse opportunities for professional development. Internal development to support your growth and enhance your skills. A competitive compensation and benefits package. An organization committed to making a difference in our communities– for you and our customers. We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!

This position is located Downtown, Toronto. This is a contract role. 
ScrapedJobID725:
Understand the digital analytics space and architect and implement digital analytics solutions for websites and mobile applications Develop domain expertise in each client's business industry to enable data-driven decisions and results within the client's organization Assess and audit the current state of analytics implementations to identify gaps, find technical issues with the code or configuration, and recommend the best technical solutions Work with consultants to strategize and architect large-scale digital analytics implementations across different Business Units within the client’s organization to meet or exceed the client’s expectations Implement digital marketing, analytics, and other tags through Tag Management Systems (TMS) utilizing Javascript to support advanced tagging solutions Write technical implementation instructions for developers including both data layer instructions and data attributes to align with the Business Requirements Document (BRD) and Solutions Design Reference (SDR) Support the development team through the coding process to ensure implementation meets the expectations as outlined in the technical instructions Build out the process and templates for Adobe Audience Manager (AAM) implementations, and train other team members to use them. Telecommuting from anywhere in the U.S. is acceptable. Bachelor's degree in analytics, data science, marketing, business, or a related field plus 3 years of experience in job offered or a related occupation 2 years of experience in HTML and CSS and advanced JavaScript skills. 1 year of experience in the following: Experience architecting, implementing, and customizing digital analytics solutions within the Adobe Analytics Cloud; Adobe Analytics Cloud ecosystem including Adobe Analytics, Adobe Launch, and Adobe Audience Manager; Products within the Adobe Experience Cloud and how different integrations work with Adobe Analytics; Working with a wide variety of programming languages and frameworks that include: Java, SQL, R, Python, and/or Hadoop, with experience building data pipelines; Experience with data science, including data classification, data mining, and forecasting using machine learning capabilities in Adobe Analytics; Experience with digital marketing data requirements: Querying the necessary data pipelines, analyzing and visualizing data with tools like Tableau, and designing tests to optimize both user experience and business outcomes. 
ScrapedJobID726:
Develop machine learning solutions to integrate into our products Balance building technically advanced solutions and swiftly shipping Keep pace with developments in Deep Learning relevant to our activities (papers, conferences, etc.) Work with a diverse team of talented ML Engineers, Backend Engineers, Developers in Test, and Product Managers Ability to write production-grade code in Python Hands-on experience with any of these frameworks: Tensorflow, PyTorch Passion for learning new things and bringing in new ideas Experience with video processing, Risk scoring, Fraud solutions Friendly and supportive Adaptable and flexible Articulate and persuasive High IQ and EQ Curious and coachable Commercially Aware Resilient and tenacious Big picture and the detail IDEAL: Integrity, Diversity, Empowerment, Accountability, Leading Innovation 
ScrapedJobID727:
Applies in-depth disciplinary knowledge, contributing to the development of new techniques and the improvement of processes and work-flows. Coordinates and contribute to the objectives of data science initiatives and overall business through leveraging in-depth understanding of how areas collectively integrate within the sub-function. Assumes informal/formal leadership role through coaching and training of new recruits. Significantly influences decisions, work, and performance of all teams through advice, counsel and/or facilitating services to others in the business. Conducts strategic data analysis, identifies insights and implications and make strategic recommendations, develops data displays that clearly communicate complex analysis. Mines and analyzes data from various banking platforms to drive optimization and improve data quality. Delivers analytics initiatives to address business problems with the ability to identify data required, assess time & effort required and establish a project plan. Consults with business clients to identify system functional specifications. Applies comprehensive understanding of how multiple areas collectively integrate to contribute towards achieving business goals. Consults with users and clients to solve complex system issues/problems through in-depth evaluation of business processes, systems and industry standards; recommends solutions. Leads system change process from requirements through implementation; provides user and operational support of application to business users Formulate and define systems scope and objectives for complex projects through research and fact-finding combined with an understanding of applicable business systems and industry standards. Impacts the business directly by ensuring the quality of work provided by self and others; impacts own team and closely related work teams. Considers the business implications of the application of technology to the current business environment; identifies and communicates risks and impacts. Drives communication between business leaders and IT; exhibits sound and comprehensive communication and diplomacy skills to exchange complex information. Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. 5-8 years experience using tools for statistical modeling of large data sets Ability to effectively use complex analytical, interpretive and problem solving techniques Demonstratedinterpersonal, verbal and written communication skills Bachelor’s/University degree or equivalent experience 
ScrapedJobID728:
Collaborating with data scientists and protein engineers to plan and analyze experiments evaluating novel antibody sequence engineering methods. Developing data analysis and visualization platforms to adapt novel methods for large-scale protein engineering applications. Training and mentoring more junior scientists. Preparing and authoring materials to educate colleagues, and communicate strategies, key findings and implications. You are strongly self-motivated and work independently to identify project needs and follow that up with building and implementing solutions You’re passionate about understanding and telling the story behind your data A PhD or Master’s degree in Computer Science, Machine Learning, Computational Chemistry, Computational Biology or related field and 3+ years of related experience. Strong fluency in Python and associated data analysis stack A grounding in modern data analysis methods and statistics Experience with software engineering best practices, including version control and collaborative software development Strong interpersonal skills with the ability to work collaboratively as a member of cross-functional team Excellent verbal and written communication skills, including public presentation of complex data Experience with data presentation and visualization tools such as Plotly Dash or R Shiny A publication record in design and quantitative analysis of experiments in the life sciences Working knowledge of antibody structure and function Experience with “big-data” wrangling tools such as BigQuery, Spark or Presto in cloud-based environments such as AWS/Azure/GCP or Kubernetes The opportunity to work with an inspired team on challenging problems that matter An attractive compensation package, including health and lifestyle benefits A minimum of 3 weeks’ vacation Opportunities for personal and professional development 
ScrapedJobID729:
Enable bringing analytics to the airline and airport baggage industry Work internally and externally to model and analyze our customers data to provide easy-to-understand metrics Build automation for data capture from disparate systems for import into a data lake Develop visualizations in Power BI Be an expert in everything Power BI related Passion for Data Science Previous experience with Microsoft Power Bi or a similar tool Excellent teamwork skills Proven ability to work with cross-functional teams Excellent written and verbal communication skills College diploma or University Degree in a relevant field of study Knowledgeable in Microsoft SQL Server and Azure DAX/R/Python and other scripting languages familiarity Microsoft Power Platform and JNet knowledge an asset 
ScrapedJobID730:
Collaborating with key stakeholders to understand the data landscape, business process value streams in the context of the evolution, transformation of Lead-to-Cash systems Translating business problems into concrete data analyses, models, migration scope, sequence, requirements. Creating artifacts like data mapping, lineage, dependency and data inventory; contributing to data dictionary and catalogue. Upholding data principles and standards and contributing to a good data governance Contributing to data security, classification, and compliance (SOX, GDPR…) Working with a team of developers, tech leads in building, testing, reconciling and implementing data transformations. Analyzing data in current systems, building procedures for data cleansing, and reconciliation. Supporting Architectural Principles and NFRs related to data accuracy, scalability, traceability, reusability, reliability, security(PII) and simplicity Collaborating with Project Managers to plan, identify risk factors and regularly communicate progress. Influencing decision regarding Data tools, technology, approaches Background in participating in successful, complex data projects, including migrations, in the context of M&A and Digital Transformation Strong business acumen and ability to translate business needs into data requirements Strong expertise in data analysis and data profiling Ability to communicate with Product Managers, Business Stakeholders, Developers Experience in data models and data flows of leading SaaS Lead-to-Cash systems like Salesforce, Netsuite, Hubspot, Zuora, Workday etc Excellent data analysis, mapping skills. Advanced SQL skills. (Asset: Experience with BigQuery and GCP) Strong experience in SQL/Python scripting (Nice to have: Exposure to iPaaS solutions like Mulesoft, API, message queues, event driven integration) Experience in SDLC including Agile, CI/CD, Cloud environments (AWS, GCP) Good knowledge of data management, data integration, data quality and database development techniques Ability to apply Data Governance principles (Lineage, Quality, Metadata) Strong analytical and problem-solving skills. Ability to stay positive and motivated while under pressure. Bachelor degree in Business Technology Management, Finance, Statistics, Mathematics or any other related fields Opportunity to learn and expand your skill set in data and technology, forge wonderful relationships and make your mark within the diverse and inclusive Lightspeed family, a true Canadian tech success story Join a recently created data team and help us move to the next level Amazing benefits & perks, including equity for all Lightspeeders Constant development of both your data skill-set and business acumen with limitless growth opportunities Lightspeed share scheme (we are all owners) Unlimited Paid Time Off Policy Comprehensive Medical, Dental, and Life Insurance RRSP Contribution $500 Health & Wellness Credit Paid leave and assistance for new parents Mental Health Online Platform, and counselling & coaching services LinkedIn Learning License 
ScrapedJobID731:

ScrapedJobID732:
Participate in the evaluation, design and implementation of technological processes to improve the accuracy and efficiency of loan origination and processing activities Proactively communicate and collaborate with stakeholders to identify information needs and functional requirements; translate into technical specifications and delivering appropriate analysis as needed, e.g., functional requirements, business requirements, use cases Chair project meetings, drive clarification of requirements and remove roadblocks for multiple initiatives simultaneously; liaise between the business units, technology teams and support teams Ensure communication among key internal and external business partners, customers and other stakeholders regarding status, milestones, issue resolution and escalation of projects Closely collaborate with developers and subject matter experts to establish the technical vision and analyzing trade-offs between usability and performance needs; conduct technical testing on new systems, platforms and databases Manage third party vendors and investigate feasibility of integrations through API Design and conduct business performance variance analysis; create, generate and present reports or dashboards to deliver essential information to staff, management and IT professionals Own the reporting and creation of dashboards using Sisense, our data aggregation and BI tool; manage all regular and ad hoc data reporting activities Troubleshooting the reporting database environment and reports Evaluating changes and updates to source production systems Contribute to the establishment and promotion of a culture which promotes quality of work, service orientation and flexibility, through influencing attitudes, utilising industry best practices and ensuring the continual review and improvement of processes Maintain an extremely high degree of quality control at all times; ensure that all systems or process changes are fully tested and de-bugged before deployment to production Pursue the continued education in the area of data analysis techniques and financial technology systems and the flow of interconnected data between them You are a self-motivated quick learner as well as a change agent that has been making real impacts in organization(s) At least 5 Years in Business and Data Analyst related role(s) in the Financial Services industry Strong knowledge in basics of lending product life cycle, from origination & understanding to processing to loan servicing Direct BA experience in managing either a new system design & implementation, or significant system improvement projects Direct experiences in UAT and/or QA testing, Production support and troubleshooting/defect investigation Hands on experience in Data Analytics / Data Management and troubleshooting (such as SQL, ETL, Master Data Management Concepts, Data visualisation using SiSense or Similar) Hands-on experiences with system and data migration Strong Project Management skills including working with 3rd party vendor on software development Strong knowledge of JIRA and of at least one BI tool (SiSense, Tableau, Power BI, etc.) Nice-to-haves:
Knowledge of Salesforce (both CRM and PaaS) and basic understanding of Apex language
Direct experiences with APIs / Web Services Integration projects
Familiar with Change Management framework
Confluence, MS SharePoint Knowledge of Salesforce (both CRM and PaaS) and basic understanding of Apex language Direct experiences with APIs / Web Services Integration projects Familiar with Change Management framework Confluence, MS SharePoint Scope of responsibilities for this opportunity may change and will include, but not be limited to the above description. 
ScrapedJobID733:
Work with business domain stakeholders to understand their needs and objectives and translate them into the functional requirements of advanced analytics and reporting Independently lead the design, development, and deployment of prioritized reports and dashboards, primarily using Microsoft Power BI and respecting data visualization best practices Produce the documentation required to illustrate the progression, treatment, and final use of data by users Ensure the integrity and quality of the data contained in dashboards and reports Ensure timely delivery of prioritized business domain reports and/or dashboards Bachelor’s or master's degree in business intelligence or a related field (mathematics, IT, statistics, etc.) About 3 years of experience as a business intelligence analyst Knowledge of Microsoft Power BI and/or other data visualization tools Mastery of solutions related to business intelligence (Microsoft Power BI, SSRS, Tableau, AWS QuickSight, SQL Server) Excellent mastery of SQL Good knowledge of client contact centres Knowledge of cloud analytics: AWS BI stack, Snowflake, Azure Synapse, Azure SQL, Databricks, PySpark, an asset Bilingualism, both spoken and written (English and French), an asset Excellent ability to influence, communicate and interact with people at all levels of the organization Independence, teamwork, and collaboration skills Strong analytical and synthesizing skills and precision Interest in new technology developments and trends Health and wellness program, including many benefits Flexible group insurance Defined benefit pension plan Employee Share Ownership Plan Employee and Family Assistance Program Preferential banking services Community involvement program Telemedicine Virtual sleep clinic 
ScrapedJobID734:
Apply advanced analytics to large data sets to drive the development of use cases that meet customer needs Work with subject matter experts to determine relevant use cases Collaborate with Data Engineers to develop use cases into deployable models Develop tools to monitor and analyze the effectiveness of use cases and new data sources Remain current with cyber threat trends to enhance use cases Other related data analytics support as may be required Master’s degree in Computer Science, Mathematics, Machine Learning or similar 5+ years related work experience with advanced analytics and machine learning Experience with Spark, R, Python, Java, SQL, Hadoop Knowledge of advanced statistical and machine learning techniques General knowledge of enterprise data security Working knowledge of Unix/Linux command line tools Excellent written and verbal communication skills and experience presenting Experience in GCP machine learning and big data tools is an asset Dental care Extended health care Vision care Master's Degree (preferred) Data Science: 3 years (required) Yes 
ScrapedJobID735:
Work with Growth Marketers to understand best practices and propose strategic ideas and turn them into initiatives for driving growth. Define and regularly monitor KPIs, success metrics, and other analytics to maximize our conversion rate across our digital channels. Set up and evaluate A/B tests results and push forward next steps at a rigorous pace. Deliver reports and strategic insights through analysis and manual data extractions from various ad platforms, data tools, and internal tracking to drive OKRs Estimate the value of different marketing strategies. Effectively communicate findings to internal and external team members. Manage research, development, and delivery of analytical models to be used for strategizing, testing, and implementing marketing campaigns across SEM, paid social, display, influencer, email, and more. BS/BA degree in Statistics, Business, Economics, Mathematics, Operations Research or related quantitative field 5+ years of experience in quantitative marketing/business analysis with solid understanding of experimentation design, marketing mix modeling solutions and statistical modeling Highly proficient with SQL and visualization tools (e.g. Tableau) and are comfortable working in at least one scripting/statistical language (R, Python preferred) Excellent communication skills, both written and oral. You are able to clearly articulate growth marketing ideas, strategies, and tactics to audiences with varying domain knowledge A curious mind, passion, and motivation to learn new skills, tools, and analytics techniques necessary to tackle business challenges Comfortable functioning in spaces with high ambiguity and adapt easily in changing environments. Advanced degree in Statistics, Information System & Management, Economics, Mathematics, Operations Research or related quantitative field
Understanding of the digital marketing ecosystem and can identify key business KPIs
Familiar with marketing analytics tools (e.g. Amplitude and/or Google Analytics, Adwords, Responsys, Facebook insights)
Previous experience in the field of education or e-commerce Advanced degree in Statistics, Information System & Management, Economics, Mathematics, Operations Research or related quantitative field Understanding of the digital marketing ecosystem and can identify key business KPIs Familiar with marketing analytics tools (e.g. Amplitude and/or Google Analytics, Adwords, Responsys, Facebook insights) Previous experience in the field of education or e-commerce Competitive salary Full private medical coverage (medical, dental, vision) Retirement savings program Paid Parental Leave Education Reimbursement Quarterly team events and outings Team lunches Free lunches twice a week, on-site cafe discount, plus an endless snack and drink supply Social responsibility program (volunteer hours and donation matching program) Front row seat to Master Educator lectures – check out our Lecture Series videos 
ScrapedJobID736:
Location: Ottawa-Kanata, Ontario Department: Digital Marketing Employment Type: Full-Time Minimum Experience: 3-5 Years Digital Marketing Experience Lead Digital Marketing Analytics & Reporting: Analyze data and market research for persuasive marketing insights. Create & analyze surveys and Net Promoter Scores (NPS) for actionable insights. Analyze target customer quality segmentation and lifetime customer value. Analyze lead gen tests to help the team achieve superior ROI optimization. Analyze lead gen growth/ROI accelerators: repeat/referral/review/advocacy. Create & automate reports & dashboards for both Clients and Contrast teams. Oversee New Client acquisition pipeline metrics, analytics, testing and reports. Live and breathe Contrast Digital’s Core Values – Talent Matters: Drive to achieve big growth goals. Discipline to keep team promises. Service to surprise & delight clients. Always improving what matters most. Aspirations to join an entrepreneurial Contrast Digital team and fast growth EBBT Corp family of firms that are successfully building teams and expanding services to disrupt traditional approaches and provide better value to Clients worldwide who mostly operate throughout the U.S. & Canada. 3-5 Years digital marketing experience creating digital content & lead gen campaigns that have delivered lead traffic & conversion, Revenue MQL growth, and superior optimized digital ROI. Proven digital marketing leader client experience. Demonstrated digital content & lead gen strategy experience including big picture thinking, customer segments & actionable insights, competitive positioning & points-of-difference, unique branding, customer journey & experience, demand generation & direct response, multivariate testing, net promoter score, performance success metrics, ROI optimization, customer life cycle, and lead gen revenue acceleration drivers (new, upsell, repeat, referral, review, advocacy). Demonstrated digital marketing aptitude: curiosity, initiative, creative problem-solving, innovative solutions, iterative test & learn, and performance-based ROI success metrics. Digital marketing content & lead gen for SEO, SEM, Display, Mobile, Social & ABM/Email to generate volume & quality lead traffic for Websites, Webstores and Landing Pages to be converted into Revenue MQL’s and New Customers with superior ROI. Ideally B2B experience. Able to juggle priorities within a fast-paced, entrepreneurial, team-based, growth-driven, ROI-centric, remote-work environment, while selling & serving demanding entrepreneurial clients. Contrast Digital welcomes applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process. While we thank all candidates for their interest, only those who best match the above qualifications will be contacted. Thank you. 
ScrapedJobID737:
Writing SQL to clean, transform, investigate, and augment large, complex database tables Working closely with business partners to make sure our business strategy is as data driven as possible Designing rich data visualizations to communicate complex ideas to customers or company leaders Ensure data and intent integrity by automated data quality verification pipelines Supporting and consulting with the business to propagate data management best practices Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, and you’re not afraid to blurt out your disruptive idea. You know SQL and are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. A Wrangler: You know how to programmatically extract data from a database or an API, bring it through a transformation or two, and convert into a human-readable form (Matplotlib, QuickSight, Tableau, etc.). Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook With Manager approval, you can travel to a conference of your choice annually (senior+) - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours and casual environment At least 1 year of experience with relational databases and programming in SQL At least 1 year of experience with version control systems like GitHub. Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) At least 1 year of experience in open source programming languages for large scale data analysis (Python or Scala) 
ScrapedJobID738:
Develops, oversees, and reinforces data strategy, governance, standards and best practices. Works with executive leadership to identify, design and establish key business measurements. Implement metrics, analytics and insights to influence user behaviours to achieve desired outcomes. Provides leadership, guidance, training and oversight to data science and business intelligence team. Build a roadmap to sustainably deliver business measurement platform, self-service capabilities and client and customer focused analytics & insights. Implement data best practices and tools including artificial intelligence and machine learning. Focus on predictive vs. reactive analytics to deliver early-watch indicators allowing for increased certainty around business outcomes. Assign work to the technical team to deliver on initiatives and enhancements, as well as manage performance. Provide estimates and/or timelines for the delivery of the solutions. Establish strategic partnerships (internally and externally) as needed to continually improve the analytics & insights service offering. Plan strategy and implementation plan for data governance, analytics & insights 2-3 years into the future. Implement self-service standards and procedures and build an analytics community across the business. Responsible and accountable for Analytics & Insights team budget including technical team and tools and data science practitioners. Prepare accurate budget estimates and manage the budget based on Continuous Improvement (CI) initiatives. Degree in Computer Science, Business Intelligence, Data Science, Engineering, Finance or Analytics is preferred. 5+ years of related experience in a medium to large project-based company, with experience in a leadership role. Experience implementing data practices, analytics and insights tools and self-service standards across a business Knowledge of project execution business model. Knowledge of data management, data science and business intelligence principles. Experience with AI/ML technologies is desirable Experience with ERP is required; experience with SAP is an asset. Experience with Analytics tools including Business Objects, HANA, Analysis for Office, SQL, and PowerBI is an asset. Competitive salary with annual bonus potential Comprehensive benefits package including dental, optical and medical and company matched pension plan. Ownership and long term equity opportunities Strong commitment to safety in the workplace Grounded and family-oriented workplace in a progressive environment that is at the forefront of a fast evolving business sector Commitment to the training and wealth of opportunities for career development across job categories, project types and locations around North America 
ScrapedJobID739:
Attract the best AI, data science, and data engineering talent and make TI synonymous with innovation, analytical excellence, and agility. Partner with senior T&O leaders to develop data-driven strategies to drive operational excellence of infrastructure and applications with RBC Deliver insights to help shape strategy across a wide spectrum of application and technology infrastructure areas, including Cloud, Distributed Hosting, Networking, End User Compute, and Middleware Platforms Lead data research and development of AI/analytics solutions to improve: End-user experience, Cost Forecasting, Resource Forecasting, Change Management, Problem Management, Incident Reduction, and MTTR reductions Deliver Data Products necessary to enable Operational/SRE Practices across RBC Oversee planning and execution of analytics data infrastructure roadmap Provide guidance and thought-leadership on analytical best practices to team members and T&O partners Translate analytic insights into concrete, actionable recommendations for TI operational or TI product improvement 6+ years of experience in the data field and software development 5+ years of experience managing teams 3+ years of experience in design and building scalable data platforms and data solutions Drive the interaction with internal and organizational partners to define, design, and develop solutions to AI, analytics and AIOPS Agile way of working (Scrum, Kanban, SafeAgile) Strong knowledge of design, development, and implementation experience utilizing data science methodologies (CRISP-DM). Strong knowledge of the data science/data engineering toolchain (e.g. MLfLow, Jypiter notebook, DataIKU, Azure MLOps, etc.) Applied knowledge of traditional, private, and public cloud data platforms (AWS, Azure, and SaaS). Financial planning and management Working knowledge of ITSM processes and general knowledge infrastructure technology stacks (Network, Storage, Compute, etc.) Understanding of SRE practices Observability and monitoring for infrastructure and applications technologies DevOps practices and tools (Jenkins CI/CD, GitHub, etc.) Leaders who support your development through coaching and managing opportunities Ability to make a difference and lasting impact Work in a dynamic, collaborative, progressive, and high-performing agile team A world-class training program in financial services Opportunities to tackle challenging innovative work Opportunities to take on progressively greater accountabilities 
ScrapedJobID740:
Understand, automate, deploy, manage, scale and enhance data science models Design, prototype and develop machine learning systems, frameworks, pipelines and tools that leverage diverse data and support end-to-end predictive analytics projects and activities (training, inference & evaluation) Partner with other specialists in the team to deliver initiatives and solve complex data problems efficiently Define and enhance the design and implementation of data architecture and integrate new data streams to power predictive models Propose, validate and iterate on ideas that can significantly improve ML solutions, and address system constraints and compute costs Develop monitoring KPIs to track the performance of new ML solutions and models Drive continuous improvement activities and create new processes and documentation as well as training material Remain abreast of latest developments and research in the ML field and train other team members as we continue to grow the team Summarise and communicate technical aspects clearly and succinctly to both technical and non-technical stakeholders Passionate about data and its value in improving people’s lives Ability to effectively adapt to change and willingness to learn and apply new technologies, processes and tools Flexible and resilient with strong sense of accountability Able to communicate technical aspects succinctly to both technical & non-technical stakeholders Appetite to design and develop solutions starting from a blank page Ability to challenge others and provide honest feedback in a constructive way Intelligent yet humble with a drive to see through the implementation of new solutions 3-5 years of ML industry experience working on complex data science projects to build production ready applications Experience working with semi-structured and unstructured data as well as model performance tuning Strong knowledge of ML related technologies and libraries (Azure ML, Python, Pandas, Numpy, SciKit-Learn, Keras, PyTorch, TensorFlow, CNTK, SparkML, etc.) Understanding of continuous integration, testing, deployment & release methodologies Strong foundation in statistics with good knowledge of both supervised and unsupervised machine learning algorithms Working knowledge of deploying data science solutions in cloud environments e.g. Azure, AWS, etc. Good understanding of data structures, data modeling and software architecture Strong ML engineering and coding skills, with ability to write high performance production code Experience working with both SQL and noSQL databases Ability to work independently and effectively across projects while managing conflicting priorities Proficiency in Python and other coding languages such as Scala, Java, R, and C++ Experienced with tools like Databricks, Keras, TensorFlow, PyTorch, etc. Strong proficiency in T-SQL/SQL/Spark SQL Version control software like Git, BitBucket, CodeCommit or similar Software development experience Experience working with audiogram data Process automation (RPA experience) Experience working with streaming and sensor data (using Kafka/Kinesis/other streaming services/platform, Hive, HBase, NoSQL) Experience with CRISP DM or similar methodology RPA Automation software such as Automation Anywhere or Blue Prism Familiarity with Dash Plotly, RShiny, React or other data visualisation framework Experience using JIRA or similar agile project management tool Familiarity with SharePoint and Confluence 
ScrapedJobID741:
Work with business domain stakeholders to understand their needs and objectives and translate them into the functional requirements of advanced analytics and reporting Independently lead the design, development, and deployment of prioritized reports and dashboards, primarily using Microsoft Power BI and respecting data visualization best practices Produce the documentation required to illustrate the progression, treatment, and final use of data by users Ensure the integrity and quality of the data contained in dashboards and reports Ensure timely delivery of prioritized business domain reports and/or dashboards Bachelor’s or master's degree in business intelligence or a related field (mathematics, IT, statistics, etc.) About 3 years of experience as a business intelligence analyst Knowledge of Microsoft Power BI and/or other data visualization tools Mastery of solutions related to business intelligence (Microsoft Power BI, SSRS, Tableau, AWS QuickSight, SQL Server) Excellent mastery of SQL Good knowledge of client contact centres Knowledge of cloud analytics: AWS BI stack, Snowflake, Azure Synapse, Azure SQL, Databricks, PySpark, an asset Bilingualism, both spoken and written (English and French), an asset Excellent ability to influence, communicate and interact with people at all levels of the organization Independence, teamwork, and collaboration skills Strong analytical and synthesizing skills and precision Interest in new technology developments and trends Health and wellness program, including many benefits Flexible group insurance Defined benefit pension plan Employee Share Ownership Plan Employee and Family Assistance Program Preferential banking services Community involvement program Telemedicine Virtual sleep clinic 
ScrapedJobID742:
Ph.D. or Masters in CS, applied mathematics, statistics, physics, or related discipline; Two or more years’ experience developing robust code on larger projects, including code review, refactoring, unit testing, version control, etc.; Knowledge of and experience with machine learning techniques, including deep neural networks, recurrent neural networks, generative models, and attention mechanisms; Expertise in Python and PyTorch; and Intellectual curiosity and drive to excel. 
ScrapedJobID743:
Creating a positive learning environment that accommodates students’ diverse cultural and educational backgrounds, experiences, and individual learning styles; Utilizing principles of adult education to actively engage students in the learning process; Effectively using educational technologies to support learning, manage and post grades, and deliver hybrid and on-line courses; Developing curriculum that uses appropriate strategies and tools to assess student learning; Ensuring that course and program curriculum is current and relevant; Working independently and demonstrating initiative; and Working effectively with students, the program team, and a variety of internal and external stakeholders. A credential in Data Analytics or in a related discipline (relevant Master’s is an asset). A professional designation is an asset. A minimum of three years of recent (within the past three years) and relevant work experience. Teaching experience at the post-secondary level with a demonstrated understanding and application of Universal Design for Learning and current assessment methodologies. Experience participating in industry-led or community-based applied research is an asset. Demonstrated use of current technologies to support student learning and the management of grades. Proven track record of life-long learning. Demonstrated ability to work effectively with a variety of internal and external stakeholders including students, faculty, support staff, administrators and community stakeholders. Understanding of the Ontario college system. 
ScrapedJobID744:
Work directly with internal and external partners to understand their needs and develop custom solutions. Munge, Validate, format, visualize datasets. Build and maintain ETL pipelines. Create production grade predictive models for a variety of tasks. Produce and deliver high quality internal and external training and presentations. Design, Develop, Maintain BI dashboards. Create production grade python solutions and work with engineering to help deploy them. Analytical undergraduate degree (Physics, Engineering, Math, Statistics) 3-5 years' experience creating and deploying models in production environments. Adept at communicating technical topics to possibly non-technical audiences Strong visualization skills (Bokeh, seaborn, D3.js, etc.) Python, MySQL/Postgres, AWS, Linux, Git Validating and integrating with external API's Tableau, Docker/Kubernetes Industry experience in InsurTech, FinTech or Cyber Security 
ScrapedJobID745:
assessing needs and solutions for large-scale data and model infrastructure owning the uptime and reliability of ML-related services and capabilities collaborating with the team to develop solutions using the ML platform developing supporting tooling, automation, and microservices to extend the platform continuous measurement and improvement of quality and performance/efficiency B.S. or M.S. in Computer Science or related disciplines 7 years professional experience in software engineering (or  5 years if  M.S. degree) excellent collaboration and communication skills strong technical background in: software engineering of production-grade services in cloud environments, theoretical thinking, problem formulation and solving operations orientation: SLIs/SLOs, monitoring and troubleshooting, on-call rotations Scala, Python Cloud provider ML frameworks (eg, AWS Sagemaker) Application and infrastructure deployment and management with Kubernetes and Terraform Workflow management (eg, Airflow) Common ML libraries and concepts (eg, scikit-learn, tensorflow) What we do: Massive Scale: Mission: 
ScrapedJobID746:
Drive analytics enablement and adoption of analytics tools (Reports, Frameworks, and Models) across Pearson through a series of practical frameworks and methodologies Efficiently drive analytics optimization programs, such as standardization of our data science and experimentation frameworks, partner with Data Engineering to ensure data quality and establish processes for how we engage with and deliver work to stakeholders. Work with data teams across Pearson including the Chief Information Security Office (CISO), and the Controls CoE to ensure compliance with internal guidelines. Create Analytics project and rollout plans by gathering requirements and recommendations from subject matter experts, identifying workstreams, establishing owners, and coordinating alignment on timelines. Assist Analytics leadership in executing roadmaps and monitoring team performance against goals. Develop and implement quality controls and standards that drive adherence to quality standards, organizational expectations and requirements Recommend best practices and tooling / automation that will drive alignment, simplify execution, improve quality, create efficiencies, and support organizational scale Collaborate within a team environment to develop relevant and repeatable policies and procedures for preparing business reports and departmental processes. Define the data elements and data structure that our team should leverage to enable analytical and reporting capabilities for our business development team. Preparing and delivering business reviews to the senior management team regarding progress and potential barriers. Participate in strategic & tactical planning discussions. Keep abreast of industry, market, and company trends. Ensure that Pearson’s use of analytics tools is scalable and sustainable. Independently drive special projects. 7-9 years of experience in leading or driving operations for business intelligence and analytics teams Good communication and interpersonal skills. Ability to interact with diverse technical and non-technical groups, spanning organizational levels. Exceptional project and organizational management skills in a fast-paced environment Advanced experience in managing dependencies, steering teams towards milestones, and collaborating across multiple stakeholders both internally and externally 3-4 Years Project Management experience required 3-4 years of experience working on SQL and reporting tools like Tableau, Power BI or equivalent. Prior experience working on delivering complex analytics projects required Ability to work within a cross-functional team setting and shifting priorities Familiarity with best practices in Analytics and Data Governance Oversight and supervision of others. 
ScrapedJobID747:
Work cross-functionally to analyze large amounts of behavioural and transaction data to uncover suspicious behaviour and activity. Able to identify red flags, suspicious activity, investigate patterns / typologies and work on appropriate solutions from 'big data' warehouse and disparate external data sources. Develop dashboards and visualizations to track these core Indicators across a variety of products. Own data acquisition and reporting pipelines related to risk. Work alongside risk, fraud and compliance analysts and provide data analytics support for complex investigations. Develop complex SQL queries to ask questions of large/complex datasets. Understand, capture and synthesize logic and rules to flag bad actors on the platform. 4+ years performing analysis, providing insights and constructing visualizations. B.S. or M.S. in Economics, Statistics, Mathematics, Computer Science, or similar. Ability to work effectively both independently and as part of a team in a fast paced environment where processes are constantly redefined. Commanding skills in any flavour of SQL. Expertise in data visualization/BI tools (MixPanel, Google Data Studio, Tableau, etc). Experience in high-paced tech environments related to fraud or compliance would be an asset. Experience with Python/R for data analysis would be an asset. Experience with cloud technologies (GCP, AWS, Azure) would be an asset. Ability to build relationships and articulate facts to a diverse audience. Any blockchain or crypto experience would be an asset. 
ScrapedJobID748:
Are you passionate or interested in learning about maritime shipping & logistics? Are you entrepreneurial at heart and want to be a part of a family owned company? Are you a people person who cares for others? Are you a dedicated and committed individual who believes in continuously evolving? Build and manage data warehouse system using best methodology suited for respective business areas Develop tabular and multidimensional models that are compatible with warehouse standards Build high performance data marts and Analysis Services reporting models Develop visual reports, dashboards, and KPIs scorecards using Power BI desktop Connect data sources, importing data and transforming data (ETL) for business intelligence Implement row level security on data and understand application security layer models in Power BI Build DAX and MDX queries in Power BI desktop to support advanced calculations Adapt in development, publishing, and scheduling Power BI reports as per Business requirements Understand business requirements and develop data models accordingly by taking care of the resources Manage assigned projects, develop project plans, monitor performance Design methodology and project documentation Have knowledge and experience in prototyping, designing, and requirement analysis Have knowledge and skills for secondary tools such as Microsoft azure, SQL data warehouse, PolyBase, Visual Studio, PowerShell, PowerApps, Power Automate etc. Integrate PBI reports into other applications using embedded analytics like PBI service (SAAS) or by API automation Bachelor’s degree in computer science or information system and a minimum of 5 years of work experience in a similar field A minimum of 2-4years experience in data preparation, data gateways, and data warehousing projects A minimum of 2-4 years’ experience working/acquaintance with Microsoft Business Intelligence Stack having Power BI, SSAS, SSRS, SSIS A minimum of 2-4 years’ experience with Structured Query Language (SQL) Excellent listening, communication, interpersonal, and presentation skills Excellent analytical, critical, and problem-solving skills Familiarity and experience with PowerShell, JavaScript, CSS, and other Java script library Team player with professional attitude Experience in advanced analytics and data science using Python and R is an asset Experience with other BI tools (Tableau, Qlik, Oracle BI, IBM Cognos, Crystal Report etc.) is an asset Shipping experience is an asset 100% health and dental benefits coverage RRSP coverage with MSC Canada matching a portion of employee contribution Tailored training program opportunities for employee development Employee mentorship, leadership and assistance opportunities An employee referral incentive program Community Involvement Gym facility Health & Wellness Program 
ScrapedJobID749:
Work with Growth Marketers to understand best practices and propose strategic ideas and turn them into initiatives for driving growth. Define and regularly monitor KPIs, success metrics, and other analytics to maximize our conversion rate across our digital channels. Set up and evaluate A/B tests results and push forward next steps at a rigorous pace. Deliver reports and strategic insights through analysis and manual data extractions from various ad platforms, data tools, and internal tracking to drive OKRs Estimate the value of different marketing strategies. Effectively communicate findings to internal and external team members. Manage research, development, and delivery of analytical models to be used for strategizing, testing, and implementing marketing campaigns across SEM, paid social, display, influencer, email, and more. BS/BA degree in Statistics, Business, Economics, Mathematics, Operations Research or related quantitative field 5+ years of experience in quantitative marketing/business analysis with solid understanding of experimentation design, marketing mix modeling solutions and statistical modeling Highly proficient with SQL and visualization tools (e.g. Tableau) and are comfortable working in at least one scripting/statistical language (R, Python preferred) Excellent communication skills, both written and oral. You are able to clearly articulate growth marketing ideas, strategies, and tactics to audiences with varying domain knowledge A curious mind, passion, and motivation to learn new skills, tools, and analytics techniques necessary to tackle business challenges Comfortable functioning in spaces with high ambiguity and adapt easily in changing environments. Advanced degree in Statistics, Information System & Management, Economics, Mathematics, Operations Research or related quantitative field
Understanding of the digital marketing ecosystem and can identify key business KPIs
Familiar with marketing analytics tools (e.g. Amplitude and/or Google Analytics, Adwords, Responsys, Facebook insights)
Previous experience in the field of education or e-commerce Advanced degree in Statistics, Information System & Management, Economics, Mathematics, Operations Research or related quantitative field Understanding of the digital marketing ecosystem and can identify key business KPIs Familiar with marketing analytics tools (e.g. Amplitude and/or Google Analytics, Adwords, Responsys, Facebook insights) Previous experience in the field of education or e-commerce Competitive salary Full private medical coverage (medical, dental, vision) Retirement savings program Paid Parental Leave Education Reimbursement Quarterly team events and outings Team lunches Free lunches twice a week, on-site cafe discount, plus an endless snack and drink supply Social responsibility program (volunteer hours and donation matching program) Front row seat to Master Educator lectures – check out our Lecture Series videos 
ScrapedJobID750:
Design and plan for robust, scalable data transformation pipelines as feature stores to enable the analytics process and support operational data products. Apply advanced machine learning techniques to prototype new predictive and prescriptive models to support key business decisions in areas of audience segmentation, engagement and personalization as well as advanced measurement solutions. Work on feature pipelines & ML model integrations across multiple advertising and marketing platforms in the Rogers Sports and Media environment using scalable pipelines to enable data-driven use cases. Support the newly introduced customer data platform (CDP) and how all relevant customer data is collected, aggregated, and transformed into a unified customer ID Graph, and used to enable customer engagement by building robust data layer strategy. Work closely with cross functional teams to analyze their data requests and work with product manager to help build a product roadmap. Work collaboratively with IT, digital and business teams to establish and support the data science process. Data science experience with strong machine learning foundations, Statistical analysis with exposure to technologies, and platforms e.g., Databricks, Azure ML, etc., as well as familiarity with one public cloud environments, e.g., Azure. Strong Python development skills, with 3+ yrs. experience with SQL. Demonstrable experience with the concepts and idioms of functional programming like spark, and with one JVM language proficiency. Experience with Databricks delta-lake environment to build scalable feature stores as pipelines. Demonstrable experience with Spark APIs (Dataframe, Spark-SQL, Spark mlib) and tuning spark applications. Strong experience in data-driven marketing or advertising fields with focus on customer segmentation and measurement. Experience with developing interactive dashboards, reports, and data visualizations. Exposure to marketing tech is preferred; digital analytics platforms, e.g., Adobe Analytics, Google Analytics, etc.), ad serving platforms, audience segmentation and Data Management Platform, e.g., Adobe Audience Manager, or Customer Data Platforms. Strong analytical and problem-solving skills as well as flexible to adjust to evolving business needs and work effectively in cross-functional teams. Superior communication skills: ability to understand objectives, lead business and technical discussion and communicate effectively. Passionate about new ideas and emerging market trends. A competitive salary and benefits that include access to our Employee Share Accumulation Program, Retirement Benefits and a variety of other perks including 50% off Rogers services and Blue Jays tickets A manager who deeply cares about your development and long-term career at Rogers A team that trusts and wants to win together Smart and accomplished colleagues who are focused on both the “what” and the “how” Your choice of hardware and software (iPhone or Android/Mac or PC etc.) As we grow our team, the well-being of our team members remains our top priority. To ensure the health and safety of our team members, including those in the recruitment process, our team members are working from home, and are equipped to do so safely and efficiently 
ScrapedJobID751:
The application of quantitative skills (Mathematics & Statistics) and methodological approach to ensure a disciplined approach to analysis and data mining Ability to create algorithms, apply 'scoring' of data Lead the Data Science team responsible for developing advanced analytical solutions to support key business goals Coach and develop team members as necessary to develop and maintain high standard of output Engage with senior stakeholders to understand and translate key business challenges into analytics solutions, leveraging ML approaches where appropriate Develop effective model management processes and performance framework to enable operational ML solutions In collaboration with Enterprise Analytics partners develop a multi-year AI/ML strategic roadmap focused on driving transformational results through analytics Minimum 10+ Years of Job Related Experience Extensive experience in advanced analytics and data science, managing and leading analytics teams Financial services experience preferred Advanced degree or certification in Data Science, Analytics, Mathematics or Statistics preferred Deep expertise with analytical tools such as SAS, MATLAB and cloud technologies such as AWS Sagemaker Advanced Experience with coding and scripting languages such as Python, R, SQL Advanced experience with ML and deep learning algorithms, methods, platforms and processes Understanding of machine learning theory and predictive modeling lifecycle Knowledge of Data Management, Data Governance, and technical architecture required to enable advanced analytics capabilities 
ScrapedJobID752:
Develop large scale shopping recommendation algorithms Build data pipelines to do data analysis and collect training data Train deep learning models to improve quality and engagement of shopping recommenders Work on backend and infrastructure to build, deploy and serve machine learning models Develop ML algorithms to balance different objectives and model long term values Drive the roadmap for next generation of shopping recommenders 3+ years working experience in the area of applied Machine Learning Interest or experience working on a large-scale search, recommendation and ranking problems Interest and experience in doing full stack ML, including backend and ML infrastructure Experience with big data technologies MapReduce/Hadoop/Hive/Presto/Spark Expert in Java, C++ or Python Ph.D. in an area of Machine Learning Experience with large scale Whole page Optimization, Search or Recommendation algorithms Domain expertise in Shopping Shopping is cross-cutting, touches all aspects of Pinterest, so a wide variety of ML problems Largely green-field so lots of opportunity Huge impact - shopping is one of the major expansion areas for Pinterest 
ScrapedJobID753:
Work directly with internal and external partners to understand their needs and develop custom solutions. Munge, Validate, format, visualize datasets. Build and maintain ETL pipelines. Create production grade predictive models for a variety of tasks. Produce and deliver high quality internal and external training and presentations. Design, Develop, Maintain BI dashboards. Create production grade python solutions and work with engineering to help deploy them. Analytical undergraduate degree (Physics, Engineering, Math, Statistics) 3-5 years' experience creating and deploying models in production environments. Adept at communicating technical topics to possibly non-technical audiences Strong visualization skills (Bokeh, seaborn, D3.js, etc.) Python, MySQL/Postgres, AWS, Linux, Git Validating and integrating with external API's Tableau, Docker/Kubernetes Industry experience in InsurTech, FinTech or Cyber Security 
ScrapedJobID754:
Implementing scalable, fault tolerant and accurate ETL pipelines that work in a distributed Hadoop environment Developing platform services to operate the big data applications at scale Gathering and processing raw data at scale from diversified sources into Hadoop Building enterprise business analytics and reporting applications on Hadoop Proven experience working with various components of Hadoop ecosystem: Spark, Hive, Impala, Kafka, Oozie Strong understanding of computer science fundamentals Proficiency with relational databases and SQL queries (MySQL, Oracle or similar) Understanding of how to handle high velocity, high volume data events Understanding of factors affecting performance of ETL processes and SQL queries, ability to work on performance tuning Experience implementing data pipelines moving large volumes of data a day Experience in implementing application in Scala on SPARK Experience coding in Python Skills in real-time streaming applications Knowledge of Scala A development workflow using Docker containers Compulsion for automating your day-to-day processes Ruby, Java, Python, and React.js Hadoop, Scala, Spark, Hive Kubernetes, Docker, Kafka PostgreSQL, NoSQL AWS 
ScrapedJobID755:
Apply your knowledge and experience to support the delivery of key projects, build valuable relationships both within EY and with clients, and develop strong capabilities through both formal training and working with senior mentors and talented colleagues across different functions. We succeed when we combine high performing team members from a variety of backgrounds. We are therefore looking for individuals with industry, consulting, delivery or vendor backgrounds. We will provide the required support to transition into the team if this is your first step into consultancy. Strong written and verbal communication, presentation, client service and technical delivery skills, coupled with a strong interest in further developing and integrating operations with technology skills Bachelor’s degree in computer science, mathematics, data science, informatics, data analytics, engineering or a related field and approximately 2-4 years of related work experience. Interest in Data Analytics along with experience in programming is a highly desired. You will need to demonstrate strong technical problem-solving abilities as well as clear proficiency in cloud technology. Experience with range of data transformation and modelling tools, for example: SQL, SSIS, SSAS, Azure Data Factory, Informatica, Power Query Experience with MS Power Platform (Power BI, Power Apps and Power Automate) Experience with range of data visualization tools, for example: Tableau, Qlik, SSRS, Cognos Experience with data virtualization, data automation, data architecture Experience with languages like SQL, DAX, Python and Scala Strong communication, presentation and business and technical writing skills; The ability to provide excellent client service and manage and build strong relationships both internally and externally, coupled with a strong interest in further developing and integrating operations with technology skills; and Awareness of emerging issues, including regulations, industry practices and new technologies. Support and coaching from some of the most engaging colleagues in the industry Learning opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way that’s right for you 
ScrapedJobID756:
Bachelor's degree in Engineering, Statistics, Computer Science, Mathematics, or a related quantitative discipline 4+ years of work experience of analyzing and interpreting data as a business intelligence engineer, data engineer, or at a similar capacity Working knowledge of data mining and modeling using statistical software like R, Python, Matlab, etc Advanced knowledge of SQL, intermediate knowledge of Python Proficient using at least one data visualization product (Tableau, Qlik, Amazon QuickSight, Power BI, etc.) Experience working with large, multi-dimensional datasets from multiple sources Ability to work cross-functionally, building and maintaining trust with internal stakeholders Engage with leadership and diversified customer groups to understand the needs and recommend business intelligence solutions. Partner with Data engineering team to define the data elements and data structure that the team should leverage to enable analytical capabilities. Design, implement, and support platforms that provide business teams ad-hoc access to large datasets (eg data visualization tools for non-tech business users) Interface with business customers, gathering requirements and delivering complete reporting solutions. Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions. Support and enhance, stakeholder experience and models of optimization decisions in multiple production planning systems. Participate in strategic & tactical planning discussions. Standardize data and report consumption across all customer groups. Make recommendations for new metrics, techniques, and strategies to improve the operational and quality metrics. Be connected and influential within the Amazon BI community. Work with Data engineering, Software development teams to enable the appropriate capture and storage of key data points Drive process efficiency and automation 5+ years of work experience of analyzing and interpreting data as a business intelligence engineer, data engineer, or at a similar capacity. Experience with AWS technologies including Redshift, S3, EMR, and QuickSight Experience with creating and building predictive/optimization tools that benefit the business and improve customer experience 
ScrapedJobID757:
gives back to the community has leadership that inspires, coaches and mentors allows you to speak up and be heard AND ... likes to have FUN? Live and breathe Big Data and analytics systems such as Apache Spark and Big Query Utilize hybrid cloud-based infrastructure (Google and AWS) to collect and process massive volumes of data; Build data processing pipelines to mine location-based insights, create audience segments and integrate them with a myriad of DMP and DSP systems; Research and build Machine Learning solutions to solve some of our prediction problems Transform ML solutions into scalable production grade systems Brainstorm and create powerful visualizations that makes data accessible and understandable; Evaluate database solutions and help to define the architecture and design of data delivery systems; Contribute with development best practices and experiment with new ideas; Work collaboratively with cross-functional teams to identify creative solutions for data targeting, and plan and execute key products from concept to production Master’s Degree or equivalent in computer science / software engineering, preferably focused on data mining, machine learning, or related quantitative fields; Deep knowledge of SQL, MapReduce and other Big Data languages and processing frameworks; Experience designing and coding data pipelines in Python or Java; Experience writing reliable, scalable and clean code, while applying software engineering best practices Understanding of statistical and predictive modelling and machine learning approaches Accomplished in the use of data analysis and machine learning packages such as pandas, jupyter and scikit-learn/Spark ML; Big plus if you have knowledge of the advertising domain and its technology stack You have a passion for keeping up with the constant state of rapid evolution in the data world! You are a creative & innovative thinker You are entrepreneurial and take initiative, finding and executing great ideas with minimal resources You are a visionary! Someone who wants to leave a lasting impact on business You are excellent at communicating within a team and with clients You thrive under pressure and have no problem meeting deadlines Remote Work Environment #ChooseOurOwnAdventure . Read more about our remote work environment here! Summer Hours ️ Wellness Program Lunchtime virtual gym sessions? Count me in! Course Reimbursement Program – We want you to keep learning, so we can too! Personal Days in addition to Vacation days An extra day off during the month of your birthday - our gift to you! Open and transparent communication, including bi-weekly All Hands Meetings with our CEO Pelmorex Learning Academy includes offerings like French, Leadership (for people leaders and non-leaders alike), yoga, mindfulness Your mental health is important to us! We partner with Inkblot for virtual counseling sessions Free online doctor visits with Maple Online Healthcare Personal Spending Account - Full-Time employees will receive $500 per year While we encourage 1:1 conversations, we recognize that not everyone is comfortable with speaking up. We have an anonymous reporting platform (Speakfully) to ensure everyone’s voice is heard Weather is inclusive, we will be too. We have an IDEAS (Inclusion, Diversity, Equity, Awareness, Solidarity) team committed to making this happen! 
ScrapedJobID758:
Leads and drives a customer focused culture throughout their team to deepen client relationships and leverage broader Bank relationships, systems and knowledge. Support development of Analytic tools such as SOFIA to enable Portfolio Management efforts Ensures data flows are designed and tested to capture accurate and reliable information from source systems on a timely basis Acts as a subject matter expert for Commercial Banking data such as Salesforce, Loan and Deposit systems, HR data, EFT etc. Participates in working sessions with key stakeholders to ensure solutions provided are efficient and optimal for users Facilitate monitoring of results and benefits from the Analytic tools Provides leading edge solutions to Business Banking stakeholders on Business Intelligence/Analytics Proactively implements leading edge business intelligence tools for MIS (e.g. Tableau, Power BI) Ensures appropriate infrastructure is in place for Business Banking teams to access reports on an on-demand basis (e.g. through Salesforce) Explores new business intelligence tools and infrastructure in the industry on an ongoing basis to provide best in class Business Intelligence solutions Ensures ongoing improvements in automation and process improvements to cut down cycle time for report generation and availability Supports Analytics and Business Intelligence to drive sales effectiveness, client advocacy, pricing, product development, financial planning, AML and compliance needs and mandate for Business Banking Ensures Sales teams and Business Bank leadership teams have appropriate amount of drill down capability to measure and manage their portfolios/business performance Manages key stakeholder relationships in relation to delivery of Business intelligence and Analytics Works collaboratively with members of the Commercial Analytics, Data Science and Analytics team in CID&A and GRM, IT&S, Salesforce and other teams to develop data infrastructure, Business Intelligence and Analytic solutions Works proactively with development teams in Salesforce and other areas to improve infrastructure required to enhance efficiencies for end users and for the Analytics teams Understands how the Bank’s risk appetite and risk culture should be considered in day-to-day activities and decisions. Creates an environment in which his/her team pursues effective and efficient operations of his/her respective areas in accordance with Scotiabank’s Values, its Code of Conduct and the Global Sales Principles, while ensuring the adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with respect to operational, compliance, AML/ATF/sanctions and conduct risk. Builds a high-performance environment and implements a people strategy that attracts, retains, develops and motivates their team by fostering an inclusive work environment; communicating vison/values/business strategy and managing succession and development planning for the team. Develops team expertise in data mining and strong analytics capabilities Bachelor's Degree in Computer Science, Finance, Economics or Statistics Master’s degree in Computer Science – preferred 3+ years of data engineering and software experience 3+ years’ experience in Data Visualization, Business Intelligence using Tableau and/or Power BI 3+ years experience in building data pipelines and/or data warehousing Enjoy discovering and learning new technologies Detailed experience in the following: Unix, Mainframe, SQL, SAS, Python other programming tools Experience accessing, compiling and analyzing large volumes of data into usable form Excellent verbal and written communication skills are required Strong prioritizing, analytical, presentation, project management and planning skills Effective strategic thinking, organizational know-how and influencing skills are critical for success High degree of knowledge of commercial products and profit drivers The role requires a high degree of collaboration across wide ranging groups: CID&A, GRM Analytics, Global Banking & Markets (GBM); GBP; Finance, Wealth Management, Retail Small Business, and various Commercial Banking areas. Works with various partners using influence and negotiation skills to ensure objectives are met. Strong technical skills in Math, Computer Science or related fields Excellent design and delivery capabilities Ability to work non-standard work hours as required 
ScrapedJobID759:
Masters in Computer Science, Statistics, or Data Science Expertise in Python Excellent communication skills Excellent leadership skills Excellent problem-solving skills Experience creating production-quality models Machine Learning/Deep Learning Experience Data Science experience with building one or more: Recommender systems, NLP(chatbot, NER, classification), Computer Vision(object detection, segmentation, classification, OCR, ICR), Reinforcement learning, Time Series forecasting 7+ years of experience with machine learning projects 4+ years of experience with leading machine learning projects 
ScrapedJobID760:
Provide statistical analysis of conversation data Transform and integrate conversation data into our Data and ETL pipeline Enhance our ML models Keep abreast of state-of-the-art technology in the NLP/ML space, perform proof of concepts, and plan to incorporate these into our NLP/ML pipeline Work closely with product managers, business stakeholders and developers to design and deliver high quality, scalable NLP/ML solutions Bachelor’s Degree (MSc+ is preferred) in Computer Science/Engineering or related field required Strong experience working with Python, Flask(Django), Numpy and Pandas An expert in NLP tasks such as Text classification, NER, Clustering, and Topic-modeling A good understanding of Machine Learning fundamentals Experience with TextCNN, LSTM, seq2seq, and BERT models A good understanding of transformers (tokenizers, pre-trained models, fine-tuning) Experience with TensorFlow, Keras, PyTorch, Scikit-learn Experience with NLP libraries like NLTK, spaCy, etc. Familiar with Linux systems Experience with Azure, GCP, or AWS Experience with Docker and Kubernetes Experience with ETL and Data Engineering projects Experience with PySpark and MapReduce Experience with DataBricks, Snowflake, or Azure Data Factory Experience with Kubeflow, or Airflow 
ScrapedJobID761:
Will only consider candidates who are able to commute to one of the following office locations : Silver Spring and Baltimore, MD; Pittsburgh, PA; Columbus, OH; Boston, MA; Spartanburg, SC; Raleigh, NC; Orlando, FL; Atlanta, GA; Minneapolis, MN; Austin, TX; Madison, WI; Denver, CO; Portland, OR; Seattle, WA; Oakland and Los Angeles, CA; Kansas City, MO; Edmonton, AB. Develop custom software tools for clients to help prioritize transportation projects, analyze bicycle and pedestrian comfort and safety, evaluate latent demand, and analyze equity impacts of investments, etc. Conduct systemic safety analysis, exposure modeling for vulnerable road users, estimate safety performance functions, and predictive crash analyses Create custom interactive web tools and dashboards using an array of transportation-related spatial data Support active transportation projects at all scales by analyzing and mapping existing conditions, bicycle level of traffic stress, pedestrian comfort, testing investment scenarios, trip potential, and more Bachelor's or Master's degree in a relevant field 10+ years of experience in transportation and/or data science 5+ years of project management experience 3+ years of leadership experience Experience as (or a desire to become) a national leader in your field Strong experience working with a variety of spatial data and specific experience/knowledge of transportation- and planning-related data Experience in consulting or a similar deadline-driven environment Toole Design's core tech stack includes Python, PostgreSQL/PostGIS, and QGIS. Familiarity with ESRI products is also important Experience with the R programming language, data visualization software (Tableau, PowerBI, etc.), and/or a variety of statistical models is a plus You have strong leadership skills and enjoy participating in multi-disciplinary teams You are passionate about sustainability and the opportunity to work on challenging multimodal projects that center safety and equity You have experience with proposal writing, grant writing, and/or business development You have strong communication skills, whether written, verbal, or graphically You can build relationships, bring enthusiasm to exciting projects, and are detail oriented with strong problem-solving skills. 
ScrapedJobID762:
Engage with prospects and customers to identify opportunities and requirements. Recommend and justify product direction and specifications. Specify and design new products, new product features, and new product enhancements. Acquire market intelligence to become an expert on Tignis’ prospective buyers, who they are, how they buy and their key buying criteria. You will be the expert on Tignis’ competition and how they are positioned. Identify and develop strategic partners and lighthouse customers in the semiconductor industry. Develop product positioning and messaging that resonates with our target buyer personas and sets our products/services apart from others in the market to give them unique selling points. Develop the business case for new products, improvements to existing products, and business initiatives. Drive the marketing effort in developing a detailed go-to-market plan, including key activities and budgets to support the acquisition of new customers and launch of new products and releases of existing products based on the needs of the semiconductor market. You will work in concert with marketing for execution but will need to roll up your sleeves on some elements so being a Strategist and a Tactician combined needs to float your boat” and be something you truly enjoy. Coordinate go-to-market activities and create sales enablement tools such as white papers, product guides, product videos, technical briefs, presentation decks, etc. This requires a balance of hands-on materials creation as well as working with external agency and contractor resources. Drive awareness and lead-generation for Tignis’ solution via social media, blogging, published articles, webinars, email marketing, online advertising, trade shows/events, etc. Substantial experience with semiconductor process engineering as well as technologies and solutions in the semiconductor manufacturing process control marketplace including primary vendors, solutions and industry trends and dynamics is required. Personal networks that include buyers and influencers are of high value value. Ideally experience working both for a major semiconductor tool manufacturer and for a major semiconductor fab company. Demonstrated success in defining and launching products that meet and exceed business objectives. Working knowledge of data science, machine learning, and AI. Excellent and demonstrable written and verbal communication skills including the ability to create and deliver effective presentations. Must be a self-starter who truly enjoys working in a fast-paced, innovative software and services development environment. Ability to prioritize and balance strategic thinking with day-to-day execution and ability to manage uncertainty. Sincere empathy for the customer and a commitment to delving deep into the challenges they present or experience. Proven ability to influence cross-functional teams without formal authority Superior project management and interpersonal skills Ability to maintain a keen attention to detail, multitask, and work well under pressure. Natural tendency to be curious, positive, and creative. Team player who collaborates well with others. 7+ years of experience in technical product marketing, product management, or sales engineering, or sales targeted at the semiconductor process control market. Bachelor degree in an Engineering field or equivalent work experience. MBA valued. 
ScrapedJobID763:
Lead a team of passionate data scientists focused on understanding members’ habits, driving new advanced features in a data-driven manner, and creating member-facing metrics to track their progress and motivate them Review the team’s designs, algorithms, and code while also spending time developing your own Lead the initiative to fully leverage the world's best and largest fitness dataset to derive insights about member's habits and motivations Work closely and collaborate with a cross-functional team of Product Manager, Designers, and Engineers to drive new, innovative, data-driven functionality Create metrics to motivate members and track their progress Analyze member behavior and engagement to inform feature roadmap and marketing Drive direction of Tonal’s architecture, data collection, analytics, infrastructure, tools, and learning systems Identify innovative opportunities for new data-driven features Advanced degree in engineering, scientific, or mathematical field 5+ years data science experience 2+ years leading and/or managing technical teams Knowledge of machine learning, probability, and statistics Strong knowledge of Python and SQL Strong data visualization Ability and desire to explain complicated concepts simply Team player with high integrity Open to feedback and constantly striving to learn and improve High degree of self-awareness Knowledge of Snowflake, DBT, Looker, and Amplitude 
ScrapedJobID764:
Work with business partners to design new workflows to transform business requirements into concrete insights. Mentor team to parse, normalize and explore financial markets data via multiple consumption methods (Message Buses, SFTP, SQL connectors, APIs). Enable the team to work efficiently through challenges and a variety of complexities through consultation as well as removing roadblocks. Monitor existing controls’ effectiveness and develop automated procedures to optimize workflow. Work as Part of a global team with internal/external partners.Engage with R&D teams by taking an active role in the development lifecycle and design sessions. Minimum 4 years of hands-on analytical experience in working as a Data Engineer, Professional Services or a Data Analyst. Experience in working with relational / non-relational data bases to turn into insights - Must Experience leading projects end to end including international stakeholders. Hands-on experience in Scripting Languages (Python) - Big Advantage Experience with REST APIs , Message bus and Linux environment – Big Advantage. Experience in troubleshooting code and logs – Big Advantage Excellent interpersonal and communication skills in English. 
ScrapedJobID765:
A team player who can work within an integrated team of product managers, designers, and developers. Expert critical thinking and problem-solving skills with a keen eye to apply machine learning solutions to solve interesting customer problems. Effectively translate requirements into feasible machine learning solutions. Develop, drive, and execute the long-term vision and strategy for content understanding and machine learning platforms. Ensure the development of consistent high quality data products. Standardize data quality measurements by establishing metrics, building tools and processes. Work with external vendors and aid build vs buy decisions. Work closely with data privacy and data security teams at Medchart to help guide the data privacy policies and comply with data protection regulations. Research state-of-the-art methods in language modelling and related natural language. processing problems, data extraction, and other machine learning problems. Prototype novel methods and productionize promising methods. Build Medchart’s machine learning pipeline. Live our company values of humble, hungry, and care BS, MS or Ph.D. in Computer Science or related field 3+ years of professional or academic experience in machine learning 5+ years of experience building clean, maintainable, and well-tested code. You are adept at machine learning algorithms. Proven ability to apply, debug, and develop machine learning models for real-world applications (especially NLP) Accomplished problem solver, able to think both creatively and methodically. Able and eager to learn about the latest technologies and ML best practices. Effective communicator who can translate complex technical concepts into simple ideas depending on the audience. Hands-on experience on large scale machine learning systems (full ML stack from modelling to deployment at scale.) Hands-on experience with big data technologies (e.g., Hadoop/Spark). Hands-on experience with medical data. Health and Lifestyle benefit spending accounts Results-oriented work environment Frequent wellness initiatives Currently in a work from home environment with offices in Toronto, Waterloo, and Dallas A positive, diverse, and growth-oriented team environment 
ScrapedJobID766:
Provides advanced data science expertise to AstraZeneca projects and recommends data science solutions. Delivers advanced data science solutions to AstraZeneca projects, appropriately communicating with non-technical stakeholders. Works within established frameworks to deliver a variety of tasks that support projects in meeting their objectives. Independently keeps own knowledge up to date and learns from senior team members, proposing appropriate training courses for personal development. Reviews working practices and ensures non-compliant processes are escalated Ensures own work is compliant within Clinical Development. Collaborate in a multidisciplinary environment with world leading clinicians, data scientists, biological experts, statisticians and IT professionals. M.Sc. degree in rigorous quantitative science (such as mathematics, computer science, engineering) or have demonstrated an outstanding track-record of industry experience with the desired data science methodologies Practical software development skills in standard data science tools: Python, Agile, Code versioning (bitbucket/git), UNIX skills, familiarity working in cloud environment (AWS preferred) AWS or other cloud compute experience including SysOps (provisioning resources required for analytics, Kubernetes, infrastructure as code is a bonus) Data visualization & interactive data visualization (interactive dashboards w/ DASH & static visualization) Experience developing machine learning first products including timeseries analysis, forecasting, behavioral analysis Knowledge of range of mathematical and statistical modelling techniques and drive to continue to learn and develop these skills. Minimum 2+ years of industry experience or post-doctoral work. Ph.D. degree in rigorous quantitative science (such as mathematics, computer science, engineering) Experience within the pharmaceutical industry Advanced experience with Kubernetes and machine learning product architecture Communication, business analysis, and consultancy Advanced machine learning models: transformer-based NLP models, reinforcement learning, GNNs, state-of-the-art timeseries & forecasting models ML Ops experience: model tracking, model governance, multiple models in different production contexts Data visualization & interactive data visualization (interactive dashboards w/ DASH & static visualization) Our Social Media, Follow AstraZeneca on LinkedIn https://www.linkedin.com/company/1603/ Follow AstraZeneca on Facebook https://www.facebook.com/astrazenecacareers/ Follow AstraZeneca on Instagram https://www.instagram.com/astrazeneca_careers/?hl=en 
ScrapedJobID767:
Develop machine learning solutions to integrate into our products Balance building technically advanced solutions and swiftly shipping Keep pace with developments in Deep Learning relevant to our activities (papers, conferences, etc.) Work with a diverse team of talented ML Engineers, Backend Engineers, Developers in Test, and Product Managers Ability to write production-grade code in Python Hands-on experience with any of these frameworks: Tensorflow, PyTorch Passion for learning new things and bringing in new ideas Experience with video processing, Risk scoring, Fraud solutions Friendly and supportive Adaptable and flexible Articulate and persuasive High IQ and EQ Curious and coachable Commercially Aware Resilient and tenacious Big picture and the detail IDEAL: Integrity, Diversity, Empowerment, Accountability, Leading Innovation 
ScrapedJobID768:

ScrapedJobID769:
Participate in the evaluation, design and implementation of technological processes to improve the accuracy and efficiency of loan origination and processing activities Proactively communicate and collaborate with stakeholders to identify information needs and functional requirements; translate into technical specifications and delivering appropriate analysis as needed, e.g., functional requirements, business requirements, use cases Chair project meetings, drive clarification of requirements and remove roadblocks for multiple initiatives simultaneously; liaise between the business units, technology teams and support teams Ensure communication among key internal and external business partners, customers and other stakeholders regarding status, milestones, issue resolution and escalation of projects Closely collaborate with developers and subject matter experts to establish the technical vision and analyzing trade-offs between usability and performance needs; conduct technical testing on new systems, platforms and databases Manage third party vendors and investigate feasibility of integrations through API Design and conduct business performance variance analysis; create, generate and present reports or dashboards to deliver essential information to staff, management and IT professionals Own the reporting and creation of dashboards using Sisense, our data aggregation and BI tool; manage all regular and ad hoc data reporting activities Troubleshooting the reporting database environment and reports Evaluating changes and updates to source production systems Contribute to the establishment and promotion of a culture which promotes quality of work, service orientation and flexibility, through influencing attitudes, utilising industry best practices and ensuring the continual review and improvement of processes Maintain an extremely high degree of quality control at all times; ensure that all systems or process changes are fully tested and de-bugged before deployment to production Pursue the continued education in the area of data analysis techniques and financial technology systems and the flow of interconnected data between them You are a self-motivated quick learner as well as a change agent that has been making real impacts in organization(s) At least 5 Years in Business and Data Analyst related role(s) in the Financial Services industry Strong knowledge in basics of lending product life cycle, from origination & understanding to processing to loan servicing Direct BA experience in managing either a new system design & implementation, or significant system improvement projects Direct experiences in UAT and/or QA testing, Production support and troubleshooting/defect investigation Hands on experience in Data Analytics / Data Management and troubleshooting (such as SQL, ETL, Master Data Management Concepts, Data visualisation using SiSense or Similar) Hands-on experiences with system and data migration Strong Project Management skills including working with 3rd party vendor on software development Strong knowledge of JIRA and of at least one BI tool (SiSense, Tableau, Power BI, etc.) Nice-to-haves:
Knowledge of Salesforce (both CRM and PaaS) and basic understanding of Apex language
Direct experiences with APIs / Web Services Integration projects
Familiar with Change Management framework
Confluence, MS SharePoint Knowledge of Salesforce (both CRM and PaaS) and basic understanding of Apex language Direct experiences with APIs / Web Services Integration projects Familiar with Change Management framework Confluence, MS SharePoint Scope of responsibilities for this opportunity may change and will include, but not be limited to the above description. 
ScrapedJobID770:
Conduct design and development to build and optimize deep learning software and hardware to accelerate deep learning on FPGAs. Design, develop and optimize for deep learning training and inference frameworks. Transform computational graph representation of neural network model. Optimizing code for FPGA computing hardware backends. Interacting with deep learning researchers and experience with deep learning frameworks. Problem Solving skills. Written/verbal communication skills. The candidate must have a Master's degree in Electrical Engineering, Computer Engineering, Computer Science or a related field. FPGA, Verilog, C/C++ and/or Python. Algorithms development. 
ScrapedJobID771:
Ensure proper data set up and management in Mattel systems Perform audits regarding data integrity for key parameters like pricing, sourcing information Perform quantitative and qualitative analysis of internal data including: demands, inventory, level of excess. Provide ad hoc analysis to meet business needs. Collaborate and support with the Demand Planning process Measure and communicate the KPI’s on regular basis Work with Sales, Marketing, and Planning to provide full transparency on key aspects of the business Provide monthly metrics reporting on net change from previous month’s supply, invalid items, programs, forecast accuracy, etc. and the resulting operational impact Set up mechanisms/new ways to detect and highlight critical forecast changes (i.e. short avails), continuously propose ways to avoid unshippables. Prepare information required for monthly demand meetings Develop reporting tools to improve the planning processes and support business decisions Create data dashboards, graphs and visualizations and continue our drive for data automation through visualization platforms like Tableau or Thoughtspot Mine and analyze large datasets, draw valid inferences and present them successfully to management using a reporting tool. Produce regular weekly / monthly business summaries that increase knowledge and insights into our impact at the point of purchase Highly audience aware and engaged, equally able to consolidate large quantities of data and insight into short form hard hitting content as with getting into highly granular depths of detail. Proactively interrogate external data and insights resources to contextualize Mattel performance and inform and challenge key stakeholders Utilizes tools to create simpler, faster, better reporting Solid interpersonal and communication skills – able to communicate effectively across all organizational levels and all functional areas, understanding and presenting the viewpoints of others Sound business judgment – able to interpret issues and recommend actions to best support group, division, and corporate goals Strong analytical skills – able to coordinate diverse information, identify relevant data, recommend, and implement corrective actions Able to identify and address process improvements and share expertise with others Ability to influence and achieve expected results independently by establishing effective cross-functional & cross-culture relationships High level of organizational and time management skills. Advanced/expert proficiency with Excel and VBA Extensive knowledge of Access will be an asset Extensive knowledge and usage of Mattel’s systems and Cognos will be an asset Exceptional problem solving & analytical ability Ability to perform in a demanding ,dynamic, highly visible organization 1+ years in a supply chain role is an asset Working knowledge of a demand planning tools We collaborate: Being a part of Mattel means being part of one team with shared values and common goals. Every person counts and working closely together always brings better results. Partnership is our process and our collective capabilities is our superpower. We innovate: At Mattel we always aim to find new and better ways to create innovative products and experiences. No matter where you work in the organization, you can always make a difference and have real impact. We welcome new ideas and value new initiatives that challenge conventional thinking. We execute: We are a performance driven company. We strive for excellence and are focused on pursuing best in class outcomes. We believe in accountability and ownership and know that our people are at their best when they are empowered to create and deliver results. 
ScrapedJobID772:
Defining analytical requirements for projects and writing design documents for analytical solutions (web and mobile platforms); Performing quality assurance on collected data; Configuring analytics tools such as Google Analytics and Google Tag Manager; Developing automated and multi-channel dashboards for monitoring client performance; Contributing to the development of digital strategies for various clients and collaborating with strategic planners to identify opportunities through available data; Collaborating on data-based recommendations and supporting internal teams in their implementation; Defining KPIs with clients and ensuring their measurement; Monitoring the latest trends/news in web analytics and data science; Supporting the content team in the performance analysis of clients' social media networks and platforms. Diploma in e-commerce, marketing, business intelligence, or equivalent related program; Experience as a web analytics specialist or equivalent; Experience with one or more web analysis tools such as Google Analytics, Google Tag Manager, Facebook Insights, and Twitter Analytics; Experience with one or more reporting and dashboarding tools such as Google Data Studio and Tableau; Fluent in written and spoken English and French (our clients are international); Intermediate to advanced understanding of web technologies (HTML, CSS, cookies, JavaScript, etc.); Experience communicating and justifying recommendations to multidisciplinary teams and clients. Certification in Google Analytics IQ (individual qualification); Knowledge of Adobe Analytics and Adobe Dynamic Tag Management; Knowledge of A/B testing tools such as Optimizely and Visual Website Optimizer; Knowledge of best practices for search engine optimization (SEO); Basic knowledge of marketing automation tools: Salesforce Marketing Cloud, Adobe Campaign, Marketo; Knowledge of social media analysis tools: Netbase, Brandwatch. Large-scale digital projects for major clients around the world; A competitive offer and wide range of social benefits from day one; A hybrid Agile methodology enriched by collaboration with passionate experts; The option of working 100% remotely, with access to a collaborative office space; A flexible schedule that truly allows work-life balance; A personalized development plan supported by our continuing education platforms. 
ScrapedJobID773:
Provide guidance and mentorship to junior team members Report on team progress and identify any risks to data analysis schedule Monitor in-field progress and activities to validate projects remain on schedule Managing master data files including creation, updates, and deletion. Collaborating with in-field data collection users, project managers, and other stakeholders. Provide quality assurance of imported data Processing confidential data in accordance with guidelines Helping develop reports and analysis Supporting the database with respect to identifying and revising reporting requirements Supporting initiatives for data integrity Learn and use task-specific software Generating reports from single or multiple systems Attend meetings with team members Other duties as required Ability to effectively supervise and develop junior staff Proficient in typing, working in databases, and computer office software such as MS Office Work experience as a data analyst or related field Ability to communicate effectively with various internal and external personnel for the purposes of gathering, relaying, and coordinating information with office and field staff. Strong verbal and written communications Working in a team environment Legally eligible to work in Canada On-site parking Paid time off 8 hour shift Monday to Friday English (required) No 
ScrapedJobID774:
Manage client relationship and key stakeholders Collaborate with client to align business requirements with data science systems and process solutions that ensure client’s overall objectives are met Collaborate and work closely with cross-functional antuit.ai and the domain experts to design and deliver the solution Create meaningful presentations and analyses that tell a “story” focused on insights, to communicate the results and ideas to key decision makers in antuit.ai and client companies Monitor, track, and report project progress to internal and external key stakeholders Lead and mentor a global services team of technical and analytical experts who deliver value to our customers both in the CPG and Retail world Develop and manage processes, systems, and KPIs for delivery excellence Advise on implementation strategies and best practices Develop, implement, and oversee the execution of implementation projects Ensure high quality proactive communication with our customers Provide non-technical support during the "go-live" period. Take hands-on role with our customers and team members, helping navigate challenging situations to achieve positive results for all parties Provide input to the product roadmap based on customer needs and experiences Master’s degree or Bachelor’s degree with relevant industry experience will be considered in lieu of advanced degree. Strong project management and organizational skills 5+ years of experience in CPG/retail particularly in forecasting 5+ years of experience with implementing Demand Planning, Sales Planning, or Advanced Planning solutions. 2+ years of experience with AI/ML solutions Relevant solutions consulting and implementation experience with other leading supply chain planning solutions such as Oracle, Blue Yonder / JDS, SAP, or similar. Strong business analysis skills, understanding and usage of statistical algorithms, SCM concepts, awareness of tactical planning on overall supply chain required. Must have excellent communication and interpersonal skills to interact with a wide variety of internal and external personnel, with emphasis on follow-through and reporting. Understand and adhere to Information Security policies, guidelines and procedure, practice them for protection of organizational data and Information System. Take part in Information Security training and act accordingly while handling information. Report all suspected security and policy breach to Infosec team or appropriate authority (CISO). 

ScrapedJobID775:
Collaborate with data engineers to build a robust, high-scalable data pipeline and API to power our machine learning products. Take ownership of developing high-quality products from concept to production, including requirements gathering, feature creation, testing, documentation, deployment, A/B testing evaluation and post production support. Collaborate with devops to create AWS Infrastructure as code for all your applications. Collaborate with data scientists to build products around ML models, reconcile the process and modularize work Following AWS well-architected framework to bring and apply industry engineering best practices Drive innovation through iteration. Degree in Computer Science or Software Engineering or any relevant background required 3+years of experience in software development or data engineering for an intermediate level 5+ years of experience for a senior level Proficient and hands on with at least one programming language, prefer Python/Java Experience in Event driven architecture using AWS Lambda, ECS/Fargate, API Gateway, Kinesis, DynamoDB, EventBridge, S3, SQS, SNS Familiar with Twelve-Factor App methodology ( https://en.wikipedia.org/wiki/Twelve-Factor_App_methodology ) Understanding of IAM policies and roles Familiar with cloud architecture and security Familiar with Codepipleline and Codebuild Familiar with test driven development methodologies Nice to have: Familiar with continuous integration and continuous delivery Nice to have: Infrastructure as code experience, such as Terraform or CloudFormation or CDK High level of personal accountability, self-motivated Strong communication, verbal and written skills Quick learner, solution-oriented, able to implement prototypes with new tools quickly Comfortable taking on new challenges with a high willingness to learn Creative and out-of-the-box thinking to come up with alternative solutions to meet the business requirements 
ScrapedJobID776:
Bonus pay Casual dress Company events Dental care Disability insurance Employee assistance program Extended health care Life insurance RRSP match Tuition reimbursement 8 hour shift Monday to Friday Are you legally entitled to work in Canada? applicable: 1 year (preferred) Temporarily due to COVID-19 
ScrapedJobID777:
Produce insightful business intelligence related to the Supply Chain Distribution Centres, Transportation teams, and Time Critical businesses globally. Support the development of key processes to design and manage Supply Chain performance management reporting leveraging data analysis while ensuring linkage to the strategic planning process. Manage data and data mining as well as translating financial data. Provide analytical support through data collection and analysis to support business decision making. Use expertise in project management, financial modeling, analytics and insights identification to support strategy Drive the effective utilization of business intelligence tools and other commercial tools designed to improve operational effectiveness to drive growth across the organization Work proactively with key business partners to identify opportunities and to drive transformational business growth initiatives, which deliver customer and shareholder value and meet targets as agreed with company senior leadership. University/College degree in Data Science/Analytics, Engineering, or related field 2+ years of relevant and demonstrable experience in the business intelligence and analytics field. Strong understanding in SQL programming language, SQL Server Analysis Services (SSAS), SQL Server Reporting Services (SSRS) Strong understanding of cloud-based platforms (Azure, Snowflake, others) and data science tools (R, Python, Apache Spark, others) Proficient in ETL (extract, transform, load) Expert knowledge of data visualization tools – must have Microsoft PowerBI Advanced Microsoft Office skills (Access, Excel, PowerPoint and Outlook). Experience working with queries, VBA and macros. Advanced Excel / Modelling skills with the ability to manipulate and analyze large volumes of data. They will be able to identify key business drivers and provide incisive commentary. Experienced in database design, data architecture, data mining, and analytics A high performing and motivated individual Creative, agile, and innovative, able to manage in an environment of change and ambiguity Build, launch and manage launching initiatives/strategies producing results for our organization and customer. Advanced Excel / Modelling skills with the ability to manipulate and analyze large volumes of data. A natural leader, not afraid of questioning the norm and changing behaviours. Problem solver with the ability to analyze and prioritize to meet business objectives A strong business acumen and thrives on bringing data and numbers to life with excellent analytical skills A high performing and motivated individual who is: Problem solvers with the ability to analyze and prioritize to meet business objectives A strong business acumen and thrives on bringing data and numbers to life with excellent analytical and visualization skills Project management mastery Humble intelligence and confidence Great attitude and demonstrated ability to roll-up sleeves and work with team members in a hands-on capacity Ability to have fun, work hard and make a difference The opportunity to build a career with a growing company Company provided medical, dental, and vision coverage for you and your family Life and disability insurance Wellness programs include an Employee Assistance Program to support your family’s well-being A Retirement Savings Program Company sponsored social events Employee Appreciation Day Community volunteering Company team wear allowance 
ScrapedJobID778:
Bachelor's degree in Engineering, Statistics, Computer Science, Mathematics, or a related quantitative discipline 4+ years of work experience of analyzing and interpreting data as a business intelligence engineer, data engineer, or at a similar capacity Working knowledge of data mining and modeling using statistical software like R, Python, Matlab, etc Advanced knowledge of SQL, intermediate knowledge of Python Proficient using at least one data visualization product (Tableau, Qlik, Amazon QuickSight, Power BI, etc.) Experience working with large, multi-dimensional datasets from multiple sources Ability to work cross-functionally, building and maintaining trust with internal stakeholders Engage with leadership and diversified customer groups to understand the needs and recommend business intelligence solutions. Partner with Data engineering team to define the data elements and data structure that the team should leverage to enable analytical capabilities. Design, implement, and support platforms that provide business teams ad-hoc access to large datasets (eg data visualization tools for non-tech business users) Interface with business customers, gathering requirements and delivering complete reporting solutions. Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions. Support and enhance, stakeholder experience and models of optimization decisions in multiple production planning systems. Participate in strategic & tactical planning discussions. Standardize data and report consumption across all customer groups. Make recommendations for new metrics, techniques, and strategies to improve the operational and quality metrics. Be connected and influential within the Amazon BI community. Work with Data engineering, Software development teams to enable the appropriate capture and storage of key data points Drive process efficiency and automation 5+ years of work experience of analyzing and interpreting data as a business intelligence engineer, data engineer, or at a similar capacity. Experience with AWS technologies including Redshift, S3, EMR, and QuickSight Experience with creating and building predictive/optimization tools that benefit the business and improve customer experience 
ScrapedJobID779:
real-time visibility on how Ubisoft titles are played; and an understanding of the habits and preferences of the people playing them. Design, prototype, develop and maintain a frontend application, and backend API services to meet the needs of internal clients. Compile, understand and evaluate product requirements + participate in developint new features. Work closely with the UI/UX team to ensure GUI consistency Identify opportunities to improve our Machine Learning Platform, in close collaboration with the Data Scientists and the other developers of the team. Reviewing code and content changes from other developers on projects Write high quality code as well as solid tests (E2E, Unit...) 2+ years of experience as a full stack developer (or relevant experience) Good knowledge of back-end components (API/REST/caching) and front-end development. Previous experience with Angular, NestJS, NodeJS... Experience in iterative-based delivery of solutions with unfinalized requirements, complex tech projects etc Resourcefulness, initiative and ability to resolve issues through elegant and innovative solutions Solid communication, interpersonal, and presentation skills A collaborative and innovative spirit Basic understanding of ML concepts and Big Data/Cloud technologies. Interest in DevOps (deployment, ongoing integration) Knowledge of Python and Java Experience with modern infrastructure and cloud technology (e.g., AWS, EMR, Docker and Kubernetes) An interest in the video game industry. Your CV, highlighting your background and skills 
ScrapedJobID780:
real-time visibility on how Ubisoft titles are played; and an understanding of the habits and preferences of the people playing them. Design, develop, and optimize extremely efficient and reliable data pipelines to prepare data for the Machine Learning use cases. Work closely with our clients/partners, internal Data Scientists and Developers on diverse data pipelines (batch and stream processes). Play a key role in the creation and improvement of our new Feature Sore solution, aimed to be the central point of interactions for the Data Scientists and everything happening on the platform. Synch up with your team to discuss work-in-progress, ideas, and blockers; plan and prioritize; overcome issues; etc. Be a key member of the team, participate in the decisions and implementations to improve the platform’s quality. Stay current on technological advancements to help develop yourself, the platform and position Ubisoft as a leader of the domain. Minimum 4 years of data engineering design/development experience in building very large data products, ideally in an AI/ML environment. Experience working with Spark and Kafka streams, plus other big data technologies (e.g. Flink, Hadoop, Hive, Athena, etc.) Solid programming knowledge in multiple languages (SQL, Python, Java, Scala...). Previous experience using cloud technology, ideally AWS (S3, EMR, DynamoDB, SageMaker...) Understanding of microservices architecture and REST APIs. Knowledge of CI / CD and associated best practices. Good understanding of ML concepts (Features, models...). Strong communication and collaboration skills. A constant desire to grow and learn and to see teammates succeed together. Experience building and interacting with REST APIs ingesting/serving large amount of data. Already worked on implementing and maintaining a Feature Store. Familiarity with industry standards such as Airflow. Knowledge of Kubernetes, Docker and other DevOps/MLOps technologies. Experience with designing and deploying Data Science/ML solutions in the cloud. An understanding of the video game industry. 
ScrapedJobID781:
Participate in the evaluation, design and implementation of technological processes to improve the accuracy and efficiency of loan origination and processing activities Proactively communicate and collaborate with stakeholders to identify information needs and functional requirements; translate into technical specifications and delivering appropriate analysis as needed, e.g., functional requirements, business requirements, use cases Chair project meetings, drive clarification of requirements and remove roadblocks for multiple initiatives simultaneously; liaise between the business units, technology teams and support teams Ensure communication among key internal and external business partners, customers and other stakeholders regarding status, milestones, issue resolution and escalation of projects Closely collaborate with developers and subject matter experts to establish the technical vision and analyzing trade-offs between usability and performance needs; conduct technical testing on new systems, platforms and databases Manage third party vendors and investigate feasibility of integrations through API Design and conduct business performance variance analysis; create, generate and present reports or dashboards to deliver essential information to staff, management and IT professionals Own the reporting and creation of dashboards using Sisense, our data aggregation and BI tool; manage all regular and ad hoc data reporting activities Troubleshooting the reporting database environment and reports Evaluating changes and updates to source production systems Contribute to the establishment and promotion of a culture which promotes quality of work, service orientation and flexibility, through influencing attitudes, utilising industry best practices and ensuring the continual review and improvement of processes Maintain an extremely high degree of quality control at all times; ensure that all systems or process changes are fully tested and de-bugged before deployment to production Pursue the continued education in the area of data analysis techniques and financial technology systems and the flow of interconnected data between them You are a self-motivated quick learner as well as a change agent that has been making real impacts in organization(s) At least 5 Years in Business and Data Analyst related role(s) in the Financial Services industry Strong knowledge in basics of lending product life cycle, from origination & understanding to processing to loan servicing Direct BA experience in managing either a new system design & implementation, or significant system improvement projects Direct experiences in UAT and/or QA testing, Production support and troubleshooting/defect investigation Hands on experience in Data Analytics / Data Management and troubleshooting (such as SQL, ETL, Master Data Management Concepts, Data visualisation using SiSense or Similar) Hands-on experiences with system and data migration Strong Project Management skills including working with 3rd party vendor on software development Strong knowledge of JIRA and of at least one BI tool (SiSense, Tableau, Power BI, etc.) Nice-to-haves:
Knowledge of Salesforce (both CRM and PaaS) and basic understanding of Apex language
Direct experiences with APIs / Web Services Integration projects
Familiar with Change Management framework
Confluence, MS SharePoint Knowledge of Salesforce (both CRM and PaaS) and basic understanding of Apex language Direct experiences with APIs / Web Services Integration projects Familiar with Change Management framework Confluence, MS SharePoint Scope of responsibilities for this opportunity may change and will include, but not be limited to the above description. 
ScrapedJobID782:
Ensure proper data set up and management in Mattel systems Perform audits regarding data integrity for key parameters like pricing, sourcing information Perform quantitative and qualitative analysis of internal data including: demands, inventory, level of excess. Provide ad hoc analysis to meet business needs. Collaborate and support with the Demand Planning process Measure and communicate the KPI’s on regular basis Work with Sales, Marketing, and Planning to provide full transparency on key aspects of the business Provide monthly metrics reporting on net change from previous month’s supply, invalid items, programs, forecast accuracy, etc. and the resulting operational impact Set up mechanisms/new ways to detect and highlight critical forecast changes (i.e. short avails), continuously propose ways to avoid unshippables. Prepare information required for monthly demand meetings Develop reporting tools to improve the planning processes and support business decisions Create data dashboards, graphs and visualizations and continue our drive for data automation through visualization platforms like Tableau or Thoughtspot Mine and analyze large datasets, draw valid inferences and present them successfully to management using a reporting tool. Produce regular weekly / monthly business summaries that increase knowledge and insights into our impact at the point of purchase Highly audience aware and engaged, equally able to consolidate large quantities of data and insight into short form hard hitting content as with getting into highly granular depths of detail. Proactively interrogate external data and insights resources to contextualize Mattel performance and inform and challenge key stakeholders Utilizes tools to create simpler, faster, better reporting Solid interpersonal and communication skills – able to communicate effectively across all organizational levels and all functional areas, understanding and presenting the viewpoints of others Sound business judgment – able to interpret issues and recommend actions to best support group, division, and corporate goals Strong analytical skills – able to coordinate diverse information, identify relevant data, recommend, and implement corrective actions Able to identify and address process improvements and share expertise with others Ability to influence and achieve expected results independently by establishing effective cross-functional & cross-culture relationships High level of organizational and time management skills. Advanced/expert proficiency with Excel and VBA Extensive knowledge of Access will be an asset Extensive knowledge and usage of Mattel’s systems and Cognos will be an asset Exceptional problem solving & analytical ability Ability to perform in a demanding ,dynamic, highly visible organization 1+ years in a supply chain role is an asset Working knowledge of a demand planning tools We collaborate: Being a part of Mattel means being part of one team with shared values and common goals. Every person counts and working closely together always brings better results. Partnership is our process and our collective capabilities is our superpower. We innovate: At Mattel we always aim to find new and better ways to create innovative products and experiences. No matter where you work in the organization, you can always make a difference and have real impact. We welcome new ideas and value new initiatives that challenge conventional thinking. We execute: We are a performance driven company. We strive for excellence and are focused on pursuing best in class outcomes. We believe in accountability and ownership and know that our people are at their best when they are empowered to create and deliver results. 
ScrapedJobID783:
Take a hands-on role in several projects, including the Fundamental Review of the Trading Book (FRTB), data solutions for capital optimization, and data quality control processes. Prototype new approaches and enhance existing methodologies to advance market data management and data quality control. Develop production level code and collaborate with IT team for integration into daily bank processes. Assist team members for various ad-hoc analyses, data methodology, documentation, reporting, preparation of materials. Execute model runs on a regular basis for reporting and perform corresponding analyses. Communicate with model developers, trading desks, risk teams, and business lines to enhance data quality control and data management for capital optimization Become an active member of the team including our D&I initiatives and communities. Solid quantitative background and problem-solving skills with a keen interest in Data Science, Finance, Economics, Market Risk, Derivatives Pricing, Risk management or Regulations. Advanced degree in a mathematics, economics, or scientific discipline (e.g., Mathematics, Finance, Statistics, Physics, Engineering, Biology, Economics, etc.). Master’s degrees or PhDs are a bonus. Experience in code development in Python or other formal programing will be important to support day-day activity. Effective communication (written and oral), specifically the ability to summarize complex ideas in simple terms; you enjoy working in collaborations. The opportunity to join a forward-thinking company surrounded by a collaborative team of innovative thinkers. A rewarding career path with diverse opportunities for professional development. Internal development to support your growth and enhance your skills. A competitive compensation and benefits package. An organization committed to making a difference in our communities– for you and our customers. We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success! 
ScrapedJobID784:
Applies in-depth disciplinary knowledge, contributing to the development of new techniques and the improvement of processes and work-flows. Coordinates and contribute to the objectives of data science initiatives and overall business through leveraging in-depth understanding of how areas collectively integrate within the sub-function. Assumes informal/formal leadership role through coaching and training of new recruits. Significantly influences decisions, work, and performance of all teams through advice, counsel and/or facilitating services to others in the business. Conducts strategic data analysis, identifies insights and implications and make strategic recommendations, develops data displays that clearly communicate complex analysis. Mines and analyzes data from various banking platforms to drive optimization and improve data quality. Delivers analytics initiatives to address business problems with the ability to identify data required, assess time & effort required and establish a project plan. Consults with business clients to identify system functional specifications. Applies comprehensive understanding of how multiple areas collectively integrate to contribute towards achieving business goals. Consults with users and clients to solve complex system issues/problems through in-depth evaluation of business processes, systems and industry standards; recommends solutions. Leads system change process from requirements through implementation; provides user and operational support of application to business users Formulate and define systems scope and objectives for complex projects through research and fact-finding combined with an understanding of applicable business systems and industry standards. Impacts the business directly by ensuring the quality of work provided by self and others; impacts own team and closely related work teams. Considers the business implications of the application of technology to the current business environment; identifies and communicates risks and impacts. Drives communication between business leaders and IT; exhibits sound and comprehensive communication and diplomacy skills to exchange complex information. Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. 5-8 years experience using tools for statistical modeling of large data sets Ability to effectively use complex analytical, interpretive and problem solving techniques Demonstratedinterpersonal, verbal and written communication skills Bachelor’s/University degree or equivalent experience 
ScrapedJobID785:

ScrapedJobID786:
Ongoing practice and process development looking for ways to improve and streamline Cardinal Path’s processes to not only deliver a superior service to our clients, but also to improve our efficiency and profitability. Mentoring/managing Data Science team members Partner with your Group Director to educate clients on the value of adding Data Science products to their business, capturing & defining needs and solutions Synthesize business needs and create business/functional design documents which can be used to build analysis and data models around. Assess data for validity in terms of predictive capabilities, required feature engineering, opportunities for data widening, or alignment to business requirements Develops, implements, and supports methodologies, standards, and tools for analysis and data science work. Build cooperative, productive relationships with clients and vendors by utilizing excellent communication skills, while also interacting effectively internally and externally. Research, prototype, and explore future, non-standard analytics approaches that push the limits of current analysis output. This will include exploring novel machine learning techniques which enable our teams to tackle segmentation, clustering, and predictive models used in a wide variety of areas. Bachelor’s degreein Mathematics, Statistics, Business Analysis or related 5+ years’ experience as an Analyst / Data Scientist 2+ years’ of managerial and leadership experience Advanced knowledge of R, Python or SAS for model development Previous experience with web analytics tools such as Adobe Marketing Cloud, Google Analytics Extensive experience with statistical modelling techniques Experience connecting Tableau or other visualization systems and using for dashboarding or analysis Self-motivated and ability to work independently in meeting deadlines Exceptional written and verbal communication skills and is comfortable working with remote teams Previous experience with marketing analytics including database marketing techniques, campaign lift, attribution and media mix modelling Familiarity with analyzing data for digital marketing and ecommerce, as well as all other non-digital aspects of a business SQL skills A solid knowledge of ETL tools Understanding of how to deal with larger data sets and parallel computing problem 
ScrapedJobID787:
Collaborate with the Marketing Strategy and Activation team to develop, execute, and analyze results for complex campaigns. Employ best practices of agile development and planned iterative delivery techniques Utilize third-party tools including Adobe Analytics, Adobe Launch, Adobe Target, Tableau, Google Marketing Platform and other marketing and advertising technology Assist in building and developing a team of talented Data Engineers, Marketing Analysts, and Analytics Translators Build relationships across Klick, working with Strategy, User Experience, Data Science and account teams for insights and to ensure that data is accessible, readily available and usable for analysis Employ best practices of agile development and planned iterative delivery techniques Demonstrate knowledge of diverse applications, platforms and technologies such as CRM/CMS/marketing automation systems ad be able to communicate requirements and create value in these areas Lead a continuous learning environment with respect to utilizing the latest methodologies, technologies, and illustrative best practices to tell stories which can drive business decisions Define approaches and lead projects that close data gaps and identify insights, as well as manage external partnerships and negotiate contracts with syndicated & custom insights suppliers Understand the contracted scope of work, proactively identifying potential out-of-scope activities and bringing to the attention of the project leader Work on business development efforts by providing ad-hoc feasibility reports, providing estimations of effort and developing methodologies that address client needs Provide selfless knowledge transfer and mentoring of junior team members. Potential for direct people management based on desire and prior experience Bachelor’s degree (Masters/PhD preferred) in statistics, information technology or computer science or other appropriate field of study The candidate must have 8+ years of experience consulting with clients on making strategic investment decisions to improve business results Strong client management/consultative experience both presenting and resolving issues. Extensive experience leading and managing marketing technology projects from ideation through installation Applied quantitative skills and the ability to roll up sleeves and dig into the numbers when necessary Matrix leadership qualities will be required to lead external and internal resources into new marketing effectiveness territories Strong attention to detail, and ability to quality check their teams’ work to ensure that data anomalies/mistakes are caught prior to delivery of the analysis to the client teams Be outgoing and able to integrate with a fast-paced Media Planning, Strategy, Technology and Activation teams Strong organization skills and ability to work on multiple tasks simultaneously while achieving quality standards and meeting deadlines with ambiguous requirements Excellent written and verbal communication skills. Strong interpersonal skills and ability to work collaboratively across teams Adobe Analytics Business Practitioner certification preferred 
ScrapedJobID788:
Completed post-secondary education in a related field (Data Science, Math/Statistics, Computer Science, Engineering), graduate level preferred 3 to 5 years of analytics experience with the understanding of growth analytics and product analytics. Significant experience working with methodologies such as predictive modeling, profiling, cohort analysis, segmentation forecasting, clustering, regression, operations research and data mining 2 or more years’ experience managing people Experience with SQL, Oracle, Teradatastudio, Python, SAS, Business Objects, Tableau, PowerBI and SAP BW preferred Experience using analytical concepts and statistical techniques Experience using analytics techniques to contribute to company growth efforts, increasing revenue and other key business outcomes. Excellent team building and leadership skills and experience Broad experience in business management, marketing, planning and finance, operation and project management, intimate knowledge of cross-enterprise functions and operations, is an asset. Demonstrated ability to build an analytical plan based on business issues Knowledge of IT processes and infrastructure required to support business intelligence and analytics Experience building aggregates and optimizing data workstreams Experience designing and assessing impact of A/B experiments in a fast-paced product development cycle Strong oral and written communication skills Technical background and programming experience–especially R or Python or familiarity with machine learning techniques is an asset. 
ScrapedJobID789:
Participating in requirements gathering / analysis, and solution documentation of large scale data transformation / feature engineering and loading routines Construction of robust data transformation / feature engineering and loading routines Working collaboratively with the data science team to engineer and integrate features from foundational data that are suitable for solving modelling problems Coming up with and conducting unit and integration test cases for data transformation and loading pipelines Assessing correlations and suitability for modelling of transformed data Curiosity with global regulatory regimes and anonymization frameworks and how they effect analytics and modeling outcomes Investigating and implementing ways to improve data reliability, efficiency, and quality Working creatively to understand, wrangle, and integrate diverse / unstructured data sources Collaborating with stakeholders including the product owners, data science, and design teams to assist with data-related technical issues and support their data infrastructure needs Bachelor’s degree in computer science, engineering, business, finance or a related area of study Upto 5 years experience in a similar role Excellent analytical and problem-solving skills Extreme attention to detail Familiarity with the modelling / analytics process, assessing the usefulness of data within that process Deep knowledge of SQL, “Big data” data pipelines, and architectures Experience with enterprise data modelling and architecture Experience working with big data tools like Apache Spark Experience working with large data sets, data pipeline and workflow management tools, and stream-processing systems Experience with data lineage concepts & related tools Experience with data cleansing, data masking for PII Experience implementing automated data quality validations within ETL pipelines Strong knowledge of Cloud environments (Unix/Windows, Virtualization, Containers, Data Management, CI/CD Management) Background in programming in Python, C, C++, or Java Experience with waterfall and agile methodologies Experience with, or willingness to develop and exercise skills in the areas of enterprise content management, web-based software applications, and application integration Ability to work cross-functionally with IT infrastructure and database administrator teams on project implementations Knowledge of Jira and Confluence Experience with OpenText Magellan Good written and verbal communication skills Able to build a sense of trust and rapport with the team and partners A self-starter attitude, a strong desire to learn as you go, and the belief that you can make a meaningful contribution to your immediate team, the business users that you serve, and to the organization 
ScrapedJobID790:
gives back to the community has leadership that inspires, coaches and mentors allows you to speak up and be heard AND ... likes to have FUN? Live and breathe Big Data and analytics systems such as Apache Spark and Big Query Utilize hybrid cloud-based infrastructure (Google and AWS) to collect and process massive volumes of data; Build data processing pipelines to mine location-based insights, create audience segments and integrate them with a myriad of DMP and DSP systems; Research and build Machine Learning solutions to solve some of our prediction problems Transform ML solutions into scalable production grade systems Brainstorm and create powerful visualizations that makes data accessible and understandable; Evaluate database solutions and help to define the architecture and design of data delivery systems; Contribute with development best practices and experiment with new ideas; Work collaboratively with cross-functional teams to identify creative solutions for data targeting, and plan and execute key products from concept to production Master’s Degree or equivalent in computer science / software engineering, preferably focused on data mining, machine learning, or related quantitative fields; Deep knowledge of SQL, MapReduce and other Big Data languages and processing frameworks; Experience designing and coding data pipelines in Python or Java; Experience writing reliable, scalable and clean code, while applying software engineering best practices Understanding of statistical and predictive modelling and machine learning approaches Accomplished in the use of data analysis and machine learning packages such as pandas, jupyter and scikit-learn/Spark ML; Big plus if you have knowledge of the advertising domain and its technology stack You have a passion for keeping up with the constant state of rapid evolution in the data world! You are a creative & innovative thinker You are entrepreneurial and take initiative, finding and executing great ideas with minimal resources You are a visionary! Someone who wants to leave a lasting impact on business You are excellent at communicating within a team and with clients You thrive under pressure and have no problem meeting deadlines Remote Work Environment #ChooseOurOwnAdventure . Read more about our remote work environment here! Summer Hours ️ Wellness Program Lunchtime virtual gym sessions? Count me in! Course Reimbursement Program – We want you to keep learning, so we can too! Personal Days in addition to Vacation days An extra day off during the month of your birthday - our gift to you! Open and transparent communication, including bi-weekly All Hands Meetings with our CEO Pelmorex Learning Academy includes offerings like French, Leadership (for people leaders and non-leaders alike), yoga, mindfulness Your mental health is important to us! We partner with Inkblot for virtual counseling sessions Free online doctor visits with Maple Online Healthcare Personal Spending Account - Full-Time employees will receive $500 per year While we encourage 1:1 conversations, we recognize that not everyone is comfortable with speaking up. We have an anonymous reporting platform (Speakfully) to ensure everyone’s voice is heard Weather is inclusive, we will be too. We have an IDEAS (Inclusion, Diversity, Equity, Awareness, Solidarity) team committed to making this happen! 
ScrapedJobID791:
Help our clients resolve their most complicated data & analytics problems to build, maintain, improve or re-architect solutions on Snowflake. Work with and lead cross functional teams on architecting, optimizing data systems and building them from the ground up. Help our clients understand advantages and disadvantages of specific Snowflake Data architecture choices and provide subject matter expertise and lessons learned for your previous projects. Develop highly efficient teams of internal resources and guide their development journey on Snowflake. Experience playing a key role where you were the lead (or one of) data or solution architect on at least 2 multi-million data projects (modernization, data lake build, migration, etc.) 3+ years of hands-on experience Snowflake (demonstrated via hands on, specific, project experience) with at least 1+ years using serverless architecture 5+ years of technology consulting or industry experience in data & analytics delivery 7+ years of progressive and diverse experience in data architecture (preferably on modern cloud data platforms) with unstructured data, Hadoop stack, data streaming, MPP architecture Effective communicator that can explain complex technical concepts to executives and business leaders Lead the way: Deloitte is not only leading the profession, but reinventing it for the future. We’re also committed to creating opportunity and leading the way to a more sustainable world. Serve with integrity: Deloitte has earned the trust of employees, clients, regulators, and the public for 175 years. Upholding that trust is our single most important responsibility. Take care of each other: We look out for one another and prioritize respect, fairness, development, and well-being. Foster inclusion: We are at our best when we foster an inclusive culture and embrace diversity in all forms. We know this attracts top talent, enables innovation, and helps us deliver well-rounded client solutions. Collaborate for measurable impact: We approach our work with a collaborative mind¬set, teaming across businesses, geographies, and skill sets to deliver tangible, measurable, attributable impact. 
ScrapedJobID792:
Machine learning et statistiques : élaboration de modèles explicatifs et prédictifs d'aide à la décision (algorithmes d'apprentissage supervisé et non supervisé, économétrie, prévision, diagnostic quantitatif, ...) Recherche opérationnelle : assistance à la conception et à la mise en oeuvre de solutions d'optimisation sous contraintes et de modèles de simulation Big Data : connaissances algorithmiques pour le traitement de grand volume de données et non structurées Le développement ou le renforcement de nos offres au travers de formations, de groupes de travail, de diffusion de support internes et externes... La politique de publication (blogs sectoriels, études, parution presse...) Le développement commercial en contribuant à la définition des besoins et en participant aux actions commerciales. Toute personne âgée de plus de 18 ans et de moins de 28 ans à la date d’inscription peut prétendre à un Volontariat International. Le départ en mission s’effectue au plus tard le jour de votre 29ème anniversaire. Au-delà, aucune dérogation n’est accordée. Vous devez être de nationalité française ou européenne (ressortissant des Etats membres de l'Espace Economique Européen qui regroupe les 27 Etats membres de l’Union européenne, la Norvège, l'Islande, le Lichtenstein) ou monégasque. Vous devez être en règle avec les obligations de service national du pays dont vous êtes ressortissant. Vous devez jouir de vos droits civiques et justifier d’un casier judiciaire vierge. 
ScrapedJobID793:
Assists with the ongoing conceptualization, development and implementation of an enterprise architecture. Partners with business line managers, providing technical and system expertise, to synergize IT strategic direction and product concepts. Partners with product development management to define IT strategic direction and assists in the mapping of projects to that strategic direction whilst ensuring product capabilities and process improvements are delivered over time within the framework of the IMS enterprise architecture. Leads cross-functional product development teams, acting also as a senior consultant to provide system and technical advice. Keeps up to date with technology changes and identifies opportunities for implementation in future systems. Incubate new ideas with working code for proof of concept Work with development teams to:
Direct their re-platforming efforts to use appropriate Functional Programming patterns
Code review and walkthrough
Coordinate interfaces and APIs (ReST and Scala) between the teams; drive adoption and agreement
Answer questions from the development teams on the platform Direct their re-platforming efforts to use appropriate Functional Programming patterns Code review and walkthrough Coordinate interfaces and APIs (ReST and Scala) between the teams; drive adoption and agreement Answer questions from the development teams on the platform Vet proposed architectures and advise on internal investment decisions Some travel will be required, as needed Ability to learn new frameworks, languages, paradigms, and techniques quickly and with little direction Strive to be a thought leader and advanced practitioner in creative tools and tactics; forward-thinking in understanding the emerging tools, technologies, and technology practices Functional programming and design experience in any language Strong Computer Science fundamentals and firm understandings of data structures and algorithms Relational database development and data warehousing know-how Object-oriented design, with a focus on type systems, static typing and application design patterns Prior experience of working in global teams. Skill to guide and coordinate with other developers SOA experience creating web services and APIs Test driven design and automated testing techniques Can take a passionate stand on technology and communicate across a large organization Development team leadership Azure or AWS experience building cloud native platforms Experience with Databricks, Azure Synapse, Snowflake Hadoop HDFS, Spark SQL, Scala, Dataframes, Streaming, MLlib, GraphX Passion for open source technologies, with a history of contributions Actor based concurrency systems (Akka, Scalaz, or Quasar) Apache Spark and related technologies (Hive, HDFS, Hadoop, YARN, Mesos) DevOps expertise (Git, Jenkins, Maven, SBT, Eclipse, IntelliJ, JIRA) CloudOps familiarity (IaaS like AWS, PaaS, Docker, Vagrant, Infrastructure as code, continuous deployment) Static code analysis tooling usage (SonarQube, Findbugs) Healthcare data a plus 
ScrapedJobID794:
You'll build frameworks & strategies to shape how we integrate data, tracking and analysis into everything we do — from quick social campaigns to larger activations — then iterate on them to improve. Revolutionize our data storytelling — in writing, in graphics / video, on social media & more. Act as a thought leader internally, as you evangelize & educate around best practices in creating data-backed frameworks. You will apply structure in the way that we measure our marketing campaigns and initiatives to ensure that we are optimizing for performance. Take lead in drawing insights from raw data sets in order to create new, exciting ways connect with our community and new fans. You are capable of applying your skills across a variety of use cases; inflexible specialists need not apply. We believe in processes and the power of planning, but you will often have to roll with the punches and prioritize the most impactful tasks on the fly. You've got a track record of working in Business Intelligence, with a history of driving business impact with data-driven analysis & presentation. You've got deep technical expertise in data systems, especially Google Cloud Console, Query, Excel, Tableau, PostgreSQL. If you have Python & R experience, too, that's even better. You've got an artistic bent, and know how to create compelling visuals using data. 
ScrapedJobID795:
Develop and maintain scalable and reusable data pipelines and APIs on cloud services such as AWS, to support all systems for all things ML related Develop and maintain logical and physical data models that support needs that are currently defined while being adaptable to future needs Work with business teams across the organization to understand their data-driven goals Bachelor’s degree in Computer Science or Engineering, or related field or relevant experience Experience building scalable data pipelines and databases on cloud services such as AWS Strong programming background. Python preferred. Experience building and integrating with 3rd party restful APIs Experience working with SQL, NoSQL databases (such as DynamoDB, MongoDB), and data warehouses (such as Snowflake, Redshift) Exposure to Docker, Kubernetes, Airflow, Spark an asset Familiarity with agile tooling to efficiently build as a team: Git, Jira, Confluence, etc. Experience working in Agile Scrum and Kanban environments Experience with infrastructure-as-code Excellent communication skills and stakeholder management Familiarity with data management capabilities (data registration, data quality, privacy and security.) and ability to learn advanced data management toolsets Be part of a collaborative, progressive and high-performing team, building revolutionary products that matter. Generous benefits, including a company match RRSP program. Continued professional development opportunities through programs such as Six Sigma. A modern workspace centrally located in Toronto’s thriving downtown core, easily accessed by transit and a few minutes’ walk from Union Station. Flexible time-off options 
ScrapedJobID796:
Collaborating with data scientists and protein engineers to plan and analyze experiments evaluating novel antibody sequence engineering methods. Developing data analysis and visualization platforms to adapt novel methods for large-scale protein engineering applications. Training and mentoring more junior scientists. Preparing and authoring materials to educate colleagues, and communicate strategies, key findings and implications. You are strongly self-motivated and work independently to identify project needs and follow that up with building and implementing solutions You’re passionate about understanding and telling the story behind your data A PhD or Master’s degree in Computer Science, Machine Learning, Computational Chemistry, Computational Biology or related field and 3+ years of related experience. Strong fluency in Python and associated data analysis stack A grounding in modern data analysis methods and statistics Experience with software engineering best practices, including version control and collaborative software development Strong interpersonal skills with the ability to work collaboratively as a member of cross-functional team Excellent verbal and written communication skills, including public presentation of complex data Experience with data presentation and visualization tools such as Plotly Dash or R Shiny A publication record in design and quantitative analysis of experiments in the life sciences Working knowledge of antibody structure and function Experience with “big-data” wrangling tools such as BigQuery, Spark or Presto in cloud-based environments such as AWS/Azure/GCP or Kubernetes The opportunity to work with an inspired team on challenging problems that matter An attractive compensation package, including health and lifestyle benefits A minimum of 3 weeks’ vacation Opportunities for personal and professional development 
ScrapedJobID797:
Design, build, evaluate and deploy robust, scalable, and production-ready ML models that enhance the speed and quality of life-saving research Collaborate with data and core infrastructure engineers to solve the complex problems of extracting insights from biomedical text data Continuously improve our machine learning workflow by keeping up to date with the latest optimizations in libraries such as PyTorch, and expand our usage of modern tools such as DVC Drive design discussions, apply best practices, diagnose problems and lead the resolution Own the solutions and long-term technical investments that will drive innovation at BenchSci Work cross-functionally with different stakeholders including BenchSci's R&D scientists and Chief Science Officer to learn, model, and capture the nuances of biology Participate and contribute to sprint planning, estimation, and design/code reviews Provide guidance to less experienced engineers and help to foster a culture of continuous growth Establish and apply best industry practices 4+ years of experience working as a professional developer or researcher applying machine learning techniques to solve business problems Strong experience with Python and programming fundamentals Extensive experience with NLP and PyTorch Experience with designing, building, and evaluating robust and scalable production-ready ML models Experience with complex problem solving and an eye for details such as scalability and performance of a potential solution Experience with data manipulation and processing, such as SQL or pandas A growth mindset and a constant desire to learn Strong cross-team communication and collaboration skills Research publications in ML/AI-related fields Experience working with cloud environments and services Experience with computer vision A degree in Computer Science, Mathematics, or other closely-related disciplines Remote first culture to allow you to work from your preferred location On-site Ph.D. scientists that give expert feedback on models Fresh datasets that are custom curated and constantly updated One-on-one coaching and investment in your personal and professional growth Empowerment to own your solutions 
ScrapedJobID798:
8+ years of experience in marketing data management, analysis, and insights, adtech, martech, and research techniques as well as an innovative vision on how to keep pace with the ever changing marketing environment. Experience leading an Analyst(s) and/or external resources in supporting multiple marketing lines of business to understand opportunities before and after campaign execution Solid experience enabling digital analytics tools, Adobe Analytics, Google Analytics, Power BI, and other marketing technologies: SMMS/ listening tools, conversion and/or media pixels, etc. Extensive knowledge of digital analytics implementation tools and techniques: tracking libraries and SDKs, cookies, Data Layer, Tag Management Systems, report suite configuration, listening keyword data collection etc. Demonstrated track record of developing and leverage media (paid, owned, and earned) performance analytics both in the context of forecasting expected results and supporting performance optimization / improvement. Strong internal client management experience both presenting and resolving issues You are naturally curious and can create a story from numbers: you have applied quantitative skills ,love identifying trends and have the ability to roll up your sleeves and dig into data when necessary You have experience with the end-to-end process of qualitative research, including planning, scoping, conducting, analyzing, and communicating results. You have the ability to problem solve and develop innovative approaches along with a drive to learn and master new technologies and techniques You understand high level technical requirements to communicate marketing needs to Technology (D&T) for efficient and effective campaign performance and measurement 
ScrapedJobID799:
Analyze business needs, problems and opportunities Facilitate process and design workshops with multidisciplinary groups to identify, validate, and document clinical, business and data requirements Conduct workflow review and process redesign, and support continuous improvement processes Apply sound change management techniques for effective stakeholder engagement and communications Lead simple to moderately complex projects of small to medium scope Coordinating and facilitating Committee and Working Groups that provides strategic guidance and management direction to the organization Supporting investigations/requirements phase of proposed strategic initiatives. Work objectives include requirements gathering, process mapping, gap analysis, and facilitation of cross-disciplinary working groups Design data collection processes, collect and analyze data, lead data reporting and data visualization activities Contributing to the development of solid customer relationships between all areas of UHN and Data & Analytics. Assisting business and clinical teams to understand services offered by Data & Analytics and connecting to the right individuals to address data needs and questions Representing Data & Analytics in a professional manner with clinical, education and research teams Undergraduate Degree in Health Informatics, Computer Science, Industrial Engineering, Business, or related field Minimum 3 years of Project Management, Business Process/Data Analysis experience or equivalent Advanced experience in creating and maintaining MS Office deliverables including Excel, PowerPoint, Outlook, Visio and Project Business Requirements knowledge in the areas of gathering and documenting requirements, workflow and process modeling Demonstrates well-formed organizational, time management, problem solving, decision making and facilitation skills Ability to maintain flexibility and willingness to compromise on positions in the interests of ensuring consensus Demonstrated ability to work independently and also as a contributing team member Excellent written and oral communication skills Excellent prioritization, organization skills and flexibility to work in a highly dynamic and fast-paced environment Excellent analytical and problem solving skills with the ability to systematically analyze situations/issues, identify options, draw logical conclusions and determine/recommend practical courses of action Excellent data analysis skills to identify patterns, visualize findings and communicate insights Able to work with minimal supervision on moderately complex tasks Able to work with multidisciplinary teams in a positive and productive manner Able to effectively deal with high priority unscheduled tasks and problems Experience developing presentations and presenting to various stakeholder groups including senior management Experience in business writing skills and documentation Familiarity with PMI project management lifecycle 
ScrapedJobID800:
Act as primary consultant to clients for data engineering services, managing the client relationship and coordinating across other support and consultant roles Estimate projects involving data integration, data architecture, business analysis or application development and collaborate with sales and client success teams to grow accounts Participate in product roadmap discussions and identifying key areas for improvement of products and services Collect client project requirements, focusing on needs & impacts and necessary technical outcomes Create solution designs to solve for clients business and technical needs while keeping within budget Produce documentation of data pipeline design and solution architecture for data warehousing and ETL, following company documentation standards Create datasets, extracts, or views of data that will be consumed by teams of analysts and data scientists to support data mining, analytics, reporting, and dashboards Develop, implement, and support methodologies, standards, and tools for data management, considering innovation and data security Create ongoing standards and process for overall data architecture team, including developing governance, support and testing models Perform exploratory data validation with analysts to ensure quality data standards are in place and ensure data integrity during all transformation steps. Bachelor’s degree in Statistics, Mathematics, Business Analytics or related field quantitative field, required with a minimum of 3-5 years experience with database development Experience with cloud / big data technologies such as BigQuery, Azure SQL DB/Synapse, Amazon Redshift is required Experience with relational database systems including SQL Server, Oracle, MySql, Postgres Advanced skills in data scripting and database development technologies (SQL, Python, R) Deep knowledge of ETL tools and how they can be applied to a big data environment Familiarity with analyzing digital marketing, advertising and ecommerce data Familiarity with web analytics tools such as Adobe Marketing Cloud or Google Analytics Experience with optimizing BI or visualization tools such as Tableau, Looker, DOMO or Power BI Experience with cloud platforms such as AWS, Azure, and Google Cloud Familiar with NoSql database technologies such as MongoDB Knowledge of technologies such as Spark, Hadoop, and Airflow 
ScrapedJobID801:
Assist in defining project scope and objectives and developing plans to monitor and track progress. Communication of the analysis processes and insights to stakeholders and other analytics teams across the organization. Partner and align with stakeholders to brainstorm, test and develop analysis that delivers quick insights to validate business hypotheses. Helping our partners make more informed decisions quickly Proactively identify analytical opportunities that will lead to improved business results Synthesizing and framing analysis and translate findings into clear, actionable insights and recommendations. Create supporting material such as reporting templates, trackers, and post mortems. Use systems such as Tableau, SQL, and Python for comprehensive database creation and management. Provide ad hoc analysis supporting the MP&A team Bachelor of Business Degree 2 - 4 years of Business, Marketing/ Project Management Experience Strong data mining and analytical skills and able to translate findings into clear, actionable insights and recommendations. Ability to “storytell” through analytics and presentation materials Advanced Excel skills with experience with Tableau, SQL, Python, database creation and management is preferred. Creative thinker and solutions oriented, committed to driving business improvements Ability to handle multiple demands and competing priorities. Ability to be flexible and adaptable while operating independently and as part of a team. A genuine interest in new approaches, fresh innovative ideas, and a strong belief in your ability to make ideas real. Proactive approach to problem-solving, working collaboratively, and supporting the team. Ability to think strategically and execute methodically. Be part of a world-class team; work with an adventurous spirit; think and act like an owner- operator Exposure to rewarding career advancement opportunities, from retail to supply chain, to digital or corporate. A culture that promotes a healthy, fulfilling work/life balance Benefits package for all eligible full-time employees (including medical, vision and dental). An amazing employee discount 
ScrapedJobID802:
Extend our gaming behaviour expertise Evolve our customer-facing machine learning products Collaborate with data scientists to bring prototypes to production Scale and solidify machine learning pipelines, from data engineering to model training/serving to monitoring and feedback Shepard the DevOps of production infrastructure Strong Python skills Crafting and building machine learning systems Data pipelines (SQL, Beam, Airflow, BigQuery) DevOps principles and technologies (Docker, Jenkins, Terraform) Cloud platforms (GCP, Azure, AWS) Creative startup-type drive Dabbled with machine learning frameworks (Tensorflow, PyTorch) Setup backend systems (Go, Java) with databases (Redis, Mongo) Développer notre expertise en matière de comportement des jeux Développer nos produits d'apprentissage automatique destinés aux clients Collaborer avec des scientifiques des données pour amener les prototypes vers la production Développer et consolider les pipelines d'apprentissage automatique, de la conception des données à la formation et au service des modèles, en passant par la surveillance et le retour d'information Piloter les DevOps de l'infrastructure de production Une bonne connaissance du langage Python Concevoir et construire des systèmes d'apprentissage automatique Une connaissance des pipelines de données (SQL, Beam, Airflow, BigQuery) Une connaissance des principes et technologies DevOps (Docker, Jenkins, Terraform) Une connaissance des plateformes infonuagiques (GCP, Azure, AWS) Un esprit créatif et entrepreneurial Une expérience avec les frameworks d'apprentissage automatique (Tensorflow, PyTorch) Une connaissance approfondie des systèmes backend (Go, Java) et des bases de données (Redis, Mongo) 
ScrapedJobID803:
Oversee the single-family hedging and all related repo transactions and completion of the related reports. Oversee the NHA MBS issuance and administration and ensure monthly NHA MBS reporting is completed as required. Ensure that the MCAP’s NHA MBS application is compliant to the guidelines of program and oversee the testing and implementation of ongoing upgrades. Oversee the allocation of loans to investors while managing criteria and volume targets, and development of reports as required. Work with Underwriting and Credit Risk to monitor quality and legal compliance of loans allocated to investors. Work with IT to oversee development and distribution of single-family reports to internal and external parties. Work with other business stakeholders to complete IT projects and applications utilized by Capital Markets. Oversee Capital Markets’ data requirements and work with other departments to ensure accurate and accessible data is available to Capital Markets. Oversee the development and implementation of behavioural model (e.g. LQR and Retention Ratio). Develop and prepare ongoing management reporting. Proactively identify new areas to leverage data science to improve the business, such as automation of manual tasks and processes. Reviews and approves any BA analysis-based recommendations and impact assessments related to projects and initiatives in CECs, ensuring accuracy and strategic alignment of results with business goals, and clear understanding of risk and rewards. Ensure Business Disaster Recovery plans and processes are in place for all production business application systems. Champion the company’s Vision, Mission and Values as set out in the Strategic Plan both internally and externally within the industry. Recruit and develop the right people that believe in and reflect in their behavior MCAP’s Values and culture. Establish, monitor and communicate performance standards to direct reports reinforcing individual results, work quality, continuous improvement, teamwork and achievement of MCAP’s objectives. Educate, coach and counsel staff to ensure they are empowered to effectively handle their roles in a confident and professional manner. Establish and maintain an effective system of communication throughout the business unit. Ensure a continuous improvement culture is established and encouraged. Over 10 years post qualification experience 5 – 10 years’ experience in the banking/financial services industry Expert knowledge of SQL, Python, VBA, SAS or other modeling tools is a must Ability to adapt positively and productively to regular changes in the workplace, accepting new challenges and turning them into successes Extremely strong knowledge of use of spreadsheets for reporting and modeling purposes Ability to understand complex business structures and transactions Must have excellent time management skills and able to meet tight deadlines while producing quality work Ability to manage multiple conflicting priorities simultaneously and able to stay focused in a fast paced environment Ability to manage difficult and demanding situations, detail oriented and must operate well within a team environment Strong leadership and interpersonal skills and able to effectively communicate with staff at all levels and respond to stakeholders’ needs Excellent oral and written communication skills Advanced Microsoft Excel and Access skills B.Com, Computer Science, Mathematics & Economics Degrees 
ScrapedJobID804:
Architect, design and evaluate novel approaches for solving complex business problems using machine learning techniques with high-volume real-time data streams Own the development, training, optimizing, and deployment of machine learning systems Develop measurement and feedback systems at a web scale to improve the selection of features and/or algorithm design Explain and present analyses and machine learning concepts to a broad technical audience Initiate and drive projects to completion with minimal guidance 2+ years of experience in building and deploying machine learning solutions at a production scale 1+ years of experience in software development at the production level, with proficiency in Python or Scala preferred Working knowledge of PyTorch, Tensorflow, or other similar frameworks Bachelor's or Master's degree or equivalent in Computer Science, Engineering, Mathematics or related field Flexibility to WFH For the third year in a row, we are proud to announce that we have been certified as a Great Place to Work We were also certified as one of the Best Workplaces for Mental Wellness in 2020 We are an open work environment that fosters collaboration, ownership, creativity, and urgency We ensure flexible hours outside of our core working hours Enrolment in the Group Health Benefits plan right from day 1, no waiting period Team building events Fuel for the day: Weekly delivery of groceries, and all types of snacks Catered lunches and desserts on a monthly basis Daily fun in the office with our competitive games of Ping Pong, Pool, Smash Bros competitions, or FIFA And of course, an unlimited amount of freshly made coffee and tea! We’re pretty serious about our coffee beans Online learning through the platform, UDEMY 
ScrapedJobID805:
Apply advanced excel data profiling, scripting, pivot table analysis techniques Manage and manipulate large and disparate data sources Enhance existing entitlement migration solutions and develop new data analytics capabilities Partner and communicate with subject matter experts, developers and colleagues verbally and in written form Participate in the identification, scoping, design, development, and delivery of business line migrations to Entitlements Discerns and solves advanced and interrelated problems in support of business objectives Applies traditional and advanced statistical modeling techniques in support of analytic activities with limited supervision Works with Business Analyst and Product managers to design/apply data modeling techniques in support of entitlement migrations Shows initiative and motivated to learn Generates quality work on assigned tasks Support Product management and management activities by producing quick-turnaround analysis, model development, and quality assurance for product development and business lines. Manipulate and manage databases and other large datasets to derive insight and support analytic activities Contribute to entitlement projects as required and as driven by business needs by working under the direction of a Product management Typically 5-8 years experience in profession, relevant technical degree or equivalent experience required University degree (Bachelors or equivalent) in Statistics, Engineering, Computer Science, Mathematics, Economics or related field Applied knowledge of traditional and advanced analytics modeling techniques Works independently and with Business analyst to enhance data migration tools, utilities and process Strong knowledge of T-SQL/SQL querying and knowledge of Oracle(PL/SQL), MySQL, MSSQL databases. Intermediate knowledge of JSON, XML, ETL preferred Strong familiarity with Word, Excel, Powerpoint, Access Strong verbal/written communication and presentation skills for internal audiences Attention to detail Organization skills including the ability to manage multiple tasks and deadlines simultaneously in a fast-paced environment Must be flexible with the ability to work effectively and collaboratively with all coworkers Self-starter with good time management, organization and problem solving skills, with an ability to handle multiple priorities. Occasional travel including overnight domestic or international trips may be required Competitive base salary, bonus plans and equity. A comprehensive, benefits package that includes medical, dental, vision and life insurance plans, paid time off, a generous 401k match with no vesting period, parental leave and 3 volunteering days each year. For work locations in the state of Colorado, the anticipated minimum base salary for this role would be $50,674. Compensation will be determined by the education, experience, knowledge, and abilities of the applicant. 
ScrapedJobID806:
You’ll be part of one of our Data Science teams, being a key player contributing to solve challenging problems on data-driven scenarios using Machine Learning at scale Deploy and maintain production models and services using both internal and open-source tools Collaborate closely with the engineering teams of B2B, sales, supply chain, fraud, user generated content and merchandising to ensure integration of our machine learning models into our microservices architecture Improve the pace of innovation and experimentation by introducing best practices and tools for Data Science workflow, code quality and MLOps Architect and write code to implement high-quality, scalable services with effective system boundaries that supports our long term vision & strategy Lead your teammates by example, as a senior member of the team your code and system designs demonstrate the path the team should follow Contribute to and influence our technology and product strategy and roadmaps Develop GCP based solutions within the Data Science team and help establish our team as the center of excellence for GCP Bachelor’s Degree in Computer Science or related field 6+ years of previous experience in Software Engineering with a strong background in Software Development Lifecycle processes. Experience with implementation in low-latency real-time platforms and/or scalable offline batch processes Solid experience with Java or Python (production level code) and SQL Job scheduling technologies (ex: Airflow) and containerization for isolated development (Docker, Kubernetes) shouldn’t be foreign concepts to you. Knowledge of Microservice architectures. Capability to communicate and collaborate across the wider organization, influencing decisions without direct authority and always with inclusive, adaptable and persuasive communication. A passion for challenging problems and the ability to work with many different teams identifying architectural boundaries and platform interfaces. Desire to always be learning, and a collaborative team-player attitude! Familiarity with Data & ML processing pipelines Familiarity with Google Cloud Platform (also good if familiar with AWS or Azure) Familiarity with AWS Sagemaker or Google Vertex AI or something similar Proficiency in Big Data and Streaming tech (Spark/Flink, Kafka, or similar) Previous exposure to Supply Chain, Fraud, Payments, or NLP projects 
ScrapedJobID807:
The ideal candidate will be familiar with the following technical skills Python or R for Data Science. Reproducible Data Science Workflows in Python or R. Machine Learning and Deep Learning Principles. Statistical Modelling Data Analytics and Business Intelligence (Techniques and Tools like PowerBI) Big Data Technologies (Spark, Hive etc). Cloud Technologies (AWS Experience preferred). Foundational Computer Science Skills are nice to have. >3 years of professional experience in Data Science Have worked in Agile development environment. >1 year of leading/managing a team Have worked in a Data Science or Analytics consulting, setting for >3 years. Experience in the following domains would be an advantage:
Telecom
Life Sciences
Technology Telecom Life Sciences Technology Bachelors required Masters preferred Agile Certified Nice to have Responsible for the timely delivery of quality results to the client. Regularly meet with and build relationships with key client stakeholders. Identify and capitalize on opportunities for upselling and cross-selling. Responsible for adequately resourcing the engagement including backfilling of rotating resources. Responsible for ensuring all consultants are documenting their work and roles as per company and client requirements. Develop Level of Effort Estimates and other related collateral as required by client. Manager is responsible for ensuring teams are running effective daily scrum meetings. Manager is responsible for ensuring projects are delivered on time and within budget Responsible for triaging with the consultants work items to align with client expectations. Select the correct PM format (Scrum/Kanban/ScrumBan) and ensure all team members are well coached on the working style. Ensure timely regular reports are generated and shared with internal stakeholders and clients. Mentor consultants on soft and hard skills required for role. Develop Performance Plans for each consultant. Develop learning plans for consultants. Ensure clean handoff of consultants to other managers in event of transition. Perform weekly 1-1 check ins with consultants. Manage and measure consultant performance. Involved in selling technical solutions to current and prospective clients. Developing deliverables for SoWs and LOE's in tandem with the Sales team. Cataloging Consultant work and ensuring Blogs, Case Studies and other material are being generated that can be used to enhance sales and marketing efforts. Will act as evangelist for ProCogia in the community -getting involved in Meetups and attending relevant conferences. Generate go-to-market service offerings Be involved in initiatives to enhance ProCogia's reputation as leaders in the Data Solutions space (e.g. Blogs, Articles, White Papers, Podcasts etc). As a hiring manager, you will be responsible for designing interview setup for open roles as well as assisting in the creation of job advertisements. Triage incoming interview requests and assist in scheduling interview rounds. Improve the quality of interview screening through the development of reusable interview collateral and the mentoring of less experienced consultants on their interview techniques. Involved in internal initiatives to improve existing processes and identify gaps and create new processes. With the management team set plans and directions for the organization. Communicate direction setting information from ProCogia leadership and the customer leadership. Manage the organization budget. 
ScrapedJobID808:
Developing NLP systems that help us structure and understand biomedical information and patient records Using a variety of structured and unstructured data sources Imagining and implementing creative data-acquisition and labeling systems, using tools and techniques like crowdsourcing and novel active learning approaches Working with the latest NLP approaches (BERT, Transformer) Training your models at scale (Horovod, Nvidia v100s) Employing and iterating on scalable and novel machine learning pipelines (Airflow on Kubernetes) Reading and integrating state of the art techniques into Fathom's ML infrastructure such as Mixed Precision on Transformer networks 5+ years of development experience in a company/production setting Experience with deep learning frameworks like TensorFlow or PyTorch Industry or academic experience working on a range of ML problems, particularly NLP Strong software development skills, with a focus on building sound and scalable ML A real passion for finding, analyzing, and incorporating the latest research, technologies and techniques directly into a production environment Good intuition for understanding what good research looks like, and where we should focus effort to maximize outcomes Developed and improved core NLP components and not by just 'grabbing things off the shelf' Led large-scale crowd-sourcing data labeling and acquisition (Amazon Turk, Crowdflower, etc.) 
ScrapedJobID809:
Provide information and insights to our stakeholders Proactively work with stakeholders to formulate and manage business questions, hypotheses, and specifications Work as an integral part of our ‘Data Analyst Chapter’ and Data Organization by providing both internal and external mentorship, and demonstrating data democratization/governance with excellence across the organization Help identify, define and build metrics and KPIs that lead to actionable results Instrument applications with user tracking analytics to gain insight into the customer journey and how our product features are being used Breakdown stakeholder asks and suggest solutions based on timeliness, accuracy, business value, and impact Stay up to date on industry standards and best practices in data analytics Own building hypotheses, scoping, running and conducting post analysis of experiments & A/B tests Grow your skills in machine learning, statistics, and data science, to enable deeper understanding of the internal data Keep a strong pulse on business metrics, and communicate when flags are raised about data integrity You have 5+ years working as an analyst, with a proven track record of generating research and insights in a repeatable and actionable manner You are an expert data storyteller and have experience with a set of tools to enable that You are an expert with SQL (we use mySQL and Postgres dialects) and highly capable with Python You have a solid grasp of data modelling, warehousing, and pipelining (we use Airflow to schedule our jobs) You have experience building advanced analytics solutions (predictive models, multivariate testing, statistical analysis) You excel at working with non-technical stakeholders to help translate, manage and drive business needs into actionable insights You build relationships across the organization to develop and maintain trust You’re skillful at making strategy recommendations, and working with senior management to identify problems, solutions, and insights to drive the business forward You’re experienced in project management: managing and prioritizing tasks across teams (we use agile ceremonies, and JIRA to track our work), knowing who to loop in when, and providing timely updates to your stakeholders You’re familiar with 3rd party tooling and data integrations, and at monitoring/maintaining data integrity across multiple systems A remote friendly office with flexible hours - for this role we will consider all applications from those based in Canada with the option to work from our Vancouver office 4 weeks vacation plus Christmas Holiday Closure - you're entitled to the week of Christmas off with pay through to and including Jan 1st Vacation bonus - $1,000.00 12 Personal Wellness Days (This includes: Personal day, Moving day, Sick day, etc) Health and Wellness budget - $500.00 Networking budget - $500.00 A paid day off for your birthday One paid Volunteer day per year All Unbouncers are encouraged to dedicate 10% of their time to Pro-D time 
ScrapedJobID810:
5+ years of experience in systems using machine learning and other artificial intelligence techniques Working knowledge of more than one programming language (Python, R, Java, C++ etc.) Experience building and operating distributed systems on the cloud Experience working closely with data scientists and appreciation for their unique workflow Excellent interpersonal, communication and presentation skills, both written and verbal Ability to stay commercially focused and to always push for quantifiable commercial impact Ability to collaborate effectively across global teams and communicate complex ideas in a simple manner 
ScrapedJobID811:
Research, explore, implement, and evaluate new machine learning models Implement and compare existing cutting-edge research works to solve business problems Test the model performance with business use cases Build prototype models Publish research papers Produce open-source software and packages Present AI solutions to the business sponsors PhD degree in machine learning or related field or PhD Student Research experience Python experience is preferred Technical and business communication in English Team and technical leadership 
ScrapedJobID812:
Lead, manage and mentor the Machine Learning Engineers on your team Collaborate with our Engineering teams to help build production features that leverage our machine learning technologies Develop infrastructure for rapid machine learning feature prototyping, deployment, and evaluation with customers Build and optimize data lakes and feature stores to feed research projects Apply best practices for ETL and batch processing of database, log, image, and HTML data. Participate in large-scale project planning and stakeholder education 5 or more years of experience working with MLOps or Machine Learning Engineering Experience leading major projects and managing team members Experience deploying machine learning models in production, and with production architecture, monitoring and logging Excellent communication and emotional intelligence is required Exceptional experience programming with Python and the associated data science/machine learning packages (e.g. scikit-learn, pandas, xgboost, numpy, scipy) Management of databases (we principally use MySQL, Postgres, and DynamoDB) Cloud infrastructure, preferably AWS, especially S3, and CloudFormation Running services in Docker environments Experience with web technologies, including APIs (we use REST and GraphQL) Linux administration and command line tools Agile development, version control, and code review processes Big Data ETL (we principally use PySpark) 
ScrapedJobID813:
Partner with the Business Lead to develop and promote the DMA research services and innovation capabilities to support business development activities with established and prospective academic and industry partners; encourage and facilitate industry interactions, including research engagements. Promote engagement of services provincially, nationally, and internationally across the bioscience community with institutional partners, collaborators, and external clients. Lead the Data Management and Analytic team by managing the employee career cycle through activities such as: recruitment, retention and separations, orientation, and onboarding, coaching and performance feedback, supporting professional growth, training, and development, managing performance, and addressing disciplinary matters. Manage the implementation of programs, activities, and systems to support the delivery of optimal services to both internal and external researchers, partner organizations, collaborators, and clients. Define and implement consistent data capture, management and access policies across GIFS and subsidiary programs and platforms (e.g., OPAL, Engineering Biology, Cell Biology, Plant Growth Facilities) to ensure long-term stewardship and data integration and enable data analytics and data repurposing across GIFS. Define and implement Machine Learning to accelerate the Design-Build-Test- and Learn cycle at GIFS. Define and implement consistent data capture, management and access policies across programs GIFS leads such as P2RIC, CERC and Bangladesh. Define the opportunity and establish cloud-computing resources to support computational needs for GIFS data analytic pipelines. Exploit economies of scale in hardware acquisitions, software licensing, and systems administration by consolidating data and computational resources across GIFS. Create, optimize, and manage workflows to meet internal and external requests, focusing on high-quality, high throughput. As the subject matter expert in bioinformatics lead the interdisciplinary application of information technology tools for collecting, analyzing, storing, and visualizing biological data applied to agriculture. Lead by example with a commitment to continuous improvement and GIFS values. Establish and manage lab processes, including but not limited to, electronic lab notebook, data and metadata management, data analytics and large-scale data warehousing infrastructure such as a laboratory-information-management-system. Negotiate and monitor fee for service agreements in partnership with the GIFS Business Development Office. Work with the Business Development team in identifying funding opportunities; provide technical review and support for developing co-funding for industry-sponsored research, grant submissions and funding opportunities to support the growth of the Platform and GIFS. Collect, analyze, and synthesize data related to overall performance. Facilitate communication among clients, the research community, and key stakeholders. Identify strategic alliance partners and develop long-term, sustainable relationships. Foster and promote a culture of innovation by dedicating time for innovation within the platform. Participate in the Scientific Executive Committee (SEC) and help in defining, supporting, and implementing scientific and strategic direction for the Institute. Other accountabilities as assigned. Minimum of five (5) years of hands-on experience in bioinformatics and machine learning applied to next-generation sequencing data, engineering biology and cloud computing. Minimum three (3) years of experience in the technical management of operations in a life sciences laboratory. Experience in using advanced genomic, computational and/or data science approaches to study biological phenomena in a range of eukaryotic organisms. Research leadership in areas at the intersection of genome biology, computational biology, biostatistics, data management and cloud computing will be prioritized. Experience with project management, product development, and/or innovation projects, ideally in the ag biotechnology ecosystem. Experience leading and developing teams. Experience with research funding models and processes. Industry-focused business development and/or marketing experience along with a strong understanding of both academic and industry environments is highly desired. Demonstrated experience and skill in building relationships with diverse constituencies and negotiating commercial agreements. The ideal candidate will have direct experience in the bridging research to industry and the ability to bring the results of scientific research to the marketplace. Innovative problem solver capable of overcoming challenging and complex issues in a fast-paced environment and growing market. Excellent oral and written communications skills, including the ability to convey complex technical ideas to non-specialist audiences. Ability to manage multiple projects simultaneously and work effectively within a high achieving team environment. Sound judgment, discretion, diplomacy, and professional integrity. Excellent interpersonal skills with the ability to establish and maintain professional relationships that support exceptional collaboration. Ability to gather, analyze, and present information with attention to detail. Ability to work effectively in a diverse working environment. 
ScrapedJobID814:
Implementing, training, and optimizing models developed by our ML Science team Developing high-performance, scalable, and maintainable inference services that communicate with the rest of our tech stack Working with Infra teams to build data collection pipelines, manage data QA, and develop code for data visualization and data cleansing to build robust datasets Turning unfamiliar research code into bulletproof, production-ready software Working with edge hardware to test and tune the latency and performance of our services Building pipelines for continuous model improvement Experience with computer vision; experience developing and deploying deep learning algorithms; you’ve previously deployed machine learning models on scalable systems Strong grasp of statistical machine learning, linear algebra, and deep learning for computer vision Excellent C++11/14/17 and Python skills; familiarity with TensorFlow Ability to rapidly learn and work with unfamiliar code Understanding of CI/CD patterns and best practices Ability to write well-tested code Highly flexible and capable of working across the stack Great communication skills You love the idea of joining a fast growing series-A startup. You are proactive about solving problems and take initiative to build tools that will help everyone in the company. You love to thoughtfully help a team member or a customer in need. Innovation - We have an ambitious vision, and any change, especially the zealous kind, requires big ideas. Integrity - We trust each other, and that trust is the foundation on which our relationships both internally and externally are built. Continuous Improvement - We see everything as improvable, and work at finding ways to do so, and enjoy moving toward our goals. Accountability - Our teammates have intrinsic enjoyment in taking ownership and delivering on what they say they will. Customer Focus - We care the most about what benefits our customers and partners. 
ScrapedJobID815:
Drive the execution of all product lifecycle processes for our Data Science and Analytics products, including product research, market research, competitive analysis, planning, positioning, roadmap development, requirements development, and product launch. Translate product strategy into detailed requirements and/or visual mockups for prototype construction and final product development by engineering teams. Communicating verbally and in writing to customers/prospects with various levels of technical knowledge, pitching Firstlight’s data science capabilities, educating them about our data systems, as well as sharing insights and recommendations. Create product strategy documents that describe business cases, high-level use cases, technical requirements, revenue, and ROI Being the champion for a data-first culture at Firstlight and ensuring requirements related to data governance and security are developed and prioritized. Analyze market data to assist in the development of sales strategies, and effective marketing communication. Contributing to creation of product collaterals including pitch decks, product demos API documentation, and more. Driving product capabilities to evaluate data from live products, including how to design and execute various A/B and multivariate tests to shape the next iteration of a product. Evaluate the output captured in statistical analyses and translate them into insights to inform product decisions. 5-8 years of progressive experience in a similar role. Mid to senior-level product management professional with background driving software products related to data visualization, data analytics, or data science/machine learning. Experience interacting directly with customers and partners on technical / product related topics. Must have a thorough understanding of the agile software development life cycle (SDLC) processes and tools. Excellent written, verbal, presentation communication skills. Experience with cloud-based data warehousing technologies such as BigQuery/Snowflake and/or data visualization tools such as Tableau/Looker and/or SQL/NoSQL databases. Excellent analytical and problem-solving skills. Self-starter, ability to work with some ambiguity and comfort working with cross-functional teams. Ability to operate in a fast-paced environment, managing multiple projects simultaneously while prioritizing time and resources based on business impact. Quick learner and ability to understand technology opportunities and challenges at a business level. Preferred Bachelor of Business/Business Analytics/Information Systems/Engineering/Math/Science degree or equivalent experience. 
ScrapedJobID816:
Leads the design, development, and implementation of analytic solutions with measurable results and benefits to the business overall and define key metrics for measuring the success of the project Explore large, new sources of data; communicate and present insight opportunities to business teams across the organization to influence decision making Communicate results of analysis and models to stakeholders effectively and confidently Translating business imperatives into data-centered questions to be able to quantify and evaluate them Bring in new sources of data by exploring data across Bell and externally Design and expand interactive dashboards and APIs Create new processes to improve the performance of the BI environment Share technical expertise with team and provide recommendations for best practices Enforce standards and discipline in the documentation and structured development Undergraduate or masters degree in Engineering, Computer Science, Physics, Mathematics, Operations Management/Research, Business, or relevant field 3+ years of industry experience in data analytics roles demonstrating an ability to derive actionable insights Proficient in SQL and NoSQL databases (SQL Server, PostgreSQL, MongoDB, InfluxDB) for data query and extraction Proficient in one or more programming languages for data collection, manipulation and statistical analysis (Python, R) Knowledge of data visualization software (Tableau, Power BI, QlikView, etc.) for effective presentation of data Experience in writing production-quality code, API interfaces, and end-to-end machine learning pipeline Knowledge of machine learning best practices and experience applying them to real datasets Must be versatile and quick to learn new languages, packages, and frameworks Strategic and creative thinker who is exceptionally adept with quantitative and qualitative analysis Ability to leverage insights and opportunities from data and metrics to build strategies and make recommendations Excellent communication skills Experience using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, etc.) Understanding of Agile Principle & methodologies (Kanban, Scrum) Experience with Agile Tools (JIRA, Confluence) Knowledge and experience with various governance or data management tools (Collibra, Informatica, IGC, etc.) 
ScrapedJobID817:
Work closely with the Analytics Director to translate internal briefs into analytical projects (to include refining the initial brief and asking the ‘right questions’, working through potential hypotheses and storyboarding the output). Conduct geo-spatial analysis, prepare and correlate additional data sources to uncover spatial and location-based insights. Conduct analysis using analytics tools and be comfortable analyzing a range of structure and non-structured data. Provide qualitative and quantitative analysis and insight to inform research strategy, economic landscape, and new data products development Synthesizing data and analysis into impactful, action-orientated reports and observations for internal stakeholders Able to communicate the key findings and insight to senior stakeholders and peers both conversationally and in formal presentation style Develop data profiling, data quality rules and supporting documentation Support data stewards in enriching data with additional dataset to uncover strategic insights. Ensures data transformation practices adhere to data management policies, principles, and standards. Maintains business glossary and metadata repository Provide project level support for data analysis and design best practices Develop, propose, and contribute to implementation of machine learning methodologies and algorithms. An undergraduate degree or diploma in Computer Science, Geographic Analysis or Business Analytics; A graduate degree is an asset At least five years of experience in data analytics, GIS analysis, and research Interest in and knowledge of applied public policy research, particularly at the municipal and provincial level Experience working on economic, transportation and planning issues in the Toronto region or other global city-regions. Experience working with highly-productive research environment would be an asset Experience and proficiency in GIS programs such ArcGIS or QGIS Experience in data analytics software such as Python or R Experience in SQL server and Microsoft Azure and data lake environment is a plus. Experience developing and delivering presentations to senior team members, using PowerPoint or dashboards. Ability to communicate clearly and effectively Ability to operate in a fast-pace, results-oriented organization Strong written and verbal communication skills Highly organized and deadline-driven Detail-oriented and focused on outcomes A self-starter with the ability to work independently Collaborative with colleagues from all levels and departments Agile and open to changing directions, adopting new practices or learning something new Self-motivated and a motivator A strong communicator and socially-savvy Empathetic and aware of interpersonal dynamics A strong multitasker with the ability to navigate competing deadlines An analytical, creative problem solver Accountability – We are accountable to our Members, stakeholders and each other. Collaboration – We are our strongest when we work together. Connections – We engage and build communities. 
ScrapedJobID818:
Have + years of hands-on ownership of all customer's technical issues and partner with the LivePerson SME's team to resolve high-complexity issues as necessary Enterprise wide strategic support/ engineering experience, working closely with large complex project initiatives post implementation. You will investigate issues by analyzing data stored by the application, checking logs and reviewing code, provide fixes and workarounds, and review changes for operability to maintain existing software solutions. Resolve technical issues using JavaScript, CSS, and API knowledge Troubleshoot issues with software Identify root causes of technical issues in production and recommend improvements Assist customer support team with customer inquiries Monitor application performance and identify trends to expose any potential performance bottlenecks or issues Experience using SaaS tools like AppDynamics and Splunk, to provide faster resolution to solution issues. API integration troubleshooting- monitor application health to investigate application issues Responsible for all customer engagements from initiation to resolution through ensuring progress by SLA and escalation Build strong customer relationships, including key customer stakeholders and sponsors Always strive to provide an exceptional customer experience Manage customer expectations and lead them to customer satisfaction Make sure all deliverables are on time, adhere to the highest quality standards and fulfill customers' requirements Keep track of key account support metrics Attend weekly meetings and quarterly reviews Take initiatives in identifying growth opportunities Provide constant transparency to an open engagement status/progress while communicating progress to both internal and external stakeholders Pre / Post-release deployment management Manage high priority incidents and work with internal/external teams towards full resolution Provide post-mortem root cause analysis Provide ongoing feedback on product usability to the Product team Stay current with the maintenance activities, change management, and bug fix releases A proven track record of Technical Account Management or System/ Production Support Engineering for a SaaS or Web company HTML / CSS / JavaScript experience and SQL Web troubleshooting experience Experience troubleshooting with API's /SDK's Ability to analyze data and provide insights Experience in managing multiple stakeholders and projects Excellent verbal and written communication skills Critical thinker and problem-solving skills Good understanding of web technologies and the associated support teams/processes Team player with the ability to work with multiple stakeholders and cross-organizational efforts with a number of different virtual teams concurrently Good time-management skills Require little to no supervision Experience in using software for sales management such as Salesforce, etc. Ability to work under pressure and tight deadlines. Available for off-hours escalations Available to travel to additional customer sites as required (up to 15%) BSc/BA degree in a relevant field or equivalent experience 
ScrapedJobID819:
Productionize deep learning acoustic models for our Houndify Voice AI Platform Build feature extraction tools and inference engines Guide junior teammates on projects and share best practices You have five-plus years of industry experience You graduated with a Bachelor's degree in Computer Science You are well-versed writing production level C++ or Python code You are adept with algorithms and data structures You do your best work when you're in a creative and diverse environment 
ScrapedJobID820:
You have a passion for testing and failing quickly You’re always looking to learn and have a growth-mindset You have a proactive mindset, are comfortable with ambiguity, and the drive to take imitative You're meticulous & resilient and have a high “figure-it-out” quotient You’re a systems mindset, coupled with a desire to always optimize Building the analytics deck for the marketing department, and drawing actionable insights from the data provided for all marketing campaigns. Aggregating complex and detailed findings to all levels of marketing management and be comfortable presenting and defending results when necessary. Undergraduate degree in data science, or business analytics or marketing science Minimum 3+ years marketing analytics experience, both online and offline Experience working with email marketing platforms such as Klaviyo, Mailchimp Experience with web analytics platforms such as Google Analytics and a sound understanding of email/web metrics Python script, SQL, VBA script, Excel required Experience working with digital channels that include email, web, experiential, social or other channels that specifically involved customer level targeted experiences. Strong data visualization skills that adhere to industry established best practices, and presentation skills to simplify and package complex ideas into intuitive, decision driving client presentations. Sound knowledge of strategies and ideologies around acquisition, conversion, loyalty, engagement, retention and attrition models, online attribution models, consumer journey optimizations, and lifecycle marketing. Demonstrated ability to effectively communicate, prioritize, and maintain focus while working on multiple complex projects. Ability to be self-managed, work independently as well as to collaborate within an agile dynamic team environment. 
ScrapedJobID821:
Graduate school with a machine learning/computer vision focus (MASc or PhD). 4+ years of industry experience in machine learning and computer vision. Expertise in an object-oriented language such as C++. Driven individual, passionate about robotics, algorithms and algorithm development, self-starter. Strong experience in perception algorithms for autonomous vehicles (localization, obstacle detection, etc). Experience in deep learning and application to obstacle detection (deep stereo, semantic segmentation, etc). Strong technical documentation skills and scientific approach to problem solving. Comfortable with Linux operating systems (CLI, scripting) as well as with robotics hardware. (not afraid to jump in and play with our robots). In-depth hands-on experience in Python (Tensorflow or PyTorch), and a track record of translating ideas into research prototypes quickly. Able to work independently. A strong desire to be part of the emerging robotics revolution. Industrial cleaning experience (we always welcome insights that will help our robots clean better). Experience running deep learning algorithms at the edge . Experience with industry-standard software development tools and processes (eg. Git, continuous integration, unit testing). A GitHub space showcasing your projects. Familiarity with ROS. 
ScrapedJobID822:
Combination of graduate education (MS or PhD) and academic research lab experience in Deep Learning, Machine Learning, or similar computationally intensive degree 2+ yrs of professional ML experience as a technical leader and major contributor on projects with other MLEs and cross-disciplinary contributors involved. Experience in running ML/DL projects from discovery to delivery is highly valued. 3-5+ yrs professional experience (industry or research lab) related to ML or software engineering. Expertise with Python (strong emphasis on keras, TF, pytorch, sklearn, opencv) Strong software experience with SQL, version control, APIs. Experience in CI/CD involved in deploying, maintaining, and monitoring ML or Data products. Special interest will be given to any of ML Ops, Graph-based data structures, advanced search/recommendations, scaling large scale ML production systems to marketplace-sized requirements. Good scripting, functional, and vectorized scientific programming skills in python. Good exploratory data analysis and reporting skills Comprehensive benefits offerings for benefits eligible Teammates. Unique culture that truly values each and every Teammate. Career development and Future Growth Opportunities. 
ScrapedJobID823:
Work with Growth Marketers to understand best practices and propose strategic ideas and turn them into initiatives for driving growth. Define and regularly monitor KPIs, success metrics, and other analytics to maximize our conversion rate across our digital channels. Set up and evaluate A/B tests results and push forward next steps at a rigorous pace. Deliver reports and strategic insights through analysis and manual data extractions from various ad platforms, data tools, and internal tracking to drive OKRs Estimate the value of different marketing strategies. Effectively communicate findings to internal and external team members. Manage research, development, and delivery of analytical models to be used for strategizing, testing, and implementing marketing campaigns across SEM, paid social, display, influencer, email, and more. BS/BA degree in Statistics, Business, Economics, Mathematics, Operations Research or related quantitative field 5+ years of experience in quantitative marketing/business analysis with solid understanding of experimentation design, marketing mix modeling solutions and statistical modeling Highly proficient with SQL and visualization tools (e.g. Tableau) and are comfortable working in at least one scripting/statistical language (R, Python preferred) Excellent communication skills, both written and oral. You are able to clearly articulate growth marketing ideas, strategies, and tactics to audiences with varying domain knowledge A curious mind, passion, and motivation to learn new skills, tools, and analytics techniques necessary to tackle business challenges Comfortable functioning in spaces with high ambiguity and adapt easily in changing environments. Advanced degree in Statistics, Information System & Management, Economics, Mathematics, Operations Research or related quantitative field
Understanding of the digital marketing ecosystem and can identify key business KPIs
Familiar with marketing analytics tools (e.g. Amplitude and/or Google Analytics, Adwords, Responsys, Facebook insights)
Previous experience in the field of education or e-commerce Advanced degree in Statistics, Information System & Management, Economics, Mathematics, Operations Research or related quantitative field Understanding of the digital marketing ecosystem and can identify key business KPIs Familiar with marketing analytics tools (e.g. Amplitude and/or Google Analytics, Adwords, Responsys, Facebook insights) Previous experience in the field of education or e-commerce Competitive salary Full private medical coverage (medical, dental, vision) Retirement savings program Paid Parental Leave Education Reimbursement Quarterly team events and outings Team lunches Free lunches twice a week, on-site cafe discount, plus an endless snack and drink supply Social responsibility program (volunteer hours and donation matching program) Front row seat to Master Educator lectures – check out our Lecture Series videos 
ScrapedJobID824:

ScrapedJobID825:
As a Senior Manager within the Financial Service Insights and Data team you will support managing a portfolio of Capgemini s Data and Insights engagements projects. The role includes nurturing client relationships leading technical workstreams coaching and mentoring Capgemini professionals with a continuous focus on personal and professional learning and growth and achieving highest levels of quality performance commensurate with the expectations of a World leading Consulting and Technology firm. This role has full life cycle of Data and Insight projects which includes proposal development and pursuit assistance project delivery team development and performance quality of our project deliverables. In this role you will Offer expertise in Data and Analytics Solution design and implementation Support the growth of a pool of talented Data and Analytics practitioners participate in sales opportunities and display knowledge in various strategic initiatives across Data and Insights service offerings and the external marketplace. Apply technical knowledge of disruptive trends to advise clients on the implementation of their Data and Analytics Strategy to drive business outcomes. Support the design Data and Analytics strategy and roadmaps for clients based on readiness aspirations and vision Implement large Data and Analytics transformation programs Entrepreneurial attitude desire to create new business ability to inspire followership amongst team members 8 plus years of consulting experience with a Professional Services Consulting or Advisory Firms and or Financial Services organizations 3 years of Financial Services experience Banking and Capital Markets and or Insurance Experience in strategy and or technology enabled business transformation innovation ideation evaluation and adoption strategic effectiveness and strategic model design review and management Understanding of enterprise data and analytics life cycle i e data strategy data governance management data architecture data migration business intelligence data science etc Superior written and verbal communication skills including presentation and facilitation skills and strong attention to detail Structured problem solving skills and logical thinking as well as ability to develop and present new ideas and conceptualize new approaches and solutions Required BSc BBA MBA preferred 
ScrapedJobID826:
Extend our gaming behaviour expertise Evolve our customer-facing machine learning products Collaborate with data scientists to bring prototypes to production Scale and solidify machine learning pipelines, from data engineering to model training/serving to monitoring and feedback Shepard the DevOps of production infrastructure Strong Python skills Crafting and building machine learning systems Data pipelines (SQL, Beam, Airflow, BigQuery) DevOps principles and technologies (Docker, Jenkins, Terraform) Cloud platforms (GCP, Azure, AWS) Creative startup-type drive Dabbled with machine learning frameworks (Tensorflow, PyTorch) Setup backend systems (Go, Java) with databases (Redis, Mongo) Développer notre expertise en matière de comportement des jeux Développer nos produits d'apprentissage automatique destinés aux clients Collaborer avec des scientifiques des données pour amener les prototypes vers la production Développer et consolider les pipelines d'apprentissage automatique, de la conception des données à la formation et au service des modèles, en passant par la surveillance et le retour d'information Piloter les DevOps de l'infrastructure de production Une bonne connaissance du langage Python Concevoir et construire des systèmes d'apprentissage automatique Une connaissance des pipelines de données (SQL, Beam, Airflow, BigQuery) Une connaissance des principes et technologies DevOps (Docker, Jenkins, Terraform) Une connaissance des plateformes infonuagiques (GCP, Azure, AWS) Un esprit créatif et entrepreneurial Une expérience avec les frameworks d'apprentissage automatique (Tensorflow, PyTorch) Une connaissance approfondie des systèmes backend (Go, Java) et des bases de données (Redis, Mongo) 
ScrapedJobID827:
Drive the execution of all product lifecycle processes for our Data Science and Analytics products, including product research, market research, competitive analysis, planning, positioning, roadmap development, requirements development, and product launch. Translate product strategy into detailed requirements and/or visual mockups for prototype construction and final product development by engineering teams. Communicating verbally and in writing to customers/prospects with various levels of technical knowledge, pitching Firstlight’s data science capabilities, educating them about our data systems, as well as sharing insights and recommendations. Create product strategy documents that describe business cases, high-level use cases, technical requirements, revenue, and ROI Being the champion for a data-first culture at Firstlight and ensuring requirements related to data governance and security are developed and prioritized. Analyze market data to assist in the development of sales strategies, and effective marketing communication. Contributing to creation of product collaterals including pitch decks, product demos API documentation, and more. Driving product capabilities to evaluate data from live products, including how to design and execute various A/B and multivariate tests to shape the next iteration of a product. Evaluate the output captured in statistical analyses and translate them into insights to inform product decisions. 5-8 years of progressive experience in a similar role. Mid to senior-level product management professional with background driving software products related to data visualization, data analytics, or data science/machine learning. Experience interacting directly with customers and partners on technical / product related topics. Must have a thorough understanding of the agile software development life cycle (SDLC) processes and tools. Excellent written, verbal, presentation communication skills. Experience with cloud-based data warehousing technologies such as BigQuery/Snowflake and/or data visualization tools such as Tableau/Looker and/or SQL/NoSQL databases. Excellent analytical and problem-solving skills. Self-starter, ability to work with some ambiguity and comfort working with cross-functional teams. Ability to operate in a fast-paced environment, managing multiple projects simultaneously while prioritizing time and resources based on business impact. Quick learner and ability to understand technology opportunities and challenges at a business level. Preferred Bachelor of Business/Business Analytics/Information Systems/Engineering/Math/Science degree or equivalent experience. 
ScrapedJobID828:
Annotate Case Report Form (acrf.pdf) following FDA/CDISC or sponsor guidelines. Develop SDTM specifications and generate SDTM datasets using SAS. Develop ADaM,specifications and generate ADaM datasets using SAS based on Statistical Analysis Plan. Develop Tables, Listings, Graphs, Patient Profile in support of the Clinical Study Report, Posters, Manuscripts. Develop ADaM data, Tables, Listings, Figures for Integrated Summary of Safety (ISS) and Integrated Summary of Efficacy (ISE). Create electronic submission package to FDA, e.g., define.xml or define.pdf following FDA guidelines with minimum supervision. Analyze information and develop innovative solutions to programming and data analysis challenges. Actively communicate with statisticians for statistical input and analysis interpretation. Follow and reinforce regulatory agency requirements during daily job. Serve as a programming team lead and contribute to department initiative. Provide guidance, mentoring, training for team members and help solve issues from cross-functional teams. Review draft and final production deliverables for project to ensure quality and consistency. Bachelor’s/Master’s degree in Statistics, Mathematics, Computer Science, Electrical Engineering, Biotechnology or related scientific disciplines with at least 3 years of clinical programming experience. Proven knowledge and training in high level computing languages such as. SAS, C/C++, Java, R, Python, MATLAB and SQL. Database programming experience is a plus. Proficient in decoding programming logic and assembling programming code based on logic provided and be able to explain to team members. Proficient in applying concepts in Artificial Intelligence and Machine Learning in the real world. In-depth knowledge of Good Clinical Practices, Clinical research, Clinical trial process and related regulatory requirements and terminology. Good understanding of clinical drug development process. Strong communication skills and coordination skills. ability to communicate with global teams with supervision. In-depth knowledge of Good Clinical Practices, Clinical research, Clinical trial process and related regulatory requirements and terminology. Good understanding of clinical drug development process. Detail-oriented and ability to learn and adapt to changes. Proficient in Microsoft Office Suite, e.g., Word, Excel, PowerPoint, etc. 
ScrapedJobID829:
This is an on-site position - not remote. Work from home as appropriate. Bachelor’s in computer science or equivalent 5 years’ software development experience 2+ years' experience running medium to large/complex projects with multiple internal / external dependencies Expertise in working with at least one deep learning framework, such as PyTorch, TensorFlow, Caffe Experienced in working with ETL pipelines Experienced in cloud providers such as GCP or AWS Strong analytical and problem solving skills Ability to understand and execute on the company’s mission and values Maintain a high degree of ethical standard and trustworthiness Strong technical written and oral communication skills 7+ years’ software development experience Proficient in Python A track record for delivering Machine Learning projects for a product Excellent written and verbal communication skills Strong and proactive communication, natural curiosity. Ambition to apply skills to a wide variety of fields Be able and open to pick up new skills, work with 3rd party technologies and devices 
ScrapedJobID830:
Are you passionate or interested in learning about maritime shipping & logistics? Are you entrepreneurial at heart and want to be a part of a family owned company? Are you a people person who cares for others? Are you a dedicated and committed individual who believes in continuously evolving? Build and manage data warehouse system using best methodology suited for respective business areas Develop tabular and multidimensional models that are compatible with warehouse standards Build high performance data marts and Analysis Services reporting models Develop visual reports, dashboards, and KPIs scorecards using Power BI desktop Connect data sources, importing data and transforming data (ETL) for business intelligence Implement row level security on data and understand application security layer models in Power BI Build DAX and MDX queries in Power BI desktop to support advanced calculations Adapt in development, publishing, and scheduling Power BI reports as per Business requirements Understand business requirements and develop data models accordingly by taking care of the resources Manage assigned projects, develop project plans, monitor performance Design methodology and project documentation Have knowledge and experience in prototyping, designing, and requirement analysis Have knowledge and skills for secondary tools such as Microsoft azure, SQL data warehouse, PolyBase, Visual Studio, PowerShell, PowerApps, Power Automate etc. Integrate PBI reports into other applications using embedded analytics like PBI service (SAAS) or by API automation Bachelor’s degree in computer science or information system and a minimum of 5 years of work experience in a similar field A minimum of 2-4years experience in data preparation, data gateways, and data warehousing projects A minimum of 2-4 years’ experience working/acquaintance with Microsoft Business Intelligence Stack having Power BI, SSAS, SSRS, SSIS A minimum of 2-4 years’ experience with Structured Query Language (SQL) Excellent listening, communication, interpersonal, and presentation skills Excellent analytical, critical, and problem-solving skills Familiarity and experience with PowerShell, JavaScript, CSS, and other Java script library Team player with professional attitude Experience in advanced analytics and data science using Python and R is an asset Experience with other BI tools (Tableau, Qlik, Oracle BI, IBM Cognos, Crystal Report etc.) is an asset Shipping experience is an asset 100% health and dental benefits coverage RRSP coverage with MSC Canada matching a portion of employee contribution Tailored training program opportunities for employee development Employee mentorship, leadership and assistance opportunities An employee referral incentive program Community Involvement Gym facility Health & Wellness Program 
ScrapedJobID831:
Incorporate data from multiple sources to provide comprehensive analysis and strategic insights. Employ, demonstrate, and advocate analytics best practices in the areas of data modeling, data wrangling, data visualization and data storytelling. Understand and prioritize business requirements while managing the expectations of stakeholders. Execute a portfolio of analytics projects that enable growth of the Martin Brower business, including enabling technologies such as self-service discovery and analytics that make it easier for Martin Brower personnel to use data to drive decisions, reduce costs, and optimize Martin Brower supply chain processes. Ensure current activities and program designs allow for future expansions into Machine Learning and Artificial Intelligence. Be a Power User of our data infrastructure – data flows from lake to visualization. Increase the Data Literacy of the Data and Analytics team by acting as a mentor to other analysts regarding core capabilities and cross functional work efforts and projects Anticipate and identify future demand from users/customers, provide input to requirements and align priorities to achieve goals. Monitor and control all project activities, issues, change requests and risks. Communicate with project sponsors, senior management, and functional area managers and/or consultants regarding the status of specific projects through formal and informal verbal and written communication methods. Building and assuring the proper data quality and governance processes Work with the Global Data Office to build and enhance Data Quality tests. This role will need to establish the escalation process of the Data Quality exception-based flags and work with internal divisions to fix issues related to data. Drive automation and efficiency by developing and implementing databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality Develop effective communication with all different parties in case of data issues. Restructure our data governance function by monitoring tasks and updating documentation. Analyze the data impact on the business and collaborate with the risk function to sign off on processes. Foster successful relationships and act as a trusted advisor for team members and stakeholders across the enterprise. Ensure the operations follow all Safe Food for Canadians Regulations (SFCR), Global Food Safety Initiative (GFSI) and Good Warehouse Practices (GWP)/Good Drivers Practices (GDP) for transport rules and regulations. Other projects or duties as assigned. 6+ years of experience as a data analyst or business analyst. 2+ years managing data analyst or business analyst. BA/BS in technical field (Computer Science, Math, Statistics, Physics, Engineering, etc.). Excellent programming skills, including expert level familiarity with DAX, SQL, Python, or similar. Demonstrated knowledge of Power BI functions such as analytics, data modeling & mining, reporting, data cleansing, Power Query. Knowledge of big data infrastructure. Strong analytical and problem-solving skills including a thorough understanding of how to interpret customer business needs and translate them into the application and operational requirements. Exceptional interpersonal skills in areas such as teamwork, facilitation, and negotiation. Skilled at precision questioning, ability to define and refine business questions to get to the root concern that can be specifically and concisely addressed. This position must pass a post-offer background and drug test. Post graduate degree Technical Certification Experience working both in a business and IT role. Experience as a liaison between IT and business. Experience within the distribution or Food Service industry. Familiarity with data science concepts like statistical modeling, machine learning and forecasting models with an ability to explain them to non-technical audiences. 
ScrapedJobID832:
Support the Business Insights and Visualization as well as Data Science teams with reporting, interaction and self-serve module development. Gather requirements from Finance teams for the development of interaction, reporting and self-serve modules and exercise leading edge analytics skills in data visualization, extraction, forecasting, etc. to address business needs Develop interface and modules for scenario modeling that could be part of an AI/ML solution Work in an agile environment and contribute to the improvement of our development processes Ensure that the return on investment in advanced financial analytics resources and technology is realised by keeping abreast with strategic requirements from senior management and that these are aligned to internal projects being actioned within our insights team Demonstrated experience in business process analysis, data architecture design and development, and the implementation of workflow enabled solutions and their intricacies in a finance environment. Defines a project approach to ensure customer success, and provide critical and constructive guidance leveraging MicroStrategy best practices to customers, steering them towards a long-term vision for success Provides technical oversight to projects and project teams, including customers and partners, taking their ideas from concept through full deployment, while mentoring junior colleagues Self starter who is comfortable working with and presenting to all management levels Creates technical and/or functional MicroStrategy solutions based on customer requirements and business objectives, including standalone applications and more complex interdependent systems within Bell’s infrastructure Support training and knowledge transfer activities Coach and mentor junior team members Degree in Data Science, Computer Science, Information Technology, Economics, Statistics, Information Systems, Applied Math, Business Administration, Finance or any other related field (masters degree considered an asset). CPA or related finance experience considered an asset Strong analytical, problem-solving skills and ability to work with large and complex technical data sets Experience in Business Intelligence or Data Analytics with eliciting business requirements Advanced Visualization Development Experience with Tableau, PowerBI, Qlik, Microstrategy, etc. Minimum 5 years of related experience with Microstrategy with relevant certifications Strong SQL skills, ability to perform effective querying involving multiple tables and subqueries Ability to leverage insights and opportunities from data and metrics to build strategies and make recommendations Advanced knowledge and experience with SQL, practical knowledge of Data Modeling and data profiling Practical knowledge of UX/UI customer-centric and performance-centric analytic solution design Experience with query tuning and performance troubleshooting Effective oral, written communication and presentation skills Commitment to personal and professional growth Certification in MSTR is an asset Experience with Rest APIs and Alteryx integration experience with MicroStrategy is an asset Knowledge in Alteryx and other ETL Tools is an asset Experience with Python or R and the ability to drill into the data and gain valuable insights along with Machine Learning and Artificial Intelligence algorithms and approaches (is an asset) Experience in Telecom, Finance or IT is a strong asset. Bilingualism is an asset (English and French); adequate knowledge of French is required for positions in Quebec. 
ScrapedJobID833:
Dynamic personalization: Serve content, propose products, promote services, or execute actions Dynamic customer cohort creation: Determine cohorts of similar behavior or tuned to specific KPIs Scalable actions across segments of customers Usage-based/behavior-based pricing models: Insurance based on behavior Abnormality and fraud detection: Identify and prevent unauthorized activity Security and remediation: Detect issues and alert responders in exponentially less time than traditional security through intelligent analyses Network performance: Monitor and respond to network performance issues faster IoT analytics: Unify disparate data sources to reduce costs and improve performance IOT TCO: Reduces the cost of installation by reducing tuning and maintenance Plan, direct, and guide the activities of data science and operational research to provide effective management of staff and projects. Design, develop, test, advocate, evangelize and build data-driven modeling approaches Assess the effectiveness and performance of modeling and data enhancement techniques Develop ontology for key market segments Develop outcome/event taxonomy for key business models Coordinate with different functional teams to implement data engineering, models and monitor outcomes 5+ years experience managing teams 10+ years experience working with and creating data architectures Experience with artificial intelligence, natural language processing, machine learning Excellent understanding of machine learning techniques: Supervised/Unsupervised/semi-supervised Learning, SVM, Tree-based Methods, Neural Networks, Naive Bayes, k-NN, ensemble methods, CNN, RNN, NLP, Feature Engineering, hyperparameters optimization, data visualization Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, 0-hypothesis, Regularization) Experience using statistical computer languages (Python, SQL, etc.) and conventional data science toolkits, such as PANDAS, Weka, NumPy, MATLAB Experience with NoSQL databases Knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations Excellent written and verbal communication skills Project management A drive to learn and master new technologies and techniques onfluence JIRA Spark, Pulsar Azure, AWS, Kubernetes Python, Scala Keras, Scikit-learn, PANDAS, Numpy Bit bucket, GitHub Jupyter Notebook Postgress, Parquet, MySQL JavaScript, airflow, Pulsar Ph.D. in operations research, applied statistics, data mining, machine learning, physics or a related quantitative discipline Experience in operations research, applied statistics, algorithmic complexity, RDS Experience with time Series, econometrics Experience with streaming systems Experience with Object-oriented modeling/MVC design patterns Sense of humor 
ScrapedJobID834:
Develop product plans and objectives; report progress against plans and KPIs to all stakeholders (Data Science, Engineering, and business leaders) Work with the partnership team to assess and integrate external data sources that could improve our products Assist on client discovery calls to inform roadmap, business requirements, and vet early outputs Guide the Data Science team through model development by clarifying business priorities for projects and identifying and scoping data pipelines as needed Prioritize features and resources to ensure critical data science resources are working on the highest impact solutions Coordinate with front-end Product team to ensure timely and successful launch of new features and functionality Work across Services, Marketing, Product, and Data Science to create and maintain educational materials, whitepapers, and other analytical documents 3+ years of product management or product development experience, preferably in a Data or Analytics role Understanding of data science and hands-on analytical skills (such as SQL, Data Science tools and workflows) Demonstrated ability to work with internal stakeholders to collect feedback, prioritize tasks, and manage the engineering backlog Strong oral and written communication skills, and ability to collaborate with, and influence cross-functional partners Self-motivated, self-directed, and the ability to thrive in a fast-paced environment in an industry that constantly changes Organized with a knack for managing complex projects Creative and resourceful when it comes to problem-solving A passionate can-do attitude; you are not afraid to try, learn, and improve Experience in the Market Research of CPG industry Experience working with consumer purchase panel data An inclusive and collaborative company culture - we work together in an open environment to get things done and adapt to the changing needs of the business and our clients An opportunity to have an impact at a high growth Technology and Data company Ownership over data and environments in an industry-leading product Competitive total compensation package Volunteer time off and charitable donation matching Strong support for career growth, including mentorship programs, leadership training, access to conferences, and employee resources groups Regular hackathons to build your own projects Great benefits package including health/vision/dental, unlimited PTO, flexible schedule, 401K matching, travel reimbursement, and more 
ScrapedJobID835:

ScrapedJobID836:
Develop highly scalable capabilities with natural language processing, machine learning, data regression, and rules-based models, and expose the results of these efforts through APIs and/or persisting the data for later consumption Measure and improve efficiency and effectiveness of the customer experience and internal processes, and help clearly identify and communicate areas for improvements Be aware of industry trends in the data, analytics, NLP, and ML space, and help with identifying applicable technologies Work collaboratively with, learn from, and share knowledge with the rest of the Analytics and Audit team Help the team tell stories with data through reporting and custom data visualizations to drive key business decisions Collaborate effectively with the Design and Product teams to understand product requirements Work closely with testing to ensure we're delivering high quality solutions Work in a true DevOps environment and work closely with operations to deploy advanced solutions Collaborate effectively with high profile customers on an as needed basis Continue to improve the thriving engineering culture across all tech functions Must have customer focus, world-class quality, and effective communication with a focus on decisive, fast-moving solutions, quick and constructive resolutions to conflicts, and a "no barriers" mentality Serve as an evangelist for the team and overall culture, both internally and externally Bachelors or higher degree in Computer Science, Mathematics, or another technical field. 3-5 years of engineering management experience in a technology environment. Highly proficient with Python 3 and Jupyter notebooks Experience telling stories with data and data visualizations
Tableau, SteamLit, Plotly Dash, matplotlib, etc. Tableau, SteamLit, Plotly Dash, matplotlib, etc. Very comfortable reading and writing complex SQL queries Experience with building natural language processing (NLP) solutions; spaCy v3+ preferred
Experience with building custom NLP processing pipelines and training new models Experience with building custom NLP processing pipelines and training new models Experience in building machine learning models and exposing them through APIs; PyTorch and FastAPI preferred Familiarity with distributed Python tools such as Ray and Dask Comfortable with Typescript or willing to learn Table stakes are VS Code and git Experience with DevOps and MLOps
Kubernetes and Docker Kubernetes and Docker Experience with any of Tableau, Redis, PostgreSQL, or Snowflake Experience in an established mid-sized growth stage company or a fast-moving start-up in the areas of data analytics or real-time data processing Medical, Dental and Vision coverage Retirement benefits Employee Assistance Program Healthy Living Rewards Program Generous Time Off Allowance Volunteering Time Off Education Assistance Program 
ScrapedJobID837:
Write, test and deploy code for various applications to meet business needs as they arise Participate in architecture design decisions, and investigate SDKs, frameworks and APIs Support internal processes through the creation of data models, workflows and automation Understand various data sets within the organization and create models for data analytics / machine learning ‘First Line’ responder to our helpdesk call center Support internal processes through the creation of workflows and automation Support company training and continuous improvement initiatives by knowledge sharing Computer Science degree, or Data Analytics related diploma, with a skillset proven through relevant work experience or personal projects Proficiency in data analysis, modelling and visualization using modern Business Intelligence tools Adept in developing ETL automations and Data Integration processes by understanding the data flow according to the requirements Knowledge of Data Science / Machine Learning related technologies and methodologies Knowledge of MS Azure Serverless offerings for eg. Function App, Event Hub, Data bricks MS SQL Server, Query performance optimization, Apache NiFi, OData framework, Stream Processing Aptitude developing applications leveraging JSON or XML based RESTful APIs Knowledge of object-oriented programming, client server architecture, relational database management Web Development experience an asset Air-conditioned manufacturing facility Health, dental, vision care Life insurance Company pension plan Tuition reimbursement Employee Assistance Plan Retirement benefits Wellness committee 
ScrapedJobID838:

ScrapedJobID839:
You will be a key player in building and improving our automated training and deployment platform. You will own the design, implementation, and maintenance of the components of our internal Machine Learning platform, including data pipelines, tools, and deployment infrastructure. Through proper implementation and delivery, you will work collaboratively with Product Management and ML Developers to deliver the best products and solutions to our customers. 3+ years of industry experience in Software Development Expertise with Cloud Infrastructure (AWS, GCP, Azure) Proficiency in Python or another back-end language (Go, Scala, Java, etc.) Knowledge of Docker and Kubernetes Proficiency with CI/CD pipelines Comfortability working with a distributed team Industry experience in productizing and deploying machine learning models at scale Graduate degree in Software Engineering, Machine Learning, Computer Vision, Image Processing, or a related field Bonus: Experience with deep learning frameworks such as TensorFlow or Pytorch Featured in Forbes: How Ethical Is Your AI? Sama Honored on Inc. Magazine’s Annual List of America’s Fastest-Growing Private Companies — the Inc. 5000 
ScrapedJobID840:
The application of quantitative skills (Mathematics & Statistics) and methodological approach to ensure a disciplined approach to analysis and data mining Ability to create algorithms, apply 'scoring' of data Lead the Data Science team responsible for developing advanced analytical solutions to support key business goals Coach and develop team members as necessary to develop and maintain high standard of output Engage with senior stakeholders to understand and translate key business challenges into analytics solutions, leveraging ML approaches where appropriate Develop effective model management processes and performance framework to enable operational ML solutions In collaboration with Enterprise Analytics partners develop a multi-year AI/ML strategic roadmap focused on driving transformational results through analytics Minimum 10+ Years of Job Related Experience Extensive experience in advanced analytics and data science, managing and leading analytics teams Financial services experience preferred Advanced degree or certification in Data Science, Analytics, Mathematics or Statistics preferred Deep expertise with analytical tools such as SAS, MATLAB and cloud technologies such as AWS Sagemaker Advanced Experience with coding and scripting languages such as Python, R, SQL Advanced experience with ML and deep learning algorithms, methods, platforms and processes Understanding of machine learning theory and predictive modeling lifecycle Knowledge of Data Management, Data Governance, and technical architecture required to enable advanced analytics capabilities 
ScrapedJobID841:
You’re the face of Speech technologies, who’s responsibility is to drive and deliver speech data science use-cases Demonstrate to internal clients how machine learning can improve their business Managing internal partnerships across the organization to align and ensure adoption of AI vision and execution Persuade Marketing and Operations groups as to why they should leverage the power found within natural language modeling Ownership of a multi year roadmap for Speech Technologies use cases Leading cross functional AI/ML teams of Data Scientists, Business and Data Analysts Support a team of approximately 10 employees Degree in a discipline such as: Data Science, applied math, applied science / engineering, economics/econometrics, management science / operations research, or related area 2+ years experience in strategy, planning, consulting, analytics or related disciplines 2+ years of direct people management experience A successful track record as a leader, developer and manager of people; demonstrated experience to attract, retain and develop strong talent and build a positive organization and team culture Experience working closely with senior VP level executives across multiple business units Self Motivation and drive to deliver high-quality solutions Strong interpersonal skills, including the ability to collaborate across the team and work closely with stakeholders Excellent written and oral communication skills (English) with a demonstrable history of developing strong partnerships and cross-team collaboration Strong business acumen, with an appreciation for the opportunities and constraints that accompany an ever-evolving competitive environment Proven project management and change management skills Advanced knowledge of ML models: deep learning, reinforcement learning, and others Theoretical understanding of neural networks, backpropagation, and optimization algorithms with emphasis on mathematical understanding Experience in the telecom and/or call centre operation sector 
ScrapedJobID842:
Design, modify, implement, test, and provide operational support for enterprise software products and platforms, including software infrastructure and development tools for the Data Develop, operate and drive scalable and resilient data platform to address the business requirements Create new opportunities in this space for Data Science as a Service (DSaaS) platform with new feature capabilities and new offerings that drive customer and business value Ensure industry best practices around data pipelines, metadata management, data quality, data governance and data privacy Strong knowledge of AWS cloud infrastructure computer, networking, storage and other AWS cloud services Proven experience with AWS services such as Data Pipeline, Step Functions, Batch, Lambda, CloudFormation, CloudWatch, EC2, EMR, SNS, IAM, ELB, EC2, S3, Redshift, Glue Experience with Big Data tech stack, including Hadoop, Python, Spark, PySpark, Scala, and Hive, and NoSQL data stores Knowledge and previous experience with Unix and Linux Experience working with large datasets and large-scale distributed computing Working knowledge of building out data marts, data warehouses, and data lakes Experience on ETL data pipelines development and performance tuning Experience with manipulating and transforming data Experience on columnar databases like Redshift, Redshift Spector Working knowledge of containers and container orchestration Proficiency using Kubeflow This individual must have strong knowledge of healthcare data, analytics & workflows, excellent problem-solving & project management capabilities, and a proven ability to design & drive Big Data platform. Excellent critical thinking, verbal and written communications skills Knowledge and experience in the healthcare industry is a plus Demonstrates strong drive to learn and advocate for development best practices. Prescription Drugs Vision Care – frames, lenses, contact lenses, eye exam, eye surgery Paramedical Services Dental Basic Services 1–5 Calendar Years of Service 120 hours 5+ Calendar Years of Service 160 hours 100% of contributions up to 3% of base salary Plus a 50% match on the next 2% contribution This role may be located anywhere in Canada – remote opportunity/home office. 
ScrapedJobID843:
This is a remote position that can reside anywhere in Canada 75-80% of the position will be using SQL to join data from various tables to get it ready for analysis/visualization (eg getting raw data together, cleansing, formatting, manipulating, etc) 20% of the role will be creating reports/dashboards to answer various business questions from stakeholders The company uses Looker tool and LookerML to manipulate data and create dashboards/reports This is a business-facing role, using data to answer various business questions from finance, marketing, sales, operations, etc 4-8 years of data engineering / BI experience, manipulating large amounts of data in RDBMS Very strong SQL experience (including complex Joins, etc) Experience with reporting/visualization tools like Looker (preferred), Tableau, PowerBI or similar Experience with user-facing activities (eg understanding reporting requirements and delivering the solution/data answers Very good communication skills Looker and LookerML experience is highly preferred Exposure to ETL is considered an asset Interest in data science / machine learning Redshift exposure is preferred Python experience is considered an asset Salesforce or CRM data exposure is an asset Interest in active travel 
ScrapedJobID844:
3+ years experience in a Data Engineering or Analytics role managing data pipelines Strong skills in Python, SQL, Airflow, Data Modeling and ETL pipelines Familiarity with: Snowflake, AWS Redshift, or BigQuery Experience working with Data Science and Machine Learning teams as stakeholders A passion for programming and solving problems with code A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience A love for technology, and an insatiable curiosity for new tools to tackle real problems We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process. We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners. We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy. We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality. 
ScrapedJobID845:
Implementing scalable, fault tolerant and accurate ETL pipelines that work in a distributed Hadoop environment Developing platform services to operate the big data applications at scale Gathering and processing raw data at scale from diversified sources into Hadoop Building enterprise business analytics and reporting applications on Hadoop Proven experience working with various components of Hadoop ecosystem: Spark, Hive, Impala, Kafka, Oozie Strong understanding of computer science fundamentals Proficiency with relational databases and SQL queries (MySQL, Oracle or similar) Understanding of how to handle high velocity, high volume data events Understanding of factors affecting performance of ETL processes and SQL queries, ability to work on performance tuning Experience implementing data pipelines moving large volumes of data a day Experience in implementing application in Scala on SPARK Experience coding in Python Skills in real-time streaming applications Knowledge of Scala A development workflow using Docker containers Compulsion for automating your day-to-day processes Ruby, Java, Python, and React.js Hadoop, Scala, Spark, Hive Kubernetes, Docker, Kafka PostgreSQL, NoSQL AWS 
ScrapedJobID846:
As an experienced audience segmentation specialist, you will work with the Rogers Data team to design and implement insights-driven audience segments using our Data Management Platform and the newly introduced Customer Data Platforms (Adobe AAM, AEP). Identify opportunities to scale audience data sources, including 1st party, 2nd party, and 3rd party data to enhance audience effectiveness Support the integration of new data sources and destinations into our DMP & CDP platforms to enhance audience capabilities. Develop a deep understanding of audience segments available for use in targeting and retargeting and identify potential gaps or opportunities in digital audience strategy. Oversee Data Management Platform (DMP) segment intake process and other day-to-day operational tasks. Support the marketing team to co-develop targeting tests/experiences, using technology to enhance digital journeys and driving better engagement for the RSM online and app users. Work with Product Owners on hypotheses testing, A/B & MVT test development and prioritization for our customer experience. Help develop a strategic roadmap for audience segmentation and personalization in support of experimentation. 3+ years of experience in digital audience segmentation using Adobe Audience Manager or other leading DMP. Experience with Online Behavioral Targeting and Web analytics tools: Adobe Analytics, Google Analytics or ComScore platform. Good understanding of HTML, CSS and JavaScript, web diagnostic tools like Charles proxy, HTTPWatch or any other browser-based extensions. Previous experience with Digital Optimization tools (Adobe Target, Optimizely, Maximizer) considered as a strong plus. Experience in Adobe Experience Cloud solutions (Target, Audience Manager, AEP, Adobe APIs etc.) is preferred. Exposure to AdTech and MarTech platforms is a plus, example, DSPs, 3rd party data, ad serving, real-time bidding, and ad exchanges. Strong analytical and problem-solving skills as well as flexible to adjust to evolving business needs and work effectively in cross-functional teams. Superior communication skills; ability to understand objectives, lead business and technical discussion and communicate effectively. Demonstrate an understanding of legal issues around data privacy and security. Passionate about new trends in audience and data platforms. A competitive salary and benefits that include access to our Employee Share Accumulation Program, Retirement Benefits and a variety of other perks including 50% off Rogers services and Blue Jays tickets A manager who deeply cares about your development and long-term career at Rogers A team that trusts and wants to win together Smart and accomplished colleagues who are focused on both the “what” and the “how” Flexibility to work from home even after the pandemic ends As we grow our team, the well-being of our team members remains our top priority. To ensure the health and safety of our team members, including those in the recruitment process, our team members are working from home, and are equipped to do so safely and efficiently Not from the city? No problem! Rogers invites candidates to apply no matter where you are located as you will be working remotely. 
ScrapedJobID847:
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. 2+ years of non-internship professional software development experience Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design Bachelor’s degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline 1+ years of experience as a data/software developer/scientist or related technical job A passion for improving customer experience Excellent verbal and written communication skills and technical writing skills Graduate degree in a related technical field 2+ years of experience as a data/software developer/scientist or related technical job Experience with Agile Development Experience with statistical modeling or machine learning (Classification, Collaborative Filtering) Experience with AWS services A love of music! 
ScrapedJobID848:
Review the literature for the state-of-the-art computer vision and machine learning methodologies. Design and implement proprietary machine learning algorithms and optimize them based on runtime system requirements and constraints. Propose, implement and monitor validation and performance metrics for the proprietary algorithms. Conduct code reviews and work closely with the software/hardware teams to transfer the prototyped models to the production environment. Setup the development pipeline including data management and deployment through continuous integration scheme. Master’s Degree or higher in Computer Science or a related technology/engineering field. 3+ years of hands-on experience in developing and implementing and evaluating machine learning models algorithms. Solid understanding of statistical learning algorithms, including (self, semi) supervised, unsupervised and transfer learning and computer vision algorithms. Proficiency in Python and version control. Basic familiarity with object- and service-oriented design, API development, containerization, and complexity analysis. Solid experience with TensorFlow, PyTorch and OpenCV. Familiarity with image processing algorithms. Strong analytical, communication and presentation skills. Published papers in top conferences or journals such as CVPR/ICCV/NeurIPS/IEEE Transactions Experience with cloud architecture design and deployment Experience with web api design and development Familiarity with software design patterns Hands on C++ programming 
ScrapedJobID849:
Agriculture Construction & Equipment Consumer Products Food Forestry and Forestry Products Retail and Distributions Shipbuilding and Industrial Fabrication Transportation and Logistics Advanced Analytics, AI & ML exploration, discovery, and solutions across all businesses Data Engineering and wrangling Master Data Management Data warehousing BI governance Reporting, analytics, data exploration Information delivery (portals, mobile) BI competency center Advanced / predictive analytics GRC (Governance, Risk, Compliance) aspects of BI and data management Monetizing data and information. Finding ways to leverage existing enterprise data and information in company's products and services. A University Degree in computer science, mathematics, science, or a related field Masters degree or PHD (in a relevant field) is an asset. Minimum of 10 years of progressively responsible experience in a directly related area, during which both professional and management capabilities have been clearly demonstrated. Extensive expertise in data platforms with a solid understanding of key BI trends, BI vendor landscape and experience business driven / self-service BI Expertise in data modeling; logical, physical and multidimensional A solid understanding of leading-edge technologies and best practices such as Hadoop and Big Data A solid understanding of mobile delivery architecture and best practices A solid understanding of Customer Experience (CX) technologies Experience with data science, statistical analysis, data mining and predictive algorithms Experience with relational - SQL - and multidimensional - MDX - query languages Extensive experience interacting with C-level executives Experience managing large [global] complex BI projects and teams Experience in building and supporting BI/analytics/big data business cases Proven skills to work effectively across internal functional with some ambiguity The desire to challenge the norm and solve business challenges through your AI/ML experience and expertise 
ScrapedJobID850:
Python, Bash SciKit-learn, TensorFlow PyTorch, NLTK, SpaCy REST MLflow, OpenShift, Kubernetes, Docker Be the primary contributor and maintainer of our data collection and validation methods Use advanced Machine Learning models to validate data, sort it and preprocess it to be used in downstream ML tasks Maintain and monitor data validation and processing jobs that run 24/7 Work as part of an agile development team to write Python code Write unit and integration tests for your Python code Design, in collaboration with team, the software implementations that satisfy business requirements Design, in collaboration with the architecture team, the system architectures that satisfy business requirements Collaborate with QA in development of test cases for Java code Develop deployment systems for Python based systems Document code and document detail designs Collaborate with product owners on user story generation and refinement Monitor and support operation of production systems Participate in knowledge sharing activities with colleagues Minimum 8 years of Python or similar developer experience Experience with:
Agile development methodologies
Network protocols such as HTTP, TLS, TCP
Web services technology such as REST, JSON, or Thrift
Multi-threaded programming
Test driven development
Continuous integration systems Agile development methodologies Network protocols such as HTTP, TLS, TCP Web services technology such as REST, JSON, or Thrift Multi-threaded programming Test driven development Continuous integration systems Experience with any of the following is an asset:
Docker or Kubernetes
Micro services
Machine Learning and Analytics Docker or Kubernetes Micro services Machine Learning and Analytics 
ScrapedJobID851:
Design, development and implementation of complex data-centric solutions, including large data set verification, transformation, and feature generation Ensure continuous high-quality input for ML model development Design and implementation of model delivery systems Design efficient data collection and ETL processes Develop effective strategies on deployment and hosting of ML models Manage and monitor deployed models Ability to deploy fast or real time inferencing a plus Extensive Machine Learning knowledge Knowledge of production infrastructure and pipelines for Machine Learning models (MLOps) Experience with one or more of the following: Classification, Pattern Recognition, Recommendation systems, Targeting systems, Ranking systems Experience with Python or other relevant programming languages and Machine Learning frameworks Work on functional design, process design (including scenario design, flow mapping), prototyping, testing, training, and defining support procedures Experience working with an advanced engineering team Knowledge of best practices for software engineering Interests in performance optimizations Deep knowledge of math, probability, statistics, and algorithms Experience with participating in the machine learning competitions such as Kaggle Published articles or papers Experience in ad tech (i.e. in-depth knowledge of digital programmatic advertising data) Comprehensive health, dental, and vision plans at no cost to you Time off and flexible work schedules Retirement plan with a 5% company match Stock options and equity packages Generous parental leave Monthly wellness stipend plus fitness discounts and quarterly wellness group activities Home office stipend Community engagement opportunities and donation-matching program Annual virtual company retreats and regular community-led team events COVID-19 guidance: We have re-opened offices in various cities following local guidelines, but are continuing to maintain a flexible work environment. 
ScrapedJobID852:
10+ years of experience in technical program/product/engineering management for large-scale business intelligence systems and/or complex software development initiatives. Bachelor’s degree (masters preferred) in business, engineering, computer science, or equivalent experience. SaaS experience / cloud native applications / backend data experience. AWS experience highly preferred; may consider other platform experience. Ability to influence at all levels and build strong partnerships across organizations to deliver the best outcome of complex programs. Excellent organizational and coordination skills along with multi-tasking capabilities to get things done in a fast-paced environment. Outstanding communication skills appropriate for executive-level audiences; ability to structure and communicate goals of program, relationship to business goals, and other relevant success criteria. Demonstrated ability to simultaneously understand and communicate the bigger picture while diving in to understand issues & risks to drive rapid resolution. Drive creation of data program roadmaps and data execution plans for complex, cross-organizational teams across all phases of planning, development, and production readiness and launch. Influence decisions by connecting strategy, priorities, and business/technical outcomes Lead execution in partnership across multiple functions including Data Engineering, Data Science, Data Analytics, as well as, with central data teams to align and deliver successful outcomes Ensure continued alignment of program scope, status, risks, and dependencies through effective communication across the organization and at all levels. Quickly and effectively identify critical issues and dependencies that need action and personally drive them through to closure. Balance business needs and technical constraints in resolving issues. Anticipate, recognize, and work through resistance or setbacks independently, work well with others when conflicts arise: see opportunities, ensure alignment with objectives, find common ground and promote understanding of alternative viewpoints before driving for closure and cooperation Effectively communicate program progress appropriately to varying levels of stakeholders. 
ScrapedJobID853:
Have + years of hands-on ownership of all customer's technical issues and partner with the LivePerson SME's team to resolve high-complexity issues as necessary Enterprise wide strategic support/ engineering experience, working closely with large complex project initiatives post implementation. You will investigate issues by analyzing data stored by the application, checking logs and reviewing code, provide fixes and workarounds, and review changes for operability to maintain existing software solutions. Resolve technical issues using JavaScript, CSS, and API knowledge Troubleshoot issues with software Identify root causes of technical issues in production and recommend improvements Assist customer support team with customer inquiries Monitor application performance and identify trends to expose any potential performance bottlenecks or issues Experience using SaaS tools like AppDynamics and Splunk, to provide faster resolution to solution issues. API integration troubleshooting- monitor application health to investigate application issues Responsible for all customer engagements from initiation to resolution through ensuring progress by SLA and escalation Build strong customer relationships, including key customer stakeholders and sponsors Always strive to provide an exceptional customer experience Manage customer expectations and lead them to customer satisfaction Make sure all deliverables are on time, adhere to the highest quality standards and fulfill customers' requirements Keep track of key account support metrics Attend weekly meetings and quarterly reviews Take initiatives in identifying growth opportunities Provide constant transparency to an open engagement status/progress while communicating progress to both internal and external stakeholders Pre / Post-release deployment management Manage high priority incidents and work with internal/external teams towards full resolution Provide post-mortem root cause analysis Provide ongoing feedback on product usability to the Product team Stay current with the maintenance activities, change management, and bug fix releases A proven track record of Technical Account Management or System/ Production Support Engineering for a SaaS or Web company HTML / CSS / JavaScript experience and SQL Web troubleshooting experience Experience troubleshooting with API's /SDK's Ability to analyze data and provide insights Experience in managing multiple stakeholders and projects Excellent verbal and written communication skills Critical thinker and problem-solving skills Good understanding of web technologies and the associated support teams/processes Team player with the ability to work with multiple stakeholders and cross-organizational efforts with a number of different virtual teams concurrently Good time-management skills Require little to no supervision Experience in using software for sales management such as Salesforce, etc. Ability to work under pressure and tight deadlines. Available for off-hours escalations Available to travel to additional customer sites as required (up to 15%) BSc/BA degree in a relevant field or equivalent experience 
ScrapedJobID854:
You'll play a pivotal part in informing and delivering upon our data strategy, by providing sales and marketing performance data, creating custom dashboards and visualization, and supporting marketing and financial strategies Providing Advance analytical insights to the team and help them improve marketing strategies Provide technical leadership to internal team members and various stakeholders Operationalize and support our underlying data systems, improving our system reliability, accuracy and stability You are analytical and outcome-oriented with a proven ability to translate technical considerations into business implications as well as to synthesize data into actionable insights You are well-versed with Business Intelligence/ Market Intelligence processes and other marketing technologies You have demonstrated the ability to successfully deliver complex projects involving people, process, technology, and change management You have experience with agile ways of working and a bias for action to break down barriers to get results fast with a test and learn mindset You can assemble large complex datasets across multiple databases and sources by building automated pipelines (ETL) Strong analytic skills related to working with unstructured datasets. Strong Business Acumen Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. SAS knowledge Business Intelligence/ Market Intelligence processes and other marketing technologies understanding Technical or data-driven educational background (computer science, engineering, statistics, data science) and/or Masters of Business Administration (MBA) degree 5+ years of progressive and relevant work experience Takes ownership, initiates improvements, and is self-directed Able to effectively engage stakeholders to establish cross functional alignment for projects Prior telecommunications expertise B2B marketing Python experience Hive / Spark / Nifi experience Experience with cloud (GCP Amazon or Azure) Data Science / Modeling experience or working in a Data Science team 
ScrapedJobID855:
Ph.D. or Masters in CS, applied mathematics, statistics, physics, or related discipline; Two or more years’ experience developing robust code on larger projects, including code review, refactoring, unit testing, version control, etc.; Knowledge of and experience with machine learning techniques, including deep neural networks, recurrent neural networks, generative models, and attention mechanisms; Expertise in Python and PyTorch; and Intellectual curiosity and drive to excel. 
ScrapedJobID856:
Research and develop models to predict customer behaviors and risk profiles across the credit lifecycle Apply scientific methods and mathematical approaches to solve business problems Collect model requirements from stakeholders. Propose, prototype and develop new models B.S. degree in Computer Science, Statistics, Mathematics or related quantitative field, or an equivalent work experience 3+ years of experience in machine learning (academic research qualifies) Strong theoretical knowledge and understanding of inner workings of ML models, such as time series forecasting, classification and regression and statistics Advanced knowledge of Python with focus on ML (PyTorch, TF, scikit-learn) and SQL Entrepreneurial and self-directed with a bias towards action in fast-paced environments Experience in end-to-end delivery of ML models in production (requirements gathering, prototype, development, performance validation, sign off) MSc. or PhD degree in Computer Science, Statistics, Mathematics or related quantitative field Familiarity with Cloud modeling tools like Sagemaker, GC Datalab, and Azure ML. Past experience with version control tools such as Git or CI/CD tools Experience in managing business stakeholders in technology projects Familiar with financial concepts, commercial credit and bank transactional data Familiarity with large-scale data pipelines Be part of a dynamic, collaborative, progressive and high-performing team, building revolutionary products that matter Generous benefits, including a company match RRSP program. Continued professional development opportunities through programs such as Six Sigma. A modern workspace centrally located in Toronto’s thriving downtown core, easily accessed by transit and a few minutes’ walk from Union Station. Flexible time-off options 
ScrapedJobID857:
Develop machine learning solutions to integrate into our products Balance building technically advanced solutions and swiftly shipping Keep pace with developments in Deep Learning relevant to our activities (papers, conferences, etc.) Work with a diverse team of talented ML Engineers, Backend Engineers, Developers in Test, and Product Managers Ability to write production-grade code in Python Hands-on experience with any of these frameworks: Tensorflow, PyTorch Passion for learning new things and bringing in new ideas Experience with video processing, Risk scoring, Fraud solutions Friendly and supportive Adaptable and flexible Articulate and persuasive High IQ and EQ Curious and coachable Commercially Aware Resilient and tenacious Big picture and the detail IDEAL: Integrity, Diversity, Empowerment, Accountability, Leading Innovation 
ScrapedJobID858:
Researching the automation of the bank’s loan adjudication process using proprietary data sets to help make better and faster decisions. Investigating additional business innovation opportunities across the Wheaton group of companies Bridging analysis and real-world business decisions Working alongside an innovative and entrepreneurial team to help business leaders make data-driven decisions Several years of experience in a data science role An undergraduate or graduate degree in data science, statistics, mathematics or related field Experience conducting large scale statistical analyses using industry-standard tools (R/Python/Stata/MATLAB/SQL/etc.) Can structure meaningful evaluations of whether, and to what degree, data science can improve business decisions relative to the status quo. Ability to navigate the messiness of real-world data Independent and entrepreneurial, but effective at collaborating across all organizational levels as needed Ability to communicate technical concepts and analyses to non-technical audiences Experience implementing machine learning-based solutions Competency in data pipeline structuring Previous work experience in the finance or insurance industry Career opportunity with a stable, growing, and entrepreneurial company Professional development support and mentoring offered Competitive compensation, benefits and RRSP Convenient downtown location with an onsite gym and rooftop patio 
ScrapedJobID859:
Develop and maintain algorithms, data pipelines, automated processes, and services to create a data science solution that are customer focused Extract mission-critical insights from datasets Innovate and bring creative ideas to building mission critical customer facing products that depend on ML solutions Work with product and business teams to identify solutions and best practices Create scalable models that drive business decisions and enable our customers’ success Design and develop processes and systems which analyze and generate actionable insights from diverse data sources Develop tools to monitor models for evolving performance and accuracy Mentor team members in the areas of technical expertise and career building Contribute to best practices around feature extraction, model development, and knowledge sharing among multiple data science teams Directly contribute to architecture planning Been in the ML engineering game for some time. You have a Bachelors/Masters and 4+ years of industry experience Proven ability to architect data science solutions to complex problems and delivering solutions in customer facing products Experience delivering solutions that analyzes big datasets using tools such as Apache Spark Experience delivering solutions that analyzes time-series data Strong programming skills in Python A strong command of SQL and working with multiple relational databases and data warehouses (Redshift, Postgres, Athena, Snowflake, etc…) Experience in end-to-end machine learning project life cycle Experience working with unstructured data Are scrappy when extracting useful insights with partial data A solid experience in working with software development teams and using source version control tools like Git Experience deploying deep learning models Experience with frameworks for in-production ML code (e.g. Kedro) Developing and deploying using Docker With some of the AWS services (e.g. EC2, S3, Sage Maker, Cloudwatch) With accessing data from other datastores in the AWS ecosystem such as ElasticSearch, S3, and DynamoDB The BEST team. Remote-first culture. International Meetups. Access to Jungle Scout tools & experts. Performance Bonus. Flexible Vacation. Comprehensive Health Benefits & Retirement Program. 
ScrapedJobID860:
Partner with our awesome AI, Product and Marketing teams to answer high-priority strategic questions. Here's a few examples: Given all our crazy ideas, what should we build next? Which features will have the highest impact and help us accomplish our goals more quickly? Deep dive on core product funnel usability and growth. Identify where we are able to improve our platform. Utilize Data to identify where we should spend our partnership and marketing efforts? What are the most promising opportunities for growing our brand? Define our user segments and identify areas where we can impact the business. Who are our most engaged users, and how can we acquire and retain more of them? Define KPIs for the company and build automated dashboards, reports, and models to enable teams at Mistplay to make better decisions Work with Product & Engineering to implement, validate, and monitor our logging and metrics Find actionable strategic insights through funnels, cohort analyses, user segmentation, regression models and more Run multivariate product experiments to help us drive growth, improve existing features, and identify new areas of opportunity Collaborer avec nos équipes IA, Produits et Marketing pour répondre aux questions stratégiques de la plus haute importance. Ex: compte tenu de nos idées les plus folles, que devrions-nous développer par la suite? Quelles fonctionnalités auront le plus grand impact et nous aideront à atteindre nos objectifs le plus rapidement? Analyser en profondeur la facilité d'utilisation et la croissance du funnel (entonnoir de conversion) des principaux produits. Identifier les points sur lesquels nous pouvons améliorer notre plateforme. Utiliser les données pour identifier les domaines dans lesquels nous devrions consacrer nos efforts de partenariat et de marketing, et pour déterminer les opportunités les plus prometteuses pour développer notre marque. Définir nos segments d&#39;utilisateurs et identifier les domaines dans lesquels nous pouvons avoir un impact sur l'activité. Déterminer quels sont nos utilisateurs les plus engagés, et comment en attirer et en retenir un plus grand nombre. Définir les indicateurs clés de performance (KPIs) de l'entreprise et concevoir des tableaux de bord, des rapports et des modèles automatisés, qui permettront aux équipes de Mistplay de prendre les meilleures décisions. Travailler en collaboration avec Produits et Ingénierie pour mettre en œuvre, valider et contrôler nos tableaux de bord et nos indicateurs. Découvrir des perspectives stratégiques concrètes grâce aux funnels, aux analyses de cohortes, à la segmentation des utilisateurs, aux modèles de régression, etc. Mener des expériences multivariées sur les produits pour nous aider à stimuler la croissance, à améliorer les fonctionnalités BA/BS in Computer Science, Math, Economics, Statistics, or other quantitative fields 3+ years of work experience doing quantitative analysis (preferably in the tech industry) and a proven track record of impacting a business or product decisions Pro-level ability to synthesize and communicate complex concepts and analyses in simple, easy-to-understand ways A solid grasp of common statistical methods and applications (A/B testing, probability, regression) along with a healthy dose of skepticism Fluency in SQL. Extensive experience pulling highly dimensional and complex data, as well as modelling scenarios and sensitivity analysis using Excel Familiarity with Tableau or any VI tool Positive attitude and a healthy dose of natural curiosity. Questions have to be answered and our data isn't just going to analyze itself. (We're working on that.) Baccalauréat (Bachelor's degree BA/BS) en informatique, mathématiques, économie, statistiques ou autres domaines d'études quantitatives. 3 ans d'expérience minimum dans l'analyse quantitative (de préférence dans le secteur des technologies) et une contribution avérée à la prise de décisions en matière de gestion commerciale ou de produits. Capacité, à un niveau professionnel, à faire la synthèse de concepts et d'analyses complexes, et à les présenter de manière simple et facile à comprendre. Maîtrise des méthodes et applications statistiques courantes (tests A/B, probabilité, régression), accompagnée d'une raisonnable dose de scepticisme. Maîtrise du langage SQL. Expérience approfondie de l'extraction de données complexes et hautement dimensionnelles, ainsi que de la modélisation de scénarios et de l'analyse de sensibilité, en utilisant Excel. Attitude positive et bonne dose de curiosité naturelle. Les questions appellent des réponses et nos données ne vont pas s'analyser d'elles-mêmes. (nous y travaillons.) A love of gaming and familiarity with the games industry Understanding of machine learning, data science and/or at least one statistics package (i.e. SciPy, Matlab, Stata, SAS). Development experience using programming languages such as R, Python or Scala Experience working with very large data sets and distributed computing (Hive/Hadoop) Familiarity with technologies such as AWS Athena, AWS Data Pipeline, TensorFlow and/or Google BigQuery to build and optimize production data pipelines Une passion pour les jeux et une bonne connaissance de l'industrie des jeux. Une compréhension de l'apprentissage automatique, de la science des données et/ou d'au moins un logiciel de statistiques (par exemple SciPy, Matlab, Stata, SAS). Une expérience du développement à l'aide de langages de programmation tels que R, Python ou Scala. Une expérience du traitement de très grands ensembles de données et du calcul réparti (Hive/Hadoop). Une bonne connaissance des technologies telles que AWS Athena, AWS Data Pipeline, TensorFlow et/ou Google BigQuery, pour créer et optimiser les pipelines de données de production. 
ScrapedJobID861:
Act as primary consultant to clients for data engineering services, managing the client relationship and coordinating across other support and consultant roles Estimate projects involving data integration, data architecture, business analysis or application development and collaborate with sales and client success teams to grow accounts Participate in product roadmap discussions and identifying key areas for improvement of products and services Collect client project requirements, focusing on needs & impacts and necessary technical outcomes Create solution designs to solve for clients business and technical needs while keeping within budget Produce documentation of data pipeline design and solution architecture for data warehousing and ETL, following Cardinal Path's documentation standards Create datasets, extracts, or views of data that will be consumed by teams of analysts and data scientists to support data mining, analytics, reporting, and dashboards Develop, implement, and support methodologies, standards, and tools for data management, considering innovation and data security Create ongoing standards and process for overall data architecture team, including developing governance, support and testing models Perform exploratory data validation with analysts to ensure quality data standards are in place and ensure data integrity during all transformation steps. Bachelor’s degree in Statistics, Mathematics, Business Analytics or related field quantitative field, required with a minimum of 3-5 years experience with database development Experience with cloud / big data technologies such as BigQuery, Azure SQL DB/Synapse, Amazon Redshift is required Experience with relational database systems including SQL Server, Oracle, MySql, Postgres Advanced skills in data scripting and database development technologies (SQL, Python, R) Deep knowledge of ETL tools and how they can be applied to a big data environment Familiarity with analyzing digital marketing, advertising and ecommerce data Familiarity with web analytics tools such as Adobe Marketing Cloud or Google Analytics Experience with optimizing BI or visualization tools such as Tableau, Looker, DOMO or Power BI Experience with cloud platforms such as AWS, Azure, and Google Cloud Familiar with NoSql database technologies such as MongoDB Knowledge of technologies such as Spark, Hadoop, and Airflow 
ScrapedJobID862:
In this role, you will report to AVP, Modelling & Pricing Analytics in the Personal Lines Insurance department. You will be responsible for overseeing the development and lifecycle management of technical machine learning models across the countrywide portfolio within all personal product lines. You will have the opportunity to lead and manage a team of 5 to 8 staff and work closely in collaboration with other business partners to develop strategies and plans to jointly meet growth and profitability targets. You will also work closely with other managers on the team, as well as analytics practitioners in other teams to support the development in our overall data and analytics capabilities. University Degree in Data Science, Computer Science, Actuarial Science, or a relevant discipline. At least one of Associateship/Fellowship in the Casualty Actuarial Society, PhD or Master degree in a relevant discipline is required. At least 4 years of full-time experience in a relevant field with a preference for individuals who have experience managing a small of team analysts. Must have strong knowledge of statistical, predictive modelling and/or data science knowledge with at least 3 years of hands-on modelling experience. Good project management skills such as communication and organizational skills and an ability to promote and supervise a team effort toward project completion. We also take potential into consideration. If you don’t have this exact experience, but you know you have what it takes, be sure to give us more insight through your application and cover letter. Competitive salaries, with potential for an annual raise and bonus Pension and savings programs, with company-matched RRSP contributions Generous time away, including vacation and personal needs days Paid volunteer days and company matching on charitable donations Educational resources, tuition assistance, and paid time off to study for exams Two annual wellness campaigns — participants earn up to $300 each year to spend on almost anything supporting health and work-life balance (think things like spa days, daycare, pet grooming) An unlimited employee referral bonus program Flexible work schedule Discounts on products and services 
ScrapedJobID863:
10+ years of experience in Data Science, Analytics, or another related technical field. 5+ years of leadership experience, with 3+ years having directly managed individual contributors. The ability to lead direct reports with empathy, while showing care for their career development and professional interests, and actively working to acknowledge & eliminate biases. Bachelors degree in Computer Science, Math, Physics, Engineering, or related quantitative field; advanced degree preferred (Masters, PhD). Proficiency in SQL and Python programming languages; familiarity with cloud environments (AWS, Azure) and distributed computing (Hive, Hadoop); familiarity with data science best practices in an enterprise environment. Acknowledges the presence of choice in every moment and takes personal responsibility for their life. Possesses an entrepreneurial spirit and continuously innovates to achieve great results. Communicates with honesty and kindness, and creates the space for others to do the same. Leads with courage, knowing the possibility of greatness is bigger than the fear of failure. Fosters connection by putting people first and building trusting relationships. Integrates fun and joy as a way of being and working, aka doesn’t take themselves too seriously. 
ScrapedJobID864:
Develop an outstanding and engaged software development team, from recruiting talent to implementing initiatives fostering engagement and resource development. Implement and continuously improve our tools and processes to increase the teams’ autonomy and efficiency, provide the necessary training and coaching. Manage projects mainly having AI components, with an understanding of the organization’s strategies, priorities and constraints. Work closely with the Product Owner to define the scope and overall objectives of the project, as well as the product increments, while providing leadership and vision. Ensure that the solution will meet the client’s expectations, Intact standards in terms of security and governance, that the impacts and infrastructure requirements will be well identified and that the solutions will be optimized. Develop and manage the integrated plan, budget, resources plan and dependencies in a context of Agile/scrum development. Coordinate activities/dependencies with the different project teams. Ensure proactive and effective communication at all levels and mobilize the teams. Produce and communicate project KPIs, manage risks and propose mitigation measures. Anticipate problems and difficult situations and take action to resolve them A team player, fostering collaboration and creativity in an open and honest environment Passionate about talent development and innovative projects A visionary with a curious mind, you have an interest in collaborating in the delivery of AI initiatives and the ability to link your expertise with business needs to create value Comfortable working in constantly evolving complex environments and multidisciplinary teams An agent of change, motivated and able to question the status quo An excellent communicator, adept at negotiating and decision-maker Bilingual Mobilizer, organized and results oriented A bachelor’s degree in Information Technology, Software Engineering or any equivalent combination of training and experience Minimum 10 years of software development experience Minimum 5 years of experience managing resources and projects. A strong understanding of technologies, project delivery and continuous integration and delivery processes Good command of AI and machine learning concepts is considered as an asset Experience delivering products in Agile/Scrum mode in software development An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID865:
Engage with prospects and customers to identify opportunities and requirements. Recommend and justify product direction and specifications. Specify and design new products, new product features, and new product enhancements. Acquire market intelligence to become an expert on Tignis’ prospective buyers, who they are, how they buy and their key buying criteria. You will be the expert on Tignis’ competition and how they are positioned. Identify and develop strategic partners and lighthouse customers in the semiconductor industry. Develop product positioning and messaging that resonates with our target buyer personas and sets our products/services apart from others in the market to give them unique selling points. Develop the business case for new products, improvements to existing products, and business initiatives. Drive the marketing effort in developing a detailed go-to-market plan, including key activities and budgets to support the acquisition of new customers and launch of new products and releases of existing products based on the needs of the semiconductor market. You will work in concert with marketing for execution but will need to roll up your sleeves on some elements so being a Strategist and a Tactician combined needs to float your boat” and be something you truly enjoy. Coordinate go-to-market activities and create sales enablement tools such as white papers, product guides, product videos, technical briefs, presentation decks, etc. This requires a balance of hands-on materials creation as well as working with external agency and contractor resources. Drive awareness and lead-generation for Tignis’ solution via social media, blogging, published articles, webinars, email marketing, online advertising, trade shows/events, etc. Substantial experience with semiconductor process engineering as well as technologies and solutions in the semiconductor manufacturing process control marketplace including primary vendors, solutions and industry trends and dynamics is required. Personal networks that include buyers and influencers are of high value value. Ideally experience working both for a major semiconductor tool manufacturer and for a major semiconductor fab company. Demonstrated success in defining and launching products that meet and exceed business objectives. Working knowledge of data science, machine learning, and AI. Excellent and demonstrable written and verbal communication skills including the ability to create and deliver effective presentations. Must be a self-starter who truly enjoys working in a fast-paced, innovative software and services development environment. Ability to prioritize and balance strategic thinking with day-to-day execution and ability to manage uncertainty. Sincere empathy for the customer and a commitment to delving deep into the challenges they present or experience. Proven ability to influence cross-functional teams without formal authority Superior project management and interpersonal skills Ability to maintain a keen attention to detail, multitask, and work well under pressure. Natural tendency to be curious, positive, and creative. Team player who collaborates well with others. 7+ years of experience in technical product marketing, product management, or sales engineering, or sales targeted at the semiconductor process control market. Bachelor degree in an Engineering field or equivalent work experience. MBA valued. 
ScrapedJobID866:
Work with business domain stakeholders to understand their needs and objectives and translate them into the functional requirements of advanced analytics and reporting Independently lead the design, development, and deployment of prioritized reports and dashboards, primarily using Microsoft Power BI and respecting data visualization best practices Produce the documentation required to illustrate the progression, treatment, and final use of data by users Ensure the integrity and quality of the data contained in dashboards and reports Ensure timely delivery of prioritized business domain reports and/or dashboards Bachelor’s or master's degree in business intelligence or a related field (mathematics, IT, statistics, etc.) About 3 years of experience as a business intelligence analyst Knowledge of Microsoft Power BI and/or other data visualization tools Mastery of solutions related to business intelligence (Microsoft Power BI, SSRS, Tableau, AWS QuickSight, SQL Server) Excellent mastery of SQL Good knowledge of client contact centres Knowledge of cloud analytics: AWS BI stack, Snowflake, Azure Synapse, Azure SQL, Databricks, PySpark, an asset Bilingualism, both spoken and written (English and French), an asset Excellent ability to influence, communicate and interact with people at all levels of the organization Independence, teamwork, and collaboration skills Strong analytical and synthesizing skills and precision Interest in new technology developments and trends Health and wellness program, including many benefits Flexible group insurance Defined benefit pension plan Employee Share Ownership Plan Employee and Family Assistance Program Preferential banking services Community involvement program Telemedicine Virtual sleep clinic 
ScrapedJobID867:
Develop highly scalable classifiers and tools leveraging machine learning, data regression, and rules based models | Développer des classificateurs et des outils hautement évolutifs en s'appuyant sur l'apprentissage automatique, la régression des données et les modèles basés sur des règles Suggest, collect and synthesize requirements and create effective feature roadmap | Suggérer, collecter et synthétiser les besoins et créer une feuille de route efficace pour les fonctionnalités Code deliverables in tandem with the engineering team | Coder les livrables en collaboration avec l’équipe d’ingénierie Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU) | Adapter les méthodes standard d'apprentissage automatique pour exploiter au mieux les environnements parallèles modernes (par exemple, grappes distribuées, SMP multicœurs et GPU) 5+ years of experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, data mining or artificial intelligence | Cinq ans ou plus d’expérience dans un ou plusieurs des domaines suivants : Apprentissage automatique, systèmes de recommandation, reconnaissance de forme, exploration de données ou intelligence artificielle Proven experience to translate insights into business recommendations | Une expérience avérée dans la traduction d'informations en recommandations commerciales Experience with Hadoop/Hbase/Pig or Mapreduce/Sawzall/Bigtable | De l'expérience avec Hadoop/Hbase/Pig ou Mapreduce/Sawzall/Bigtable Knowledge developing and debugging in C/C++ and Java | Développement et débogage des connaissances en C/C++ et Java Experience with scripting languages such as Perl, Python, PHP, and shell scripts | Expérience dans les langages de script tels que Perl, Python, PHP et les scripts shell Bachelor’s in Computer Science or related quantitative field | Licence en informatique ou dans un domaine quantitatif connexe Experience with filesystems, server architectures, and distributed systems | Expérience des systèmes de fichier, des architectures serveur et des systèmes distribués 
ScrapedJobID868:
Collaborer avec des scientifiques des données pour tester et mettre à l'échelle de nouveaux algorithmes dans l'environnement d'analyse de Pratt & Whitney Canada, puis industrialiser les solutions, les surveiller et les maintenir en production Influencer, créer et maintenir la plate-forme d'analyse à grande échelle requise pour les projets d'IA et l'intégrer à l'infrastructure/au service DT pour fournir une solution de bout en bout Tirer parti d'une compréhension de l'architecture logicielle et des modèles de conception logicielle pour écrire un code évolutif, maintenable, bien conçu et évolutif Concevoir, développer et maintenir le cadre du pipeline analytique Développer des composants communs pour résoudre les problèmes liés aux projets d'apprentissage automatique, tels que la gestion du cycle de vie des modèles, le magasin de fonctionnalités et l'évaluation de la qualité des données Fournir des commentaires et aider à mettre en œuvre un cadre et des outils pour améliorer la qualité des données Travailler au sein d'équipes agiles interfonctionnelles d'ingénieurs en logiciel/apprentissage machine hautement qualifiés, de scientifiques des données, de concepteurs, de chefs de produits et autres pour construire l'écosystème de l'IA au sein de l'entreprise Livrer à temps, en démontrant un engagement fort envers la mission de l'équipe et le carnet de commandes convenu Maitrise ou doctorat en informatique, en génie informatique, en statistiques, en mathématiques appliquées ou sur des sujets connexes Plus de 5 ans d'expérience dans un poste d'apprentissage automatique, de scientifique des données, d'ingénieur de données ou d'ingénieur logiciel Capacité à transformer des modèles d'apprentissage automatique de preuve de concept en solutions évolutives Capacité à appliquer les meilleures pratiques de développement logiciel dans les projets d'apprentissage automatique, y compris les tests unitaires, l'intégration DevOps, la gestion des versions, le développement piloté par les tests, etc. Capacité à automatiser le processus de développement d'un projet d'apprentissage automatique en tirant parti d'outils et de technologies de pointe tels que les conteneurs, l'intégration et la livraison continues, les outils d'orchestration, etc. Solide expérience en mathématiques, statistiques et programmation Expérience en SQL, bases de données relationnelles, concepts de bases de données, modélisation dimensionnelle et conception de bases de données Maîtrise d'un ou plusieurs langages de programmation utilisés pour la modélisation tels que Python, Scala . Familiarité avec un ou plusieurs outils d'apprentissage automatique ou de modélisation statistique Expérience avec les plateformes cloud (AWS, Azure) Bonne compréhension et expérience des principes de conception de logiciels et des modèles de conception Bonne compréhension de la méthodologie Agile et Scrum, en restant concentré sur la création de valeur commerciale Programme de congé à rémunération différée Garderie pour jeunes enfants Programmes d’avancement professionnel et de scolarisation Horaires flexibles Programmes et formations sur le leadership Gamme d’avantages sociaux, régime d’épargne et régime de retraite Programme d’aide de financement pour les congés parentaux Programme de reconnaissance et de récompense Collaborate with data scientists to test and scale new algorithms within Pratt & Whitney Canada’s analytics environment and later industrialize the solutions, monitor and maintain them in production Influence, build and maintain the large-scale analytics platform required for the AI projects, and integrate with DT infrastructure/service to provide an end-to-end solution Leverage an understanding of software architecture and software design patterns to write scalable, maintainable, well-designed and future-proof code Design, develop and maintain the framework for analytical pipeline Develop common components to address pain points in machine learning project, like model lifecycle management, feature store and data quality evaluation Provide input and help implement framework and tools to improve data quality Work in cross-functional agile teams of highly skilled software/machine learning engineers, data scientists, designers, product managers and others to build the AI ecosystem within the company Deliver on time, demonstrating strong commitment to the team’s mission and agreed backlog M.S. or Ph.D. in Computer Science, Computer Engineering, Statistics, Applied Math or related topics 5+ years of experience working in a Machine Learning, Data Scientist, Data Engineer or Software Engineer role Ability to transform proof of concept machine learning models into scalable solutions Ability to apply software development best practice into machine learning projects, including unit test, DevOps integration, release management, test driven development, etc. Ability to automate the development process of machine learning project by leveraging state of art tools and technology such as container, continuous integration and delivery, orchestration tools etc. Strong background in mathematics, statistics and programming Experience in SQL, relational databases, database concepts, dimensional modeling and database design Proficient in one or more programming languages used for modeling such as Python, Scala . Familiar with one or more machine learning or statistical modeling tools Experience with cloud platforms (AWS, Azure) Good understanding and experience with software design principles and design patterns Good understanding of Agile and scrum methodology, keeping focus on delivering business value Long-term deferred compensation programs Daycare for young children Advancement programs to enhance education skills Flexible work schedules Leadership and training programs Comprehensive benefits, savings and pension plans Financial support for parental leave Reward programs for outstanding work 
ScrapedJobID869:
Support market opportunity definition for Varicent’s AI solutions; perform research to understand the competitive landscape, identify routes to market, and segments with highest propensity to buy. Conduct secondary and primary research to gather data and insight about key buyer roles, needs and purchasing requirements. Create personas and build differentiated positioning and messaging for our solutions based on buyer understanding, marketing trends and competitors. Create sales and marketing content including demos, videos, articles, blog posts, etc. based on analyses performed using Varicent’s AI solution. Create marketing content including messaging guides, presentations, ebooks, articles, blog posts, videos, demos, digital/social assets, etc. with support from the content marketing team. Cultivate and develop customer references, testimonials, and case studies for external and internal use. Evangelize and serve as spokesperson for AI solutions by speaking at proprietary and third-party events to create market “buzz” and drive higher value to customers and the business. Provide market and buyer insights to drive the development of campaign strategies including demand creation and reputation building. Plan and orchestrate product launch/release activities using effective tools and techniques to maximize market penetration and sales impa Support influencer and media relations activities to improve awareness and consideration for Varicent’s AI solutions. Partner across teams to create competitive intelligence and content for use in positioning Varicent’s AI solutions against similar offerings. Collaborate with a sales enablement to produce a sales enablement plan as well as develop and deliver enablement and sales materials. B.A./B.S. in marketing or related field, M.B.A. or equivalent in related work experience preferred 10+ years of work experience with 5+ years of experience in product marketing or related roles 3+ years of experience in the data science, machine learning, and augmented analytics markets Passion for content and demonstrated experience creating effective product content Ability to converse with product managers and developers and distill technical information into simple and meaningful marketing messaging and storylines Start-up mentality; experience building a business from scratch Operates effectively in a dynamic environment, adaptable and keeps a can-do attitude Strong interpersonal and teaming skills that foster cross-functional teamwork and collaboration Demonstrated bias for action and driving results Experience marketing to analysts, data scientists or developers a plus Product management experience a plus 
ScrapedJobID870:
You’ll serve as a team lead, manager and mentor to other Machine Learning Engineers on your team Working with our Engineering teams, you will help build production features that leverage our machine learning technologies You will help develop infrastructure for rapid machine learning feature prototyping, deployment, and evaluation with customers Working on our Data Products team, you will build and optimize data lakes and feature stores to feed research projects Applying best practices for ETL and batch processing of database, log, image, and HTML data. Participate in large-scale project planning and stakeholder education 5 or more years of experience working with MLOps or Machine Learning Engineering Experience leading major projects and managing junior team members You have experience deploying machine learning models in production, and with production architecture, monitoring and logging You can communicate clearly and empathetically with developers, product managers, and UX designers to explain the abilities and limitations of ML systems Programming with Python and the associated data science/machine learning packages (e.g. scikit-learn, pandas, xgboost, numpy, scipy) Management of databases (we principally use MySQL, Postgres, and DynamoDB) Cloud infrastructure, preferably AWS, especially S3, and CloudFormation Running services in Docker environments An understanding of web technologies, including APIs (we use REST and GraphQL) Linux administration and command line tools Agile development, version control, and code review processes Big Data ETL (we principally use PySpark) A remote friendly office with flexible hours - for this role we will consider all applications from those based in Canada with the option to work from our Vancouver office 4 weeks vacation plus Christmas Holiday Closure - you're entitled to the week of Christmas off with pay through to and including Jan 1st Vacation bonus - $1,000.00 12 Personal Wellness Days (This includes: Personal day, Moving day, Sick day, etc) Health and Wellness budget - $500.00 Networking budget - $500.00 A paid day off for your birthday One paid Volunteer day per year One day every 2 weeks of dedicated professional development time 
ScrapedJobID871:
In this role, you will report to AVP, Modelling & Pricing Analytics in the Personal Lines Insurance department. You will be responsible for overseeing the development and lifecycle management of technical machine learning models across the countrywide portfolio within all personal product lines. You will have the opportunity to lead and manage a team of 5 to 8 staff and work closely in collaboration with other business partners to develop strategies and plans to jointly meet growth and profitability targets. You will also work closely with other managers on the team, as well as analytics practitioners in other teams to support the development in our overall data and analytics capabilities. University Degree in Data Science, Computer Science, Actuarial Science, or a relevant discipline. At least one of Associateship/Fellowship in the Casualty Actuarial Society, PhD or Master degree in a relevant discipline is required. At least 4 years of full-time experience in a relevant field with a preference for individuals who have experience managing a small of team analysts. Must have strong knowledge of statistical, predictive modelling and/or data science knowledge with at least 3 years of hands-on modelling experience. Good project management skills such as communication and organizational skills and an ability to promote and supervise a team effort toward project completion. We also take potential into consideration. If you don’t have this exact experience, but you know you have what it takes, be sure to give us more insight through your application and cover letter. Competitive salaries, with potential for an annual raise and bonus Pension and savings programs, with company-matched RRSP contributions Generous time away, including vacation and personal needs days Paid volunteer days and company matching on charitable donations Educational resources, tuition assistance, and paid time off to study for exams Two annual wellness campaigns — participants earn up to $300 each year to spend on almost anything supporting health and work-life balance (think things like spa days, daycare, pet grooming) An unlimited employee referral bonus program Flexible work schedule Discounts on products and services 
ScrapedJobID872:
Data scientist or engineer experienced with leadership experience and familiarity with machine learning, data analytics, big data processing, data lakes & warehouses, and related technologies and architectures. Expected to lead and manage teams of data scientists and data engineers on various data and machine learning projects. Required experience developing solutions on a major cloud platform, as well as demonstrated people management experience. Expected skills to include cloud architecture design and implementation, as well as experience with machine learning tools and libraries. Expected to have demonstrated technical leadership in the development of multiple successful production solutions. Expected to have demonstrated people management skills with direct reports. Experience with neural networks, computer vision, language processing, big data processing, or other machine learning sub-domains is desired. Familiarity with data engineering languages and platforms, such as SQL, Spark or Hadoop, is desired. Familiarity with managed machine learning services on a major cloud platform is also desired. Candidate will be expected to lead projects to solve a variety of problems by developing cloud-based solutions for customers. Candidate should be able to work independently, demonstrate technical leadership and people management experience, and have excellent communication skills. This is a virtual role The candidate needs to be based in US or Canada 
ScrapedJobID873:
Bachelor’s degree in Data Science, Financial/Accounting, Commerce or a related field and 3 years of recent, related experience*; OR an equivalent combination of education and experience may be considered. A valid BC Class 5 Driver’s Licence or equivalent. Recent, related experience must include a minimum of 3 years in each of the following: Audit and/or accounting experience, for example experience working with accounting principles, auditing standards, information technology and management auditing. Completing complex analysis of large volumes of raw data. A Chartered Professional Accountant (CPA) designation, or Certified Fraud Examiner (CFE) or Certified Internal Auditor (CIA) certification, in good standing. Currently enrolled in one of the above professional programs. Health sector experience. Willingness to conduct field work which includes travel within the province. 
ScrapedJobID874:
Experience leading a technical team, including managing tasks and processes Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline 3+ years of Software Development experience with modern programming languages (Python, C/C++, Julia) Experience with at least one deep learning framework (TensorFlow, PyTorch, MXNet …) Experience working in version control such as git Experience in big data architectures and pipelines to build and deploy models Experience in building machine learning models optimized for speed, accuracy, scalability, reliability and resiliency Ability to perform complex data analysis and present findings to stakeholders Master’s degree in Computer Science, Computer Engineering or related technical discipline Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations Experience with prototyping machine learning solutions (e.g. Kaggle, demos, hackathons) Experience working with cloud platforms (e.g. AWS, Azure …) Experience with web development for demonstrations Strong communication skills Competitive salary Health and lifestyle benefits Positive & creative work environment in a great location Leadership role on an expanding team with opportunities for career growth 
ScrapedJobID875:

ScrapedJobID876:
Partner with our awesome AI, Product and Marketing teams to answer high-priority strategic questions. Here's a few examples: Given all our crazy ideas, what should we build next? Which features will have the highest impact and help us accomplish our goals more quickly? Deep dive on core product funnel usability and growth. Identify where we are able to improve our platform. Utilize Data to identify where we should spend our partnership and marketing efforts? What are the most promising opportunities for growing our brand? Define our user segments and identify areas where we can impact the business. Who are our most engaged users, and how can we acquire and retain more of them? Define KPIs for the company and build automated dashboards, reports, and models to enable teams at Mistplay to make better decisions Work with Product & Engineering to implement, validate, and monitor our logging and metrics Find actionable strategic insights through funnels, cohort analyses, user segmentation, regression models and more Run multivariate product experiments to help us drive growth, improve existing features, and identify new areas of opportunity Collaborer avec nos équipes IA, Produits et Marketing pour répondre aux questions stratégiques de la plus haute importance. Ex: compte tenu de nos idées les plus folles, que devrions-nous développer par la suite? Quelles fonctionnalités auront le plus grand impact et nous aideront à atteindre nos objectifs le plus rapidement? Analyser en profondeur la facilité d'utilisation et la croissance du funnel (entonnoir de conversion) des principaux produits. Identifier les points sur lesquels nous pouvons améliorer notre plateforme. Utiliser les données pour identifier les domaines dans lesquels nous devrions consacrer nos efforts de partenariat et de marketing, et pour déterminer les opportunités les plus prometteuses pour développer notre marque. Définir nos segments d&#39;utilisateurs et identifier les domaines dans lesquels nous pouvons avoir un impact sur l'activité. Déterminer quels sont nos utilisateurs les plus engagés, et comment en attirer et en retenir un plus grand nombre. Définir les indicateurs clés de performance (KPIs) de l'entreprise et concevoir des tableaux de bord, des rapports et des modèles automatisés, qui permettront aux équipes de Mistplay de prendre les meilleures décisions. Travailler en collaboration avec Produits et Ingénierie pour mettre en œuvre, valider et contrôler nos tableaux de bord et nos indicateurs. Découvrir des perspectives stratégiques concrètes grâce aux funnels, aux analyses de cohortes, à la segmentation des utilisateurs, aux modèles de régression, etc. Mener des expériences multivariées sur les produits pour nous aider à stimuler la croissance, à améliorer les fonctionnalités BA/BS in Computer Science, Math, Economics, Statistics, or other quantitative fields 3+ years of work experience doing quantitative analysis (preferably in the tech industry) and a proven track record of impacting a business or product decisions Pro-level ability to synthesize and communicate complex concepts and analyses in simple, easy-to-understand ways A solid grasp of common statistical methods and applications (A/B testing, probability, regression) along with a healthy dose of skepticism Fluency in SQL. Extensive experience pulling highly dimensional and complex data, as well as modelling scenarios and sensitivity analysis using Excel Familiarity with Tableau or any VI tool Positive attitude and a healthy dose of natural curiosity. Questions have to be answered and our data isn't just going to analyze itself. (We're working on that.) Baccalauréat (Bachelor's degree BA/BS) en informatique, mathématiques, économie, statistiques ou autres domaines d'études quantitatives. 3 ans d'expérience minimum dans l'analyse quantitative (de préférence dans le secteur des technologies) et une contribution avérée à la prise de décisions en matière de gestion commerciale ou de produits. Capacité, à un niveau professionnel, à faire la synthèse de concepts et d'analyses complexes, et à les présenter de manière simple et facile à comprendre. Maîtrise des méthodes et applications statistiques courantes (tests A/B, probabilité, régression), accompagnée d'une raisonnable dose de scepticisme. Maîtrise du langage SQL. Expérience approfondie de l'extraction de données complexes et hautement dimensionnelles, ainsi que de la modélisation de scénarios et de l'analyse de sensibilité, en utilisant Excel. Attitude positive et bonne dose de curiosité naturelle. Les questions appellent des réponses et nos données ne vont pas s'analyser d'elles-mêmes. (nous y travaillons.) A love of gaming and familiarity with the games industry Understanding of machine learning, data science and/or at least one statistics package (i.e. SciPy, Matlab, Stata, SAS). Development experience using programming languages such as R, Python or Scala Experience working with very large data sets and distributed computing (Hive/Hadoop) Familiarity with technologies such as AWS Athena, AWS Data Pipeline, TensorFlow and/or Google BigQuery to build and optimize production data pipelines Une passion pour les jeux et une bonne connaissance de l'industrie des jeux. Une compréhension de l'apprentissage automatique, de la science des données et/ou d'au moins un logiciel de statistiques (par exemple SciPy, Matlab, Stata, SAS). Une expérience du développement à l'aide de langages de programmation tels que R, Python ou Scala. Une expérience du traitement de très grands ensembles de données et du calcul réparti (Hive/Hadoop). Une bonne connaissance des technologies telles que AWS Athena, AWS Data Pipeline, TensorFlow et/ou Google BigQuery, pour créer et optimiser les pipelines de données de production. 
ScrapedJobID877:
Drive on-time and quality delivery of our Machine Learning Platform projects within budget Collect requirements from engineering teams, particularly machine learning teams, prioritize and triage the requirements Collaborate with other cross functional teams to achieve company goals Identify roadblocks and issues in the project and product areas Improve communication with teams and stakeholders Bachelor's degree in Computer Science, Computer Engineering or related fields 5+ years industry experience in technical program / project management or engineering management Experience working with backend services, machine learning services, ideally in autonomous driving Experience in agile methodologies and full product lifecycle Excellent communication and interpersonal skills Experience in the autonomous driving space Fluency in Mandarin Visa sponsorship is available for this position Opportunity for professional growth and career advancement Competitive salary and benefits Up to a 30% discretionary bonus. Daily breakfast, lunch, and dinner Shape the landscape of autonomous driving 100% Company paid Medical, Vision, and Dental insurance plan Company 401(K) program Company paid life insurance Company paid education/training. Company paid gym membership. 
ScrapedJobID878:
Responsible for the successful delivery of the portfolio of projects and services in own domain according to agreed KPIs like revenue, cost control, engagement margin and customer satisfaction Analyzing Clients’ business needs in context of their Big Data/Analytics architecture Collaboration with Client to set direction for Big Data/Analytics business transformation to meet their Goals and Objectives Work with delivery organization to turn business ideas into actionable innovations Preparing project proposals according to corporate procedures Managing relationship with Clients Active involvement in developing follow up business Contributing to internal community by defining the standards (technology and process related) , best practices, lessons learned etc. Managing project financials including P&L Managing project teams Mentoring and encouraging skill development of project team members Providing detail performance review input and development recommendations for team members Min 5 years of experience in FMCG/CPG industry in analyst or management role Proven skill and track record in delivery of large-scale software development projects and services in Agile, DevOps frameworks 5 plus years of experience in analytics (e.g. Database, Business Intelligence, ETL, Big Data, Data Science) Technical understanding of Azure Analytics technology stack PMP certified ITIL Foundation certificate and PSM I certification will be an asset First Level University degree Strong leadership and ownership Excellent communication skills and teamwork abilities Excellent command of English Experience in working with Clients, strong focus on Client satisfaction Ability to work under pressure and meet project timetables Ability to juggle multiple tasks and assignments Ability to work in multinational environment Ability to speak with authority to most layers of depth related to project management methods Collaborative approach to people, flexibility, and responsiveness Travel availability Demonstration of in-depth understanding of key company Services' operational policies, processes, and methodologies applicable to project management This position pays $89,000 to 134,400 CAD Dental care Extended health care RRSP match Vision care 8 hour shift Temporarily due to COVID-19 
ScrapedJobID879:
Client's IA Data transformation leader Digital Product Owners ITS organization Fit4Future change leaders Other data scientists across the digital DS organization Master’s degree in mathematics, computer science, engineering, physics,
statistics, economics, computational sciences or a related quantitative
discipline and 5+ years of Data Science experience, or PhD + 3years of with
relevant work & domain experience. Direct experience with any of the following techniques: advanced NLP
modeling, machine learning, semi-supervised, deep learning, graph neural
networks, Bayesian networks and numerical optimization Experience deploying (micro) apps cf. Shiny or Flask Visual analytics and/or data story telling with Power BI or other Experience with some aspects of pharmaceutical operations, specially
manufacturing Expertise with the core data science languages (such as Python, R), and
familiarity & flexibility with data systems (e.g. SQL, NoSQL, knowledge graphs) Comfortable working in cloud and high-performance computational
environments (e.g. AWS, Apache Spark) Excellent written and verbal communication, business analysis, and consultancy skills Experience working in an agile environment Disciplined AI / ML development (CI / CD, Orchestration) Experience with Tableau or Power BI Regulatory, GxP, or similar standards Orchestration, AWS stepfunctions, Apache Airflow or Kedro Build models, algorithms, and performance evaluation by writing highly
optimized, deployable code and using state-of-the art machine learning
technologies Define and implement architectures for predictive algorithm for cloud-based
manufacturing application Industrializing solutions together with small teams (pods, scrum) in an agile
way of working Proficient at collecting and mining data from disparate data sources, and
willing to dig deeper and understand the process that creates the data Work with a data lake as well as graph databases (cf. neo4js and AWS
Neptune) Use data analysis, visualization, storytelling, and data technologies to scope,
define and deliver AI-based data products to accelerate and data product
deployments Developing digital data products and pipelines for IA that scale He/she will be able to generate work product that includes interactive
visualizations, presentations, publications, web applications, predictive
algorithms, and API Document insides and architecture as well as planning using Jira/Confluence 
ScrapedJobID880:
Experience with multiple modalities (image, NLP, audio) Proficient in coding (C, C++, Python) Proven prototyping skills Familiarity with ML & experience placing research in context with state of art You have strong analytical and problem solving skills You're aware of the challenges associated to the transition of a prototype into a final product You're familiar with the challenges of developing algorithms that run efficiently on resource constrained platforms You've demonstrated leadership in both applied research and development Excellent written and verbal communications skills, be comfortable presenting research to large audiences, and have the ability to work hands-on in multi-functional teams You should be motivated and results-oriented Experience with OS X and iOS development tools and familiarity with GPU programming is a plus Basic knowledge of Objective-C is desirable Experience in software engineering is a major plus Experience in industry is a plus 
ScrapedJobID881:
Develop and maintain algorithms, data pipelines, automated processes, and services to create a data science solution that are customer focused Extract mission-critical insights from datasets Innovate and bring creative ideas to building mission critical customer facing products that depend on ML solutions Work with product and business teams to identify solutions and best practices Create scalable models that drive business decisions and enable our customers’ success Design and develop processes and systems which analyze and generate actionable insights from diverse data sources Develop tools to monitor models for evolving performance and accuracy Mentor team members in the areas of technical expertise and career building Contribute to best practices around feature extraction, model development, and knowledge sharing among multiple data science teams Directly contribute to architecture planning Been in the ML engineering game for some time. You have a Bachelors/Masters and 4+ years of industry experience Proven ability to architect data science solutions to complex problems and delivering solutions in customer facing products Experience delivering solutions that analyzes big datasets using tools such as Apache Spark Experience delivering solutions that analyzes time-series data Strong programming skills in Python A strong command of SQL and working with multiple relational databases and data warehouses (Redshift, Postgres, Athena, Snowflake, etc…) Experience in end-to-end machine learning project life cycle Experience working with unstructured data Are scrappy when extracting useful insights with partial data A solid experience in working with software development teams and using source version control tools like Git Experience deploying deep learning models Experience with frameworks for in-production ML code (e.g. Kedro) Developing and deploying using Docker With some of the AWS services (e.g. EC2, S3, Sage Maker, Cloudwatch) With accessing data from other datastores in the AWS ecosystem such as ElasticSearch, S3, and DynamoDB The BEST team. Remote-first culture. International Meetups. Access to Jungle Scout tools & experts. Performance Bonus. Flexible Vacation. Comprehensive Health Benefits & Retirement Program. 
ScrapedJobID882:
Casual dress Work from home 8 hour shift Monday to Friday Machine Learning: 8 years (preferred) Yes 
ScrapedJobID883:
You will be building state-of-the-art personalized recommendation systems. You will leverage state-of-the-art approaches across recommendation, NLP, data science. You will train models, run experiments, build data pipelines, and define measurements and metrics all in the pursuit of delighting 1B+ users through recommendation. Set strategic direction and plan of execution based on insights gained through data analysis and customer feedback to drive meaningful business results. You will mentor with potential to tech-lead teams of Data and Applied Scientists and Software Engineers to successfully execute on our roadmap and achieve your strategic objectives. Drive collaboration and partnership with other R&D teams in Microsoft to deliver an outstanding product. 4+ years of industry experience in a Data Scientist, Applied Scientist or related role. 4+ years of hands-on experience in one or more of the following areas: recommendation, deep learning, machine learning, text analysis, information retrieval, NLP, computer vision with a strong understanding of both practical and theoretical aspects. 2+ years of experience with large scale data processing infrastructure such as Spark, Hadoop, or similar. Advanced degree in CS/CE/EE/Data Science or related areas Experience developing in Python/R/C++/C# Ability to own Machine Learning systems end-to-end - from data pipelines and training to real-time prediction engines. Ability to independently drive cross team collaborations and ship production features in a fast-paced startup environment. Excellent communication and presentation skills, both verbal and written. 
ScrapedJobID884:
Develop integrations using Apigee Edge Platform Translate business rules and requirements into api proxies, produce data mappings and write abstracted, reusable code components accordingly. Deploy and integrate solutions on the cloud and on-premises Facilitate technical meetings with client staff and advise clients with technical options analyses based on leading practices, identifying opportunities and risks along with API management for analysis of API usage and engagement. A BA/BSc or MA/MSc degree in Applied Mathematics, Statistics, Computer Science, Engineering, Business, or related field Experience in application development using Apigee Edge Platform, SOA/EAI technologies and API Management/Gateway Experience with micro services architectural design using API led approach Hands-on experience in SOA Development Frameworks and micro service modelling Solid programming skills using REST/Graph QL/SOAP Java, JavaScript, Agile Good understanding of Apigee architecture with experience on server admin and physical deployment (on cloud, on prem, hybrid) Solid understanding of containerization and virtualization. Quick to learn new technologies, easy to adapt to new environments, thrive on solving challenging problems with technical solutions Able to work in multiple technical environments and able to work with peers and business stakeholder Lead the way: Deloitte is not only leading the profession, but reinventing it for the future. We’re also committed to creating opportunity and leading the way to a more sustainable world. Serve with integrity: Deloitte has earned the trust of employees, clients, regulators, and the public for 175 years. Upholding that trust is our single most important responsibility. Take care of each other: We look out for one another and prioritize respect, fairness, development, and well-being. Foster inclusion: We are at our best when we foster an inclusive culture and embrace diversity in all forms. We know this attracts top talent, enables innovation, and helps us deliver well-rounded client solutions. Collaborate for measurable impact: We approach our work with a collaborative mind¬set, teaming across businesses, geographies, and skill sets to deliver tangible, measurable, attributable impact. 
ScrapedJobID885:

ScrapedJobID886:
Bachelor’s degree or equivalent practical experience. 8 years of experience with software development in one or more programming languages (e.g., Java, C/C++, C#, Objective C, Python, JavaScript, or Go). 5 years of experience with machine learning algorithms and tools (e.g., TensorFlow), deep learning, and/or Natural Language Processing. Master's degree or PhD in Computer Science or related technical field. 3 years of experience in a technical leadership role. 3 years of experience working in a complex, matrixed organization involving cross-functional, and/or cross-business projects. Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, recommendation systems, targeting systems, ranking systems or similar. Experience with relevant technologies (e.g., Tensorflow, Flume, machine learning libraries). Relevant professional experience with applied data analytics and predictive modeling. Act as a thought leader, designing/building next-generation models. Lead and grow machine learning software developers. Improve, simplify, productionization, and launch of our cloud based models. Design, run, and analyze experiments. Collaborate with other modeling and research teams across Google. 
ScrapedJobID887:
Lead the team responsible for building and managing the technical infrastructure, data platform and visualization technologies, and all aspects of data analytics efforts. Establish data science as a discipline and unite the analytics, data engineering, and machine learning efforts across the company. Drive, mentor, and motivate the organization to focus on continuous operational excellence and the delivery of information and analytics platforms and solutions to the business's key stakeholders. Own and develop the vision, strategy, and execution for global enterprise data & advanced analytics, ensuring scalability of systems processes and talent. Design, build and drive overall strategy, governance, methodology, and roadmap for the processes, systems, tools and capabilities required to produce and maintain core data assets, OKRs, KPIs, metrics and resulting predictive analytics Drive both strategic and tactical execution. apply statistical and data science methods to the wealth of available data stored in variety of internal and external data stores to generate critical actionable insights to inform the organization's strategy to help meet the changing business needs and drive the decision-making process Consult with key internal stakeholders to ensure organizational research needs are met and all data collection and analytics efforts are streamlined and optimized. Develop, implement and utilize machine learning algorithms and data science approaches Partner with multiple business stakeholders and cross-functional teams to design, develop and execute data science projects and/or build out of machine learning products with the urgency appropriated for the business objectives Implement and follow reproducible, auditable, collaborative development practices. Ensure the team has the right tools, processes and agile principles in place to deliver work that is on time and to specification. Focus on automation and utilizing technology to provide repeatable solutions; drive optimization and efficiency initiatives to support reduced cycle time. Monetizing data and information. Find ways to leverage existing enterprise data and information in company's products and services. Bachelor's degree in Computer Science, Engineering, Statistics, Applied Mathematics or a related field. Extensive experience working in data pipelines, data warehouse, data analytics, data science, machine learning, data visualization, and business intelligence. Ability to work with different data architectures to derive insights and build analytic solutions. Proven ability to establish and articulate a vision, set goals, develop and execute integrated analytics strategies, and track and measure results. Demonstrated extensive experience ideating, designing, building, applying and automating mathematical models and data science methods, statistical analyses, predictive analytics, and modeling, to provide repeatable solutions. Proven ability to oversee global data governance and data integrity protocols and procedures. Proven ability to manage data insights and analytics, including enterprise dashboards and support the creation of functional dashboards in partnership with business functions. Experience with business driven / self-service BI A solid understanding of data security and privacy technologies Proven ability to complete projects and achieve results in an ambiguous work environment. Proven leadership building data analytics, data science or data engineering teams with the ability to motivate a team to achieve well communicated expectations. Proven strong negotiating and consensus building abilities. Proven skills to work effectively across internal functional areas in ambiguous situations. A passion for solving complex system and data challenges and desire to thrive in a constantly innovating and changing environment Outstanding business acumen with an understanding of business drivers and of how to drive value to the customer. Ability to translate business needs to analytic requirements and interpret the results of complex data analysis and communicate them to broad audiences. Resilience, Tolerance for Change/Ambiguity: can effectively cope with change, finding ways to advance work and projects, even in the face of uncertainty Collaboration and Teamwork: works with others to deliver results, meaningfully contributing to the team and prioritizing group needs over individual needs Commitment to Results: consistently achieves results, demonstrating high performance, and challenging self and others to deliver results Decision Making: consistently chooses the best course of action (from a number of alternatives) to address business problems and/or opportunities Influence: Asserts own ideas and persuades others, gaining support and commitment and mobilizing people to take action Process/Project Management: skilled at figuring out and managing the processes and timelines necessary to get work accomplished Builds inclusive, cohesive teams which apply diversity to achieve common goals Capably delivers results through others, is good at establishing clear direction, helping others achieve their best work Identifies key issues and relationships relevant to achieving a long-range goal or vision; Builds an integrated plan for course of action to accomplish this vision Challenges and supports others to create results but also develop new capabilities. Successfully develops the capacity and capability of team and individuals on the team Tenacious. You are determined to succeed, and you are motivated by the success of customers, colleagues and the community. Curious. You are always learning and seeking ways to make things better. Conscientious. You keep your promises, taking your commitments to others seriously, and you have strong integrity. Humble. You lead with humility and empathy, respecting and learning from the perspectives of others. 
ScrapedJobID888:
Act as primary consultant to clients for data engineering services, managing the client relationship and coordinating across other support and consultant roles Estimate projects involving data integration, data architecture, business analysis or application development and collaborate with sales and client success teams to grow accounts Participate in product roadmap discussions and identifying key areas for improvement of products and services Collect client project requirements, focusing on needs & impacts and necessary technical outcomes Create solution designs to solve for clients business and technical needs while keeping within budget Produce documentation of data pipeline design and solution architecture for data warehousing and ETL, following company documentation standards Create datasets, extracts, or views of data that will be consumed by teams of analysts and data scientists to support data mining, analytics, reporting, and dashboards Develop, implement, and support methodologies, standards, and tools for data management, considering innovation and data security Create ongoing standards and process for overall data architecture team, including developing governance, support and testing models Perform exploratory data validation with analysts to ensure quality data standards are in place and ensure data integrity during all transformation steps. Bachelor’s degree in Statistics, Mathematics, Business Analytics or related field quantitative field, required with a minimum of 3-5 years experience with database development Experience with cloud / big data technologies such as BigQuery, Azure SQL DB/Synapse, Amazon Redshift is required Experience with relational database systems including SQL Server, Oracle, MySql, Postgres Advanced skills in data scripting and database development technologies (SQL, Python, R) Deep knowledge of ETL tools and how they can be applied to a big data environment Familiarity with analyzing digital marketing, advertising and ecommerce data Familiarity with web analytics tools such as Adobe Marketing Cloud or Google Analytics Experience with optimizing BI or visualization tools such as Tableau, Looker, DOMO or Power BI Experience with cloud platforms such as AWS, Azure, and Google Cloud Familiar with NoSql database technologies such as MongoDB Knowledge of technologies such as Spark, Hadoop, and Airflow 
ScrapedJobID889:
By delivering an award-winning product, conceptualized and developed by award-winning leaders, that result in award-winning customer employee experiences By hiring highly innovative, diverse talent that fully embraces and embodies our core values in everything they do: Customer Focus, Equity, Shared Ambition, Agility, Transparency, Optimism By using modern technology, such as voice-activation with Dayforce Assistant and access to your money as soon as you earn it with Dayforce Wallet to stay in rhythm with the evolving demands of our 4 million global users Work with Chief Data Officer and others to define, refine and detail the mandate of the Algorithmics & Machine Learning Group Lead the team responsible for algorithm development, including analysis and annotation of data for fit, training, validation and test Recruit the appropriate mix and number of experts to cover all mandated areas of responsibility Work across all product teams to research, discover and test solutions for the application of algorithms/AI Work across all product teams to educate them about the benefits and drawbacks of AI/algorithmic approaches, and set standards and guidelines for the efficient, effective, and consistent use of these tools across the entire value chain Deliver solutions covering both static and active supervised/unsupervised algorithms Partner with business and technical leaders to identify and solve for specific data and resourcing for ongoing and future product development opportunities Support various software development teams in developing prototype models to validate effectiveness Expand the company’s use of client data as a strategic enabler to improve product performance and develop new product capabilities In conjunction with Data Science leadership, build the process and auditability for trustworthy AI including efficacy tests, malicious action tests and fairness tests Monitor over time for system details and performance with appropriate owners for deployed algorithms, their impact and efficacy Be an active contributor from an ML Ops discipline to the Data Architecture team providing support to the Architectural Review Board Evaluate, recommend, and select platform tools and recommend platform components to support the deployment, measurement and performance of algorithm and related applications Partner with internal teams on major projects to support initiatives related to governance Support evaluation of external applications used within the development of models and algorithms Support interactions with regulatory bodies and drafts content for regulatory submissions as needed for legal group Support organization’s need to evaluate companies for partnering and acquisition Leading advocate and leader supporting internal education, as well as responsible for external speaking, press and other opportunities to share insight and best practice Where applicable, define and develop materials for patentability of algorithms and ideas working closely with intellectual property experts A Bachelor’s Degree in computer science or mathematics A Master's degree is preferred in computer science, mathematics or equivalent business experience 10+ years of relevant data experience covering both natural language and quantitative data experience 10+ years of direct experience in formulating and developing specific algorithms for engineering use 10+ years direct experience partnering and working with different groups to develop novel, targeted solutions Experience with leading SaaS platforms, and other forms of service-based computing models Strong understanding of numerical algorithms, graph theory and related disciplines Leadership in reaching across organizations to educate and inform (in the development of new algorithms/approaches) Ability to adapt new approaches (from publications) to be applied to different product opportunities Communicate, to non-technical stakeholders, approaches to enable or resolve complex data problems Strength in independently engaging cross-functional stakeholders to discover new automation opportunities Proven track record in leading the use of data to drive commercial competitive differentiation Build strong relationships across the enterprise to ensure delivery expectations are met and priorities are set at the appropriate level. 
ScrapedJobID890:
Design and implement robust, efficient and cost-effective infrastructure to run ML services in production, support data extraction and preparation, model training and evaluation Communicate with stakeholders and other teams to coordinate goals, priorities and deadlines Take part in architectural decisions, analyze overall system performance, propose technical solutions, review code contributed by teammates Write production-quality Python code (clean, easy to understand and support, covered by tests and well documented) Be responsible for preparing services for deployment to production, monitoring key performance indicators, resolving issues and assisting other teams. Be part of the 24x7 on-call rotation Guide junior team members, participate in hiring A Bachelor’s Degree in Computer Science/Engineering Experience working with the infrastructure (Kubernetes, Kubeflow, GCP/Azure) A strong background in ML theory and algorithms, both deep learning and classical ones like SVM, random forest or gradient boosting methods Proficiency with Python and common ML/DL frameworks like sklearn, tensorflow, theano, pytorch or keras Experience developing recommendation/personalization systems The ability to process large amounts of data Knowledge of common NLP problems (language recognition, stemming & morphological segmentation/parsing, text categorization, topic modeling, text clustering or text summarization) Good communication skills and enjoy being part of a team A creative mind, critical thinking capabilities Solid troubleshooting skills and a problem-solving approach The capacity to work with minimal supervision and can be proactive Enjoy sharing your knowledge with others Can train and guide others Have a strong interest in the technology sector 
ScrapedJobID891:
In this role, you will report to AVP, Modelling & Pricing Analytics in the Personal Lines Insurance department. You will be responsible for overseeing the development and lifecycle management of technical machine learning models across the countrywide portfolio within all personal product lines. You will have the opportunity to lead and manage a team of 5 to 8 staff and work closely in collaboration with other business partners to develop strategies and plans to jointly meet growth and profitability targets. You will also work closely with other managers on the team, as well as analytics practitioners in other teams to support the development in our overall data and analytics capabilities. University Degree in Data Science, Computer Science, Actuarial Science, or a relevant discipline. At least one of Associateship/Fellowship in the Casualty Actuarial Society, PhD or Master degree in a relevant discipline is required. At least 4 years of full-time experience in a relevant field with a preference for individuals who have experience managing a small of team analysts. Must have strong knowledge of statistical, predictive modelling and/or data science knowledge with at least 3 years of hands-on modelling experience. Good project management skills such as communication and organizational skills and an ability to promote and supervise a team effort toward project completion. We also take potential into consideration. If you don’t have this exact experience, but you know you have what it takes, be sure to give us more insight through your application and cover letter. Competitive salaries, with potential for an annual raise and bonus Pension and savings programs, with company-matched RRSP contributions Generous time away, including vacation and personal needs days Paid volunteer days and company matching on charitable donations Educational resources, tuition assistance, and paid time off to study for exams Two annual wellness campaigns — participants earn up to $300 each year to spend on almost anything supporting health and work-life balance (think things like spa days, daycare, pet grooming) An unlimited employee referral bonus program Flexible work schedule Discounts on products and services 
ScrapedJobID892:
Apply the latest, cutting-edge advancements in AI/ML research to create technologies for automating business processes from end-to-end. Work closely with the application engineering teams to integrate state-of-the-art algorithms and model research into the Hyperscience product. Take full ownership of ML models, including collecting training data, deploying in production, and overseeing the quality and ongoing evaluation of models. Collaborate with other engineers to build tools for accelerating ML research internally. 3+ years relevant professional experience Solid understanding of Math and CS fundamentals Strong analytical skills Deep knowledge of modern ML/DL technologies and proven experience applying them to real-world problems Experience in Computer Vision or NLP is a plus Able to perform applied research projects and bring them to production Strong experience with one or more general-purpose languages (Java, C/C++, Python, etc) Demonstrated ability to write high-quality code is an advantage Team player with strong communication skills Top notch medical and dental coverage for you and your family 30 days of paid leave annually to help nurture work-life symbiosis Stock options Wellness stipend Pre-tax transportation and commuter benefits 6-month parental leave (or double salary to pay for your partner's unpaid leave) Free travel for any person accompanying a breastfeeding mother and her baby on a business trip A dependent care stipend up to $3,000 (USD) per month, per child, under the age of 21 for a maximum of $6,000 (USD) per month total Budget to attend conferences, train, and further your education $1,250 (CAD) one-time-use WFH stipend and $95 (CAD) monthly WFH stipend Relocation assistance 
ScrapedJobID893:
Serve as a technical lead on a fast-moving, innovative team of data scientists Build machine learning models to enable effective and efficient sales interactions (phone, chat, virtual) for Wayfair customers Identify and innovate new opportunities to drive business results through data science Own the full data science life cycle: scoping to prototyping, testing, deploying, measuring value and iterating Partner with engineering teams (ML Engineering, Service R&D) to integrate ML products into technical platforms and deploy real-time models at large scale Partner with operational teams to help guide business decisions through model outputs and findings Master’s degree in quantitative field (statistics, mathematics, economics, operations research, physics, neuroscience etc) and 4-6+ years of experience OR PhD (preferred) and 3-4+ years of experience in quantitative field (statistics, mathematics, economics, operations research, physics, neuroscience etc) 4+ years of experience in computational language (R/Python/Matlab/etc) with proven recent experience in Python Thorough command of general data science and machine learning techniques, good understanding of data engineering practices Ability to work on cross-functional projects and communicate with stakeholders at multiple levels of technical detail Good understanding of experimental and statistical techniques for the design of A/B tests to measure the impact of initiatives Experience with distributed systems such as PySpark, Dask with cloud-native infrastructure experience (AWS, GCP, Azure) Communication skills that can influence across organizations and at all levels 
ScrapedJobID894:
Collaborer avec des scientifiques des données pour tester et mettre à l'échelle de nouveaux algorithmes dans l'environnement d'analyse de Pratt & Whitney Canada, puis industrialiser les solutions, les surveiller et les maintenir en production Influencer, créer et maintenir la plate-forme d'analyse à grande échelle requise pour les projets d'IA et l'intégrer à l'infrastructure/au service DT pour fournir une solution de bout en bout Tirer parti d'une compréhension de l'architecture logicielle et des modèles de conception logicielle pour écrire un code évolutif, maintenable, bien conçu et évolutif Concevoir, développer et maintenir le cadre du pipeline analytique Développer des composants communs pour résoudre les problèmes liés aux projets d'apprentissage automatique, tels que la gestion du cycle de vie des modèles, le magasin de fonctionnalités et l'évaluation de la qualité des données Fournir des commentaires et aider à mettre en œuvre un cadre et des outils pour améliorer la qualité des données Travailler au sein d'équipes agiles interfonctionnelles d'ingénieurs en logiciel/apprentissage machine hautement qualifiés, de scientifiques des données, de concepteurs, de chefs de produits et autres pour construire l'écosystème de l'IA au sein de l'entreprise Livrer à temps, en démontrant un engagement fort envers la mission de l'équipe et le carnet de commandes convenu Maitrise ou doctorat en informatique, en génie informatique, en statistiques, en mathématiques appliquées ou sur des sujets connexes Plus de 5 ans d'expérience dans un poste d'apprentissage automatique, de scientifique des données, d'ingénieur de données ou d'ingénieur logiciel Capacité à transformer des modèles d'apprentissage automatique de preuve de concept en solutions évolutives Capacité à appliquer les meilleures pratiques de développement logiciel dans les projets d'apprentissage automatique, y compris les tests unitaires, l'intégration DevOps, la gestion des versions, le développement piloté par les tests, etc. Capacité à automatiser le processus de développement d'un projet d'apprentissage automatique en tirant parti d'outils et de technologies de pointe tels que les conteneurs, l'intégration et la livraison continues, les outils d'orchestration, etc. Solide expérience en mathématiques, statistiques et programmation Expérience en SQL, bases de données relationnelles, concepts de bases de données, modélisation dimensionnelle et conception de bases de données Maîtrise d'un ou plusieurs langages de programmation utilisés pour la modélisation tels que Python, Scala . Familiarité avec un ou plusieurs outils d'apprentissage automatique ou de modélisation statistique Expérience avec les plateformes cloud (AWS, Azure) Bonne compréhension et expérience des principes de conception de logiciels et des modèles de conception Bonne compréhension de la méthodologie Agile et Scrum, en restant concentré sur la création de valeur commerciale Programme de congé à rémunération différée Garderie pour jeunes enfants Programmes d’avancement professionnel et de scolarisation Horaires flexibles Programmes et formations sur le leadership Gamme d’avantages sociaux, régime d’épargne et régime de retraite Programme d’aide de financement pour les congés parentaux Programme de reconnaissance et de récompense Collaborate with data scientists to test and scale new algorithms within Pratt & Whitney Canada’s analytics environment and later industrialize the solutions, monitor and maintain them in production Influence, build and maintain the large-scale analytics platform required for the AI projects, and integrate with DT infrastructure/service to provide an end-to-end solution Leverage an understanding of software architecture and software design patterns to write scalable, maintainable, well-designed and future-proof code Design, develop and maintain the framework for analytical pipeline Develop common components to address pain points in machine learning project, like model lifecycle management, feature store and data quality evaluation Provide input and help implement framework and tools to improve data quality Work in cross-functional agile teams of highly skilled software/machine learning engineers, data scientists, designers, product managers and others to build the AI ecosystem within the company Deliver on time, demonstrating strong commitment to the team’s mission and agreed backlog M.S. or Ph.D. in Computer Science, Computer Engineering, Statistics, Applied Math or related topics 5+ years of experience working in a Machine Learning, Data Scientist, Data Engineer or Software Engineer role Ability to transform proof of concept machine learning models into scalable solutions Ability to apply software development best practice into machine learning projects, including unit test, DevOps integration, release management, test driven development, etc. Ability to automate the development process of machine learning project by leveraging state of art tools and technology such as container, continuous integration and delivery, orchestration tools etc. Strong background in mathematics, statistics and programming Experience in SQL, relational databases, database concepts, dimensional modeling and database design Proficient in one or more programming languages used for modeling such as Python, Scala . Familiar with one or more machine learning or statistical modeling tools Experience with cloud platforms (AWS, Azure) Good understanding and experience with software design principles and design patterns Good understanding of Agile and scrum methodology, keeping focus on delivering business value Long-term deferred compensation programs Daycare for young children Advancement programs to enhance education skills Flexible work schedules Leadership and training programs Comprehensive benefits, savings and pension plans Financial support for parental leave Reward programs for outstanding work 
ScrapedJobID895:
8+ years of experience in marketing data management, analysis, and insights, adtech, martech, and research techniques as well as an innovative vision on how to keep pace with the ever changing marketing environment. Experience leading an Analyst(s) and/or external resources in supporting multiple marketing lines of business to understand opportunities before and after campaign execution Solid experience enabling digital analytics tools, Adobe Analytics, Google Analytics, Power BI, and other marketing technologies: SMMS/ listening tools, conversion and/or media pixels, etc. Extensive knowledge of digital analytics implementation tools and techniques: tracking libraries and SDKs, cookies, Data Layer, Tag Management Systems, report suite configuration, listening keyword data collection etc. Demonstrated track record of developing and leverage media (paid, owned, and earned) performance analytics both in the context of forecasting expected results and supporting performance optimization / improvement. Strong internal client management experience both presenting and resolving issues You are naturally curious and can create a story from numbers: you have applied quantitative skills ,love identifying trends and have the ability to roll up your sleeves and dig into data when necessary You have experience with the end-to-end process of qualitative research, including planning, scoping, conducting, analyzing, and communicating results. You have the ability to problem solve and develop innovative approaches along with a drive to learn and master new technologies and techniques You understand high level technical requirements to communicate marketing needs to Technology (D&T) for efficient and effective campaign performance and measurement 
ScrapedJobID896:
AI & Analytics lifecycle: working with end users to understand the business need & translating business problems to technical requirements Requirement analysis and design documentation, build and test, user acceptance testing, documenting the solution Business analysis: working with end users to document their business requirements and translate those into functional requirements, data requirements and a modelling approach Product management: defining technical roadmap and the required product features to support that roadmap Taking ownership of the backlog and prioritizing features, and bugs Familiarity with a wide breadth of data science technologies and techniques Educating partners on how AI & Analytics can be applied to solve business problems Evangelizing about the benefits of AI & Analytics Bachelor’s degree in computer science, engineering, business, finance or a related area of study or significant experience in a similar role 8+ years experience in analytics, consulting, product management or a similar function Experience with product ownership - backlog prioritization, proven demonstration of analytical thinking, consensus building, superior communication skills Excellent analytical and problem-solving skills Attention to detail Knowledge of AI and Machine Learning and how they can be applied to solve problems Business analysis, project management, and software development lifecycle (SDLC). Familiarity with Waterfall and Agile methodologies Experience with Python or other relevant programming languages and Machine Learning frameworks Ability to work cross-functionally with IT infrastructure and database administrator teams on project implementations Knowledge of Jira and Confluence Experience with OpenText Magellan Good written and verbal communication skills Able to build a sense of trust and rapport with the team and partners A self-starter attitude, a strong desire to learn as you go, and the belief that you can make a meaningful contribution to your immediate team, the business users that you serve, and to the organization 
ScrapedJobID897:
Work closely with cross functional data and analytics teams, enabling data & AI solutions driving successful business outcomes Actively contribute in the development of AI strategy engagements, helping our clients define how to successfully manage their data and deploy AI capabilities Provide subject matter expertise and technical leadership for data migration, conversion, and load initiatives as part of transformational programs Lead and support development of data models for AI and Analytics initiatives Provide leadership and expertise designing, configuring, and deploying SAP transformation programs, focused in leading practices around Business Intelligence, Data and Analytics capabilities leveraging industry leading data tools Lead and support SAP & AI pursuits and practice development initiatives Understand requirements, data sets, key success criteria, and issues which can be solved using analytics and/or data science techniques and provide accurate estimates. 5+ years’ experience with SAP Data structures (SAP ECC and/or S/4 Data Models) and tools (BW, BOBJ, HANA, BW4/HANA, Data Services) and/or other tools specifically used for data migration/integration Experience developing data models, ETLs, views, conversion routines from multiple source systems into SAP S/4 data structures OR exporting SAP Data into Enterprise Data Warehouses/Data Lakes Experience with SAP Data Migration, Conversion and Load processes and tools (e.g. BODS, Migration Cockpit, Data Intelligence, and others) Functional and Technical proficiency with at least 3+ years hands-on full life-cycle complex/large scale data warehouse and ETL design and development experience, including architecting, implementing, and successfully operationalizing large scale SAP data solutions in production environments using SAP BW/4HANA, Native HANA, S/4HANA or BOBJ Relevant experience with AI/ML models, automation, predictive or advanced analytics solutions are highly desirable, regardless if they were or not developed within SAP projects/technologies. Lead the way: Deloitte is not only leading the profession, but reinventing it for the future. We’re also committed to creating opportunity and leading the way to a more sustainable world. Serve with integrity: Deloitte has earned the trust of employees, clients, regulators, and the public for 175 years. Upholding that trust is our single most important responsibility. Take care of each other: We look out for one another and prioritize respect, fairness, development, and well-being. Foster inclusion: We are at our best when we foster an inclusive culture and embrace diversity in all forms. We know this attracts top talent, enables innovation, and helps us deliver well-rounded client solutions. Collaborate for measurable impact: We approach our work with a collaborative mind¬set, teaming across businesses, geographies, and skill sets to deliver tangible, measurable, attributable impact. 
ScrapedJobID898:
Build infrastructure to support an end-to-end pipeline that leverages machine learning, supporting data scientists and data engineers to make sure that they can work in the most productive and scalable way. Design and develop highly scalable and reliable machine learning pipelines within a cloud architecture (Snowflake, ADLS, AzureML, Databricks). Implement our internal methodology and architecture for ML model deployment through all stages of the ML life cycle. Bring expertise, knowledge and guidance to team members relating to ML Operations technology, tools, and best practices. Provide expertise, support and POC’s (Proof of concept) with various ML Operations infrastructure components. Bachelors or Master’s degree in computer science, software/computer engineering or equivalent experience in a technical role 2-5 year of software engineering experience while working in an AI / ML context alongside Data Scientists, ML Engineers and Data Engineers Strong experience in programmatically deploying and monitoring ML pipelines Proven track record of operationalizing successful end-to-end Machine Learning solutions Ability to challenge the status quo by identifying common issues, problems for the implementation phase of the life cycle Strong understanding of ML Ops architecture building blocks, such as Feature Stores and Data pipelines Familiarity with ML development frameworks and libraries (Tensorflow, Pytorch, Scikit-learn, etc.) Strong programming skills in Python programming language Experience in CI/CD/CT pipeline implementation using Azure DevOps Experience with IAM services such as Azure AD Experience with version control tools such as Git Experience with containerization, and Kubernetes (eg. AKS) Experience with SQL/NoSQL Experience with PySpark would is an asset Familiarity with Databricks is an asset Competitive matching defined contribution pension plan Comprehensive group insurance plan (with coverage from day one) Vacation days available on day one Unlimited access to virtual healthcare services for you and your family Generous and inclusive paid family leave policy for all caregivers Investment in career development 
ScrapedJobID899:
Conduct impact assessments and effort estimates for approving and documenting the IT solution using effective methods and interacting with both business users and the IT project team; Verify and validate business requirements using prototyping techniques, traceability matrices, as well as the definition of scenarios and test cases; Analyze, profile data and support the development of solutions and the performed analysis; Manage the backlog and create the list of backlog items and prioritize them based on the overall strategy, business objectives, scope, budget, and time; Prioritizing needs for iteration planning, while gathering requirements and performing root-cause analysis; Write, review and recommend changes on documentation (business processes, system documentation and procedures) in order to facilitate users' training as well as the integration of new processes and technologies within current operations; Identify detailed acceptance criteria on User Stories; Understand and anticipate the client’s needs to more effectively manage the development process; Play a primary communicator role and link between stakeholders and the team; Communicate status and deliverables to stakeholders and collect feedback for the development team; Play a primary role in inspecting and evaluating development progress through each iteration; Document the proposed solution, its scope and the requirements; Work with the Scrum Master to ensure cohesion in the team process; Keep abreast with Agile/Scrum best practices and new trends. Eager to understand how the business works and how your work impacts the business; Comfortable working in complex environments and multidisciplinary teams; Fast learner, versatile and a good team player; Excellent communicator with good analytical skills in data fields. Bachelor’s degree in Engineering, Architecture, Computer Science or equivalent; 6 + years of experience in functional analysis as business analyst - in a data driven environment; Very good knowledge in Data Lake, Data Warehouses (Data Vault, Informatica, PL / SQL, Oracle, Snowflake, Hadoop, AWS S3, etc.). Extensive experience in data querying, data integration, data modeling and data mapping; Extensive understanding of the Agile development process and best practices; Strong analytical, technical, verbal and written communication skills; Excellent organizational and time management skills; Experience with a data catalog (e.g. Erwin) Your experience and application knowledge in the insurance field, an asset. An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career Flexibility in how and where you work A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A casual ‘dress for your day’ culture that encourages you to be yourself A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID900:
Bring strong technical expertise to help expand Ads Problem solving skills, can excel in an ill-defined problem space and walk the way out with a structural solution Drive innovation, generate and validate new data, tactics and product ideas that maximize our business impact Build key algorithms behind our ads platform Design and analyze experiments to verify their impact Masters degree in Operations Research, Statistics, Economics, Machine Learning, or other quantitative fields Experience developing and deploying large scale machine learning and optimization models in production At least 5 years of industry experience in data science, with significant personal experience as a technical contributor. Strong experience of experimental design and analysis Strong experience with Python or R, and SQL. Experience working on Ads platforms Ph.D. in Operations Research, Statistics, Economics, Machine Learning, or other quantitative fields Experience mentoring more junior members Academic or industry publications Strong communication skills - this includes writing documents, putting together presentations, and speaking with people of all levels, from peers to top executives End-to-end ownership - you'll dive into the data to understand the whole context, passionately advocate for your ideas, help out with implementation where needed, and always take responsibility for ensuring that riders and drivers have a great experience on our network. 
ScrapedJobID901:
Develop advanced computer vision and deep learning models to solve object detection, imagery segmentation and imagery classification. Architect and build a highly scalable and fully automated deep learning model training and deployment pipeline. Create and own a 6-18 month technical roadmap, coordinate and execute the roadmap with your immediate team. Work with partner engineering teams to build real-time models & services for company-wide consumption Uncover deep insight hidden in our vast repository of raw data, and provide tactical guidance on how to act on findings Deliver presentations to high level business stakeholders that tell cohesive, logical stories using data. PhD (preferred) in quantitative field (statistics, mathematics, economics, operations research, physics, neuroscience etc) and 3-4+ years of experience with a computer vision focus or Master’s degree in quantitative field and 4-6+ years of experience OR Thorough command of general data science especially computer vision techniques, good understanding of parallel computing and data engineering practices. 3+ years of experience with Python, PySpark, SQL, deep learning platforms (i.e. tensorflow, pytorch, openCV), Google Cloud (or AWS/Azure),and (nice to have) containerization (Docker). A bias towards solving problems from a customer-centric lens and an intuitive sense for how the work aligns closely with business objectives. A knack for finding the right degree of pragmatism and delivering solutions in an iterative manner, adding only as much complexity as needed in each step along the way. Ability to effectively work with business leads: strong communication skills, ability to synthesize conclusions for non-experts and desire to influence business decisions. A curious mind open to continuous learning and motivated to autonomously drive projects and thrive in a dynamic environment where there can be ambiguity. 
ScrapedJobID902:
Develop and demonstrate solutions using NVIDIA’s platforms including state-of-the-art ML/DL, data science, visual computing, and HPC. Engage with customers to develop a keen understanding of their goals, strategies, and technical needs – and help to define and deliver high-value solutions that meet these needs. Assist field business development in guiding the customer through the sales process for GPU Computing products, owning the technical relationship and assisting customers in building creative solutions based on the NVIDIA platform. Provide customer requirements to engineering to foster product and platform improvements. Document what you know and teach others. This can vary from building targeted training for partners and other Solutions Architects, to writing whitepapers, blogs, and wiki articles, to simply working through hard problems with a customer on a whiteboard. 5+ years proven experience as a sales engineer/solutions architect. B.S. in Computer Science, IT or related field, or higher level of education (or equivalent experience) Experience using modern Deep Learning software architectures and frameworks including Tensorflow, PyTorch. Strong analytical and problem-solving skills and the ability to learn new technologies quickly. Results-oriented, independent and able to multitask effectively with minimal day-to-day direction. Strong written and oral communications skills leading to effective collaboration with management and engineering. Professional Visualization experience with M&E software such as Omniverse and vGPU. Graduate degree in Engineering, Computer Science, or related field. Parallel programming and GPU experience e.g., CUDA. Experience programming embedded platforms e.g., NVIDIA Jetson or similar. Cloud development/deployment experience e.g., Docker and Kubernetes. Experience in data science methods, analysis and languages including Python. 
ScrapedJobID903:
Bachelor’s degree in Data Science or Business Administration, MA or MBA preferred. Professional-level, current, subject matter expertise in various topics in Excel, Power Query and Power BI. Experience with adult instruction and/or training, with proven track record of online communication. Proficiency with MS suite, ability to connect to online hubs with reliable devices and internet access. Experience with online learning platforms such as D2L, Blackboard, and Moodle. 3-5 years teaching experience required. Documented experience working as an Instructor in a post-secondary or industry setting within a team environment is an asset. Ability to excel under pressure and ‘think on your feet’. Professional competence preparing, developing, delivering and administering post-secondary courses. Excellent English-language communication (written and verbal), and interpersonal and people-management skills. Demonstrated ability to deliver in class and within an online learning platform. Ability to motivate adult learners to achieve academic success. An established network of relevant professional contacts. Please note: These are the minimum required qualifications. Being a part of BC’s Top 100 Employers, and a member of the CCDI. A generous Total Compensation package which includes extended health and dental benefits and a superb pension plan. Access to Professional Development Funds and opportunities for career development. Increase your knowledge with Tuition waivers for BCIT courses. Enjoy discounted access to our fitness facilities (including classes like Yoga and Zumba). Additional Wellness and Employee Assistance programs. 
ScrapedJobID904:
Drive the vision for a new area of machine learning work with an ambitious charter Architect and develop end-to-end Machine Learning models/Reinforcement learning systems, working collaboratively with your team and cross-functional partners to build scalable solutions Partner with marketers to understand pain points and translate them into clear and robust data science solutions Build and own execution of a technical roadmap, ensuring that the vision aligns with broader company objectives Help grow the team through mentorship and developing learning opportunities Promote a culture of data science excellence and strengthen the technical expertise of our data science, engineering, and marketing teams 5+ years of experience working as a professional data scientist or ML engineer, including autonomously designing and building production models and algorithmic decision-making systems at scale 2+ years of experience mentoring and developing data scientists, analysts, or engineers Hands-on experience developing and deploying ML models, data pipelines, and running experiments to validate your models Excellent communication skills with demonstrated experience driving teams forward and ability to influence technical decisions to line up with the company’s strategy Nice-to-haves: Experience with Google Cloud Platform, Airflow, and containerization (Docker) Experience using Contextual Multi-armed Bandits, or Reinforcement Learning in an applied setting Advanced degree (Master or PhD) in a quantitative field 
ScrapedJobID905:
Data organization and analysis Partner with application experts in understanding the needs, be responsible in designing and developing predictive models. Test, improve and measure effectiveness of the developed approaches Contribute to writing scientific publications Must be a Ph. D. student in statistics / applied statistics A strong mathematical foundation, good computational and modeling (parametric, non-parametric, multi dimensional) skills Proven experience working in applied statistics Experience in handling large database Autonoumous, self motivated as well as a good team player Exceptional skills in programming and using open source libraries Ability to contribute to peer-reviewed publications Fluency in English and in French (written and spoken). 
ScrapedJobID906:
Use any available deep learning techniques in conjunction with PDFTron’s SDKs to develop next generation document understanding framework. Engage in Python programming and any other applicable programming languages such as C++ to develop and support new and existing products related to document understanding. Contribute full efforts to the software development process (from requirements gathering and analysis to high-level design/architecture, implementation, testing and maintenance/debugging). Write clean, concise and efficient codes that can be easily reviewed and maintained Contribute to technical documentation for PDFTron’s products being developed. Assist with research and development of future technologies and products. Prepare technical proposals, demonstrations and prototypes for new projects. Keep abreast of current and latest graphics technologies (i.e. PDF, XPS, SVG, image compression, etc.) Participate in technical/design reviews and group problem solving activities. Provide customer technical support by answering/solving customer questions and/or problems related to the PDFTron’s products or services. Masters or a PhD related to machine learning or 2 – 5 years experience developing advanced commercial applications related to deep learning/machine learning. A degree in computer science, computer/software engineering or equivalent. Strong computer science fundamentals: data structures, algorithms; programming languages Experience using Torch, TensorFlow, and other neural-networks toolkits Experience designing efficient network & training architectures. Strong proficiency in Python development, with additional experience in C/C++ would be benefitical Strong mathematical analysis and problem solving abilities. Excellent interpersonal and communication skills, both written and verbal. Ability to work effectively on assignments through correct prioritization and management of tasks in order to ensure high-quality deliverables at each stage of the project. Comfortable working independently, as well as part of a fast-paced and collaborative team environment. Ability to self-start projects with little to no guidance Competitive salary commensurate with experience & qualifications. A comprehensive extended benefits package including health, dental and vision for you and your family that starts from day one. A great team environment and resources, supporting you to do the best work of your life and providing unlimited career growth potential. Highly autonomous and entrepreneurial environment. Bi-weekly lunches and monthly socials (virtual for now). Unlimited learning development budget so you can master your craft. Annually recurring WFH allowance Work with the hardware you're most comfortable with (Windows or Mac) Diverse and inclusive workplace where we all learn from each other. Excellent work-life balance with a flexible work environment. Work remotely in Canada/Vancouver or in our convenient office location in downtown, your choice! 
ScrapedJobID907:
You love wrangling data to create performant streaming data that feeds Machine Learning models You enjoy straddling the worlds of Data Science and Developer, and when reviewing a Jupyter Notebook you find yourself drawn more to how to efficiently implement the solution space for product (even though the research is amazing) You love building tools for yourself to make working with Machine Learning solutions in production easier to troubleshoot You love to keep on top of the latest and greatest in technology, and are able to be opinionated on which are winners, and which are hype You’re a strong believer in Continuous integration, and the DevOps mindset You think it is critical to understand of how your software runs on infrastructure in detail, and are experienced in how it should be designed You like working in teams, mentoring, and sharing neat things you come across enjoy Design, develop, and support production grade streaming Machine Learning pipelines and solutions, including the areas of fast and efficient data processing, fault-tolerance, scalability Work closely with a Data Science team focused on the research aspects, and comprehend, design, and implement the path to product Drive the surrounding Machine Learning technology eco-system to support our product and workflows Work closely with product management, QA, and Support to build and support product Analyze, scope, review, and estimate development activities Be the subject matter expert of your ownership areas of the product Participate in evolving the team’s processes so we’re efficient, and loving what we do Mentor less experienced team members 2 years experience with building efficient and scalable data pipelines feeding Machine Learning models (including efficient and scalable preprocessing, training path, inference path, graceful degredation, dirty data mitigation) 2 years of experience with scalable data processing technologies (i.e. Spark, Flink, Apache Beam) 3 years of experience developing advanced Python using Object Oriented techniques, Modules (i.e. more than scripting) Experience with the Machine Learning Life-Cycle (i.e. scoping, data review, data processing, feature extraction, model development, testing, troubleshooting, performance monitoring) Experience with Tensorflow, or equivalents Multiple releases of your code deployed live and having to support it with customers at arms length Experience developing streaming data analytics including the storage and access challenges at scale and in production Clear verbal and written communication and the ability collaborate effectively in a geographically dispersed working environment Experience with Data Lake design, implementation, and life-cycle combining multiple disseparate types of data Advanced experience with the whole life-cycle of Python dependency management strategy across multiple repositories Experience with at least once IaaS provider Experience with the Power Systems domain and the software that manages it Knowledge, skills, and professional networking in one of the most exciting and positively impactful technology domains that is an intersection of machine learning, data science, electrical engineering, and software Startup experience and ground floor opportunities for growth in a team that includes PhD Smart Grid Engineers, Data Scientists, recent grads, and seasoned business professionals Competitive compensation High quality of life and career in Canada's National Capital Region Working on a team with a serious approach towards our work, rather than ourselves, together with fun and random team events such as Ice Cream Fridays and Cosmological Lunches. You will get the opportunity to come up with one 
ScrapedJobID908:
Working closely with other data scientists and developers in building and deploying various machine learning models for Global Relay's customers Being a subject matter expert on current speech transcription and speaker identification techniques Interacting with product managers on enhancements to our core products Executing all steps in the data science process from understanding business requirements to deploying models Producing reports detailing model performance 5+ years of experience with solving machine learning/speech recognition problems Experience working with very large data sets in an enterprise-wide application environment Knowledge of signal processing methods for audio processing and time series analysis An understanding of different neural network architectures as applied to speech recognition such as: Attention-based models, RNNs and CNNs Python, Bash and C++ experience Knowledge of common machine learning libraries such as: Scikit-learn, TensorFlow, PyTorch, HTK, Kaldi, Julius, Sphinx and others Strong organizational and communication skills MSc or PhD in a STEM or Linguistics subject Data collection and cleaning experience Data engineering skills Experience building acoustic or language models for speech recognition Experience with:
Natural language processing models
Kubernetes and micro services
Working in an agile development environment Natural language processing models Kubernetes and micro services Working in an agile development environment 
ScrapedJobID909:
Design and deployment of n-tier application and security design, documentation, and configuration for medium and large corporate implementations to the cloud. Coordinate the development and integration of large enterprise applications, Software defined storage, infrastructure, virtualization, technology roadmap, data architecture roadmap, data product roadmap. Direct cooperation with development teams on providing guidance about product development, roadmap and backlog Enhance platform capabilities, including data processing task automation, integration and deployment of analysis pipelines for internal use Knowledge and practical experience in data products development, that includes data processing and modelling techniques, tools, metadata structures, data lakes, and data dictionaries. BS/BA in computer sciences, mathematics, life sciences or related degrees Graduate degree in Data Science or other quantitative field is preferred Practical (ie. development) and conceptual (on the solution architecture level) knowledge and relevant experience on the front-end application development and integration with 3rd party tools and platforms (eg. Tibco Spotfire, Tableau, etc.) Product Ownership experience and skills, ie. ability to work directly with business users to determine the product direction and backlog Ability to translate business requirements into functional requirements Ability to perform Solution Architect role for web-based applications (both JS and TS) in the cloud environment Experience with AWS cloud infrastructure services Defined standards and lead implementation of software development processes Strong SAAS skills Monday to Friday front-end application development: 5 years (preferred) AWS cloud infrastructure service: 5 years (preferred) SaaS: 5 years (preferred) 
ScrapedJobID910:
Design and deployment of n-tier application and security design, documentation, and configuration for medium and large corporate implementations to the cloud. Coordinate the development and integration of large enterprise applications, Software defined storage, infrastructure, virtualization, technology roadmap, data architecture roadmap, data product roadmap. Direct cooperation with development teams on providing guidance about product development, roadmap and backlog Enhance platform capabilities, including data processing task automation, integration and deployment of analysis pipelines for internal use Knowledge and practical experience in data products development, that includes data processing and modelling techniques, tools, metadata structures, data lakes, and data dictionaries. BS/BA in computer sciences, mathematics, life sciences or related degrees Graduate degree in Data Science or other quantitative field is preferred Practical (ie. development) and conceptual (on the solution architecture level) knowledge and relevant experience on the front-end application development and integration with 3rd party tools and platforms (eg. Tibco Spotfire, Tableau, etc.) Product Ownership experience and skills, ie. ability to work directly with business users to determine the product direction and backlog Ability to translate business requirements into functional requirements Ability to perform Solution Architect role for web-based applications (both JS and TS) in the cloud environment Experience with AWS cloud infrastructure services Defined standards and lead implementation of software development processes Strong SAAS skills Monday to Friday front-end application development: 5 years (preferred) AWS cloud infrastructure service: 5 years (preferred) SaaS: 5 years (preferred) 
ScrapedJobID911:
Build solutions for machine learning inference for AMD GPUs. Design and develop lower level system software that works with underlying libraries, runtime systems and hardware. Analyze and optimize solutions to achieve the highest performance. Test and deploy these solutions. Work with cutting-edge compiler technologies. Apply one's knowledge of software engineering best practices. Excellent C/C++ programming and software design skills including debugging, performance analysis, and test design. Experience developing software in Linux environment including commonly used tools. Basic understanding of Deep Learning. Bachelor's, Master's, or PhD or equivalent experience in Computer Science, Computer Engineering, or related field. 
ScrapedJobID912:
Manage and contribute to the delivery of reporting and analytics solutions, mainly in Looker Understand business needs and technical requirements to meet those needs Lead and develop your team of analysts Set and achieve challenging goals for yourself and your team (OKRs) Foster a culture of data-driven decision making throughout the company Keep up with the latest data industry tools and techniques Top-notch communication (verbal and written) and interpersonal skills Excellent math and statistical analysis skills Proficiency in the presentation and visualization of numbers and statistical data Ability to understand business imperatives and drivers, find relevant data correlations, and create processes by which the data correlations are translated to information flows that help drive the business 5+ years developing and coaching analytics teams 5+ years of quantitative analysis work experience 5+ years of experience handling, manipulating and analyzing data and creating analytical reports Strong expertise with an SQL language, database structures, and data lake architectures Experience with Looker Experience with Snowflake Proficiency with Python An understanding of the principles, tools, and processes of data science Post-secondary education in a technical field, or B.S./M.S. 
ScrapedJobID913:
Data Science MS or Phd in Computer Science Data Science Statistics Mathematics or experience in a related field At least 10 years of experience in OCR Predictive model NLP time series model Strong in SQL ML libraries and frameworks like Scikit learn Spark ML TensorFlow Proficiency in programming languages including Python Java or similar Experience with visualization tools like Power BI Tableau In depth knowledge of statistical methods and test techniques as well as exceptional analytical skills Knowledge of best practices in data analysis and data science Exposure to cloud Machine Learning Azure AWS Plus but not required Residential whole loans data knowledge is a plus Monday to Friday Temporarily due to COVID-19 
ScrapedJobID914:

ScrapedJobID915:
Creating a positive learning environment that accommodates students’ diverse cultural and educational backgrounds, experiences, and individual learning styles; Utilizing principles of adult education to actively engage students in the learning process; Effectively using educational technologies to support learning, manage and post grades, and deliver hybrid and on-line courses; Developing curriculum that uses appropriate strategies and tools to assess student learning; Ensuring that course and program curriculum is current and relevant; Working independently and demonstrating initiative; and Working effectively with students, the program team, and a variety of internal and external stakeholders. A credential in Data Analytics or in a related discipline (relevant Master’s is an asset). A professional designation is an asset. A minimum of three years of recent (within the past three years) and relevant work experience. Teaching experience at the post-secondary level with a demonstrated understanding and application of Universal Design for Learning and current assessment methodologies. Experience participating in industry-led or community-based applied research is an asset. Demonstrated use of current technologies to support student learning and the management of grades. Proven track record of life-long learning. Demonstrated ability to work effectively with a variety of internal and external stakeholders including students, faculty, support staff, administrators and community stakeholders. Understanding of the Ontario college system. 
ScrapedJobID916:
Act as primary consultant to clients for data engineering services, managing the client relationship and coordinating across other support and consultant roles Estimate projects involving data integration, data architecture, business analysis or application development and collaborate with sales and client success teams to grow accounts Participate in product roadmap discussions and identifying key areas for improvement of products and services Collect client project requirements, focusing on needs & impacts and necessary technical outcomes Create solution designs to solve for clients business and technical needs while keeping within budget Produce documentation of data pipeline design and solution architecture for data warehousing and ETL, following company documentation standards Create datasets, extracts, or views of data that will be consumed by teams of analysts and data scientists to support data mining, analytics, reporting, and dashboards Develop, implement, and support methodologies, standards, and tools for data management, considering innovation and data security Create ongoing standards and process for overall data architecture team, including developing governance, support and testing models Perform exploratory data validation with analysts to ensure quality data standards are in place and ensure data integrity during all transformation steps. Bachelor’s degree in Statistics, Mathematics, Business Analytics or related field quantitative field, required with a minimum of 3-5 years experience with database development Experience with cloud / big data technologies such as BigQuery, Azure SQL DB/Synapse, Amazon Redshift is required Experience with relational database systems including SQL Server, Oracle, MySql, Postgres Advanced skills in data scripting and database development technologies (SQL, Python, R) Deep knowledge of ETL tools and how they can be applied to a big data environment Familiarity with analyzing digital marketing, advertising and ecommerce data Familiarity with web analytics tools such as Adobe Marketing Cloud or Google Analytics Experience with optimizing BI or visualization tools such as Tableau, Looker, DOMO or Power BI Experience with cloud platforms such as AWS, Azure, and Google Cloud Familiar with NoSql database technologies such as MongoDB Knowledge of technologies such as Spark, Hadoop, and Airflow 
ScrapedJobID917:
Stay abreast of innovations and publications in the field of operations research and business intelligence systems. Research and solve complex scheduling, resource allocation and pricing scenarios involved in operations optimization. Analyze raw operational data and design algorithms that can automatically and consistently generate operational recommendations for clients. Contribute to the invention of novel solutions to client’s operational problems by collaboratively working with product managers, co-developers, and our client success team. Utilize efficient algorithm design in a parallelized fashion capable of crunching gigabytes of operations data in minutes and scaling up with client growth. Build dashboards that transform operational data into visualizations that are intuitive and actionable Contribute refinements to our existing product through the development of new features as well as refactoring existing code to make it more efficient and object-oriented. Advance your knowledge of new software tools, agile programming methods, business intelligence technologies and share your knowledge with the development team, thus catalyzing process / technology changes to help us be more effective. Languages: C#, JavaScript, TypeScript Frameworks: .NET Core, Angular Web Server: IIS, NGINX Databases: MS SQL, Azure SQL Infrastructure: Azure, Docker, Kubernetes, GitLab Logistics engine: algorithms for discrete optimization problems Operation Systems: Windows, Linux Development Processes: Agile, CI/CD 2+ years of experience in Software Development, preferably with high performance algorithms or data intensive applications. A deep and intuitive understanding of Algorithms and Data Structures. Ability to process, assimilate, and explain complex and abstract concepts from research publications. Operations Research or Management Engineering Mathematical Optimization Data Science / Machine Learning Master’s Degree or PhD in Applied Mathematics/ Management Science/ Operations Research/ Computer Science / Engineering, or related technical discipline. Base salary of $80K - $115K + performance-based bonus or stock options Work-Life Balance: Flex time, work from home days and travel incentives. Set-up: Standing / adjustable desks, massage chair & quiet rooms, employee lounge with Xbox, Switch & PS4. Benefits Plan: Fitness allowance, dental/prescription/vision, massage & physio, and healthcare spending account. Food & Fun: Fully stocked kitchen, fancy coffee machine, team lunches, long weekend bottle draws and monthly employee events. 
ScrapedJobID918:
Follow NLP research and apply it to create technologies for business automation Own ML models end-to-end, from collecting training data to deploying in production Lead the planning, design, and implementation of the ML projects Serve as a mentor to junior team members and a standard-bearer for engineering best practice Manage the collaboration and communications with project stakeholders Minimum 3 years of industry experience in Machine Learning or related fields Solid understanding of Math and CS fundamentals related to Machine Learning algorithms Practical experience in modern NLP technologies (applying ML research to real-world projects) Previous experience in leading multi-person projects and building end-to-end Machine Learning systems Experience with one or more general purpose languages (Java, C/C++, Python, etc.) Team player with strong communication skills BS, MS or PhD in Computer Science, Engineering or a related technical field Top notch medical and dental coverage for you and your family 30 days of paid leave annually to help nurture work-life symbiosis Stock options Wellness stipend Pre-tax transportation and commuter benefits 6-month parental leave (or double salary to pay for your partner's unpaid leave) Free travel for any person accompanying a breastfeeding mother and her baby on a business trip A dependent care stipend up to $3,000 (USD) per month, per child, under the age of 21 for a maximum of $6,000 (USD) per month total Budget to attend conferences, train, and further your education $1,250 (CAD) one-time-use WFH stipend and $95 (CAD) monthly WFH stipend Relocation assistance 
ScrapedJobID919:
Overseeing the development of software to clean and investigate large, messy data sets of numerical and textual data Networking with various teams to explore internal and external data sources and APIs to help uncover new trends and improve analysis Designing and contributing to highly scalable data pipelines, tools, and products to enable the analyst community to fully leverage the power of AWS Working with your team to analyze large swaths of data in order to optimize various business programs Managing and developing talent to drive a highly performant and engaged team Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, you’re not afraid to blurt out your disruptive idea. You know how the latest tech works, yet you are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. Crafty: You know how to get things done. You can navigate a large organization, motivate people, and influence your peers. Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Inspiring: You have a passion for developing people and take great pride in your management system. You know how to deliver through others while paving the way for their growth. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook and all the monitors you want! You can travel to a relevant conference of your choice annually - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours, dress code and environment Bachelor’s Degree in a quantitative field At least 5 year of experience in open source programming languages for large scale data analysis (Python, Scala, or Java) At least 5 year of experience with version control system like Git and GitHub. At least 5 year of experience with relational databases and programming in SQL At least 2 years in lead positions (managing people/owning products/architecting and driving an agenda) Master’s Degree or PhD Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) Experience with CICD tools Experience with Machine Learning workflows 5+ years experience in Python 5+ years’ experience with SQL 3+ years in lead positions (managing people/owning products/architecting and driving an agenda) 
ScrapedJobID920:

ScrapedJobID921:
Experience with business analytics products like ThoughtSpot and Tableau Knowledge of one or more database technologies (Snowflake, SQL Server, etc.) Extensive understanding of global corporate business processes and their relationship to technology Excellent problem-solving abilities, strong written, verbal, and presentation skills Thrive in a dynamic environment, maintaining composure and a positive attitude Demonstrable understanding of development processes and agile methodologies Successful track record managing solutions from requirements analysis, to feature definition to deployment Proactively initiates, develops, and identifies opportunities to improve data quality Successful interaction with offshore team members is important Proficiency in writing Advanced SQLs, experience with data science tools and technologies is a plus Bachelor’s degree in Computer Science, Information Technology, or related field Experience in building advanced data visualizations using ThoughtSpot and Tableau 6+ years of IT experience with dimensional modeling, data investigation, optimization & using Cloud Databases Experience utilizing, and optimizing the use of, multiple large data sets Prior experience in the facilitating conversations to translate business requirements into the technical data requirements needed to develop solutions Excellent organization, time management, and communication skills Ability to work independently with strong attention to detail and accuracy Willingness and ability to adapt to rapid business and organizational change 
ScrapedJobID922:
Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. AWS Cloud (certification is an asset) AWS services like AWS glue or other AWS services Python programming language. Big Data technologies (like a Spark, hive/HDFS, PySpark, Hadoop) SQL and NoSQL databases, including Postgres and Cassandra. Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. AWS cloud services: EC2, EMR, RDS, Redshift Stream-processing systems: Storm, Spark-Streaming, etc. Object-oriented/object function scripting languages: Java, C++, Scala, etc. 
ScrapedJobID923:
Architecture the design and drive the development of highly robust, scalable and real-time machine learning platforms Build new features and tools for machine learning models and data scientists that help to amplify their effectiveness Drive efficiencies through automation and optimization Drive and uphold high engineering standards and best practices Collaborate with business leaders, subject matter experts, product managers, machine learning modelers etc. to solve interesting and highly impactful business problems 2+ years of software development experience Experiences in architecting scalable and low latency services A bachelor’s degree (or above) in computer science or related field is very helpful but we are open to be convinced that you are an exception Strong grasp of Computer Science fundamentals Strong ownership coupled with strong teamwork and collaboration A background in Machine Learning is preferred but not required The ability to clearly communicate complex results to technical and non-technical audiences and stakeholders (PMs, Operations, Engineers). Healthcare coverage Retirement Plans Employee Stock Purchase Program Wellness perks Paid parental leave Paid time off Learning and Development resources Healthcare coverage Retirement Plans Employee Stock Purchase Program Wellness perks Paid parental leave Paid time off Learning and Development resources 
ScrapedJobID924:
10+ years of experience in technical program/product/engineering management for large-scale business intelligence systems and/or complex software development initiatives. Bachelor’s degree (masters preferred) in business, engineering, computer science, or equivalent experience. SaaS experience / cloud native applications / backend data experience. AWS experience highly preferred; may consider other platform experience. Ability to influence at all levels and build strong partnerships across organizations to deliver the best outcome of complex programs. Excellent organizational and coordination skills along with multi-tasking capabilities to get things done in a fast-paced environment. Outstanding communication skills appropriate for executive-level audiences; ability to structure and communicate goals of program, relationship to business goals, and other relevant success criteria. Demonstrated ability to simultaneously understand and communicate the bigger picture while diving in to understand issues & risks to drive rapid resolution. Drive creation of data program roadmaps and data execution plans for complex, cross-organizational teams across all phases of planning, development, and production readiness and launch. Influence decisions by connecting strategy, priorities, and business/technical outcomes Lead execution in partnership across multiple functions including Data Engineering, Data Science, Data Analytics, as well as, with central data teams to align and deliver successful outcomes Ensure continued alignment of program scope, status, risks, and dependencies through effective communication across the organization and at all levels. Quickly and effectively identify critical issues and dependencies that need action and personally drive them through to closure. Balance business needs and technical constraints in resolving issues. Anticipate, recognize, and work through resistance or setbacks independently, work well with others when conflicts arise: see opportunities, ensure alignment with objectives, find common ground and promote understanding of alternative viewpoints before driving for closure and cooperation Effectively communicate program progress appropriately to varying levels of stakeholders. 
ScrapedJobID925:
Design, development and evaluation of highly innovative models Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation Work closely with software engineering teams to drive real-time model implementations and new feature creations Analyze internal behavior tracking data and forecast Wish demand Implement the strategies and set up A/B test experiments to gauge the impact, and reiterate Propose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process Create & own dashboards and analytical reports to track progress & share learnings Bachelor's or advanced degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics or similar) 3+ years of hands-on experience in predictive modeling and analysis 3+ years experience writing complex SQL queries in a business environment 2+ years in Python A/B test experience Experience collaborating with business & eng teams Analytical mindset and ability to see the big picture and influence others Detail-oriented and must have an aptitude for solving unstructured problems Ability to work effectively in a multi-task, high volume environment Ability to be adaptable and flexible in responding to deadlines and workflow fluctuations Experience operating in a Unix/Linux environment Strong presentation skills 
ScrapedJobID926:
Providing solutions for the deployment, execution, validation, monitoring, and improvement of data science solutions Creating Scalable Machine Learning systems that are highly performant Building reusable production data pipelines for implemented machine learning models Writing production-quality code and libraries that can be packaged as containers, installed and deployed Bachelor's degree or higher in computer science or related, with 5+ years of work experience Ability to collaborate with Data Engineers and Data Scientist to build data and model pipelines and help running machine learning tests and experiments Ability to manage the infrastructure and data pipelines needed to bring ML solution to production End-to-end understanding of applications being created and maintain scalable machine learning solutions in production Ability to abstract complexity of production for machine learning using containers Ability to troubleshoot production machine learning model issues, including recommendations for retrain, revalidate, and improvements Experience with Big Data Projects using multiple types of structured and unstructured data Ability to work with a global team, playing a key role in communicating problem context to the remote teams Excellent communication and teamwork skills Python, Spark, Hadoop, Docker, with an emphasis on good coding practices in a continuous integration context, model evaluation, and experimental design Test-driven development (prefer py. test/nose), experience with Cloud environments Proficiency in statistical tools, relational databases, and expertise in programming language like python/SQL is desired. Knowledge of ML frameworks like Scikitlearn, Tensorflow, Keras, etc. Knowledge of MLflow, Airflow, Kubernetes Knowledge on any of the cloud-native MLaaS offerings like AWS SageMaker, AzureML, or Google AI platform 
ScrapedJobID927:
Overseeing the development of software to clean and investigate large, messy data sets of numerical and textual data Networking with various teams to explore internal and external data sources and APIs to help uncover new trends and improve analysis Designing and contributing to highly scalable data pipelines, tools, and products to enable the analyst community to fully leverage the power of AWS Working with your team to analyze large swaths of data in order to optimize various business programs Managing and developing talent to drive a highly performant and engaged team Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, you’re not afraid to blurt out your disruptive idea. You know how the latest tech works, yet you are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. Crafty: You know how to get things done. You can navigate a large organization, motivate people, and influence your peers. Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Inspiring: You have a passion for developing people and take great pride in your management system. You know how to deliver through others while paving the way for their growth. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook and all the monitors you want! You can travel to a relevant conference of your choice annually - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours, dress code and environment Bachelor’s Degree in a quantitative field At least 5 year of experience in open source programming languages for large scale data analysis (Python, Scala, or Java) At least 5 year of experience with version control system like Git and GitHub. At least 5 year of experience with relational databases and programming in SQL At least 2 years in lead positions (managing people/owning products/architecting and driving an agenda) Master’s Degree or PhD Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) Experience with CICD tools Experience with Machine Learning workflows 5+ years experience in Python 5+ years’ experience with SQL 3+ years in lead positions (managing people/owning products/architecting and driving an agenda) 
ScrapedJobID928:

ScrapedJobID929:

ScrapedJobID930:
Degree in mathematics, computer science, engineering, physics, statistics, economics, computational sciences or a related quantitative discipline and 5+ years of analytical experience in an industrial or commercial setting OR PhD degree with at least 3+ years of industry experience Experience AI/ML/NLP modelling of complex datasets. Advanced software development skills in at least two of the standard data science languages (such as Python, R, Scala, C++, Julia) and strong data manipulations skills (e.g. SQL, NoSQL, graph, etc.) Knowledge of SQL and relational databases, query authoring (SQL) and designing variety of databases (e.g. Postgres SQL) Comfortable working in cloud and high-performance compute environments (e.g. AWS, Apache Spark) Disciplined AI/ML deployment (MLOps, CI/CD) and Agile delivery Experience in coordination of delivery teams and providing feedback to their management Excellent written and verbal communication, business analysis, and consultancy skills Knowledge on health care knowledge management systems (e.g. ICD, SNOMED, MedDRA, UMLS) preferred Experience AI/ML modelling of complex datasets, network analysis or direct experience in creating and maintaining graph data models Experience with a variety of graph technologies Knowledge of graph databases like Neo4J (Cypher, causal clusters), JanusGraph (Gremlin, GraphML), AWS Neptune, OrientDB Expertise in machine learning/deep learning-based graph algorithms relevant to link prediction, ranking/recommendation, completion, community detection, node embedding, etc. Lead data science area deliverables for digital products / programs / initiatives including the allocation of work within the team, monitors the quantitative and qualitative achievements of the team, and reports results Work as an individual contributor, providing data science expertise to digital products / programs / initiatives. Apply in-depth experience with both statistical and modern data science approaches, including unsupervised, supervised, regression algorithms. Apply advanced techniques such as neural networks, deep learning, NLP and federated learning. Build models, algorithms, simulations and experiments by writing highly optimized code and using state-of-the art machine learning technologies. Collaborate cross-functionally in teams involved in data driven analytics to maximize impact of graph-based capabilities Build and manage support models incorporated into digital or AI products; Work with Infrastructure and Ops teams to ensure appropriate architecture and tooling Capacity to mentor junior personnel Be able to apply in-depth experience with both statistical and modern data science approaches to business cases and knowledge management tasks Strong written and verbal communication skills - ability to communicate complex ideas up to people of varying technical skills Work with developers, engineers, and MLOps to deliver AI/ML solutions for new products/services 
ScrapedJobID931:
Linux GPU driver development in support of Machine Learning and Data Centre applications Contributes to software projects of significant technical importance Solves sophisticated non-recurring problems that leads to development and implementation Debug, analyze and resolve quality and certification issues as reported by Customers and QA Write detailed design notes for new features Coordinate closely with peers and colleagues to ensure timely and effective communication of all assigned work activities Coordinate with developers in the open-source development community Proficient in C and C++ programming Excellent debugging and trouble-shooting skills Strong general Linux systems administration, software development, and troubleshooting knowledge and experience. Linux kernel development experience, either core kernel development or device driver development. PC architecture knowledge Strong oral and written communication skills Experience with Linux containers kernel level implementation (cgroups, namespaces) Familiarity with Linux networking and network/cluster management Familiarity with Linux GPU driver development (kernel and user-mode), ideally on AMD hardware. Familiarity with compute, graphics, or multimedia GPU application development using APIs such as OpenCL, OpenGL, and VAAPI. Proven track record of contributions to open-source projects Familiarity with Linux security subsystems such as selinux and/or AppArmor Bachelor's degree or Master’s in Computer Science or related degree with validated experience 
ScrapedJobID932:
You'll play a pivotal part in informing and delivering upon our data strategy, by providing sales and marketing performance data, creating custom dashboards and visualization, and supporting marketing and financial strategies Providing Advance analytical insights to the team and help them improve marketing strategies Provide technical leadership to internal team members and various stakeholders Operationalize and support our underlying data systems, improving our system reliability, accuracy and stability You are analytical and outcome-oriented with a proven ability to translate technical considerations into business implications as well as to synthesize data into actionable insights You are well-versed with Business Intelligence/ Market Intelligence processes and other marketing technologies You have demonstrated the ability to successfully deliver complex projects involving people, process, technology, and change management You have experience with agile ways of working and a bias for action to break down barriers to get results fast with a test and learn mindset You can assemble large complex datasets across multiple databases and sources by building automated pipelines (ETL) Strong analytic skills related to working with unstructured datasets. Strong Business Acumen Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. SAS knowledge Business Intelligence/ Market Intelligence processes and other marketing technologies understanding Technical or data-driven educational background (computer science, engineering, statistics, data science) and/or Masters of Business Administration (MBA) degree 5+ years of progressive and relevant work experience Takes ownership, initiates improvements, and is self-directed Able to effectively engage stakeholders to establish cross functional alignment for projects Prior telecommunications expertise B2B marketing Python experience Hive / Spark / Nifi experience Experience with cloud (GCP Amazon or Azure) Data Science / Modeling experience or working in a Data Science team 
ScrapedJobID933:
Stay abreast of innovations and publications in the field of operations research and business intelligence systems. Research and solve complex scheduling, resource allocation and pricing scenarios involved in operations optimization. Analyze raw operational data and design algorithms that can automatically and consistently generate operational recommendations for clients. Contribute to the invention of novel solutions to client’s operational problems by collaboratively working with product managers, co-developers, and our client success team. Utilize efficient algorithm design in a parallelized fashion capable of crunching gigabytes of operations data in minutes and scaling up with client growth. Build dashboards that transform operational data into visualizations that are intuitive and actionable Contribute refinements to our existing product through the development of new features as well as refactoring existing code to make it more efficient and object-oriented. Advance your knowledge of new software tools, agile programming methods, business intelligence technologies and share your knowledge with the development team, thus catalyzing process / technology changes to help us be more effective. Languages: C#, JavaScript, TypeScript Frameworks: .NET Core, Angular Web Server: IIS, NGINX Databases: MS SQL, Azure SQL Infrastructure: Azure, Docker, Kubernetes, GitLab Logistics engine: algorithms for discrete optimization problems Operation Systems: Windows, Linux Development Processes: Agile, CI/CD 2+ years of experience in Software Development, preferably with high performance algorithms or data intensive applications. A deep and intuitive understanding of Algorithms and Data Structures. Ability to process, assimilate, and explain complex and abstract concepts from research publications. Operations Research or Management Engineering Mathematical Optimization Data Science / Machine Learning Master’s Degree or PhD in Applied Mathematics/ Management Science/ Operations Research/ Computer Science / Engineering, or related technical discipline. Base salary of $80K - $115K + performance-based bonus or stock options Work-Life Balance: Flex time, work from home days and travel incentives. Set-up: Standing / adjustable desks, massage chair & quiet rooms, employee lounge with Xbox, Switch & PS4. Benefits Plan: Fitness allowance, dental/prescription/vision, massage & physio, and healthcare spending account. Food & Fun: Fully stocked kitchen, fancy coffee machine, team lunches, long weekend bottle draws and monthly employee events. 
ScrapedJobID934:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID935:
Collaborate with our digital stakeholders to define KPIs, reporting requirements, and overall measurement strategy for our digital and mobile customer journeys Translate business requirements into technical specifications for custom digital analytics implementation using a combination of data layer, processing rules, SAINT classification, report suite configuration, custom JavaScript, JSON and applicable integrations with other systems Manage daily operations and implementation of TD's analytics stack (Adobe Analytics, Adobe Target, Adobe Audience Manager, Adobe Launch, Adobe Mobile Services, Ensighten) and 3rd party marketing tags (DoubleClick, Rakuten, Facebook, etc.) Develop and own all implementation documents such as SDR, Data Layer specifications, custom JavaScript Ensure the timely delivery and accuracy of documentation and technical coding (HTML, JavaScript, ActionScript) via our Tag Management System Collaborate with technology teams on implementation of analytics solutions, including guidance on data layer implementation and troubleshooting, data feeds and integrations with other systems Keep abreast of product updates (Adobe, Ensighten), best practices and proactively follow up with required changes in our implementation and appropriate communications Provide consultative service, training and validation support to quality assurance/testing teams. 4+ years' experience in analytics, with digital experience preferred 5+ years' experience of web development including JavaScript, jQuery and Angular Strong understanding of JSON structures and best practices Strong understanding of Native Mobile development standards Strong understanding of JavaScript & Node.js & DOM manipulation, web markup, including HTML5 and CSS3 Expertise with tag management tools (DTM, Adobe Launch, Tealium, Ensighten) and their configuration All-hands experience in implementing/troubleshooting/deploying the Adobe stack, Google 360 and/or 3rd party marketing tags using DTM or Adobe Launch or Ensighten Expert level knowledge in developing Adobe Analytics Solution Design Reference (SDR) Understanding of Adobe Analytics processing rules, SAINT classifications, report suite configuration, and data feeds Experience architecting a Data Layer Specification and guiding the development team on implementation and troubleshooting Experience debugging Adobe Analytics utilizing browser network calls, extensions, and tools such as Fiddler, Charles or Omnibug Ability to own and work independently on assigned deliverables, but also collaborate with multiple team members and stakeholders when necessary Solid communications skills – verbal and written Strong time-management skills and ability to work on multiple projects at once 
ScrapedJobID936:
Supports internal business partners globally by executing tasks outlined in the Global Data Operations Service Catalogue as well as the North America Portfolio Support Service Catalogue. Sets up, maintains, reviews, and validates security masters, brokers, and various reference data elements. Delivers production support tasks accurately and in a timely manner that meets established SLAs. Participates in the data reconciliation processes amongst various internal and external systems. Takes ownership, with some guidance (if needed), on complex escalated position, cash, coupon payment, and security master related reconciliation breaks requiring non-standard research and problem-solving abilities. Maintains an overall understanding of the assigned investment strategy (i.e. cash weights, financial instruments within the portfolio, cash management, etc.) Responsible for cash management support by calculating / verifying current day and net investable cash in multiple currencies for portfolio managers and resolve discrepancies within established deadlines. Participates in the analysis of the characteristics of new instruments to determine the associated data requirements and support procedures across all relevant systems. Participates in Product Shelf changes (e.g. new fund launch, new institutional mandates, portfolio manager change, fund name change, etc.) related activities within Support Services. Liaises with other functions to ensure the integrity of portfolio related data (position, cash, security master, pricing, corporate action, FX, derivatives, etc.) via reconciliation resolution oversight, coordination, and escalation globally. Acts as the escalation point for critical reconciliation breaks Contributes to the production of management reports and executive-level commentaries University degree in Accounting, Finance, Math or business area of concentration or equivalent experience MBA is an asset Certify Financial Analyst (CFA) or Professional accounting designation (CMA, CGA, CA, CPA) is an asset Minimum 3 years' financial services industry experience in a data analysis capacity Strong knowledge of investment products and global security markets is required Knowledge of market data services such as Bloomberg and Reuters is required Must have previous knowledge and work experience with data management applications (e.g. CADIS, Eagle PACE), order management systems (e.g. Charles River, Aladdin), portfolio administration applications (e.g. Eagle STAR, FMC), fund accounting applications (e.g. PAS, Eagle STAR), reconciliation tools (e.g. TLM), and data warehouse platforms (e.g. Eagle PACE) Must have a solid understanding of the end-to-end investment services processes, including but not limited to trade entry, trade process, settlement, security master set up/maintenance, valuation, corporate action processing, fund accounting and reconciliation resolution. Demonstrated ability to process and assimilate data and information into meaningful management and reporting information. Strong interpersonal, conflict resolution, written and verbal communication skills Customer focus and with a keen interest in providing superb services to clients. Strong organization skills and detail orientation, with an ability to understand the big picture and work under pressure with tight deadlines. Strong research, analytical as well as problem-solving skills. Aptitude for mathematical calculations and the ability to analyze detailed numerical data. Good Microsoft Office skills – in particular Excel, Access, Word, PowerPoint, Project, and Visio. Aptitude for learning new technology and adapting to rapid changes Rotating support coverage is required for international markets that are open during statutory holidays Participate in Business Recovery testing on an as-needed basis as defined by the manager Overtime, off-hours support, and travel may be required Staggering shift work is required on a rotational basis and as defined by the manager to provide global business coverage Current hours of business coverage for the North America Team (subject to change to fit global operations coverage needs): Mondays to Thursdays: Eastern Time 7:00a.m. – 8:00p.m, Fridays: Eastern Time 7:00a.m. – 6:00p.m, Sundays: Eastern Time 4:00p.m – 8:00p.m. Temporarily due to COVID-19 
ScrapedJobID937:
By delivering an award-winning product, conceptualized and developed by award-winning leaders, that result in award-winning customer employee experiences By hiring highly innovative, diverse talent that fully embraces and embodies our core values in everything they do: Customer Focus, Equity, Shared Ambition, Agility, Transparency, Optimism By using modern technology, such as voice-activation with Dayforce Assistant and access to your money as soon as you earn it with Dayforce Wallet to stay in rhythm with the evolving demands of our 4 million global users As a ML Engineer, you join a high performing agile team, responsible for building new models, updating current modules, and adding new features to our products, as well as other duties as assigned. The selected candidate will have prior experience with ML deployment, Python, and have used Linux or Git. Prior SQL knowledge is also desired. Our machine learning team works on challenging problems related to text mining, predictive model building and validation, data normalization and other data science activities. Your impact will be evident through your effective participation in the entire lifecycle of our software including design, analysis, prototyping, development, testing and support of our products. You will work closely and collaborate with implementation partners, to envision and deliver the required functionality. Encouragement to be the best version of yourself at and away from work: YOUnity diversity and inclusion programs Amazing time away from work programs Support for your total well-being through our Live Well, Work Well programs targeting all aspects of your life Recognition for your contributions through excellent pay, perks, and rewards Giving where you’re living: volunteer days, Ceridian sponsored events, and our very own charity, Ceridian Cares Opportunities to fuel your career growth through numerous internal and external programs and events Expertise in building and configuring production-ready machine learning systems. Expertise in using machine learning libraries in Python, or similar. Experience with complex SQL using PostgreSQL, or similar. Experience in consuming and building APIs in Node.js, Python, or similar. A passion for software development that often extends beyond your work An understanding of Linux systems A high level of comfort using Git and Github A desire to learn new technologies and techniques Nice to have: projects or contributions on github we can see 
ScrapedJobID938:
Creation and optimization of advanced analytics tools and regular reporting of insights derived from them to internal and external audiences, including senior leadership Uncover long-term opportunities based on research and analysis of our store performance to create actionable strategic insights Drive companywide efficiencies through standardization of systems, processes and analytics frameworks Major stakeholder in companywide development execution system rollout implementing process improvements and new analytical frameworks Build strong working relationships and influence cross-functional teams, including but not limited to; Regional Development Teams, IT, FP&A, Global Business Services (GBS) Develops and delivers presentations both internally and externally to executive level leadership Bachelors or Master's degree in the fields of Business, Economics, Data Science or equivalent field required 5+ years relevant work experience, 2+ year's experience working in analytics, project management and/or FP&A experience preferred Strong understanding of the fundamentals of statistical modelling, data science and analytics Advanced analytical skillset with ability to transform data into action plans, advanced proficiency excel modeling and super user of data visualization software (Smartsheet, Power BI, VBA, etc.) Experience collaborating with cross-functional teams (Technology, Finance, Business Development) to drive results/projects demonstrating effective communication, influencing and organizational skills Start-up mentality with ability to perform under pressure and adapt to a fast-paced environment working with a lean team Honesty, high integrity, personal accountability, ownership mentality and a passion for the success of the company, the team, and personal career growth Knowledge in one or more general-purpose programming languages (SQL, Python, Java, etc.) 
ScrapedJobID939:

ScrapedJobID940:
PhD received within the past 5 years or graduating PhD candidate (within the next three months) in computer science, biomedical engineering, neuroscience, biological science, or related discipline Experience with machine and deep learning libraries Scikit-learn, Tensorflow, Keras or Pytorch Strong research record Excellent verbal and written communication skills Proficiency with programming languages (Python/MATLAB, C/C++, etc.) Intermediate knowledge of Linux and scripting Ability and willingness to work in a dynamic interdisciplinary team environment Advanced knowledge of machine learning models for image processing, segmentation or registration Advanced knowledge of computer vision Experience with designing data analysis workflows and incorporating existing tools Working knowledge of neuroimaging software: FSL, FreeSurfer, SPM, ITK or microscopy software: Fiji/ImageJ, Ilastik Python software packaging, virtual environments, Anaconda/Conda, Jupyter/IPython Experience with statistical analyses and relevant software: example R or SPSS Experience with version control systems (Git) and software testing Demonstrated ability to learn quickly and problem-solve Sunnybrook Research Institute: sunnybrook.ca/research University of Toronto: utoronto.ca The Dr. Sandra Black Centre for Brain Resilience & Recovery: https://sunnybrook.ca/foundation/content/?page=brain-sciences-sandra-black Medical Biophysics: https://medbio.utoronto.ca/faculty/goubran Harquail Centre for Neuromodulation: https://sunnybrook.ca/research/content/?page=sri-centre-harquail LC Campbell Cognitive Neurology Research Unit:sunnybrook.ca/research/?page=cognitiveneurologyhome imaging.brainlab.ca Heart and Stroke Foundation Canadian Partnership for Stroke Recovery: sunnybrook.ca/research/?page=csrhome 
ScrapedJobID941:
Implementing, training, and optimizing models developed by our ML Science team Developing high-performance, scalable, and maintainable inference services that communicate with the rest of our tech stack Working with Infra teams to build data collection pipelines, manage data QA, and develop code for data visualization and data cleansing to build robust datasets Turning unfamiliar research code into bulletproof, production-ready software Working with edge hardware to test and tune the latency and performance of our services Building pipelines for continuous model improvement Experience with computer vision; experience developing and deploying deep learning algorithms; you’ve previously deployed machine learning models on scalable systems Strong grasp of statistical machine learning, linear algebra, and deep learning for computer vision Excellent C++11/14/17 and Python skills; familiarity with TensorFlow Ability to rapidly learn and work with unfamiliar code Understanding of CI/CD patterns and best practices Ability to write well-tested code Highly flexible and capable of working across the stack Great communication skills You love the idea of joining a fast growing series-A startup. You are proactive about solving problems and take initiative to build tools that will help everyone in the company. You love to thoughtfully help a team member or a customer in need. Innovation - We have an ambitious vision, and any change, especially the zealous kind, requires big ideas. Integrity - We trust each other, and that trust is the foundation on which our relationships both internally and externally are built. Continuous Improvement - We see everything as improvable, and work at finding ways to do so, and enjoy moving toward our goals. Accountability - Our teammates have intrinsic enjoyment in taking ownership and delivering on what they say they will. Customer Focus - We care the most about what benefits our customers and partners. 
ScrapedJobID942:
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. 2+ years of non-internship professional software development experience Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design Bachelor’s degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline 1+ years of experience as a data/software developer/scientist or related technical job A passion for improving customer experience Excellent verbal and written communication skills and technical writing skills Graduate degree in a related technical field 2+ years of experience as a data/software developer/scientist or related technical job Experience with Agile Development Experience with statistical modeling or machine learning (Classification, Collaborative Filtering) Experience with AWS services A love of music! 
ScrapedJobID943:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID944:
Design and deployment of n-tier application and security design, documentation, and configuration for medium and large corporate implementations to the cloud. Coordinate the development and integration of large enterprise applications, Software defined storage, infrastructure, virtualization, technology roadmap, data architecture roadmap, data product roadmap. Direct cooperation with development teams on providing guidance about product development, roadmap and backlog Enhance platform capabilities, including data processing task automation, integration and deployment of analysis pipelines for internal use Knowledge and practical experience in data products development, that includes data processing and modelling techniques, tools, metadata structures, data lakes, and data dictionaries. BS/BA in computer sciences, mathematics, life sciences or related degrees Graduate degree in Data Science or other quantitative field is preferred Practical (ie. development) and conceptual (on the solution architecture level) knowledge and relevant experience on the front-end application development and integration with 3rd party tools and platforms (eg. Tibco Spotfire, Tableau, etc.) Product Ownership experience and skills, ie. ability to work directly with business users to determine the product direction and backlog Ability to translate business requirements into functional requirements Ability to perform Solution Architect role for web-based applications (both JS and TS) in the cloud environment Experience with AWS cloud infrastructure services Defined standards and lead implementation of software development processes Strong SAAS skills Monday to Friday front-end application development: 5 years (preferred) AWS cloud infrastructure service: 5 years (preferred) SaaS: 5 years (preferred) 
ScrapedJobID945:

ScrapedJobID946:
Design, development and evaluation of highly innovative models Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation Work closely with software engineering teams to drive real-time model implementations and new feature creations Analyze internal behavior tracking data and forecast Wish demand Implement the strategies and set up A/B test experiments to gauge the impact, and reiterate Propose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process Create & own dashboards and analytical reports to track progress & share learnings Bachelor's or advanced degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics or similar) 3+ years of hands-on experience in predictive modeling and analysis 3+ years experience writing complex SQL queries in a business environment 2+ years in Python A/B test experience Experience collaborating with business & eng teams Analytical mindset and ability to see the big picture and influence others Detail-oriented and must have an aptitude for solving unstructured problems Ability to work effectively in a multi-task, high volume environment Ability to be adaptable and flexible in responding to deadlines and workflow fluctuations Experience operating in a Unix/Linux environment Strong presentation skills 
ScrapedJobID947:
Generate meaningful insights to solve sometimes ambiguous business/customer problems identify new opportunities to drive member growth and digital engagement of PC Optimum Deep dive into customer journeys to understand and empathize with customer pain points and identify opportunities with respect to customer engagement, business strategy, and experience with our Loyalty program Oversee the extraction, review, and preparation of complex operational and customer behavior information from a variety of databases (SQL, GCP, etc). Synthesize large amounts of data from multiple sources, including customer transaction data, consumer & syndicated research, market share, and campaign results. Use Cloud based Python/Scala environment to process big data, conduct analysis, and visualizing the results. Build presentations to clearly articulate insights, while simplifying complex data and processes for various levels of audiences including senior management Provide leadership and coaching to ensure a high performing team with appropriate skills and capacity required to enable the organization’s objectives with the goal of enabling customer centric decision making Collaborate and be strategic lead across cross-functional pods of Loblaw Digital, Marketing, Loblaw Technology, DI&A, Operations, and the Customer COE to see strategy through to execution Develop short term and long term strategies paired with realistic go to market executional plans that is centered in customer centricity. Support the execution of loyalty campaigns at Loblaws, analyze results, and loop back on how to improve University Degree in Data Science, Computer Science, Statistics, Mathematics, Economics, Engineering, Business or other relevant field 5+ years related work experience in an analytical role. Experience ideally in Retail, Loyalty, CPG industry, Consumer Finance, Telecommunications, or Consulting A Passion for advocating for the customer and helping teams deliver exceptional customer experiences Programming skills in various languages (Python, Spark, PySpark, SQL, R, Hive). AdvancedSQL is mandatory. Advanced Python is preferred. Experience with cloud platforms (i.e. GCP and Azure) is preferred. Strong skills in Microsoft Office suite (Excel, Powerpoint) Experience with building models on big data is preferred Ability to synthesize large amounts of data into insights Strong ability to build presentations and present complex ideas in a clear, articulate way Self-starter: demonstrated initiative and willingness to take ownership and learn A creative and curious thinker who is comfortable working with ambiguity, ability to multi-task, prioritize workload and work in a fast-paced environment Strong interpersonal skills with the ability to build and maintain strong working relationships with cross functional teams; able to effectively communicate issues, actively engage and influence, and work collaboratively as a team member Showcase leadership and availability to coach high performing team Effective organizational skills with a strong attention to detail while managing multiple projects or workstreams 
ScrapedJobID948:
Be part of a team with a high profile and a multitude of challenges to take on. Develop and evolve the AI platform architecture and integration models with our systems and market tools. Collaborate with members of various technical teams to develop solutions that address the constraints of our systems, data warehouses and environments. Develop scalable and robust architectures that can support the growing volumes of our AI environment. Provide solutions that meet our security and data protection standards. Ensure the architecture is aligned with our corporate vision and objectives, while being able to propose new approaches. Passionate about creating software that uses artificial intelligence, able to interact with teams of software developers, data scientists and researchers. An agent of change with up-to-the-minute awareness of new AI technologies and approaches on the market. Able to take a business problem and turn it into a technological solution. Comfortable working in complex and constantly changing environments, and with multidisciplinary teams. Excellent at explaining your ideas to various stakeholders. Well organized, with a good sense of how to manage priorities. A very good communicator who is able to cope with stress. Bilingual A bachelor’s degree in information technology/software engineering or any equivalent combination of education and experience. At least 5 years' experience in an architecture role. At least 10 years' experience in software engineering. Knowledge of SOA/REST, DevOps, Micro-services, Cloud services (PaaS and SaaS), Docker, Security/OWASP, Python and Java and Agile/Lean practices. Skills in machine learning/AI Hands-on experience delivering solutions using AI An award-winning, inspiring workplace that supports its people and recognizes great work (Canada’s Top 100 Employers, Aon Platinum Best Employers, LinkedIn Top Company, Glassdoor Best Place to Work & Top CEO, Indeed Top-Rated Workplaces) Stimulating, challenging projects and development opportunities to help you grow your skills and career Flexibility in how and where you work A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A casual ‘dress for your day’ culture that encourages you to be yourself A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID949:
Recognition programs to showcase your talent! To be part of a company that takes a stand on issues affecting people, the environment, and our partners Summer Fridays (because Summer is for fun) Purchase discount on merchandise sold in all our divisions. Family & Friends events with discounts on our products Subsidized cafeteria & daycare Subsidized public transportation, carpooling network and free parking On campus gym with access to a trainer Flex schedules and telecommuting Sick days Attractive total compensation! Collaborate and work closely with internal teams (buying, distribution, product design, e-commerce etc.) to identify business performance gaps and analytical opportunities Extract, mine and analyze data from various sources to provide actionable business insights, build visualizations and presentations to communicate findings Develop, implement and monitor Advanced Analytics / ML solutions to improve customer experience, drive marketing effectiveness, optimize supply chain and inventory, etc. Work with business teams to assist with data related technical issues and support their data infrastructure needs Collaborate with our Data Team to develop the data platform, identify data quality issues, build or enhance data flows, identify, profile and acquire new data sources Design, conduct and analyze complex experiments Build and maintain large datasets for self-service analytics Graduate degree in statistics, mathematics, computer science or related field 3+ years of work experience in data analytics and machine learning Expert level proficiency in data analysis, querying and crunching data from multiple systems and data transformation approaches Capable of translating analysis results into business recommendations and preparing presentations for various stakeholders Knowledge of R, Python, SQL, etc. Experience with AWS / Redshift or Google Cloud / Big Query to move and access large amounts of structured and unstructured data Experience developing and implementing machine learning models such as clustering, classification, forecasting, etc. Knowledge of techniques such as generalized linear model/regression, random forest, boosting, trees, time-series and forecasting, text mining, neural networks, etc. Experience designing datasets and visualizations with tools like Power BI, Tableau, Qlik, etc. Experience designing and analyzing experiments (A plus) Experience analyzing data from third-party providers, including Google Analytics, Site Catalyst, Coremetrics, AdWords, Crimson Hexagon, Facebook etc. (A Plus) 
ScrapedJobID950:
Take a hands-on role in several projects, including the Fundamental Review of the Trading Book (FRTB), data solutions for capital optimization, and data quality control processes. Prototype new approaches and enhance existing methodologies to advance market data management and data quality control. Develop production level code and collaborate with IT team for integration into daily bank processes. Assist team members for various ad-hoc analyses, data methodology, documentation, reporting, preparation of materials. Execute model runs on a regular basis for reporting and perform corresponding analyses. Communicate with model developers, trading desks, risk teams, and business lines to enhance data quality control and data management for capital optimization Become an active member of the team including our D&I initiatives and communities. Solid quantitative background and problem-solving skills with a keen interest in Data Science, Finance, Economics, Market Risk, Derivatives Pricing, Risk management or Regulations. Advanced degree in a mathematics, economics, or scientific discipline (e.g., Mathematics, Finance, Statistics, Physics, Engineering, Biology, Economics, etc.). Master’s degrees or PhDs are a bonus. Experience in code development in Python or other formal programing will be important to support day-day activity. Effective communication (written and oral), specifically the ability to summarize complex ideas in simple terms; you enjoy working in collaborations. The opportunity to join a forward-thinking company surrounded by a collaborative team of innovative thinkers. A rewarding career path with diverse opportunities for professional development. Internal development to support your growth and enhance your skills. A competitive compensation and benefits package. An organization committed to making a difference in our communities– for you and our customers. We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success! 
ScrapedJobID951:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID952:
real-time visibility on how Ubisoft titles are played; an understanding of the habits and preferences of the people playing them. Design, prototype, build and maintain APIs, tools, code and a scalable infrastructure for operating Merlin's machine learning pipeline at scale. Synch up with your team to discuss work-in-progress, ideas, and blockers; plan and prioritize; overcome issues; etc. Be a key member of the team, participate in the decisions and implementations to improve the platform’s quality. Work closely with Data Scientists to design and implement the optimal environment for their maximized efficiency. Advocate for automation and monitoring at all steps of the ML pipeline and help to define best practices based on personal industry experience and research. Stay current on technological advancements to help develop yourself, the platform and position Ubisoft as a leader of the domain. Experience in Software/Data engineering (or related experience). Experience with modern infrastructure, tools and cloud technology (e.g. AWS, EMR, Docker, Kubernetes, Terraform, etc.). Knowledge of Python, Java. Experience with big data technologies, like Kafka, S3, Spark, and Hive. Experience building and interacting with REST APIs. Familiar with GitLab and its CI/CD tool. A constant desire to grow and learn. Strong communication and collaboration skills. Ability to navigate between the big picture and the micro details. You love being responsible for owning and improving a new, fast-growing platform. You are curious and like asking questions until you fully understand why/what you are doing. A desire to see teammates succeed together. Experience with maintaining architectures for end-to-end Machine Learning in the cloud. Familiarity with industry standards such as MLFlow, Airflow... Knowledge of additional programming languages like Scala. Exposure to automated testing and CI/CD in the ML context. Good understanding of ML concepts. An understanding of the video game industry. Your CV, highlighting your background and skills 
ScrapedJobID953:

ScrapedJobID954:
Responsible for the design, development, and maintenance of data pipelines and back-end services for data collection and related functions for large external and internal data sources. Manage Automated Unit and integration test suites Support and contribute to master data functions as required during critical junctures Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, Analytics and AI roadmaps, and ensure long term technical viability of new deployments. Infuse key analytics technologies where appropriate including but not limited to SQL Server, Azure Synapse, Azure ML, Azure Cognitive Services, Azure Data Factory, Big Data, Data Lake, Azure Databricks, Power BI Experiment and recommend new technologies that simplify or improve current data ingestion process A key relationship contact for all tools development suppliers including designers and third-party platform investments Indirect support and coaching for total company analytical initiatives and data science acceleration plans Support requests for both the individual and the team’s analysis Post-audit and compliance tracking for all projects and routines Support ad-hoc requests for deep dives and productivity projects Assist in analyzing data, fields, and overall hierarchy to support analytics projects and provide collaborative solutions Key item accountability within routines and rituals including project management, meeting ownership, documentation, cross-functional alignment, and measurement. Development of a continuous list of ongoing process improvement projects. Collaborative mindset Exceptional attention to detail and analytical thinking Strong ability to design effective and efficient data structures and schemas Strong ability for developing for continuous integration and automated deployments Problem solver that finds efficiencies through innovation Customer and Consumer first mindset Affinity for trial & error mentality A/B testing culture support Progress over perfection mentality with usability & simplicity at the forefront of decision making Performance driven with ability to meet deadlines in a fast-paced environment Willingness to learn with a team-oriented attitude Strong Aptitude for learning new technologies and tools Bachelor’s in computer science or related technical field or equivalent work experience 4+ years designing, building and maintaining end-to-end data systems Expert in wrangling large-scale data sets Strong ability to write high quality, maintainable rode in SQL, Python and spark Experience with Databricks, Snowflake a plus Hands-on Experience with leading commercial cloud platform: Azure preferred (services including: Blob storage, ADF, Azure Synapse etc.) Experience in scripting languages 
ScrapedJobID955:
Responsible for the design, development, and maintenance of data pipelines and back-end services for data collection and related functions for large external and internal data sources. Manage Automated Unit and integration test suites Support and contribute to master data functions as required during critical junctures Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, Analytics and AI roadmaps, and ensure long term technical viability of new deployments. Infuse key analytics technologies where appropriate including but not limited to SQL Server, Azure Synapse, Azure ML, Azure Cognitive Services, Azure Data Factory, Big Data, Data Lake, Azure Databricks, Power BI Experiment and recommend new technologies that simplify or improve current data ingestion process A key relationship contact for all tools development suppliers including designers and third-party platform investments Indirect support and coaching for total company analytical initiatives and data science acceleration plans Support requests for both the individual and the team’s analysis Post-audit and compliance tracking for all projects and routines Support ad-hoc requests for deep dives and productivity projects Assist in analyzing data, fields, and overall hierarchy to support analytics projects and provide collaborative solutions Key item accountability within routines and rituals including project management, meeting ownership, documentation, cross-functional alignment, and measurement. Development of a continuous list of ongoing process improvement projects. Collaborative mindset Exceptional attention to detail and analytical thinking Strong ability to design effective and efficient data structures and schemas Strong ability for developing for continuous integration and automated deployments Problem solver that finds efficiencies through innovation Customer and Consumer first mindset Affinity for trial & error mentality A/B testing culture support Progress over perfection mentality with usability & simplicity at the forefront of decision making Performance driven with ability to meet deadlines in a fast-paced environment Willingness to learn with a team-oriented attitude Strong Aptitude for learning new technologies and tools Bachelor’s in computer science or related technical field or equivalent work experience 4+ years designing, building and maintaining end-to-end data systems Expert in wrangling large-scale data sets Strong ability to write high quality, maintainable rode in SQL, Python and spark Experience with Databricks, Snowflake a plus Hands-on Experience with leading commercial cloud platform: Azure preferred (services including: Blob storage, ADF, Azure Synapse etc.) Experience in scripting languages 
ScrapedJobID956:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID957:
Dynamic personalization: Serve content, propose products, promote services, or execute actions Dynamic customer cohort creation: Determine cohorts of similar behavior or tuned to specific KPIs Scalable actions across segments of customers Usage-based/behavior-based pricing models: Insurance based on behavior Abnormality and fraud detection: Identify and prevent unauthorized activity Security and remediation: Detect issues and alert responders in exponentially less time than traditional security through intelligent analyses Network performance: Monitor and respond to network performance issues faster IoT analytics: Unify disparate data sources to reduce costs and improve performance IOT TCO: Reduces the cost of installation by reducing tuning and maintenance Architect, build, test, deploy distributed, scalable, and resilient Spark/Scala/Kafka Big Data processing, and Machine Learning model pipelines for batch, micro-batch, and streaming workloads sets into Cerebri AI’s proprietary data stores for use in machine learning modeling Develop and maintain data ontologies for key market segments Collaborate with data scientists to develop automated orchestration of model pipelines to solve Cerebri AI business use case objectives Collaborate with clients to develop pipeline infrastructure, and to ask appropriate questions to gain a deep understanding of client data Deploy fully containerized Docker/Kubernetes Data processing, and Machine Learning model pipelines into Azure, AWS, GCP cloud environments and on-premise systems as necessary Document Detailed Designs (including source to target mappings) and Code for Data Quality frameworks that can measure and maintain Data Completeness, Data Integrity, and Data Validity between interfacing systems Ensure all solutions comply with the highest levels of security, privacy, and data governance requirements as outlined by Cerebri and Client legal and information security guidelines, law enforcement, and privacy legislation, including data anonymization, encryption, and security in transit and at rest, etc. Train and mentor junior team members Acts as a Subject Matter Expert and a Thought Leader, continuously following industry trends, the latest competitive developments, and delivering papers and presentations at major industry conferences and events. A degree in Computer Science, Engineering, AI, Machine Learning, BI, MIS, or an equivalent technology field Minimum 2 years of Production programming experience in Scala, Spark, PySpark, Big Data, Python Minimum 2 years of Production experience with the Hadoop Big Data platform Able to program and understand data science and data engineering ideas in Python and translate into modular, functional components in Scala Streaming and micro-batch application development experience would be an asset, including Kafka, Storm, NiFi, Spark Streaming, Confluent or equivalent Proficiency with Linux/Unix operating systems, utilities, and tools Experience working directly with relational database structures and flat files Ability to write efficient database queries, functions, and views to include complex joins and the identification and development of custom indices Knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, continuous integration and development, and operations. Experience deploying containerized Docker/Kubernetes applications Experience with Microsoft Azure or similar cloud computing solutions Big Data application architecture experience and in-depth understanding of the Big Data ecosystem, applications, services, and design patterns Production systems integration experience Good verbal and written communication skills, with both technical and non-technical stakeholders Experience in business intelligence visualization tools such as Grafana, Superset, Redash or Tableau. Master’s degree or higher in a relevant quantitative subject Experience with the Atlassian suite (JIRA, Confluence, BitBucket). Any other related experience with Big Data, artificial intelligence, natural language processing, machine learning and/or deep learning, predictive analytics Familiar with automated machine learning (AutoML) concepts would be an asset Experience with Breeze would be an asset 
ScrapedJobID958:

ScrapedJobID959:
Deploy machine learning solutions to improve Skype/Teams real-time collaboration quality and reliability Design, develop, and own components, tools, platforms, and systems for real-time media communication and collaboration. Drive independent investigations resulting in shipping product code, patents, and publications. Ph.D. in Computer Science, Mathematics, Physics, Electrical Engineering, or Masters plus equivalent work experience Minimum 7 year experience in professional software development 3+ years C/C++ coding, design and testing in a production environment Comfortable with Python or other scripting for rapid prototyping. Minimum of 1 years of experience in machine learning using tools like TensorFlow/Pytorch/Scikit-learn, etc. Strong system development skills, with a long-range system view that leverages development ranging from rapid research prototypes to carefully architected complex systems Excellent inter-personal skills and ability to work well in a scrum team. Experience developing and testing code in large codebases Experience developing production applications for the edge/IoT is a strong plus 
ScrapedJobID960:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID961:
Experience with Python in production environments and a strong understanding of computer science fundamentals Experience designing experiments, A/B testing and data analysis in the domain of quality metrics for machine learning services Experience with designing and building metrics collection and data visualization Solid understanding of modern web applications architecture and development process Passion for decision making based on sound data analysis. A strong sense of ownership and a persistent desire to grow and lead beyond the scope of the current role Basic understanding of modern frontend development frameworks (e.g., Angular or React) REST-based API design, e.g., Flask or Django. Interest in or experience with machine learning methodologies and tools (e.g. Natural Language Processing (NLP), sklearn, pandas, numpy, keras, tensorflow, etc.) Exposure to large-scale data processing tools like Kafka, Spark, or Hadoop Exposure to cloud-computing technologies like AWS/GCP, Docker, Kubernetes etc. Experience using modern frontend development frameworks (e.g., Angular or React) 
ScrapedJobID962:
Provide the Data Intelligence and Governance team with data analyses from researching systems and processes, profiling data via SQL queries, and validating data quality requirements. Identify and partner with data stewardship across the organization to operationalize the Data Governance framework. Champion data governance initiatives by promoting ideas into action; including developing and implementing data quality rules, communication, and adoption strategy. Oversee data quality management and data quality issue prioritization. Assist in developing data governance policies, processes, and documentation. Support corporate data quality initiatives through recommendation for solutions and leadership around data validation. Analyze and understand corporate data across data domains, on both source and target levels. Collaborate with other data analysts from cross-functional teams to address data quality issues and educate data stewardship on data governance principles. Identify new opportunities for data governance continually. Coordinates with various stakeholders and leaders across business functions to apply established data governance framework (training and education, developing data stewardship, data custodian roles, data dictionary, definitions and documentation, approval, and sign-off protocols). Are proficient in data analysis (preferably within software development, data delivery, and data analytics settings). Have a post-secondary degree in Data Science, Computing, Mathematics or Healthcare Informatics (preferably master’s level). Have 5+ years of experience in data management or data governance Are highly knowledgeable in databases and adept in SQL. Have hands-on experience in data visualization tools such as PowerBI. Are experienced with CRM tools such as SalesForce and NetSuite. Are exceptional at rapport building and creative problem solving. Have strong organizational, planning, and prioritization skills. Are goal-oriented, positive, a self-starter, with strong analytical skills. Are a data detective with excellent communication, known for collaborating and your ability to communicate complex data findings to various audiences. Demonstrate a proven track record of delivering results while guiding and facilitating business partners in solving data quality issues. Able to work independently and manage multiple commitments and responsibilities 
ScrapedJobID963:
Implementing, training, and optimizing models developed by our ML Science team Developing high-performance, scalable, and maintainable inference services that communicate with the rest of our tech stack Working with Infra teams to build data collection pipelines, manage data QA, and develop code for data visualization and data cleansing to build robust datasets Turning unfamiliar research code into bulletproof, production-ready software Working with edge hardware to test and tune the latency and performance of our services Building pipelines for continuous model improvement Experience with computer vision; experience developing and deploying deep learning algorithms; you’ve previously deployed machine learning models on scalable systems Strong grasp of statistical machine learning, linear algebra, and deep learning for computer vision Excellent C++11/14/17 and Python skills; familiarity with TensorFlow Ability to rapidly learn and work with unfamiliar code Understanding of CI/CD patterns and best practices Ability to write well-tested code Highly flexible and capable of working across the stack Great communication skills You love the idea of joining a fast growing series-A startup. You are proactive about solving problems and take initiative to build tools that will help everyone in the company. You love to thoughtfully help a team member or a customer in need. Innovation - We have an ambitious vision, and any change, especially the zealous kind, requires big ideas. Integrity - We trust each other, and that trust is the foundation on which our relationships both internally and externally are built. Continuous Improvement - We see everything as improvable, and work at finding ways to do so, and enjoy moving toward our goals. Accountability - Our teammates have intrinsic enjoyment in taking ownership and delivering on what they say they will. Customer Focus - We care the most about what benefits our customers and partners. 
ScrapedJobID964:
Perform and plan: (i) the programming, testing, and documentation of programs for use in creating statistical tables, figures and listing summaries, (ii) the programming of analysis databases (derived datasets) and transfers of data for internal and external clients. May perform and plan the programming of database quality control checks. Program the integration of databases from multiple studies or sources. Develop programming documentation including plans and specifications, as appropriate. Provide advanced technical expertise in conjunction with internal and external clients, and independently bring project solutions to teams and department. Perform and plan the development, implementation and validation of new process technologies, macros and applications. Fulfill project responsibilities at the level of statistical team lead for single studies, under supervision. Understand the Scope of Work, estimate the work completed, and manage Out of Scope for single studies. May manage budget and resource requirements and provide revenue and resource forecasts for single studies. May be required to understand budget and quote assumptions. Provide training and guidance to lower level and new staff. Typically requires 2 - 3 years of prior relevant experience. Requires intermediate level knowledge of principles, theories, and concepts of a job area, typically obtained through advanced education combined with experience. Knowledge of statistics, programming and/or clinical drug development process Working knowledge of computing applications such as Base SAS, SAS/STAT and SAS Macro Language Good organizational, interpersonal, leadership and communication skills Ability to effectively handle multiple tasks and projects Excellent accuracy and attention to detail Ability to establish and maintain effective working relationships with coworkers, managers and clients 
ScrapedJobID965:
We are building a state of the art platform to enable our network of data scientists and resellers to create hundreds of jupyter notebooks that can analyze immense amounts of data and produce real-time results to the user through customized dashboarding. Running thousands of notebooks at a time can be taxing on a system, so the magic we have running under the hood is what you and your team will own, operate, and iterate on. Improving and designing our SDK that lets developers create notebooks, visualizations and automation for their end-users. Python 3 (Tornado, Celery, Pandas) Java 8/11 (Spring Boot) Node.js (nest/graphql) Microservices hosted on AWS EKS, Fargate, Lambda Orchestration with AWS Step Functions & SNS/SQS AWS EMR (Presto, Spark, Hadoop) AWS Aurora, DynamoDB, S3 Angular 11 GitHub monorepo for our source code LucidChart for diagrams & collaboration JIRA to manage our backlog Our devs prefer to use IntelliJ (IDEA/PyCharm) We use GSuite (mail, drive, meet, docs, sheets, etc.) Slack Contribute to the codebase to help deliver product features on our roadmap Create prototypes and software design proposals based on product requirements Champion accepted proposals into production Facilitate technical design discussions within the team Research and break down large initiatives into iterative coding tasks Build upon our best practices and coding standards Participate in code reviews to ensure code quality Share knowledge, and provide mentorship to the team Automates the boring stuff. You take humans out of the equation where you can Thrives in ambiguity. With innovation, there is often no straight answer Driven by continuous innovation. You stay up to date with tech trends Action-oriented. When you see a problem you help solve it Transparent by nature. You are clear about the challenges you face Strengthened by peer feedback. You continuously grow and improve yourself Empathetic and lack an ego. You are team-oriented rather than a lone wolf A seeker of efficiency. You improve processes that help us work better, faster & smarter 
ScrapedJobID966:
Act as an HXM system administrator, advisor, subject matter expert and technical mentor for the PnC team and other Admin Users. Identify areas to improve systems processes, functionality and workflow while maximizing technological capabilities to reduce manual processes and create more effective use of the HXM and other PnC systems Provide technical insights, advice, and analysis on any PnC systems or software evaluations, reviewing vendor options, features, and modules and making recommendations on the best solutions Manage the implementation of new PnC systems and technologies, including documentation of current / future – state processes, coordination of stakeholders and tasks, data mining, testing and training, and other related project activities Facilitate a strong partnership between People and Culture and system user communities to increase usage and self-service, including leading training and education sessions or creating content for systems course development Respond to employee inquires/questions with a 'service-first' mindset Conduct business analysis to define, design, document, test, and deploy features that propose viable solutions or improved processes to achieve current state requirements as well as the ability to scale for future requirements Anticipates clients long term needs by establishing a clear sense of their organizational and business unit strategies. Delivers and provides additional information beyond client expectations. Provide data analysis, offer insights and identify trends to the business, including the senior leadership team Provide oversight on data governance, including systems and dashboard architecture and maintenance Build custom reporting and dashboards to respond to People and Culture team and business requests Accountable for high level of data integrity, auditing, and enforcing data validation processes within the HXM Design, map out and document new workflows and business processes with a 'Better, Smarter, Faster' mentality Manage upcoming system releases, testing and reviewing for possible issues and correcting any negative impacts Compile weekly/monthly/quarterly reporting packages and dashboards Manage time away from work balance and liability reporting Help project manage PnC's Employment Equity initiative and manage employee data collection in HXM, equity reports, and support any related Diversity & Inclusion activities and reporting analysis needs Communicates a clear vision for project initiatives and helps to translate vision into specific actions. Actively employs critical thinking towards anticipating trends in the external and internal environment by developing proactive plans to address or prevent future factors. Assist with regular operational reporting Document and maintain various processes Manage ad hoc People and Culture projects as requested 5-7 years of relevant experience working in a fast-paced, high-tech environment Experience administering and configuring an HRIS/HXM Experience with SharePoint, PowerBI (or Dashboard software), SQL and XML preferred Experience implementing an HXM an asset Advanced knowledge of Excel and proven ability to work with other MS Office tools Understands relational database concepts and can query and transform data dynamically using complex queries and scripting Strong analytical and problem-solving skills with an aptitude for working with data Excellent attention to detail; understands the importance of data integrity Excellent communication skills and ability to collaborate with and influence key stakeholder groups Proven ability to identify process efficiencies and drive continuous improvement initiatives Strength in organizing and coordinating multiple activities and projects at one time, while effectively managing disruptions and changing priorities Ability to independently exercise decision making authority over technical tasks and recommend system functionality to meet business requirements. Business acumen and curiosity Self-starter with proven initiative and a collaborative approach Flexible work hours Health and wellness programs Collaborative work environment Dog friendly office Snacks and food trays! Foosball and Ping-Pong tables Showers on site Centrally located in downtown, close to restaurants and pubs, easily accessible by public transit 
ScrapedJobID967:
Building and integrating end to end lifecycles of large-scale, distributed machine learning systems using the latest open source and cloud technologies Building automated tests and validations for machine learning models and underlying data Comparing different versions of machine learning models using methods like AB testing, champion/challenger etc. Identifying model and data drifts Developing scalable tools and services for handling machine learning workflows Implementing cloud distributed training approaches for deep learning models Collaborating with engineers across functions to solve complex data problems at scale Collaborating with data scientists to test and deploy ML models at scale Identifying and evaluating new patterns and technologies to improve performance, maintainability and elegance of our machine learning systems Leading technical projects to completion and communicate with peers to build requirements and track progress Experience in MLOps to deploy and maintain machine learning models Experience building systems with scalable data processing technologies using Spark, Python, SQL Experience in CI/CD and be able to follow good branching practices Exposure to Databricks and associated tools like ML Flow and Delta Lake Familiarity with data-oriented workflow orchestration frameworks (Databricks Jobs, Azure DevOps, Azure Data Factory, Airflow etc.) Experience developing with containers and Kubernetes in cloud computing environments (Azure, AWS, GCloud, etc.) Exposure to machine learning and drift detection methodology and best practices. Exposure to deep learning approaches and modeling frameworks (PyTorch, Tensorflow, etc.) Strong software engineering skills in complex multi-language systems Rigor in high code quality, automated testing, and other engineering best practices Experience working with cloud computing and database systems Fluency in Python (asset only) Collaborative Self-motivated Innovative Able to work independently while part of a team 
ScrapedJobID968:
Consult with key stakeholders to understand requirements. Plan out work in an agile framework, taking part in internal daily scrum meetings and other agile activities as adopted by the team. Design, build and test solutions to customer problems in a robust manner. Build reports and/or dashboards to showcase results to stakeholders in the technology that is most accessible to them. Utilize advanced analytical techniques to build smart solutions to customer problems. Actively take part in and contributes to key customer facing meetings. Be a thought leader, understanding customer problems and proposing solutions that most effectively solve them. Keep up to date with best practices and continuously seeks to learn new skills. Validate new skill development through pursuit of relevant certifications. Contribute towards the growth of the business by observing opportunities for upselling or cross-selling within the customer organization. Contribute to development of the delivery team and their practice area through participating in internal TED talks, mentoring junior team-mates and developing reusable training materials and standard operating procedures. Contributes to the broader business through involvement in recruiting, marketing and sales activities. Contribute to the overall collaborative and innovative culture of the company by taking part in group events and spearheading initiatives that grow the company and help make life at ProCogia more enjoyable for all. Experience building computer vision and NLP models R or Python for Data Science Advanced Statistical Analysis Building and validating search, personalization, and recommendation algorithms Data Visualization Skills (Shiny and PowerBI preferred) Experience building Machine Learning and Deep Learning libraries Machine Learning Frameworks (SparkML preferred) SQL (Structured Query Language) Experience with Structured and Unstructured Data Git for Version Control Working with Command Line on Unix based systems Spark Experience (PySpark preferred) Cloud Experience (AWS and Snowflake preferred) Docker and Kubernetes experience SDLC (Software Development Life Cycle) experience AI (Artificial Intelligence) and Deep Learning experience Python, SQL, Hive, etc. Bachelors in a quantitative field with a deep understanding of mathematics, statistics, and computer science. Masters or PhD in a quantitative field with a deep understanding of mathematics, statistics, and computer science. An experienced professional will have at least 3 years of professional experience in a data related role with a Masters Degree or 5 years of experience in a data related role with a Bachelors degree. 
ScrapedJobID969:
Provide a leadership role in the development and communication of Data Management strategies, principles, standards, and best practices. Develop and maintain both operational and data warehouse conceptual, logical, and physical data models. Partner with Business Analysts to gather business, data, and reporting requirements and translate the business needs into logical data structures. Act as an important contributor to the development and maintenance of IT strategies and plans. Experience with metadata management, data stewardship, data quality, IT governance, Enterprise Data Models, and Enterprise Frameworks. Direct team members on architecture concepts Business intelligence, query, and reporting tools Data Warehouse / Data Lake / MDM architecture principles Data integration and streaming integration concepts and architecture Database design for read-only access Data warehousing design issues such as star schema Data warehousing technologies such as OLAP (including ROLAP, MOLAP, and HOLAP) Data transformation and conversion Data quality issues Data formats for loading and unloading of data. Middleware Platform-specific workload management rules Data Partitioning Architecting for Mixed workload Data Modelling for Data Warehousing / Data Lakes (Denormalized – Star & Snowflake Schemas, Data Vault) Parallel execution Indexing and statistics strategies Build and maintain optimized reliable data pipelines that facilitate deeper analysis, additionally develop queries for ad hoc business projects, that translate raw data into powerful features and signals as well as ongoing reporting. Builds data processing frameworks that handle the business’s growing database and enrich big data with tertiary data at scale. Working with stakeholders in leveraging data with reporting and scientific tools while striving to continuously develop new and improved data engineering capabilities. Support and maintenance of existing big data infrastructure on Google BigQuery and develop processes and alert systems to monitor the health of the big data infrastructure (Java). Semantic modeling and modeling for parallel access (high concurrency access) Use SQL and Python to interact with big data infrastructure as needed for data engineering. Performing code reviews (SQL Stored Procedures, Python) Change Management: releasing code into Production environments using CI/CD processes Provide coaching and mentoring other developers on the team. University Degree or College Equivalent 10+ years IT experience in large scale technology architecture, operations, and design-related disciplines 8 – 10 + years of concrete programming experience in core Python/C# with Software Development Life Cycle 5+ years of SQL experience with large data sets (experience with Google BigQuery, Dockers, Kubernetes) is preferred Good to have - AWS (RedShift) Hands-on experience in writing complex, highly-optimized SQL queries across large data sets Deep understanding of object-oriented design principles Familiar with various design patterns, good component, and modeling ability Solid understanding and experience of any relational databases (SQL Server, PostgreSQL, etc.) Experience working with and developing Rest APIs. Experience working closely with data science teams to arrive at data infrastructure solutions that are optimized for scale. 4+ years in a Data Modeler or Data Architect role 3rd Normal Form and Dimensional modeling expertise Team player with excellent communication skills Facilitation and workshop coordination experience Business information requirement analysis experience Adept at balancing the immediate needs of a project with the future vision of the enterprise to achieve a win-win situation. Experience in Automotive and /or eCommerce Google BigQuery and AzureSQL Server experience an asset. ETL and data integration experience CA Erwin experience would be an asset. Solid understanding of Project Management and SDLC methodologies Advanced business analysis, architecture, and design skills Ability to communicate highly technical and complex security concepts effectively across all levels of the organization (both IT and business) 
ScrapedJobID970:
Responsible for the design, development, and maintenance of data pipelines and back-end services for data collection and related functions for large external and internal data sources. Manage Automated Unit and integration test suites Support and contribute to master data functions as required during critical junctures Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, Analytics and AI roadmaps, and ensure long term technical viability of new deployments. Infuse key analytics technologies where appropriate including but not limited to SQL Server, Azure Synapse, Azure ML, Azure Cognitive Services, Azure Data Factory, Big Data, Data Lake, Azure Databricks, Power BI Experiment and recommend new technologies that simplify or improve current data ingestion process A key relationship contact for all tools development suppliers including designers and third-party platform investments Indirect support and coaching for total company analytical initiatives and data science acceleration plans Support requests for both the individual and the team’s analysis Post-audit and compliance tracking for all projects and routines Support ad-hoc requests for deep dives and productivity projects Assist in analyzing data, fields, and overall hierarchy to support analytics projects and provide collaborative solutions Key item accountability within routines and rituals including project management, meeting ownership, documentation, cross-functional alignment, and measurement. Development of a continuous list of ongoing process improvement projects. Collaborative mindset Exceptional attention to detail and analytical thinking Strong ability to design effective and efficient data structures and schemas Strong ability for developing for continuous integration and automated deployments Problem solver that finds efficiencies through innovation Customer and Consumer first mindset Affinity for trial & error mentality A/B testing culture support Progress over perfection mentality with usability & simplicity at the forefront of decision making Performance driven with ability to meet deadlines in a fast-paced environment Willingness to learn with a team-oriented attitude Strong Aptitude for learning new technologies and tools Bachelor’s in computer science or related technical field or equivalent work experience 4+ years designing, building and maintaining end-to-end data systems Expert in wrangling large-scale data sets Strong ability to write high quality, maintainable rode in SQL, Python and spark Experience with Databricks, Snowflake a plus Hands-on Experience with leading commercial cloud platform: Azure preferred (services including: Blob storage, ADF, Azure Synapse etc.) Experience in scripting languages 
ScrapedJobID971:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID972:
Dynamic personalization: Serve content, propose products, promote services, or execute actions Dynamic customer cohort creation: Determine cohorts of similar behavior or tuned to specific KPIs Scalable actions across segments of customers Usage-based/behavior-based pricing models: Insurance based on behavior Abnormality and fraud detection: Identify and prevent unauthorized activity Security and remediation: Detect issues and alert responders in exponentially less time than traditional security through intelligent analyses Network performance: Monitor and respond to network performance issues faster IoT analytics: Unify disparate data sources to reduce costs and improve performance IOT TCO: Reduces the cost of installation by reducing tuning and maintenance Architect, build, test, deploy distributed, scalable, and resilient Spark/Scala/Kafka Big Data processing, and Machine Learning model pipelines for batch, micro-batch, and streaming workloads sets into Cerebri AI’s proprietary data stores for use in machine learning modeling Develop and maintain data ontologies for key market segments Collaborate with data scientists to develop automated orchestration of model pipelines to solve Cerebri AI business use case objectives Collaborate with clients to develop pipeline infrastructure, and to ask appropriate questions to gain a deep understanding of client data Deploy fully containerized Docker/Kubernetes Data processing, and Machine Learning model pipelines into Azure, AWS, GCP cloud environments and on-premise systems as necessary Document Detailed Designs (including source to target mappings) and Code for Data Quality frameworks that can measure and maintain Data Completeness, Data Integrity, and Data Validity between interfacing systems Ensure all solutions comply with the highest levels of security, privacy, and data governance requirements as outlined by Cerebri and Client legal and information security guidelines, law enforcement, and privacy legislation, including data anonymization, encryption, and security in transit and at rest, etc. Train and mentor junior team members Acts as a Subject Matter Expert and a Thought Leader, continuously following industry trends, the latest competitive developments, and delivering papers and presentations at major industry conferences and events. A degree in Computer Science, Engineering, AI, Machine Learning, BI, MIS, or an equivalent technology field Minimum 2 years of Production programming experience in Scala, Spark, PySpark, Big Data, Python Minimum 2 years of Production experience with the Hadoop Big Data platform Able to program and understand data science and data engineering ideas in Python and translate into modular, functional components in Scala Streaming and micro-batch application development experience would be an asset, including Kafka, Storm, NiFi, Spark Streaming, Confluent or equivalent Proficiency with Linux/Unix operating systems, utilities, and tools Experience working directly with relational database structures and flat files Ability to write efficient database queries, functions, and views to include complex joins and the identification and development of custom indices Knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, continuous integration and development, and operations. Experience deploying containerized Docker/Kubernetes applications Experience with Microsoft Azure or similar cloud computing solutions Big Data application architecture experience and in-depth understanding of the Big Data ecosystem, applications, services, and design patterns Production systems integration experience Good verbal and written communication skills, with both technical and non-technical stakeholders Experience in business intelligence visualization tools such as Grafana, Superset, Redash or Tableau. Master’s degree or higher in a relevant quantitative subject Experience with the Atlassian suite (JIRA, Confluence, BitBucket). Any other related experience with Big Data, artificial intelligence, natural language processing, machine learning and/or deep learning, predictive analytics Familiar with automated machine learning (AutoML) concepts would be an asset Experience with Breeze would be an asset 
ScrapedJobID973:

ScrapedJobID974:
Deploy machine learning solutions to improve Skype/Teams real-time collaboration quality and reliability Design, develop, and own components, tools, platforms, and systems for real-time media communication and collaboration. Drive independent investigations resulting in shipping product code, patents, and publications. Ph.D. in Computer Science, Mathematics, Physics, Electrical Engineering, or Masters plus equivalent work experience Minimum 7 year experience in professional software development 3+ years C/C++ coding, design and testing in a production environment Comfortable with Python or other scripting for rapid prototyping. Minimum of 1 years of experience in machine learning using tools like TensorFlow/Pytorch/Scikit-learn, etc. Strong system development skills, with a long-range system view that leverages development ranging from rapid research prototypes to carefully architected complex systems Excellent inter-personal skills and ability to work well in a scrum team. Experience developing and testing code in large codebases Experience developing production applications for the edge/IoT is a strong plus 
ScrapedJobID975:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID976:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID977:
Réaliser le développement des rapports et tableaux de bord dans le respect des Modifier les rapports et tableaux de bord existants afin de répondre aux besoins Effectuer les essais et l"assurance qualité des développements avant la mise en Assurer la performance des rapports et tableaux de bord développées Assurer le support de premier niveau des produits informationnels Travailler en étroite collaboration avec les équipes de gestion de l"information afin Assurer le lien avec l"équipe de l"entrepôt de données afin de spécifier les besoins et Participer au profilage des données des systèmes sources Tester les extractions et les requêtes afin d"assurer la qualité des données Créer des tables de faits, de dimensions, et des vues pouvant être utilisées dans les Créer des champs calculés directement dans les bases de données pour supporter Participer aux discussions et aux ateliers de gouvernance Proposer et utiliser les définitions et le lexique d"entreprise Assurer la conformité et l"alignement des indicateurs clefs de performance Recueillir les besoins d"affaires et ceux des clients et utilisateurs Organiser et conduire des séances de travail afin de développer et proposer des Effectuer l"analyse détaillée des besoins et rédiger les spécifications détaillées afin de Participer et conduire des réunions et des revues d"avancement des projets avec les Analyser, cartographier et schématiser les systèmes et les processus d"affaires Créer et supporter la mise en place d"une architecture des données Proposer les meilleures solutions possibles afin d"atteindre les objectifs de l"unité Proposer des indicateurs clefs de performance pertinents Rédiger la documentation des produits informationnels afin d"en permettre une Supporter le déploiement du portail web pour la diffusion des différents rapports et Mettre en place une structure temporaire pour le traitement et la transformation des Supporter l"automatisation des tâches de rafraichissement des données, des rapports Proposer et développer des solutions numériques afin de permettre le suivi des Participer aux initiatives en science des données (apprentissage machine, prévision, Diplôme universitaire en génie, en science informatique, en intelligence d"affaires ou en Diplôme universitaire de 2e cycle en intelligence d"affaires, en science des données, ou Idéalement 1 à 4 ans d"expérience, mais ouvert aux nouveaux diplômés Maîtrise du français et de l"anglais parlé et écrit Expérience de travail dans le secteur manufacturier ou aérospatial un atout Maîtrise de la suite Microsoft 365 Maîtrise avancée du logiciel Power BI Bonne compréhension des besoins d"affaires, des systèmes et des architectures dans un Expérience dans le développement et l"utilisation de modèles relationnels et Bonnes connaissances SQL (fonctions de fenêtre, requêtes imbriquées, tables Expérience de programmation dans un contexte d"analyse de données (ex. VBA, Python, Connaissances de base de SAP, PLM, Jupyter et HDFS un atout Connaissance de la méthodologie agile Connaissance des plateformes en gestion de projets et partage de codes (ex. Azure Le poste est présentement offert en télétravail. Un retour au bureau sera possible lorsque L"horaire de travail est flexible Une analyse de cas sera demandée aux candidats présélectionnés afin de valider les Develop reports and dashboards in compliance with Modify existing reports and dashboards to meet needs Perform tests and quality assurance of developments before implementation Ensure the performance of reports and dashboards developed Provide first level support for information products Work closely with information management teams to Liaise with the data warehouse team in order to specify the needs and Participate in the profiling of data from source systems Test extractions and queries to ensure data quality Create tables of facts, dimensions, and views that can be used in Create calculated fields directly in the databases to support Participate in governance discussions and workshops Propose and use the definitions and the business lexicon Ensure compliance and alignment of key performance indicators Collect business needs and those of customers and users Organize and lead working sessions in order to develop and propose Perform detailed needs analysis and write detailed specifications in order to Participate and lead meetings and project progress reviews with Analyze, map and map systems and business processes Create and support the implementation of a data architecture Propose the best possible solutions in order to achieve the objectives of the unit Propose relevant key performance indicators Write the documentation of information products in order to allow Support the deployment of the web portal for the distribution of the various reports and Set up a temporary structure for the processing and transformation of Support the automation of data refresh tasks, reports Propose and develop digital solutions to allow the monitoring of Participate in data science initiatives (machine learning, forecasting, University degree in engineering, computer science, business intelligence or 2nd year university diploma Ideally 1 to 4 years of experience, but open to new graduates Fluency in spoken and written French and English Work experience in the manufacturing or aerospace sector an asset Proficiency in the Microsoft 365 suite Advanced knowledge of Power BI software Good understanding of business needs, systems and architectures in a Good SQL knowledge (window functions, nested queries, tables Programming experience in a data analysis context (eg VBA, Python, Basic knowledge of SAP, PLM, Jupyter and HDFS an asset Knowledge of agile methodology Knowledge of project management and code sharing platforms (eg Azure The position is currently offered by telecommuting. A return to the office will be possible when The work schedule is flexible A case analysis will be requested from shortlisted candidates in order to validate the 
ScrapedJobID978:
Work on ROCm stack packaging solution for individual and enterprise level deployment on distributed cloud infrastructure Debug Machine Learning/ High Performance Computing related issues on Radeon Open Compute Stack (ROCm) Develop test contents for sophisticated Machine Learning algorithms on distributed nodes Port High Performance computing application on ROCm Reproduce field defects and develop appropriate tests to prevent future issues. Design, develop and deploy testing tools and automation libraries vital to perform testing. Be responsible for the adoption of tooling and industry standard methodologies by means of advocacy and outreach to help our development communities’ level up. Languages: Python, C, C++, Linux Shell scripting. Frameworks/Libraries: TensorFlow, PyTorch, ONNXRT Tools: Prior experience with Linux, Docker, LLVM compilers, GNU make /CMAKE, Jenkins, Git/Gerrit Understanding of High-Performance Computing application, Machine learning and GPU Programming, MPI Parallel Programming 
ScrapedJobID979:
Lead the team responsible for driving AI/ML adoption across Rogers Establish data science as a discipline and drive adoption of the data enablers across the organization Work across Rogers technology and business teams to further develop the AI/ML vision and strategy that outlines a target operating model and roadmap to maximize the value of information assets via their creation, access and use. Develop the technology, tools and enablers that will deliver the desired business outcomes. Establish frameworks and policies around use of AI/ML at Rogers, in particular ethics framework. Develop and deliver ML algorithms and data science approaches for the business Establish strategic industry partnerships to drive innovation Deliver ML Ops and guard rails for deployment to ensure consistent use of AI across Rogers and align to security and data standards Manage onboarding of talent, serve as a talent pipeline by establishing onboarding and skilling journeys Bachelor’s degree in Computer Science, Engineering, Data Science, Applied Mathematics or a related field Extensive experience working with data technologies, including pipelines, data lakes, data warehouse, analytics tools, machine learning, visualization and business intelligence Experience developing and deploying AI/ML models to address specific industry challenges Understanding of cloud, data, security and AI/ML and ML Ops with proven experience establishing strategy and frameworks to drive adoption and solid understanding of data security and privacy Collaborative by nature and comfortable running a COE model and shared services Experience developing business cases and strategy and an ability to drive strategy through to execution and operations Large program delivery experience, working across different teams and organization Proven leader with ability to motivate a team to achieve outstanding results Extraordinary team player that thrives in a fast-paced environment where quality, innovation, speed of decision making and execution are critical to organizational success Supports and strengthens the corporate brand and company culture Executive presence, with the ability to navigate difficult situations and build relationships via persuasive negotiator skills Brings a high degree of initiative, is able to work in an ever changing environment, and is able to manage ambiguity and relentless focus on prioritizing and balancing multiple stakeholder goals Our people are at the heart of our success Our customers come first. They inspire everything we do We do what’s right, each and every day We believe in the power of new ideas We work as one team, with one vision We give back to our communities and protect our environment 
ScrapedJobID980:
BS, MS in Computer Science, or related technical discipline 5+ year’s experience in the marketing technology space Strong working knowledge of cloud warehouses such as BigQuery Experience with Azure Strong data engineering skills with distributed computing background and proven experience in delivering large scale data platforms · Good grasp of analytics, measurement, reporting, and business intelligence including modeling, insights generation and data science Hands-on technologist with deep expertise in big data eco-system for data integration, data storage, compute framework, analytics, and advanced visualization. (i.e. ETL Tools, Streaming Tools, No-SQL data bases, Spark, Reporting Tools, AI/ML Platforms) Hands-on experience in GA360, CRM platforms (Salesforce), and /or Customer Data Platforms (e.g. Amperity), and /or user and product analytics (GA, Adobe), and /or DSP Experience with Power BI, Tableau, SQL, and data programming languages Python and/or R required Certifications for any of the cloud services like Azure or any Machine Learning/Advanced Analytics Courses is an asset 
ScrapedJobID981:
Experience with Python in production environments and a strong understanding of computer science fundamentals Experience designing experiments, A/B testing and data analysis in the domain of quality metrics for machine learning services Experience with designing and building metrics collection and data visualization Solid understanding of modern web applications architecture and development process Passion for decision making based on sound data analysis. A strong sense of ownership and a persistent desire to grow and lead beyond the scope of the current role Basic understanding of modern frontend development frameworks (e.g., Angular or React) REST-based API design, e.g., Flask or Django. Interest in or experience with machine learning methodologies and tools (e.g. Natural Language Processing (NLP), sklearn, pandas, numpy, keras, tensorflow, etc.) Exposure to large-scale data processing tools like Kafka, Spark, or Hadoop Exposure to cloud-computing technologies like AWS/GCP, Docker, Kubernetes etc. Experience using modern frontend development frameworks (e.g., Angular or React) 
ScrapedJobID982:
Operate as a thought leader and visionary, with the ability to guide, influence and inspire peak performance, innovation and adoption of AI-enabled technologies across the Axon value chain Grow and lead a world-class team of research scientists that deliver novel, strategic AI solutions with diverse, industry-leading skills in deep learning, computer vision, natural language processing and more Collaborate with tech and product teams on sourcing data and model building strategies from experimentation and implementation to deployment and continuous improvement Bring your industry, research expertise and deep knowledge of the state-of-the-art in your field to challenge existing assumptions and introduce new machine learning algorithms, statistical approachers and training workflows Develop a collaborative and inclusive team that fosters a culture of ownership, experimentation, and innovation while joining forces with product teams to deliver working solutions for our Customers A Ph.D. Degree in Computer Science, Machine Learning, Statistics, Applied Mathematics or an equivalent highly technical field 7+ years of modeling experience in one or more the following areas: Natural Language Processing/Understanding (NLP/NLU), Computer Vision (CV) and Acoustic Event Detection 4+ years in a leadership/management role; with a solid track record capable of building and leading science teams Hands on experience developing, scaling and implementing machine learning using relevant programming languages (such as Python), state of the art deep learning frameworks and big data tools Working knowledge of advanced ML techniques: Multi-task Learning, Transfer Learning, Reinforcement Learning as well as Unsupervised and Semi-supervised Learning Track record of publications and contributions to the machine learning community at large Experience with designing and shipping software products that leverage machine learning at scale Excellent problem solving skills and ability to dive into learning algorithms, evaluation metrics, model architecture, code, test plans, project plans, deployments and operations Comfort communicating and interacting with scientists, engineers and product managers as well as understanding and translating the science of AI and Machine Learning to a more general audience 9+ years of modeling experience in the areas of NLP, CV, Sensor Fusion and Acoustic Event Detection Demonstrated knowledge and experience with distributed machine learning and deploying models at scale in cloud environments (such as AWS, Microsoft Azure and Google Cloud) Familiarity with IoT/Edge AI and optimizing ML models to run on-device with constrained compute, power and latency budgets Previous Experience leading multiple geographically distributed teams Competitive salary and 401K with employer match Discretionary paid time off Robust parental leave policy An award-winning office/working environment Ride along with police officers to see them use our technology and get inspired And more... 
ScrapedJobID983:
Lead - Master’s degree in mathematics, computer science, engineering, physics, statistics, economics, computational sciences or a related quantitative discipline and 5+ years of analytical experience in an industrial or commercial setting OR PhD degree with at least 3+ years of industry experience DS- Master’s degree in mathematics, computer science, engineering, physics, statistics, economics, computational sciences or a related quantitative discipline and 3+ years of analytical experience in an industrial or commercial setting OR PhD degree with industry experience Experience AI/ML/NLP modelling of complex datasets. Advanced software development skills in at least two of the standard data

science languages (such as Python, R, Scala, C++, Julia) and strong data

manipulations skills (e.g. SQL, NoSQL, graph, etc.) Knowledge of SQL and relational databases, query authoring (SQL) and designing variety of databases (e.g. Postgres SQL) Comfortable working in cloud and high-performance compute environments (e.g. AWS, Apache Spark) Disciplined AI/ML deployment (MLOps, CI/CD) and Agile delivery Experience in coordination of delivery teams and providing feedback to their management Excellent written and verbal communication, business analysis, and consultancy skills Graph- Experience AI/ML modelling of complex datasets, network analysis or

direct experience in creating and maintaining graph data models. Experience

with a variety of graph technologies Knowledge of graph databases like Neo4J (Cypher, causal clusters), JanusGraph (Gremlin, GraphML), AWS Neptune, OrientDB. xpertise in machine learning/deep learning-based graph algorithms relevant to link prediction, ranking/recommendation, completion, community detection, node embedding, etc. Familiarity with Deep Learning, neural network architectures including CNNs,

RNNs, Embeddings, Transfer Learning, Attention-based Networks, Statistical

Learning, Restricted Boltzmann Machines (RBMs), Belief Networks, and

Reinforcement Learning Deep experience in developing models for private sector or industrial setting e.g. Lead data science area deliverables for digital products / programs / initiatives including the allocation of work within the team, monitors the quantitative and qualitative achievements of the team, and reports results Work as an individual contributor, providing data science expertise to digital

products / programs / initiatives. Apply in-depth experience with both statistical and modern data science

approaches, including unsupervised, supervised, regression algorithms. Apply advanced techniques such as neural networks, deep learning, NLP and federated learning. Build models, algorithms, simulations and experiments by writing highly

optimized code and using state-of-the art machine learning technologies. Collaborate cross-functionally in teams involved in data driven analytics to

maximize impact of graph-based capabilities Build and manage support models incorporated into digital or AI products; Work with Infrastructure and Ops teams to ensure appropriate architecture and tooling Capacity to mentor junior personnel Be able to apply in-depth experience with both statistical and modern data

science approaches to business cases and knowledge management tasks Strong written and verbal communication skills - ability to communicate complex ideas up to people of varying technical skills Work with developers, engineers, and MLOps to deliver AI/ML solutions for new products/services 
ScrapedJobID984:
Partner with internal stakeholders to define data requirements, build necessary data pipelines and perform analytics to extract insights contributing to CCG’s growth Build, validate, implement, and maintain statistical/ML models from ground-up to support monthly/quarterly forecasts as well as annual budgets while gathering inputs from the business and benchmarking it against relevant comparable Transform daily transactional data across the enterprise to determine critical performance indicators (KPIs and KRIs) by entity to track and evaluate achievement of daily/weekly/monthly targets Engage in Exploratory Data Analysis (EDA) with a focus on Descriptive, Predictive and Prescriptive Analytics through application of ML techniques to support Customer & Loyalty Analytics, Acquisition & Churn Prediction, Product Recommendation, etc Merge operational and financial data to create executive reporting dashboards highlighting the root-cause of variance between actual and expected financial results Support FP&A in conducting value-added reporting and financial analysis (e.g. revenue, expense and capital expenditures, return on equity, productivity, etc.) to provide the Board and Senior Management with a basis for measuring performance, financial position and making decisions Oversee the consolidation of the CCG month-end presentation to C-suite while working closely with various Business and Finance & Accounting functions to summarize conclusions, reasons and explanations for difference between forecasted and actual results Post-secondary degree in Mathematics, Computer Science, Finance or Economics (Masters would be considered an asset) 3-5 yrs. experience demonstrating hands-on experience in applying Data Science (Data Collection, Exploration and Visualization, and Experimentation and Prediction) coupled with strong knowledge of Financial Analysis concepts (financial modeling, profitability analysis, scenario analysis, business case development, etc.) Advanced Knowledge of SAP (BPC), SQL, Python (or R) along with commonly used ML Algorithms (Regression, Naive Bayes, SVM, Dimensionality Reduction, Ensemble, Clustering, etc.), frameworks and libraries to discover insights and trends from structured and unstructured datasets required Familiarity with data visualization tools reflective from experience in creating impactful dashboards using internal and external datasets (MS Power BI along with proficiency in DAX programming would be considered a strong asset) Naturally inquisitive mindset with a genuine interest in problem solving. Ability to self-initiate and bring forth complex issues to various audiences for business discussion Critical time-management skills and attention to detail, coupled with ability to work independently under tight deadlines with minimal supervision. Polished communication skills (oral and written) with an ability to present data-driven stories to management 
ScrapedJobID985:
Set up analytics configurations for new clients through the completion of analytics audits and evaluations Ensure the flow of data through various stages of our clients’ customer journeys Collaborate with the Marketing Strategy and Activation team to develop, execute, and analyze results for complex campaigns Utilize third-party tools including Adobe Analytics (Omniture/SiteCatalyst), Adobe Activation (Dynamic Tag Management), Adobe Launch, Adobe Target, Tableau, Google Marketing Platform and Google Tag Manager Guide the long-term vision and architecture for the data pipelines, data repositories, and data models required to provide high-scale and high-integrity solutions that meet the dynamic, complex data needs of Klick Assist in building and developing a team of talented Data Engineers, Marketing Analysts, and Data scientists Build relationships across Klick, working with Analytics and Data Science teams for insights and to ensure that data is accessible, readily available and usable for analysis Lead a continuous learning environment with respect to utilizing the latest methodologies, technologies, and illustrative best practices to tell stories which can drive business decisions Define approaches and lead projects that close data gaps and identify insights, as well as manage external partnerships and negotiate contracts with syndicated & custom insights suppliers Understand the contracted scope of work, proactively identifying potential out-of-scope activities and bringing to the attention of the project leader Work on business development efforts by providing ad-hoc feasibility reports, providing estimations of effort and developing methodologies that address client needs Provide selfless knowledge transfer and mentoring of junior team members. Potential for direct people management based on desire and prior experience Bachelor’s degree (Masters / PhD preferred) in statistics, information technology or computer science The candidate must have 8+ years of experience consulting clients on making strategic investment decisions to improve business results Senior resource must have strong functional understanding of current marketing analytics, adtech, martech and research techniques, as well as an innovative vision on how to keep pace with the ever changing marketing environment Strong client management/consultative experience both presenting and resolving issues. Extensive experience leading and managing marketing technology projects from ideation through installation Demonstrated experience with programmatic audience buying concepts and execution Applied quantitative skills and the ability to roll up sleeves and dig into the numbers when necessary Matrix leadership qualities will be required to lead external and internal resources into new marketing effectiveness territories Strong attention to detail, and ability to quality check their teams’ work to ensure that data anomalies/mistakes are caught prior to delivery of the analysis to the client teams Be outgoing and able to integrate with a fast-paced Media Planning, Strategy, Technology and Activation teams Ability to cultivate relationships with technology and research partners Ability to problem solve and develop innovative approaches along with a drive to learn and master new techniques and technologies Strong organization skills and ability to work on multiple tasks simultaneously while achieving quality standards and meeting deadlines with ambiguous requirements Excellent written and verbal communication skills. Strong interpersonal skills and ability to work collaboratively across teams Project management and/or team leadership experience preferred Consulting experience preferred Adobe Analytics Business Practitioner certification preferred Google Marketing Platform Certification(s) preferred Experience with people management, mentorship preferred 
ScrapedJobID986:
Develop the global business analytics strategy and action plan. Own the GFA Data and AI platform, define the data strategy and roadmap, drive platform integration with advisory assets, manage vendor data contracts and expansion of the platform to meet business needs. Establish and lead the global Analytics community of practitioners to drive adoption of data and analytics offerings within the practice, increase collaboration and sharing of analytics-oriented solutions on emerging client issues and best practices. Proactively engage with MF colleagues to communicate vision, create enthusiasm and followership, and assess progress related to analytics adoption. Supervise technology leads and product managers on the data platform expansion and predictive model development. Ensure development protocols and QRM policies are incorporated in the overall solution design. Lead discussions with DTTL procurement, Global Privacy, QRM, and vendors on data licenses, establish data governance, and access strategy in alignment with contracts. Collaborate with Deloitte Technology engagement and delivery leaders to articulate platform strategy and delivery approaches ensuring alignment and commitment. Build a dynamic team across delivery centers, member firms and Deloitte Technology to lead development and rollout of innovative analytics assets Facilitate discussions with stakeholders to ensure business needs and objectives are clearly understood and analytics solutions meet the expressed needs and expectations of the business. Communicate progress on a periodic basis to senior business leaders as requested. Build relationships and collaborate with peers and stakeholders across Global technology, MF business, and delivery centers. Bachelor’s or master’s degree in Computer Science, Information Systems or a related technical discipline. Certification in data science and cloud-based analytics technologies. 10+ years of related experience in leading analytics-oriented solutions. Experience in building and supporting a cloud hosted data platform for the business or service line, experience in advanced technologies including cloud analytics capabilities, AI, data science and engineering, NLP, NLG etc. Proficiency in business intelligence and data analytics tools including Tableau, Power BI, Alteryx, Azure Databricks, Azure Data Factory etc. Experience in software development methodologies such as SAFE, agile, etc. Ability to be a leader who is dynamic, proactive, and decisive, adapts well to change and ambiguity, has exceptional leadership and management skills to lead global virtual teams through influence Demonstrated proficiency in facilitating, delegating, and motivating cross functional groups or activities. Highly developed communications skills, motivational, team player, strategic and creative, excellent project management, and advanced MS Office skills. Able to communicate effectively in English with media and/or in front of large audiences; International experience preferred; important to have a strong network outside of home country through client engagements or roles. Willingness to travel internationally (2-4 times per year). Lead the way: Deloitte is not only leading the profession, but reinventing it for the future. We’re also committed to creating opportunity and leading the way to a more sustainable world. Serve with integrity: Deloitte has earned the trust of employees, clients, regulators, and the public for 175 years. Upholding that trust is our single most important responsibility. Take care of each other: We look out for one another and prioritize respect, fairness, development, and well-being. Foster inclusion: We are at our best when we foster an inclusive culture and embrace diversity in all forms. We know this attracts top talent, enables innovation, and helps us deliver well-rounded client solutions. Collaborate for measurable impact: We approach our work with a collaborative mind¬set, teaming across businesses, geographies, and skill sets to deliver tangible, measurable, attributable impact. 
ScrapedJobID987:
You'll play a pivotal part in informing and delivering upon our data strategy, by providing sales and marketing performance data, creating custom dashboards and visualization, and supporting marketing and financial strategies Providing Advance analytical insights to the team and help them improve marketing strategies Provide technical leadership to internal team members and various stakeholders Operationalize and support our underlying data systems, improving our system reliability, accuracy and stability You are analytical and outcome-oriented with a proven ability to translate technical considerations into business implications as well as to synthesize data into actionable insights You are well-versed with Business Intelligence/ Market Intelligence processes and other marketing technologies You have demonstrated the ability to successfully deliver complex projects involving people, process, technology, and change management You have experience with agile ways of working and a bias for action to break down barriers to get results fast with a test and learn mindset You can assemble large complex datasets across multiple databases and sources by building automated pipelines (ETL) Strong analytic skills related to working with unstructured datasets. Strong Business Acumen Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. SAS knowledge Business Intelligence/ Market Intelligence processes and other marketing technologies understanding Technical or data-driven educational background (computer science, engineering, statistics, data science) and/or Masters of Business Administration (MBA) degree 3+ years of progressive and relevant work experience Takes ownership, initiates improvements, and is self-directed Able to effectively engage stakeholders to establish cross functional alignment for projects Prior telecommunications expertise B2B marketing 
ScrapedJobID988:
Bonus pay Commission pay Casual dress Flexible schedule Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? or Are you willing to relocate? Yes 
ScrapedJobID989:
Leverage deep technology expertise for own area of specialization to deliver and ensure that all areas across the organization that provision, manage and support various technologies have the necessary tools, processes and documentation required to effectively execute on their respective mandates Execute on Engineering strategy as it relates to the introduction of tools and the automation of build, test, release and configure activities across Application, Platform and Infrastructure Partner with the Operations team to automatically integrate with appropriate tools and processes as part of automated/self-serve Application, Platform or Infrastructure releases Work with partners across Technology and apply in-depth understanding of relevant business needs to identify and leverage synergies across the various areas Act as the expert or lead innovator and agent of change for the programs and services under management Work with other teams to implement best practices for engineering and management Work with vendor platform providers and engineering peers to keep abreast of trends, products, frameworks, and applications Identify and effectively manage stakeholder engagement and impacts across the enterprise Interpret client needs, assess engineering related requirements and identify solutions to non-standard requests Apply best practices and knowledge of internal / external business issues to improve products or services in own discipline Monitor and control costs within own work May interact with governance and control groups, (e.g. regulatory / operational risk, compliance and audit) to provide subject matter expertise and consult on risk issues / items related to Engineering technology and tools May develop and/or contribute to negotiations of third party contracts/agreements Maintain knowledge and understanding of external development, engineering and emerging solutions, market conditions and their impact Proactively identify emerging technologies and innovative solutions for building more robust platform domains Implement complex data-centric solutions, including extremely complex and large data set verification, transformation and feature generation, to ensure continuous high-quality input for the model development Build model delivery systems, including inference pipeline, automatic model validation reports generation, automatic model performance monitoring and model retraining, to ensure fast model productionization and reliable production system Maintain the model in production and ensure the data/model related knowledge continuation within L6 Continuously enhance knowledge/expertise in own area and keep current with emerging industry trends, new technologies and best practices in the external market that can contribute to delivering effective client solutions Prioritize and manage own workload in order to deliver quality results and meet timelines Support a positive work environment that promotes service to the business, quality, innovation and teamwork and ensure timely communication of issues/ points of interest Participate in knowledge transfer with senior management, the team, other technical areas and business units Work effectively as a team, supporting other members of the team in achieving business objectives and providing client services Identify and recommend opportunities to enhance productivity, effectiveness and operational efficiency of the business unit and/or team Expert knowledge of specific domain or range of engineering frameworks, technology, tools, processes and procedures, as well as organization issues Expert knowledge of TD applications, systems, networks, innovation, design activities, best practices, business / organization, Bank standards, and may fulfill a governance role Expert knowledge and experience in own discipline; integrates knowledge of business and functional priorities Acts as a key contributor in a complex and critical environment May provide leadership to teams or projects; shares expertise Applies in-depth skills and broad knowledge of the business to address complex problems and non-standard situations Generally reports to a Senior Manager or above University or post-graduate degree Strong academic background (e.g., computer science, engineering) 7 + years relevant experience BSc+ in Computer Science, Math, Physics, or similar 2+ years of extensive programming experience, at least 1 year in building production data systems 1+ year experience of building machine learning production system Strong experience with major Big Data technologies and frameworks including but not limited to Hadoop, MapReduce, Spark, Cassandra, Kafka, Elasticsearch Good knowledge of Machine Learning and Deep Learning Practical expertise in performance tuning, bottleneck problems analysis, and troubleshooting Strong experience with Scala and Java 8 C++, Python experience Experience in systems/infrastructure projects on AWS and Azure Entrepreneurial and inclusive culture Excellent health coverage and pension plan Four weeks paid vacation Catered lunches twice a week over machine learning talks 
ScrapedJobID990:
We love books and all things beautiful We are Canada’s Cultural Department Store Books are our heart and our soul and Great Books are JUST the Beginning… We exist to add joy to our customers’ lives each and every time they interact with us and our products Our job is to create joyful moments for our customers We treat each other the way we’d treat a valued friend We inspire each other to do our best work We seek to ignite creativity and innovation every day We give back to the communities in which we operate Support the broader Indigo strategic pillars for the year with proactive customer insights Maintain a high level of strategic foresight by identifying customer and business needs Drive the broader data culture across Indigo and be a champion to drive business decisions through insights Manage day-to-day priorities for the analytics team, ensuring a high bar for quality and actionable insights for the organization Develop and deliver insights on all aspects of digital performance Build and develop Indigo’s customer language and ensure it is used throughout the business Build and share tools (i.e. customer dashboard) to provide self-serve access to data and insights throughout across the organization Support Indigo digital experimentation and personalization practice with design and measurement of AB tests Partner with Data Science team to deliver optimized digital marketing attribution and measurement Build excellent partnerships with leaders across Digital, Retail and Merchandising teams; empower them with the data and insights required for their roles Provide adhoc customer insights to support strategic business decisions Ensure the reporting, insights and visualization needs of the business are met Ensure customer data is collected, stored and used with integrity and in compliance with privacy and legislation As an experienced leader and analytics expert, prioritize coaching, development, and knowledge sharing across the CoP, learning from global best practice Manage departmental budget Ensure the completion of team deliverables and set/adhere to team budgets, as applicable Act as an advocate for the customer by placing them at the forefront of all design and decision-making processes Proactively identify and anticipate customer expectations and needs Embrace and seek out technology that creates high tech and high touch solutions for Indigo’s customers Challenge the status quo and consistently identify areas for improvement, diagnose issues and working to resolve them Build strong teams by attracting, retaining and developing the best talent Bring out the best in others, empower and constructively stretch talent Give authentic feedback on performance and potential Ensure all team members understand where they stand and have clear performance objectives aligned with Indigo and department goals Support the creation and maintenance of a talent succession plan Collaborate with others to drive flexible and iterative solutions, quickly and easily Share technical knowledge with others and actively seek to learn from those more knowledgeable than yourself Help others see the impacts of their efforts & proactively engage other functions to get input Encourage others to freely share their point of view and be open to feedback Accountable for the overall engagement, productivity, turnover and bench strength of the team Model Indigo’s beliefs and convey a positive image in everything you do Challenge the status quo by consistently identifying areas for improvement, diagnosing issues and working to resolve them Celebrate diversity of thought and have an open mindset Take an active role in fostering a culture of continual learning, taking risks without the fear of making mistakes Embrace, champion and influence change through your team and/or the organization University educated, preferably statistics, mathematics, engineering or computer science 5-7years of demonstrated experience in advanced customer analytics and digital analytics, across different digital platforms Experience in retail or consumer goods preferred Proven ability and experience leading teams to analyze customer data for actionable business insight Strong SQL skills for querying relational databases Solid experience using Adobe Analytics/Google Analytics Experience using and implementing visualization tools like Qlik, Tableau or Power BI is an asset Experience with common machine learning libraries in R, Python, Spark is an asset Strong critical thinking, analytical and problem-solving skills, and excellent attention to detail Strong balance between the science of analytics, and the creativity required to appropriately interpret business insights: skilled at turning complex analysis into simple conclusions and recommendations Solid understanding of databases and data structures and ability to work with large and complex technical data sets Technical analytics leadership: ability and desire to coach the team to build technical skills Strong critical thinking, analytical and problem-solving skills, and excellent attention to detail Outstanding communication skills – able to inform and inspire through visual, written, and oral communication Strong project management capability, ideally including experience building new CRM data environments The ability to collaborate with cross-functional teams and consider the business impact of decisions on diverse groups; influence others to achieve project goals Strong and timely decision-making abilities Demonstrated time management skills, including the ability to adhere to schedules and manage processes; the ability to organize and prioritize work to manage timelines and to meet defined deadlines in a fast-paced work environment Dedication to exceed performance expectations and approaches work with a sense of urgency and passion Highly customer centric approach to all initiatives Passionate about the Indigo brand 
ScrapedJobID991:
Provides advanced data science expertise to AstraZeneca projects and recommends data science solutions. Delivers advanced data science solutions to AstraZeneca projects, appropriately communicating with non-technical stakeholders. Works within established frameworks to deliver a variety of tasks that support projects in meeting their objectives. Independently keeps own knowledge up to date and learns from senior team members, proposing appropriate training courses for personal development. Reviews working practices and ensures non-compliant processes are escalated Ensures own work is compliant within Clinical Development. Collaborate in a multidisciplinary environment with world leading clinicians, data scientists, biological experts, statisticians and IT professionals. M.Sc. degree in rigorous quantitative science (such as mathematics, computer science, engineering) or have demonstrated an outstanding track-record of industry experience with the desired data science methodologies Practical software development skills in standard data science tools: Python, Agile, Code versioning (bitbucket/git), UNIX skills, familiarity working in cloud environment (AWS preferred) AWS or other cloud compute experience including SysOps (provisioning resources required for analytics, Kubernetes, infrastructure as code is a bonus) Data visualization & interactive data visualization (interactive dashboards w/ DASH & static visualization) Experience developing machine learning first products including timeseries analysis, forecasting, behavioral analysis Knowledge of range of mathematical and statistical modelling techniques and drive to continue to learn and develop these skills. Minimum 2+ years of industry experience or post-doctoral work. Ph.D. degree in rigorous quantitative science (such as mathematics, computer science, engineering) Experience within the pharmaceutical industry Advanced experience with Kubernetes and machine learning product architecture Communication, business analysis, and consultancy Advanced machine learning models: transformer-based NLP models, reinforcement learning, GNNs, state-of-the-art timeseries & forecasting models ML Ops experience: model tracking, model governance, multiple models in different production contexts Data visualization & interactive data visualization (interactive dashboards w/ DASH & static visualization) Our Social Media, Follow AstraZeneca on LinkedIn https://www.linkedin.com/company/1603/ Follow AstraZeneca on Facebook https://www.facebook.com/astrazenecacareers/ Follow AstraZeneca on Instagram https://www.instagram.com/astrazeneca_careers/?hl=en 
ScrapedJobID992:
real-time visibility on how Ubisoft titles are played; an understanding of the habits and preferences of the people playing them. Design, prototype, build and maintain APIs, tools, code and a scalable infrastructure for operating Merlin's machine learning pipeline at scale. Synch up with your team to discuss work-in-progress, ideas, and blockers; plan and prioritize; overcome issues; etc. Be a key member of the team, participate in the decisions and implementations to improve the platform’s quality. Work closely with Data Scientists to design and implement the optimal environment for their maximized efficiency. Advocate for automation and monitoring at all steps of the ML pipeline and help to define best practices based on personal industry experience and research. Stay current on technological advancements to help develop yourself, the platform and position Ubisoft as a leader of the domain. Experience in Software/Data engineering (or related experience). Experience with modern infrastructure, tools and cloud technology (e.g. AWS, EMR, Docker, Kubernetes, Terraform, etc.). Knowledge of Python, Java. Experience with big data technologies, like Kafka, S3, Spark, and Hive. Experience building and interacting with REST APIs. Familiar with GitLab and its CI/CD tool. A constant desire to grow and learn. Strong communication and collaboration skills. Ability to navigate between the big picture and the micro details. You love being responsible for owning and improving a new, fast-growing platform. You are curious and like asking questions until you fully understand why/what you are doing. A desire to see teammates succeed together. Experience with maintaining architectures for end-to-end Machine Learning in the cloud. Familiarity with industry standards such as MLFlow, Airflow... Knowledge of additional programming languages like Scala. Exposure to automated testing and CI/CD in the ML context. Good understanding of ML concepts. An understanding of the video game industry. Your CV, highlighting your background and skills 
ScrapedJobID993:
Experience with Python in production environments and a strong understanding of computer science fundamentals Experience designing experiments, A/B testing and data analysis in the domain of quality metrics for machine learning services Experience with designing and building metrics collection and data visualization Solid understanding of modern web applications architecture and development process Passion for decision making based on sound data analysis. A strong sense of ownership and a persistent desire to grow and lead beyond the scope of the current role Basic understanding of modern frontend development frameworks (e.g., Angular or React) REST-based API design, e.g., Flask or Django. Interest in or experience with machine learning methodologies and tools (e.g. Natural Language Processing (NLP), sklearn, pandas, numpy, keras, tensorflow, etc.) Exposure to large-scale data processing tools like Kafka, Spark, or Hadoop Exposure to cloud-computing technologies like AWS/GCP, Docker, Kubernetes etc. Experience using modern frontend development frameworks (e.g., Angular or React) 
ScrapedJobID994:
Provide the Data Intelligence and Governance team with data analyses from researching systems and processes, profiling data via SQL queries, and validating data quality requirements. Identify and partner with data stewardship across the organization to operationalize the Data Governance framework. Champion data governance initiatives by promoting ideas into action; including developing and implementing data quality rules, communication, and adoption strategy. Oversee data quality management and data quality issue prioritization. Assist in developing data governance policies, processes, and documentation. Support corporate data quality initiatives through recommendation for solutions and leadership around data validation. Analyze and understand corporate data across data domains, on both source and target levels. Collaborate with other data analysts from cross-functional teams to address data quality issues and educate data stewardship on data governance principles. Identify new opportunities for data governance continually. Coordinates with various stakeholders and leaders across business functions to apply established data governance framework (training and education, developing data stewardship, data custodian roles, data dictionary, definitions and documentation, approval, and sign-off protocols). Are proficient in data analysis (preferably within software development, data delivery, and data analytics settings). Have a post-secondary degree in Data Science, Computing, Mathematics or Healthcare Informatics (preferably master’s level). Have 5+ years of experience in data management or data governance Are highly knowledgeable in databases and adept in SQL. Have hands-on experience in data visualization tools such as PowerBI. Are experienced with CRM tools such as SalesForce and NetSuite. Are exceptional at rapport building and creative problem solving. Have strong organizational, planning, and prioritization skills. Are goal-oriented, positive, a self-starter, with strong analytical skills. Are a data detective with excellent communication, known for collaborating and your ability to communicate complex data findings to various audiences. Demonstrate a proven track record of delivering results while guiding and facilitating business partners in solving data quality issues. Able to work independently and manage multiple commitments and responsibilities 
ScrapedJobID995:
Designs, develops, and implements innovative analytical solutions. Designs and produces regular and ad-hoc reports, and dashboards. Builds reports and visualizations to effectively communicate data driven insights to users for a variety of audiences e.g. visualization solutions of data into reports, graphics, dashboards to illustrate facts, trends, and insights. Develops solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs. Supports development and execution of strategic analytics & reporting initiatives in collaboration with internal and external stakeholders. Analyzes data and information to provide subject-matter insights and recommendations. Develops tools and delivers training programs for use of reporting tools and self-serve analytics by non-analytical end users; may include delivery of training to audiences. Documents and maintain operational procedures and processes relating to analytical and reporting processes. Builds effective relationships with internal/external stakeholders. Collaborates with internal and external stakeholders in order to deliver on business objectives. Acts as a trusted advisor to assigned business/group. Leads the design, development, and implementation of analytic solutions. Recommends and implements solutions based on analysis of issues and implications for the business. Identifies emerging issues and trends to inform decision-making. Ensures alignment between stakeholders about business needs and data needs. Ensures alignment between stakeholders about business needs and data needs. Builds effective relationships with internal/external stakeholders. Breaks down strategic problems, and analyses data and information to provide subject matter insights and recommendations. Leads/participates in the design, implementation and management of new analytics & reporting solutions. Designs, develops, and implements innovative analytical solutions. Designs and produces regular and ad-hoc reports, and dashboards. Structures and assembles data into multi-dimensions with various granularities (e.g., demographics, customers, products, transactions). Monitors and tracks tool performance, user acceptance testing, and addresses any issues. Integrates information from multiple sources to enable more efficient processes, enhanced analysis and/or streamlined reporting. Cleanses, manipulates, and transforms data through programming / scripting for model training and validation. Automates validation tests to improve quality and efficiency of the validation process. Validates and tests models used in analytics and reporting to assess/address performance and compliance. Conducts various pre-implementation and postimplementation analyses to estimate/measure business impact caused by model adoption (e.g., revenue increase, cost reduction, corporate brand image). Promotes reporting automation, self-serve analytics consumption, and the culture of analytics driven decision making Typically between 5 - 7 years of relevant experience and postsecondary degree in related field of study or an equivalent combination of education and experience. Knowledge and experience in data preparation, data analysis, and statistical tool sets including but not limited to Spotfire, Power BI, SQL, SAS, R, Python - In-depth. Experience with distributed computing language (e.g. Hive / Hadoop/ Spark) & cloud technologies (e.g. AWS Sagemaker, AzureML) Deep knowledge and technical proficiency gained through extensive education and business experience. Verbal & written communication skills – In-depth. Collaboration & team skills - In-depth. Analytical and problem solving skills - In-depth. Influence skills - In-depth. Data driven decision making - In-depth. 
ScrapedJobID996:
Implementing, training, and optimizing models developed by our ML Science team Developing high-performance, scalable, and maintainable inference services that communicate with the rest of our tech stack Working with Infra teams to build data collection pipelines, manage data QA, and develop code for data visualization and data cleansing to build robust datasets Turning unfamiliar research code into bulletproof, production-ready software Working with edge hardware to test and tune the latency and performance of our services Building pipelines for continuous model improvement Experience with computer vision; experience developing and deploying deep learning algorithms; you’ve previously deployed machine learning models on scalable systems Strong grasp of statistical machine learning, linear algebra, and deep learning for computer vision Excellent C++11/14/17 and Python skills; familiarity with TensorFlow Ability to rapidly learn and work with unfamiliar code Understanding of CI/CD patterns and best practices Ability to write well-tested code Highly flexible and capable of working across the stack Great communication skills You love the idea of joining a fast growing series-A startup. You are proactive about solving problems and take initiative to build tools that will help everyone in the company. You love to thoughtfully help a team member or a customer in need. Innovation - We have an ambitious vision, and any change, especially the zealous kind, requires big ideas. Integrity - We trust each other, and that trust is the foundation on which our relationships both internally and externally are built. Continuous Improvement - We see everything as improvable, and work at finding ways to do so, and enjoy moving toward our goals. Accountability - Our teammates have intrinsic enjoyment in taking ownership and delivering on what they say they will. Customer Focus - We care the most about what benefits our customers and partners. 
ScrapedJobID997:
Perform and plan: (i) the programming, testing, and documentation of programs for use in creating statistical tables, figures and listing summaries, (ii) the programming of analysis databases (derived datasets) and transfers of data for internal and external clients. May perform and plan the programming of database quality control checks. Program the integration of databases from multiple studies or sources. Develop programming documentation including plans and specifications, as appropriate. Provide advanced technical expertise in conjunction with internal and external clients, and independently bring project solutions to teams and department. Perform and plan the development, implementation and validation of new process technologies, macros and applications. Fulfill project responsibilities at the level of statistical team lead for single studies, under supervision. Understand the Scope of Work, estimate the work completed, and manage Out of Scope for single studies. May manage budget and resource requirements and provide revenue and resource forecasts for single studies. May be required to understand budget and quote assumptions. Provide training and guidance to lower level and new staff. Typically requires 2 - 3 years of prior relevant experience. Requires intermediate level knowledge of principles, theories, and concepts of a job area, typically obtained through advanced education combined with experience. Knowledge of statistics, programming and/or clinical drug development process Working knowledge of computing applications such as Base SAS, SAS/STAT and SAS Macro Language Good organizational, interpersonal, leadership and communication skills Ability to effectively handle multiple tasks and projects Excellent accuracy and attention to detail Ability to establish and maintain effective working relationships with coworkers, managers and clients 
ScrapedJobID998:
We are building a state of the art platform to enable our network of data scientists and resellers to create hundreds of jupyter notebooks that can analyze immense amounts of data and produce real-time results to the user through customized dashboarding. Running thousands of notebooks at a time can be taxing on a system, so the magic we have running under the hood is what you and your team will own, operate, and iterate on. Improving and designing our SDK that lets developers create notebooks, visualizations and automation for their end-users. Python 3 (Tornado, Celery, Pandas) Java 8/11 (Spring Boot) Node.js (nest/graphql) Microservices hosted on AWS EKS, Fargate, Lambda Orchestration with AWS Step Functions & SNS/SQS AWS EMR (Presto, Spark, Hadoop) AWS Aurora, DynamoDB, S3 Angular 11 GitHub monorepo for our source code LucidChart for diagrams & collaboration JIRA to manage our backlog Our devs prefer to use IntelliJ (IDEA/PyCharm) We use GSuite (mail, drive, meet, docs, sheets, etc.) Slack Contribute to the codebase to help deliver product features on our roadmap Create prototypes and software design proposals based on product requirements Champion accepted proposals into production Facilitate technical design discussions within the team Research and break down large initiatives into iterative coding tasks Build upon our best practices and coding standards Participate in code reviews to ensure code quality Share knowledge, and provide mentorship to the team Automates the boring stuff. You take humans out of the equation where you can Thrives in ambiguity. With innovation, there is often no straight answer Driven by continuous innovation. You stay up to date with tech trends Action-oriented. When you see a problem you help solve it Transparent by nature. You are clear about the challenges you face Strengthened by peer feedback. You continuously grow and improve yourself Empathetic and lack an ego. You are team-oriented rather than a lone wolf A seeker of efficiency. You improve processes that help us work better, faster & smarter 
ScrapedJobID999:
Act as an HXM system administrator, advisor, subject matter expert and technical mentor for the PnC team and other Admin Users. Identify areas to improve systems processes, functionality and workflow while maximizing technological capabilities to reduce manual processes and create more effective use of the HXM and other PnC systems Provide technical insights, advice, and analysis on any PnC systems or software evaluations, reviewing vendor options, features, and modules and making recommendations on the best solutions Manage the implementation of new PnC systems and technologies, including documentation of current / future – state processes, coordination of stakeholders and tasks, data mining, testing and training, and other related project activities Facilitate a strong partnership between People and Culture and system user communities to increase usage and self-service, including leading training and education sessions or creating content for systems course development Respond to employee inquires/questions with a 'service-first' mindset Conduct business analysis to define, design, document, test, and deploy features that propose viable solutions or improved processes to achieve current state requirements as well as the ability to scale for future requirements Anticipates clients long term needs by establishing a clear sense of their organizational and business unit strategies. Delivers and provides additional information beyond client expectations. Provide data analysis, offer insights and identify trends to the business, including the senior leadership team Provide oversight on data governance, including systems and dashboard architecture and maintenance Build custom reporting and dashboards to respond to People and Culture team and business requests Accountable for high level of data integrity, auditing, and enforcing data validation processes within the HXM Design, map out and document new workflows and business processes with a 'Better, Smarter, Faster' mentality Manage upcoming system releases, testing and reviewing for possible issues and correcting any negative impacts Compile weekly/monthly/quarterly reporting packages and dashboards Manage time away from work balance and liability reporting Help project manage PnC's Employment Equity initiative and manage employee data collection in HXM, equity reports, and support any related Diversity & Inclusion activities and reporting analysis needs Communicates a clear vision for project initiatives and helps to translate vision into specific actions. Actively employs critical thinking towards anticipating trends in the external and internal environment by developing proactive plans to address or prevent future factors. Assist with regular operational reporting Document and maintain various processes Manage ad hoc People and Culture projects as requested 5-7 years of relevant experience working in a fast-paced, high-tech environment Experience administering and configuring an HRIS/HXM Experience with SharePoint, PowerBI (or Dashboard software), SQL and XML preferred Experience implementing an HXM an asset Advanced knowledge of Excel and proven ability to work with other MS Office tools Understands relational database concepts and can query and transform data dynamically using complex queries and scripting Strong analytical and problem-solving skills with an aptitude for working with data Excellent attention to detail; understands the importance of data integrity Excellent communication skills and ability to collaborate with and influence key stakeholder groups Proven ability to identify process efficiencies and drive continuous improvement initiatives Strength in organizing and coordinating multiple activities and projects at one time, while effectively managing disruptions and changing priorities Ability to independently exercise decision making authority over technical tasks and recommend system functionality to meet business requirements. Business acumen and curiosity Self-starter with proven initiative and a collaborative approach Flexible work hours Health and wellness programs Collaborative work environment Dog friendly office Snacks and food trays! Foosball and Ping-Pong tables Showers on site Centrally located in downtown, close to restaurants and pubs, easily accessible by public transit 
ScrapedJobID1000:
Consult with key stakeholders to understand requirements. Plan out work in an agile framework, taking part in internal daily scrum meetings and other agile activities as adopted by the team. Design, build and test solutions to customer problems in a robust manner. Build reports and/or dashboards to showcase results to stakeholders in the technology that is most accessible to them. Utilize advanced analytical techniques to build smart solutions to customer problems. Actively take part in and contributes to key customer facing meetings. Be a thought leader, understanding customer problems and proposing solutions that most effectively solve them. Keep up to date with best practices and continuously seeks to learn new skills. Validate new skill development through pursuit of relevant certifications. Contribute towards the growth of the business by observing opportunities for upselling or cross-selling within the customer organization. Contribute to development of the delivery team and their practice area through participating in internal TED talks, mentoring junior team-mates and developing reusable training materials and standard operating procedures. Contributes to the broader business through involvement in recruiting, marketing and sales activities. Contribute to the overall collaborative and innovative culture of the company by taking part in group events and spearheading initiatives that grow the company and help make life at ProCogia more enjoyable for all. Experience building computer vision and NLP models R or Python for Data Science Advanced Statistical Analysis Building and validating search, personalization, and recommendation algorithms Data Visualization Skills (Shiny and PowerBI preferred) Experience building Machine Learning and Deep Learning libraries Machine Learning Frameworks (SparkML preferred) SQL (Structured Query Language) Experience with Structured and Unstructured Data Git for Version Control Working with Command Line on Unix based systems Spark Experience (PySpark preferred) Cloud Experience (AWS and Snowflake preferred) Docker and Kubernetes experience SDLC (Software Development Life Cycle) experience AI (Artificial Intelligence) and Deep Learning experience Python, SQL, Hive, etc. Bachelors in a quantitative field with a deep understanding of mathematics, statistics, and computer science. Masters or PhD in a quantitative field with a deep understanding of mathematics, statistics, and computer science. An experienced professional will have at least 3 years of professional experience in a data related role with a Masters Degree or 5 years of experience in a data related role with a Bachelors degree. 
ScrapedJobID1001:
Provide a leadership role in the development and communication of Data Management strategies, principles, standards, and best practices. Develop and maintain both operational and data warehouse conceptual, logical, and physical data models. Partner with Business Analysts to gather business, data, and reporting requirements and translate the business needs into logical data structures. Act as an important contributor to the development and maintenance of IT strategies and plans. Experience with metadata management, data stewardship, data quality, IT governance, Enterprise Data Models, and Enterprise Frameworks. Direct team members on architecture concepts Business intelligence, query, and reporting tools Data Warehouse / Data Lake / MDM architecture principles Data integration and streaming integration concepts and architecture Database design for read-only access Data warehousing design issues such as star schema Data warehousing technologies such as OLAP (including ROLAP, MOLAP, and HOLAP) Data transformation and conversion Data quality issues Data formats for loading and unloading of data. Middleware Platform-specific workload management rules Data Partitioning Architecting for Mixed workload Data Modelling for Data Warehousing / Data Lakes (Denormalized – Star & Snowflake Schemas, Data Vault) Parallel execution Indexing and statistics strategies Build and maintain optimized reliable data pipelines that facilitate deeper analysis, additionally develop queries for ad hoc business projects, that translate raw data into powerful features and signals as well as ongoing reporting. Builds data processing frameworks that handle the business’s growing database and enrich big data with tertiary data at scale. Working with stakeholders in leveraging data with reporting and scientific tools while striving to continuously develop new and improved data engineering capabilities. Support and maintenance of existing big data infrastructure on Google BigQuery and develop processes and alert systems to monitor the health of the big data infrastructure (Java). Semantic modeling and modeling for parallel access (high concurrency access) Use SQL and Python to interact with big data infrastructure as needed for data engineering. Performing code reviews (SQL Stored Procedures, Python) Change Management: releasing code into Production environments using CI/CD processes Provide coaching and mentoring other developers on the team. University Degree or College Equivalent 10+ years IT experience in large scale technology architecture, operations, and design-related disciplines 8 – 10 + years of concrete programming experience in core Python/C# with Software Development Life Cycle 5+ years of SQL experience with large data sets (experience with Google BigQuery, Dockers, Kubernetes) is preferred Good to have - AWS (RedShift) Hands-on experience in writing complex, highly-optimized SQL queries across large data sets Deep understanding of object-oriented design principles Familiar with various design patterns, good component, and modeling ability Solid understanding and experience of any relational databases (SQL Server, PostgreSQL, etc.) Experience working with and developing Rest APIs. Experience working closely with data science teams to arrive at data infrastructure solutions that are optimized for scale. 4+ years in a Data Modeler or Data Architect role 3rd Normal Form and Dimensional modeling expertise Team player with excellent communication skills Facilitation and workshop coordination experience Business information requirement analysis experience Adept at balancing the immediate needs of a project with the future vision of the enterprise to achieve a win-win situation. Experience in Automotive and /or eCommerce Google BigQuery and AzureSQL Server experience an asset. ETL and data integration experience CA Erwin experience would be an asset. Solid understanding of Project Management and SDLC methodologies Advanced business analysis, architecture, and design skills Ability to communicate highly technical and complex security concepts effectively across all levels of the organization (both IT and business) 
ScrapedJobID1002:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID1003:
Dynamic personalization: Serve content, propose products, promote services, or execute actions Dynamic customer cohort creation: Determine cohorts of similar behavior or tuned to specific KPIs Scalable actions across segments of customers Usage-based/behavior-based pricing models: Insurance based on behavior Abnormality and fraud detection: Identify and prevent unauthorized activity Security and remediation: Detect issues and alert responders in exponentially less time than traditional security through intelligent analyses Network performance: Monitor and respond to network performance issues faster IoT analytics: Unify disparate data sources to reduce costs and improve performance IOT TCO: Reduces the cost of installation by reducing tuning and maintenance Architect, build, test, deploy distributed, scalable, and resilient Spark/Scala/Kafka Big Data processing, and Machine Learning model pipelines for batch, micro-batch, and streaming workloads sets into Cerebri AI’s proprietary data stores for use in machine learning modeling Develop and maintain data ontologies for key market segments Collaborate with data scientists to develop automated orchestration of model pipelines to solve Cerebri AI business use case objectives Collaborate with clients to develop pipeline infrastructure, and to ask appropriate questions to gain a deep understanding of client data Deploy fully containerized Docker/Kubernetes Data processing, and Machine Learning model pipelines into Azure, AWS, GCP cloud environments and on-premise systems as necessary Document Detailed Designs (including source to target mappings) and Code for Data Quality frameworks that can measure and maintain Data Completeness, Data Integrity, and Data Validity between interfacing systems Ensure all solutions comply with the highest levels of security, privacy, and data governance requirements as outlined by Cerebri and Client legal and information security guidelines, law enforcement, and privacy legislation, including data anonymization, encryption, and security in transit and at rest, etc. Train and mentor junior team members Acts as a Subject Matter Expert and a Thought Leader, continuously following industry trends, the latest competitive developments, and delivering papers and presentations at major industry conferences and events. A degree in Computer Science, Engineering, AI, Machine Learning, BI, MIS, or an equivalent technology field Minimum 2 years of Production programming experience in Scala, Spark, PySpark, Big Data, Python Minimum 2 years of Production experience with the Hadoop Big Data platform Able to program and understand data science and data engineering ideas in Python and translate into modular, functional components in Scala Streaming and micro-batch application development experience would be an asset, including Kafka, Storm, NiFi, Spark Streaming, Confluent or equivalent Proficiency with Linux/Unix operating systems, utilities, and tools Experience working directly with relational database structures and flat files Ability to write efficient database queries, functions, and views to include complex joins and the identification and development of custom indices Knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, continuous integration and development, and operations. Experience deploying containerized Docker/Kubernetes applications Experience with Microsoft Azure or similar cloud computing solutions Big Data application architecture experience and in-depth understanding of the Big Data ecosystem, applications, services, and design patterns Production systems integration experience Good verbal and written communication skills, with both technical and non-technical stakeholders Experience in business intelligence visualization tools such as Grafana, Superset, Redash or Tableau. Master’s degree or higher in a relevant quantitative subject Experience with the Atlassian suite (JIRA, Confluence, BitBucket). Any other related experience with Big Data, artificial intelligence, natural language processing, machine learning and/or deep learning, predictive analytics Familiar with automated machine learning (AutoML) concepts would be an asset Experience with Breeze would be an asset 
ScrapedJobID1004:

ScrapedJobID1005:
Deploy machine learning solutions to improve Skype/Teams real-time collaboration quality and reliability Design, develop, and own components, tools, platforms, and systems for real-time media communication and collaboration. Drive independent investigations resulting in shipping product code, patents, and publications. Ph.D. in Computer Science, Mathematics, Physics, Electrical Engineering, or Masters plus equivalent work experience Minimum 7 year experience in professional software development 3+ years C/C++ coding, design and testing in a production environment Comfortable with Python or other scripting for rapid prototyping. Minimum of 1 years of experience in machine learning using tools like TensorFlow/Pytorch/Scikit-learn, etc. Strong system development skills, with a long-range system view that leverages development ranging from rapid research prototypes to carefully architected complex systems Excellent inter-personal skills and ability to work well in a scrum team. Experience developing and testing code in large codebases Experience developing production applications for the edge/IoT is a strong plus 
ScrapedJobID1006:
Lead the team responsible for driving AI/ML adoption across Rogers Establish data science as a discipline and drive adoption of the data enablers across the organization Work across Rogers technology and business teams to further develop the AI/ML vision and strategy that outlines a target operating model and roadmap to maximize the value of information assets via their creation, access and use. Develop the technology, tools and enablers that will deliver the desired business outcomes. Establish frameworks and policies around use of AI/ML at Rogers, in particular ethics framework. Develop and deliver ML algorithms and data science approaches for the business Establish strategic industry partnerships to drive innovation Deliver ML Ops and guard rails for deployment to ensure consistent use of AI across Rogers and align to security and data standards Manage onboarding of talent, serve as a talent pipeline by establishing onboarding and skilling journeys Bachelor’s degree in Computer Science, Engineering, Data Science, Applied Mathematics or a related field Extensive experience working with data technologies, including pipelines, data lakes, data warehouse, analytics tools, machine learning, visualization and business intelligence Experience developing and deploying AI/ML models to address specific industry challenges Understanding of cloud, data, security and AI/ML and ML Ops with proven experience establishing strategy and frameworks to drive adoption and solid understanding of data security and privacy Collaborative by nature and comfortable running a COE model and shared services Experience developing business cases and strategy and an ability to drive strategy through to execution and operations Large program delivery experience, working across different teams and organization Proven leader with ability to motivate a team to achieve outstanding results Extraordinary team player that thrives in a fast-paced environment where quality, innovation, speed of decision making and execution are critical to organizational success Supports and strengthens the corporate brand and company culture Executive presence, with the ability to navigate difficult situations and build relationships via persuasive negotiator skills Brings a high degree of initiative, is able to work in an ever changing environment, and is able to manage ambiguity and relentless focus on prioritizing and balancing multiple stakeholder goals Our people are at the heart of our success Our customers come first. They inspire everything we do We do what’s right, each and every day We believe in the power of new ideas We work as one team, with one vision We give back to our communities and protect our environment 
ScrapedJobID1007:
Work on ROCm stack packaging solution for individual and enterprise level deployment on distributed cloud infrastructure Debug Machine Learning/ High Performance Computing related issues on Radeon Open Compute Stack (ROCm) Develop test contents for sophisticated Machine Learning algorithms on distributed nodes Port High Performance computing application on ROCm Reproduce field defects and develop appropriate tests to prevent future issues. Design, develop and deploy testing tools and automation libraries vital to perform testing. Be responsible for the adoption of tooling and industry standard methodologies by means of advocacy and outreach to help our development communities’ level up. Languages: Python, C, C++, Linux Shell scripting. Frameworks/Libraries: TensorFlow, PyTorch, ONNXRT Tools: Prior experience with Linux, Docker, LLVM compilers, GNU make /CMAKE, Jenkins, Git/Gerrit Understanding of High-Performance Computing application, Machine learning and GPU Programming, MPI Parallel Programming 
ScrapedJobID1008:
Creation and optimization of advanced analytics tools and regular reporting of insights derived from them to internal and external audiences, including senior leadership Uncover long-term opportunities based on research and analysis of our store performance to create actionable strategic insights Drive companywide efficiencies through standardization of systems, processes and analytics frameworks Major stakeholder in companywide development execution system rollout implementing process improvements and new analytical frameworks Build strong working relationships and influence cross-functional teams, including but not limited to; Regional Development Teams, IT, FP&A, Global Business Services (GBS) Develops and delivers presentations both internally and externally to executive level leadership Bachelors or Master's degree in the fields of Business, Economics, Data Science or equivalent field required 5+ years relevant work experience, 2+ year's experience working in analytics, project management and/or FP&A experience preferred Strong understanding of the fundamentals of statistical modelling, data science and analytics Advanced analytical skillset with ability to transform data into action plans, advanced proficiency excel modeling and super user of data visualization software (Smartsheet, Power BI, VBA, etc.) Experience collaborating with cross-functional teams (Technology, Finance, Business Development) to drive results/projects demonstrating effective communication, influencing and organizational skills Start-up mentality with ability to perform under pressure and adapt to a fast-paced environment working with a lean team Honesty, high integrity, personal accountability, ownership mentality and a passion for the success of the company, the team, and personal career growth Knowledge in one or more general-purpose programming languages (SQL, Python, Java, etc.) 
ScrapedJobID1009:

ScrapedJobID1010:
Lead - Master’s degree in mathematics, computer science, engineering, physics, statistics, economics, computational sciences or a related quantitative discipline and 5+ years of analytical experience in an industrial or commercial setting OR PhD degree with at least 3+ years of industry experience DS- Master’s degree in mathematics, computer science, engineering, physics, statistics, economics, computational sciences or a related quantitative discipline and 3+ years of analytical experience in an industrial or commercial setting OR PhD degree with industry experience Experience AI/ML/NLP modelling of complex datasets. Advanced software development skills in at least two of the standard data

science languages (such as Python, R, Scala, C++, Julia) and strong data

manipulations skills (e.g. SQL, NoSQL, graph, etc.) Knowledge of SQL and relational databases, query authoring (SQL) and designing variety of databases (e.g. Postgres SQL) Comfortable working in cloud and high-performance compute environments (e.g. AWS, Apache Spark) Disciplined AI/ML deployment (MLOps, CI/CD) and Agile delivery Experience in coordination of delivery teams and providing feedback to their management Excellent written and verbal communication, business analysis, and consultancy skills Graph- Experience AI/ML modelling of complex datasets, network analysis or

direct experience in creating and maintaining graph data models. Experience

with a variety of graph technologies Knowledge of graph databases like Neo4J (Cypher, causal clusters), JanusGraph (Gremlin, GraphML), AWS Neptune, OrientDB. xpertise in machine learning/deep learning-based graph algorithms relevant to link prediction, ranking/recommendation, completion, community detection, node embedding, etc. Familiarity with Deep Learning, neural network architectures including CNNs,

RNNs, Embeddings, Transfer Learning, Attention-based Networks, Statistical

Learning, Restricted Boltzmann Machines (RBMs), Belief Networks, and

Reinforcement Learning Deep experience in developing models for private sector or industrial setting e.g. Lead data science area deliverables for digital products / programs / initiatives including the allocation of work within the team, monitors the quantitative and qualitative achievements of the team, and reports results Work as an individual contributor, providing data science expertise to digital

products / programs / initiatives. Apply in-depth experience with both statistical and modern data science

approaches, including unsupervised, supervised, regression algorithms. Apply advanced techniques such as neural networks, deep learning, NLP and federated learning. Build models, algorithms, simulations and experiments by writing highly

optimized code and using state-of-the art machine learning technologies. Collaborate cross-functionally in teams involved in data driven analytics to

maximize impact of graph-based capabilities Build and manage support models incorporated into digital or AI products; Work with Infrastructure and Ops teams to ensure appropriate architecture and tooling Capacity to mentor junior personnel Be able to apply in-depth experience with both statistical and modern data

science approaches to business cases and knowledge management tasks Strong written and verbal communication skills - ability to communicate complex ideas up to people of varying technical skills Work with developers, engineers, and MLOps to deliver AI/ML solutions for new products/services 
ScrapedJobID1011:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID1012:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1013:
Develop the global business analytics strategy and action plan. Own the GFA Data and AI platform, define the data strategy and roadmap, drive platform integration with advisory assets, manage vendor data contracts and expansion of the platform to meet business needs. Establish and lead the global Analytics community of practitioners to drive adoption of data and analytics offerings within the practice, increase collaboration and sharing of analytics-oriented solutions on emerging client issues and best practices. Proactively engage with MF colleagues to communicate vision, create enthusiasm and followership, and assess progress related to analytics adoption. Supervise technology leads and product managers on the data platform expansion and predictive model development. Ensure development protocols and QRM policies are incorporated in the overall solution design. Lead discussions with DTTL procurement, Global Privacy, QRM, and vendors on data licenses, establish data governance, and access strategy in alignment with contracts. Collaborate with Deloitte Technology engagement and delivery leaders to articulate platform strategy and delivery approaches ensuring alignment and commitment. Build a dynamic team across delivery centers, member firms and Deloitte Technology to lead development and rollout of innovative analytics assets Facilitate discussions with stakeholders to ensure business needs and objectives are clearly understood and analytics solutions meet the expressed needs and expectations of the business. Communicate progress on a periodic basis to senior business leaders as requested. Build relationships and collaborate with peers and stakeholders across Global technology, MF business, and delivery centers. Bachelor’s or master’s degree in Computer Science, Information Systems or a related technical discipline. Certification in data science and cloud-based analytics technologies. 10+ years of related experience in leading analytics-oriented solutions. Experience in building and supporting a cloud hosted data platform for the business or service line, experience in advanced technologies including cloud analytics capabilities, AI, data science and engineering, NLP, NLG etc. Proficiency in business intelligence and data analytics tools including Tableau, Power BI, Alteryx, Azure Databricks, Azure Data Factory etc. Experience in software development methodologies such as SAFE, agile, etc. Ability to be a leader who is dynamic, proactive, and decisive, adapts well to change and ambiguity, has exceptional leadership and management skills to lead global virtual teams through influence Demonstrated proficiency in facilitating, delegating, and motivating cross functional groups or activities. Highly developed communications skills, motivational, team player, strategic and creative, excellent project management, and advanced MS Office skills. Able to communicate effectively in English with media and/or in front of large audiences; International experience preferred; important to have a strong network outside of home country through client engagements or roles. Willingness to travel internationally (2-4 times per year). Lead the way: Deloitte is not only leading the profession, but reinventing it for the future. We’re also committed to creating opportunity and leading the way to a more sustainable world. Serve with integrity: Deloitte has earned the trust of employees, clients, regulators, and the public for 175 years. Upholding that trust is our single most important responsibility. Take care of each other: We look out for one another and prioritize respect, fairness, development, and well-being. Foster inclusion: We are at our best when we foster an inclusive culture and embrace diversity in all forms. We know this attracts top talent, enables innovation, and helps us deliver well-rounded client solutions. Collaborate for measurable impact: We approach our work with a collaborative mind¬set, teaming across businesses, geographies, and skill sets to deliver tangible, measurable, attributable impact. 
ScrapedJobID1014:
Recognized as a technical leader with an innate ability to develop and motivate team members, as well as positively influence change Passion for data and new technologies Acknowledged for your strong general knowledge of the overall data analysis technology ecosystem Known for your deep specific knowledge in one or two specific data analysis technology stacks Confident in the use of Agile, iterative, Lean product lifecycles Commended for your ability to communicate clearly and collaborate with a broad array of stakeholders at all levels Knack for collaboration, openly contributing ideas within a highly cross-functional team Willingness to do both Development and Operations Confident with your ability to articulate an end-to-end customer experience Skilled in assessing and articulating the financial impact of a customer experience Senior level experience of 5+ years’ within the industry Have a Bachelor's degree in Engineering or Computer Science Database bingo: SQL; noSQL; Hadoop; Oracle; MongoDB; ETL bingo: ELK; DOMO; Tableau; Splunk; Programming bingo: JAVA; Python; UNIX; Selenium; Cucumber; Process bingo: Agile; Scrum; Kanban Other tools: Slack; Assembla; Google Suite; Telecom knowledge Reconnu comme un leader technique avec une capacité innée à développer et motiver les membres de l'équipe, ainsi qu'à influencer positivement le changement Passion pour les données et les nouvelles technologies Reconnu pour votre solide connaissance générale de l'écosystème technologique global d'analyse des données Connu pour vos connaissances spécifiques approfondies dans une ou deux piles technologiques spécifiques d'analyse de données Confiant dans l'utilisation des cycles de vie des produits Agiles, itératifs et Lean Félicité pour votre capacité à communiquer clairement et à collaborer avec un large éventail de parties prenantes à tous les niveaux Savoir travailler en collaboration, apporter ouvertement des idées au sein d'une équipe hautement interfonctionnelle Volonté de faire du développement et des opérations Confiant dans votre capacité à articuler une expérience client de bout en bout Habile à évaluer et à articuler l'impact financier d'une expérience client Expérience de niveau supérieur de 5 ans et plus dans l'industrie Détenir un baccalauréat en génie ou en informatique Bingo de base de données: SQL; noSQL; Hadoop; Oracle; MongoDB; Bingo ETL: ELK; DOMO; Tableau; Splunk; Programmation du bingo: JAVA; Python; UNIX; Sélénium; Concombre; Processus de bingo: Agile; Scrum; Kanban Autres outils: mou; Assembla; Google Suite; Connaissance des télécoms 8 hour shift Data Scientist: 5 years (preferred) Python: 5 years (preferred) Jupiter: 3 years (preferred) Machine learning: 4 years (preferred) Temporarily due to COVID-19 
ScrapedJobID1015:
real-time visibility on how Ubisoft titles are played; an understanding of the habits and preferences of the people playing them. Design, prototype, build and maintain APIs, tools, code and a scalable infrastructure for operating Merlin's machine learning pipeline at scale. Synch up with your team to discuss work-in-progress, ideas, and blockers; plan and prioritize; overcome issues; etc. Be a key member of the team, participate in the decisions and implementations to improve the platform’s quality. Work closely with Data Scientists to design and implement the optimal environment for their maximized efficiency. Advocate for automation and monitoring at all steps of the ML pipeline and help to define best practices based on personal industry experience and research. Stay current on technological advancements to help develop yourself, the platform and position Ubisoft as a leader of the domain. Experience in Software/Data engineering (or related experience). Experience with modern infrastructure, tools and cloud technology (e.g. AWS, EMR, Docker, Kubernetes, Terraform, etc.). Knowledge of Python, Java. Experience with big data technologies, like Kafka, S3, Spark, and Hive. Experience building and interacting with REST APIs. Familiar with GitLab and its CI/CD tool. A constant desire to grow and learn. Strong communication and collaboration skills. Ability to navigate between the big picture and the micro details. You love being responsible for owning and improving a new, fast-growing platform. You are curious and like asking questions until you fully understand why/what you are doing. A desire to see teammates succeed together. Experience with maintaining architectures for end-to-end Machine Learning in the cloud. Familiarity with industry standards such as MLFlow, Airflow... Knowledge of additional programming languages like Scala. Exposure to automated testing and CI/CD in the ML context. Good understanding of ML concepts. An understanding of the video game industry. Your CV, highlighting your background and skills 
ScrapedJobID1016:
BS, MS in Computer Science, or related technical discipline 5+ year’s experience in the marketing technology space Strong working knowledge of cloud warehouses such as BigQuery Experience with Azure Strong data engineering skills with distributed computing background and proven experience in delivering large scale data platforms · Good grasp of analytics, measurement, reporting, and business intelligence including modeling, insights generation and data science Hands-on technologist with deep expertise in big data eco-system for data integration, data storage, compute framework, analytics, and advanced visualization. (i.e. ETL Tools, Streaming Tools, No-SQL data bases, Spark, Reporting Tools, AI/ML Platforms) Hands-on experience in GA360, CRM platforms (Salesforce), and /or Customer Data Platforms (e.g. Amperity), and /or user and product analytics (GA, Adobe), and /or DSP Experience with Power BI, Tableau, SQL, and data programming languages Python and/or R required Certifications for any of the cloud services like Azure or any Machine Learning/Advanced Analytics Courses is an asset 
ScrapedJobID1017:
Problem Solver: You are curious and love exploring multiple approaches to find the most efficient, scalable solution and solve a problem Collaborative: You work well with other people Passionate: You have a passion for Big Data and an interest in the latest trends and developments constantly researching new tools and data technologies Self-starter: You are comfortable helping your team get things done Leadership: You can mentor the team on the design, and implementation of our solutions Design, implement, and create customized pipelines for ingestion that are robust using Kafka. Work with Terabytes of data and data aggregation. Identify, design, and implement system performance improvements Identify, design, and implement internal process improvements Automate manual processes and optimize data delivery Guide and mentor team members Identify and assess potential solutions for technical and business suitability Bachelor/Master degree in Data Science, Computer Science, Computer/Electrical Engineering or related field 7+ years of work experience in a software engineering environment Experience working in Agile methodologies 3+ years of work experience designing and building high performance data applications with Hadoop, Spark, Kafka, Hive or other equivalent technologies Proficiency in some of the following languages: Scala, Java, Python, Bash Deep understanding of design principles of distributed systems and familiar with mainstream big data related technologies and distributed frameworks Experience with SQL and NoSQL systems Experience with automated testing systems Mentorship, collaboration, and communication skills Knowledge of data modelling, data warehousing, ETL processes, and business intelligence reporting tools Experience optimizing performance with large data sets Experience working with CI/CD, containerization, and virtualization tools such as Gitlab, Jenkins, Kubernetes, Docker Comprehensive health, dental, and vision plans at no cost to you Time off and flexible work schedules Retirement plan with a 5% company match Stock options and equity packages Generous parental leave Monthly wellness stipend plus fitness discounts and quarterly wellness group activities Home office stipend Community engagement opportunities and donation-matching program Annual virtual company retreats and regular community-led team events COVID-19 guidance: We have re-opened offices in various cities following local guidelines, but are continuing to maintain a flexible work environment. 
ScrapedJobID1018:
Design and build large and complex data sets, from spurious sources while thinking strategically about uses of data and how data use interacts with data design. Design and implement statistical data quality procedures for new data sources. Communicate findings to business leaders in a way that can influence how an organization approaches a business challenge Develop algorithms/software for accessing and handling data appropriately. Implement and hand off data checking and updating procedures to teams. Visualize and report data findings creatively in a variety of visual formats that appropriately provides insights to the organization. Train others on what data is available and how to use various sources Previous Telecommunications data analysis experience is an asset; emphasis on location data and time series analytics Master’s Degree (or higher) in Computer Science, Statistics, Applied Math, Engineering or other quantitative field; With a solid foundation in modeling, statistics, analytics and math Minimum of 5 years of hands-on data analytics experience in a corporate environment; Comfortable working with large, complex data sets from varying sources; Experience in team leadership. Highly motivated with the ability to work on a multiple projects simultaneously; Team player, creative, entrepreneurial, willing to experiment, persistent and structured. Working with structured and unstructured data sets;
Leading analytics projects to support the strategic product direction, sales and customer efforts;
Performing hypothesis testing and develop predictive model;
Evaluating and providing input on potential business intelligence solutions.
Applying statistical principles to data analytics;
Comfortable in statistical analysis, clustering and data mining techniques to identify trends and insights
Developing end-end to models/ projects and automation in production environment. Leading analytics projects to support the strategic product direction, sales and customer efforts; Performing hypothesis testing and develop predictive model; Evaluating and providing input on potential business intelligence solutions. Applying statistical principles to data analytics; Comfortable in statistical analysis, clustering and data mining techniques to identify trends and insights Developing end-end to models/ projects and automation in production environment. Thorough understanding of relational database design; High proficiency in SQL. Fluent programming in Python, Hive, or SAS Extensive experience in Google Cloud Platform, BigQuery, JupyterLab, docker container and workspace set up. Knowledgeable about common supervised and unsupervised Machine Learning approaches (eg. feature engineering, classification, regression, clustering, NLP, time series forecasting, etc. "Tensorflow”, “Deep Learning” and synthetic tabular data generation is a strong asset. 
ScrapedJobID1019:
Square Enix Montréal est à la recherche d’un·e Analyste en chef, passionné·e par les jeux et l’expérience utilisateur, pour prendre en charge l’activité analytique sur l’un des jeux mobiles en cours de développement au sein de la division mobile de Square Enix West. Rôle de leadership au sein de l'équipe de production : porter et déployer la vision BI et analytique au sein du projet, participer à l'amélioration continue des processus décisionnels, éduquer les équipes de productions et de marketing sur ce qu’il est possible de faire au niveau analytique et data science. Manager un·e Data Analyst Junior déjà en place : coordonner les tâches et priorités coté BI en interaction avec l’équipe du jeu (Product Manager, Game Designer, etc); Participer à la mise en place de bonnes pratiques et à la création de processus et produits transverse à l’ensemble des équipes BI en production Définir les spécifications de la collecte d'information et apporter du support aux programmeurs lors de l'implémentation du système de collecte de données; Participer au processus de vérification de qualité des données en collaboration avec l'équipe QA; Créer des modèles analytiques, tableaux de bord et rapports d'analyse personnalisés; Présenter, sous forme de storytelling, les insights générés au travers des analyses, à tout type d'audience; Fournir des recommandations opérationnelles en termes de design et de monétisation; Diplôme universitaire en statistiques, mathématiques, génie informatique, génie logiciel ou l’équivalent; 5+ années d’expérience en tant qu’analyste de données, idéalement en partie dans le domaine du jeu mobile; Maitrise du SQL, Python est un plus; Maitrise du Data Mining et des statistiques; Excellente maitrise de l’analyse de données et de la génération d’insights impactants; Maitrise d’outils de Reporting (Looker, Tableau, PowerBI, Amplitude ou équivalent); Maitrise des systèmes de collection de données de type Events; Bonne connaissance des systèmes de base de données dans le cloud BigQuery, Snowflake, Redshift ou équivalent; Expérience en coaching et mentoring est un plus; Connaissance des plateformes analytiques comme Amplitude, deltaDNA, Mixpanel etc. est un plus. Capacité à résoudre des problèmes complexes; Grande habileté pour expliquer des phénomènes complexes de façon claire et complexe à tout type d’audience (anglais et français) Rigoureux et précis; Axé sur l’impact opérationnel, débrouillard et capable de prendre de l’initiative; Être capable de s’adapter dans un environnement où les priorités peuvent changer régulièrement; De l’ambition et de la passion pour les jeux vidéo mobiles sont essentielles! Square Enix Montréal is looking for a Lead Data Analyst, passionate about games and user experience, to take charge of the analytical activity on one of the mobile games under development within the mobile division of Square Enix West. Leadership role within the production team: carry and deploy the BI and analytical vision within the project, participate in the continuous improvement of decision-making processes, educate the production and marketing teams on what is possible to do at the analytical and data science level. Manage a junior data analyst already in place: coordinate tasks and priorities on the BI side in interaction with the game team (product manager, game designers, etc.); Participate in the implementation of best practices and the creation of processes and products across all BI teams in production Define the specifications of the information collection and provide support to programmers during the implementation of the data collection system; Participate in the data quality verification process in collaboration with the QA team; Create analytical models, dashboards and personalized analysis reports; Present, in the form of storytelling, the insights generated through analyzes, to any type of audience; Provide operational recommendations in terms of design and monetization; University degree in statistics, mathematics, computer engineering, software engineering or equivalent; 5+ years of experience as a data analyst, ideally partly in the field of mobile gaming; Proficiency in SQL, Python is a plus; Mastery of Data Mining and statistics; Excellent knowledge of data analysis and the generation of impactful insights; Proficiency in reporting tools (Looker, Table, PowerBI, Amplitude or equivalent); Mastery of Events type data collection systems; Good knowledge of BigQuery, Snowflake, Redshift or equivalent cloud database systems; Coaching and mentoring experience is a plus; Knowledge of analytical platforms such as Amplitude, deltaDNA, Mixpanel etc. is a plus. Ability to solve complex problems; Great ability to explain complex phenomena in a clear and complex manner to any type of audience (English and French) Rigorous and precise; Operational impact oriented, resourceful and able to take initiative; Be able to adapt in an environment where priorities can change regularly; Ambition and passion for mobile video games are essential! 
ScrapedJobID1020:
Bonus pay Commission pay Casual dress Flexible schedule Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? or Are you willing to relocate? Yes 
ScrapedJobID1021:
Design, development and evaluation of highly innovative models Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation Work closely with software engineering teams to drive real-time model implementations and new feature creations Analyze internal behavior tracking data and forecast Wish demand Implement the strategies and set up A/B test experiments to gauge the impact, and reiterate Propose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process Create & own dashboards and analytical reports to track progress & share learnings Bachelor's or advanced degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics or similar) 3+ years of hands-on experience in predictive modeling and analysis 3+ years experience writing complex SQL queries in a business environment 2+ years in Python A/B test experience Experience collaborating with business & eng teams Analytical mindset and ability to see the big picture and influence others Detail-oriented and must have an aptitude for solving unstructured problems Ability to work effectively in a multi-task, high volume environment Ability to be adaptable and flexible in responding to deadlines and workflow fluctuations Experience operating in a Unix/Linux environment Strong presentation skills 
ScrapedJobID1022:

ScrapedJobID1023:
Consult with key stakeholders to understand requirements. Plan out work in an agile framework, taking part in internal daily scrum meetings and other agile activities as adopted by the team. Design, build and test solutions to customer problems in a robust manner. Build reports and/or dashboards to showcase results to stakeholders in the technology that is most accessible to them. Utilize advanced analytical techniques to build smart solutions to customer problems. Actively take part in and contributes to key customer facing meetings. Be a thought leader, understanding customer problems and proposing solutions that most effectively solve them. Keep up to date with best practices and continuously seeks to learn new skills. Validate new skill development through pursuit of relevant certifications. Contribute towards the growth of the business by observing opportunities for upselling or cross-selling within the customer organization. Contribute to development of the delivery team and their practice area through participating in internal TED talks, mentoring junior team-mates and developing reusable training materials and standard operating procedures. Contributes to the broader business through involvement in recruiting, marketing and sales activities. Contribute to the overall collaborative and innovative culture of the company by taking part in group events and spearheading initiatives that grow the company and help make life at ProCogia more enjoyable for all. Experience building computer vision and NLP models R or Python for Data Science Advanced Statistical Analysis Building and validating search, personalization, and recommendation algorithms Data Visualization Skills (Shiny and PowerBI preferred) Experience building Machine Learning and Deep Learning libraries Machine Learning Frameworks (SparkML preferred) SQL (Structured Query Language) Experience with Structured and Unstructured Data Git for Version Control Working with Command Line on Unix based systems Spark Experience (PySpark preferred) Cloud Experience (AWS and Snowflake preferred) Docker and Kubernetes experience SDLC (Software Development Life Cycle) experience AI (Artificial Intelligence) and Deep Learning experience Python, SQL, Hive, etc. Bachelors in a quantitative field with a deep understanding of mathematics, statistics, and computer science. Masters or PhD in a quantitative field with a deep understanding of mathematics, statistics, and computer science. An experienced professional will have at least 3 years of professional experience in a data related role with a Masters Degree or 5 years of experience in a data related role with a Bachelors degree. 
ScrapedJobID1024:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID1025:
Follow NLP research and apply it to create technologies for business automation Own ML models end-to-end, from collecting training data to deploying in production Lead the planning, design, and implementation of the ML projects Serve as a mentor to junior team members and a standard-bearer for engineering best practice Manage the collaboration and communications with project stakeholders Minimum 3 years of industry experience in Machine Learning or related fields Solid understanding of Math and CS fundamentals related to Machine Learning algorithms Practical experience in modern NLP technologies (applying ML research to real-world projects) Previous experience in leading multi-person projects and building end-to-end Machine Learning systems Experience with one or more general purpose languages (Java, C/C++, Python, etc.) Team player with strong communication skills BS, MS or PhD in Computer Science, Engineering or a related technical field Top notch medical and dental coverage for you and your family 30 days of paid leave annually to help nurture work-life symbiosis Stock options Wellness stipend Pre-tax transportation and commuter benefits 6-month parental leave (or double salary to pay for your partner's unpaid leave) Free travel for any person accompanying a breastfeeding mother and her baby on a business trip A dependent care stipend up to $3,000 (USD) per month, per child, under the age of 21 for a maximum of $6,000 (USD) per month total Budget to attend conferences, train, and further your education $1,250 (CAD) one-time-use WFH stipend and $95 (CAD) monthly WFH stipend Relocation assistance 
ScrapedJobID1026:
Own and contribute to the ML Pipeline development lifecycle from Data wrangling, Feature development, Training and tuning ML model with Data Scientist, Deploy and manage the Inference Pipeline. Develop a reusable code and pattern to scale the ML Pipeline to new business use cases and create a self service platform. Partner closely with the ML Platform team, Infrastructure team, and similar teams to ensure the Data science org has the data, computing resources, and workflows/abstractions needed to do our best work. Contribute to the roadmap, and project execution with cross-functional stakeholders and Eng partner teams. Define and advance MLOps best practices within data science and product teams Be obsessed with the customer and maintain a customer-centric lens in how we frame, approach, and ultimately solve every problem we work on. Contribute to SME initiative and code review in support of spreading best practices 4+ years experience as a ML Engineer, Data Engineer, Data Scientist with strong engineering skills and a passion for working on turning reference implementations into production-ready software. Proficiency in at least one high-level programming language (Python, Java, Scala or equivalent) used both for ML and automation tasks. Experience with Python ML ecosystem (numpy, pandas, sklearn, XGBoost, etc.) and Apache Spark Ecosystem (Spark SQL, MLlib/Spark ML) Hands-on experience building scalable ML & big data processing pipelines with big data tools such as Hadoop, Hive, SQL, Spark and GCP cloud services such as DataProc, BigQuery, GCS etc. Experience with automated data pipeline and workflow management tools, i.e. Airflow. Strong sense of ownership and growth mindset. Experience with basic software engineering tools, e.g., git, CI/CD environment (such as Jenkins or Buildkite), PyPi, Docker, Kubernetes, unit testing, and general object-oriented design. PhD or MSc or Bsc in Computer Science / Operations Research / Statistics or other quantitative fields Experience with common ML frameworks/libraries such as Vowel wabbit, Tensorflow, PyTorch is preferred. Experience with Cloud Services such as AWS SageMaker/GCP AI Platform. Deploying and scaling ML solutions using open-source frameworks (MLFlow, TFX, H2O, etc.) 
ScrapedJobID1027:
Provide the Data Intelligence and Governance team with data analyses from researching systems and processes, profiling data via SQL queries, and validating data quality requirements. Identify and partner with data stewardship across the organization to operationalize the Data Governance framework. Champion data governance initiatives by promoting ideas into action; including developing and implementing data quality rules, communication, and adoption strategy. Oversee data quality management and data quality issue prioritization. Assist in developing data governance policies, processes, and documentation. Support corporate data quality initiatives through recommendation for solutions and leadership around data validation. Analyze and understand corporate data across data domains, on both source and target levels. Collaborate with other data analysts from cross-functional teams to address data quality issues and educate data stewardship on data governance principles. Identify new opportunities for data governance continually. Coordinates with various stakeholders and leaders across business functions to apply established data governance framework (training and education, developing data stewardship, data custodian roles, data dictionary, definitions and documentation, approval, and sign-off protocols). Are proficient in data analysis (preferably within software development, data delivery, and data analytics settings). Have a post-secondary degree in Data Science, Computing, Mathematics or Healthcare Informatics (preferably master’s level). Have 5+ years of experience in data management or data governance Are highly knowledgeable in databases and adept in SQL. Have hands-on experience in data visualization tools such as PowerBI. Are experienced with CRM tools such as SalesForce and NetSuite. Are exceptional at rapport building and creative problem solving. Have strong organizational, planning, and prioritization skills. Are goal-oriented, positive, a self-starter, with strong analytical skills. Are a data detective with excellent communication, known for collaborating and your ability to communicate complex data findings to various audiences. Demonstrate a proven track record of delivering results while guiding and facilitating business partners in solving data quality issues. Able to work independently and manage multiple commitments and responsibilities 
ScrapedJobID1028:
Use any available deep learning techniques in conjunction with PDFTron’s SDKs to develop next generation document understanding framework. Engage in Python programming and any other applicable programming languages such as C++ to develop and support new and existing products related to document understanding. Contribute full efforts to the software development process (from requirements gathering and analysis to high-level design/architecture, implementation, testing and maintenance/debugging). Write clean, concise and efficient codes that can be easily reviewed and maintained Contribute to technical documentation for PDFTron’s products being developed. Assist with research and development of future technologies and products. Prepare technical proposals, demonstrations and prototypes for new projects. Keep abreast of current and latest graphics technologies (i.e. PDF, XPS, SVG, image compression, etc.) Participate in technical/design reviews and group problem solving activities. Provide customer technical support by answering/solving customer questions and/or problems related to the PDFTron’s products or services. Masters or a PhD related to machine learning or 2 – 5 years experience developing advanced commercial applications related to deep learning/machine learning. A degree in computer science, computer/software engineering or equivalent. Strong computer science fundamentals: data structures, algorithms; programming languages Experience using Torch, TensorFlow, and other neural-networks toolkits Experience designing efficient network & training architectures. Strong proficiency in Python development, with additional experience in C/C++ would be benefitical Strong mathematical analysis and problem solving abilities. Excellent interpersonal and communication skills, both written and verbal. Ability to work effectively on assignments through correct prioritization and management of tasks in order to ensure high-quality deliverables at each stage of the project. Comfortable working independently, as well as part of a fast-paced and collaborative team environment. Ability to self-start projects with little to no guidance Competitive salary commensurate with experience & qualifications. A comprehensive extended benefits package including health, dental and vision for you and your family that starts from day one. A great team environment and resources, supporting you to do the best work of your life and providing unlimited career growth potential. Highly autonomous and entrepreneurial environment. Bi-weekly lunches and monthly socials (virtual for now). Unlimited learning development budget so you can master your craft. Annually recurring WFH allowance Work with the hardware you're most comfortable with (Windows or Mac) Diverse and inclusive workplace where we all learn from each other. Excellent work-life balance with a flexible work environment. Work remotely in Canada/Vancouver or in our convenient office location in downtown, your choice! 
ScrapedJobID1029:
Perform and plan: (i) the programming, testing, and documentation of programs for use in creating statistical tables, figures and listing summaries, (ii) the programming of analysis databases (derived datasets) and transfers of data for internal and external clients. May perform and plan the programming of database quality control checks. Program the integration of databases from multiple studies or sources. Develop programming documentation including plans and specifications, as appropriate. Provide advanced technical expertise in conjunction with internal and external clients, and independently bring project solutions to teams and department. Perform and plan the development, implementation and validation of new process technologies, macros and applications. Fulfill project responsibilities at the level of statistical team lead for single studies, under supervision. Understand the Scope of Work, estimate the work completed, and manage Out of Scope for single studies. May manage budget and resource requirements and provide revenue and resource forecasts for single studies. May be required to understand budget and quote assumptions. Provide training and guidance to lower level and new staff. Typically requires 2 - 3 years of prior relevant experience. Requires intermediate level knowledge of principles, theories, and concepts of a job area, typically obtained through advanced education combined with experience. Knowledge of statistics, programming and/or clinical drug development process Working knowledge of computing applications such as Base SAS, SAS/STAT and SAS Macro Language Good organizational, interpersonal, leadership and communication skills Ability to effectively handle multiple tasks and projects Excellent accuracy and attention to detail Ability to establish and maintain effective working relationships with coworkers, managers and clients 
ScrapedJobID1030:
Deploy machine learning solutions to improve Skype/Teams real-time collaboration quality and reliability Design, develop, and own components, tools, platforms, and systems for real-time media communication and collaboration. Drive independent investigations resulting in shipping product code, patents, and publications. Ph.D. in Computer Science, Mathematics, Physics, Electrical Engineering, or Masters plus equivalent work experience Minimum 7 year experience in professional software development 3+ years C/C++ coding, design and testing in a production environment Comfortable with Python or other scripting for rapid prototyping. Minimum of 1 years of experience in machine learning using tools like TensorFlow/Pytorch/Scikit-learn, etc. Strong system development skills, with a long-range system view that leverages development ranging from rapid research prototypes to carefully architected complex systems Excellent inter-personal skills and ability to work well in a scrum team. Experience developing and testing code in large codebases Experience developing production applications for the edge/IoT is a strong plus 
ScrapedJobID1031:
Recognition programs to showcase your talent! To be part of a company that takes a stand on issues affecting people, the environment, and our partners Summer Fridays (because Summer is for fun) Purchase discount on merchandise sold in all our divisions. Family & Friends events with discounts on our products Subsidized cafeteria & daycare Subsidized public transportation, carpooling network and free parking On campus gym with access to a trainer Flex schedules and telecommuting Sick days Attractive total compensation! Collaborate and work closely with internal teams (buying, distribution, product design, e-commerce etc.) to identify business performance gaps and analytical opportunities Extract, mine and analyze data from various sources to provide actionable business insights, build visualizations and presentations to communicate findings Develop, implement and monitor Advanced Analytics / ML solutions to improve customer experience, drive marketing effectiveness, optimize supply chain and inventory, etc. Work with business teams to assist with data related technical issues and support their data infrastructure needs Collaborate with our Data Team to develop the data platform, identify data quality issues, build or enhance data flows, identify, profile and acquire new data sources Design, conduct and analyze complex experiments Build and maintain large datasets for self-service analytics Graduate degree in statistics, mathematics, computer science or related field 3+ years of work experience in data analytics and machine learning Expert level proficiency in data analysis, querying and crunching data from multiple systems and data transformation approaches Capable of translating analysis results into business recommendations and preparing presentations for various stakeholders Knowledge of R, Python, SQL, etc. Experience with AWS / Redshift or Google Cloud / Big Query to move and access large amounts of structured and unstructured data Experience developing and implementing machine learning models such as clustering, classification, forecasting, etc. Knowledge of techniques such as generalized linear model/regression, random forest, boosting, trees, time-series and forecasting, text mining, neural networks, etc. Experience designing datasets and visualizations with tools like Power BI, Tableau, Qlik, etc. Experience designing and analyzing experiments (A plus) Experience analyzing data from third-party providers, including Google Analytics, Site Catalyst, Coremetrics, AdWords, Crimson Hexagon, Facebook etc. (A Plus) 
ScrapedJobID1032:
Provides advanced data science expertise to AstraZeneca projects and recommends data science solutions. Delivers advanced data science solutions to AstraZeneca projects, appropriately communicating with non-technical stakeholders. Works within established frameworks to deliver a variety of tasks that support projects in meeting their objectives. Independently keeps own knowledge up to date and learns from senior team members, proposing appropriate training courses for personal development. Reviews working practices and ensures non-compliant processes are escalated Ensures own work is compliant within Clinical Development. Collaborate in a multidisciplinary environment with world leading clinicians, data scientists, biological experts, statisticians and IT professionals. M.Sc. degree in rigorous quantitative science (such as mathematics, computer science, engineering) or have demonstrated an outstanding track-record of industry experience with the desired data science methodologies Practical software development skills in standard data science tools: Python, Agile, Code versioning (bitbucket/git), UNIX skills, familiarity working in cloud environment (AWS preferred) AWS or other cloud compute experience including SysOps (provisioning resources required for analytics, Kubernetes, infrastructure as code is a bonus) Data visualization & interactive data visualization (interactive dashboards w/ DASH & static visualization) Experience developing machine learning first products including timeseries analysis, forecasting, behavioral analysis Knowledge of range of mathematical and statistical modelling techniques and drive to continue to learn and develop these skills. Minimum 2+ years of industry experience or post-doctoral work. Ph.D. degree in rigorous quantitative science (such as mathematics, computer science, engineering) Experience within the pharmaceutical industry Advanced experience with Kubernetes and machine learning product architecture Communication, business analysis, and consultancy Advanced machine learning models: transformer-based NLP models, reinforcement learning, GNNs, state-of-the-art timeseries & forecasting models ML Ops experience: model tracking, model governance, multiple models in different production contexts Data visualization & interactive data visualization (interactive dashboards w/ DASH & static visualization) Our Social Media, Follow AstraZeneca on LinkedIn https://www.linkedin.com/company/1603/ Follow AstraZeneca on Facebook https://www.facebook.com/astrazenecacareers/ Follow AstraZeneca on Instagram https://www.instagram.com/astrazeneca_careers/?hl=en 
ScrapedJobID1033:
Experience with business analytics products like ThoughtSpot and Tableau Knowledge of one or more database technologies (Snowflake, SQL Server, etc.) Extensive understanding of global corporate business processes and their relationship to technology Excellent problem-solving abilities, strong written, verbal, and presentation skills Thrive in a dynamic environment, maintaining composure and a positive attitude Demonstrable understanding of development processes and agile methodologies Successful track record managing solutions from requirements analysis, to feature definition to deployment Proactively initiates, develops, and identifies opportunities to improve data quality Successful interaction with offshore team members is important Proficiency in writing Advanced SQLs, experience with data science tools and technologies is a plus Bachelor’s degree in Computer Science, Information Technology, or related field Experience in building advanced data visualizations using ThoughtSpot and Tableau 6+ years of IT experience with dimensional modeling, data investigation, optimization & using Cloud Databases Experience utilizing, and optimizing the use of, multiple large data sets Prior experience in the facilitating conversations to translate business requirements into the technical data requirements needed to develop solutions Excellent organization, time management, and communication skills Ability to work independently with strong attention to detail and accuracy Willingness and ability to adapt to rapid business and organizational change 
ScrapedJobID1034:

ScrapedJobID1035:
Lead the translation of marketing requests and questions into analytical problems. Requests can be strategic or tactical in nature, including but not limited to targeting, segmentation, list generation and automation, development of dashboards, reports, and measurement. Responsible for the extraction, review, and preparation of complex operational and customer behavior information from a variety of databases (SQL, GCP, etc). Use Cloud based Python/Scala environment to process big data, conduct analysis, and visualizing the results. Generate meaningful insights to solve business problems, identify new opportunities and drive strategy. Build presentations to clearly articulate insights, while simplifying complex data and processes for various levels of audiences including senior management Support the execution of loyalty campaigns at Loblaws Work collaboratively with business partners in marketing, digital and tech teams. Synthesize large amounts of data from multiple sources, including customer transaction data, consumer & syndicated research, market share, and campaign results. Extrapolate and interpret appropriate information to deliver value-added recommendations University Degree in Data Science, Computer Science, Statistics, Mathematics, Economics, Engineering, Business or other relevant field 3-5 years related work experience in an analytical role. Experience ideally in Retail, Loyalty, CPG industry, Consumer Finance, Telecommunications, or Consulting Programming skills in various languages (Python, Spark, PySpark, SQL, R, Hive). Advanced SQL is mandatory. Advanced Python is preferred. Experience with cloud platforms (i.e. GCP and Azure) is preferred. Experience with building models on big data is preferred. Ability to synthesize large amounts of data into insights Strong ability to build presentations and present complex ideas in a clear, articulate way Strong interpersonal skills and comfortable leading discussions and collaborating with cross functional teams Demonstrate strong business acumen Strong skills in Microsoft Office suite (Excel, Powerpoint) Strong attention to detail Curiosity and willingness to ask questions 
ScrapedJobID1036:
Work on ROCm stack packaging solution for individual and enterprise level deployment on distributed cloud infrastructure Debug Machine Learning/ High Performance Computing related issues on Radeon Open Compute Stack (ROCm) Develop test contents for sophisticated Machine Learning algorithms on distributed nodes Port High Performance computing application on ROCm Reproduce field defects and develop appropriate tests to prevent future issues. Design, develop and deploy testing tools and automation libraries vital to perform testing. Be responsible for the adoption of tooling and industry standard methodologies by means of advocacy and outreach to help our development communities’ level up. Languages: Python, C, C++, Linux Shell scripting. Frameworks/Libraries: TensorFlow, PyTorch, ONNXRT Tools: Prior experience with Linux, Docker, LLVM compilers, GNU make /CMAKE, Jenkins, Git/Gerrit Understanding of High-Performance Computing application, Machine learning and GPU Programming, MPI Parallel Programming 
ScrapedJobID1037:
Bachelor’s in computer science or equivalent 5 years’ software development experience 2+ years' experience running medium to large/complex projects with multiple internal/external dependencies Expertise in working with at least one machine learning or deep learning framework, such as Pandas, Sklearn, TensorFlow Experienced in working with ETL pipelines Computer science fundamentals: data structures, algorithms, performance complexity, and implications of computer architecture on software performance (e.g., I/O and memory tuning). Strong analytical and problem-solving skills Ability to understand and execute on the company’s mission and values Maintain a high degree of ethical standard and trustworthiness Baccalauréat en informatique ou équivalent. 5 ans d'expérience en développement de logiciels Plus de 2 ans d'expérience dans la gestion de projets de taille moyenne à grande/complexe avec de multiples dépendances internes/externes. Expertise dans l'utilisation d'au moins un cadre d'apprentissage automatique ou d'apprentissage profond, tel que Pandas, Sklearn, TensorFlow. Expérience de travail avec des pipelines ETL Principes fondamentaux de l'informatique : structures de données, algorithmes, complexité des performances et implications de l'architecture informatique sur les performances des logiciels (par exemple, réglage des E/S et de la mémoire). Compétences solides en matière d'analyse et de résolution de problèmes Capacité à comprendre et à mettre en œuvre la mission et les valeurs de l'entreprise. Maintenir un haut degré d'éthique et de fiabilité. 
ScrapedJobID1038:
Creation and optimization of advanced analytics tools and regular reporting of insights derived from them to internal and external audiences, including senior leadership Uncover long-term opportunities based on research and analysis of our store performance to create actionable strategic insights Drive companywide efficiencies through standardization of systems, processes and analytics frameworks Major stakeholder in companywide development execution system rollout implementing process improvements and new analytical frameworks Build strong working relationships and influence cross-functional teams, including but not limited to; Regional Development Teams, IT, FP&A, Global Business Services (GBS) Develops and delivers presentations both internally and externally to executive level leadership Bachelors or Master's degree in the fields of Business, Economics, Data Science or equivalent field required 5+ years relevant work experience, 2+ year's experience working in analytics, project management and/or FP&A experience preferred Strong understanding of the fundamentals of statistical modelling, data science and analytics Advanced analytical skillset with ability to transform data into action plans, advanced proficiency excel modeling and super user of data visualization software (Smartsheet, Power BI, VBA, etc.) Experience collaborating with cross-functional teams (Technology, Finance, Business Development) to drive results/projects demonstrating effective communication, influencing and organizational skills Start-up mentality with ability to perform under pressure and adapt to a fast-paced environment working with a lean team Honesty, high integrity, personal accountability, ownership mentality and a passion for the success of the company, the team, and personal career growth Knowledge in one or more general-purpose programming languages (SQL, Python, Java, etc.) 
ScrapedJobID1039:

ScrapedJobID1040:
Lead - Master’s degree in mathematics, computer science, engineering, physics, statistics, economics, computational sciences or a related quantitative discipline and 5+ years of analytical experience in an industrial or commercial setting OR PhD degree with at least 3+ years of industry experience DS- Master’s degree in mathematics, computer science, engineering, physics, statistics, economics, computational sciences or a related quantitative discipline and 3+ years of analytical experience in an industrial or commercial setting OR PhD degree with industry experience Experience AI/ML/NLP modelling of complex datasets. Advanced software development skills in at least two of the standard data

science languages (such as Python, R, Scala, C++, Julia) and strong data

manipulations skills (e.g. SQL, NoSQL, graph, etc.) Knowledge of SQL and relational databases, query authoring (SQL) and designing variety of databases (e.g. Postgres SQL) Comfortable working in cloud and high-performance compute environments (e.g. AWS, Apache Spark) Disciplined AI/ML deployment (MLOps, CI/CD) and Agile delivery Experience in coordination of delivery teams and providing feedback to their management Excellent written and verbal communication, business analysis, and consultancy skills Graph- Experience AI/ML modelling of complex datasets, network analysis or

direct experience in creating and maintaining graph data models. Experience

with a variety of graph technologies Knowledge of graph databases like Neo4J (Cypher, causal clusters), JanusGraph (Gremlin, GraphML), AWS Neptune, OrientDB. xpertise in machine learning/deep learning-based graph algorithms relevant to link prediction, ranking/recommendation, completion, community detection, node embedding, etc. Familiarity with Deep Learning, neural network architectures including CNNs,

RNNs, Embeddings, Transfer Learning, Attention-based Networks, Statistical

Learning, Restricted Boltzmann Machines (RBMs), Belief Networks, and

Reinforcement Learning Deep experience in developing models for private sector or industrial setting e.g. Lead data science area deliverables for digital products / programs / initiatives including the allocation of work within the team, monitors the quantitative and qualitative achievements of the team, and reports results Work as an individual contributor, providing data science expertise to digital

products / programs / initiatives. Apply in-depth experience with both statistical and modern data science

approaches, including unsupervised, supervised, regression algorithms. Apply advanced techniques such as neural networks, deep learning, NLP and federated learning. Build models, algorithms, simulations and experiments by writing highly

optimized code and using state-of-the art machine learning technologies. Collaborate cross-functionally in teams involved in data driven analytics to

maximize impact of graph-based capabilities Build and manage support models incorporated into digital or AI products; Work with Infrastructure and Ops teams to ensure appropriate architecture and tooling Capacity to mentor junior personnel Be able to apply in-depth experience with both statistical and modern data

science approaches to business cases and knowledge management tasks Strong written and verbal communication skills - ability to communicate complex ideas up to people of varying technical skills Work with developers, engineers, and MLOps to deliver AI/ML solutions for new products/services 
ScrapedJobID1041:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID1042:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1043:
Develop the global business analytics strategy and action plan. Own the GFA Data and AI platform, define the data strategy and roadmap, drive platform integration with advisory assets, manage vendor data contracts and expansion of the platform to meet business needs. Establish and lead the global Analytics community of practitioners to drive adoption of data and analytics offerings within the practice, increase collaboration and sharing of analytics-oriented solutions on emerging client issues and best practices. Proactively engage with MF colleagues to communicate vision, create enthusiasm and followership, and assess progress related to analytics adoption. Supervise technology leads and product managers on the data platform expansion and predictive model development. Ensure development protocols and QRM policies are incorporated in the overall solution design. Lead discussions with DTTL procurement, Global Privacy, QRM, and vendors on data licenses, establish data governance, and access strategy in alignment with contracts. Collaborate with Deloitte Technology engagement and delivery leaders to articulate platform strategy and delivery approaches ensuring alignment and commitment. Build a dynamic team across delivery centers, member firms and Deloitte Technology to lead development and rollout of innovative analytics assets Facilitate discussions with stakeholders to ensure business needs and objectives are clearly understood and analytics solutions meet the expressed needs and expectations of the business. Communicate progress on a periodic basis to senior business leaders as requested. Build relationships and collaborate with peers and stakeholders across Global technology, MF business, and delivery centers. Bachelor’s or master’s degree in Computer Science, Information Systems or a related technical discipline. Certification in data science and cloud-based analytics technologies. 10+ years of related experience in leading analytics-oriented solutions. Experience in building and supporting a cloud hosted data platform for the business or service line, experience in advanced technologies including cloud analytics capabilities, AI, data science and engineering, NLP, NLG etc. Proficiency in business intelligence and data analytics tools including Tableau, Power BI, Alteryx, Azure Databricks, Azure Data Factory etc. Experience in software development methodologies such as SAFE, agile, etc. Ability to be a leader who is dynamic, proactive, and decisive, adapts well to change and ambiguity, has exceptional leadership and management skills to lead global virtual teams through influence Demonstrated proficiency in facilitating, delegating, and motivating cross functional groups or activities. Highly developed communications skills, motivational, team player, strategic and creative, excellent project management, and advanced MS Office skills. Able to communicate effectively in English with media and/or in front of large audiences; International experience preferred; important to have a strong network outside of home country through client engagements or roles. Willingness to travel internationally (2-4 times per year). Lead the way: Deloitte is not only leading the profession, but reinventing it for the future. We’re also committed to creating opportunity and leading the way to a more sustainable world. Serve with integrity: Deloitte has earned the trust of employees, clients, regulators, and the public for 175 years. Upholding that trust is our single most important responsibility. Take care of each other: We look out for one another and prioritize respect, fairness, development, and well-being. Foster inclusion: We are at our best when we foster an inclusive culture and embrace diversity in all forms. We know this attracts top talent, enables innovation, and helps us deliver well-rounded client solutions. Collaborate for measurable impact: We approach our work with a collaborative mind¬set, teaming across businesses, geographies, and skill sets to deliver tangible, measurable, attributable impact. 
ScrapedJobID1044:
real-time visibility on how Ubisoft titles are played; an understanding of the habits and preferences of the people playing them. Design, prototype, build and maintain APIs, tools, code and a scalable infrastructure for operating Merlin's machine learning pipeline at scale. Synch up with your team to discuss work-in-progress, ideas, and blockers; plan and prioritize; overcome issues; etc. Be a key member of the team, participate in the decisions and implementations to improve the platform’s quality. Work closely with Data Scientists to design and implement the optimal environment for their maximized efficiency. Advocate for automation and monitoring at all steps of the ML pipeline and help to define best practices based on personal industry experience and research. Stay current on technological advancements to help develop yourself, the platform and position Ubisoft as a leader of the domain. Experience in Software/Data engineering (or related experience). Experience with modern infrastructure, tools and cloud technology (e.g. AWS, EMR, Docker, Kubernetes, Terraform, etc.). Knowledge of Python, Java. Experience with big data technologies, like Kafka, S3, Spark, and Hive. Experience building and interacting with REST APIs. Familiar with GitLab and its CI/CD tool. A constant desire to grow and learn. Strong communication and collaboration skills. Ability to navigate between the big picture and the micro details. You love being responsible for owning and improving a new, fast-growing platform. You are curious and like asking questions until you fully understand why/what you are doing. A desire to see teammates succeed together. Experience with maintaining architectures for end-to-end Machine Learning in the cloud. Familiarity with industry standards such as MLFlow, Airflow... Knowledge of additional programming languages like Scala. Exposure to automated testing and CI/CD in the ML context. Good understanding of ML concepts. An understanding of the video game industry. Your CV, highlighting your background and skills 
ScrapedJobID1045:
BS, MS in Computer Science, or related technical discipline 5+ year’s experience in the marketing technology space Strong working knowledge of cloud warehouses such as BigQuery Experience with Azure Strong data engineering skills with distributed computing background and proven experience in delivering large scale data platforms · Good grasp of analytics, measurement, reporting, and business intelligence including modeling, insights generation and data science Hands-on technologist with deep expertise in big data eco-system for data integration, data storage, compute framework, analytics, and advanced visualization. (i.e. ETL Tools, Streaming Tools, No-SQL data bases, Spark, Reporting Tools, AI/ML Platforms) Hands-on experience in GA360, CRM platforms (Salesforce), and /or Customer Data Platforms (e.g. Amperity), and /or user and product analytics (GA, Adobe), and /or DSP Experience with Power BI, Tableau, SQL, and data programming languages Python and/or R required Certifications for any of the cloud services like Azure or any Machine Learning/Advanced Analytics Courses is an asset 
ScrapedJobID1046:
Problem Solver: You are curious and love exploring multiple approaches to find the most efficient, scalable solution and solve a problem Collaborative: You work well with other people Passionate: You have a passion for Big Data and an interest in the latest trends and developments constantly researching new tools and data technologies Self-starter: You are comfortable helping your team get things done Leadership: You can mentor the team on the design, and implementation of our solutions Design, implement, and create customized pipelines for ingestion that are robust using Kafka. Work with Terabytes of data and data aggregation. Identify, design, and implement system performance improvements Identify, design, and implement internal process improvements Automate manual processes and optimize data delivery Guide and mentor team members Identify and assess potential solutions for technical and business suitability Bachelor/Master degree in Data Science, Computer Science, Computer/Electrical Engineering or related field 7+ years of work experience in a software engineering environment Experience working in Agile methodologies 3+ years of work experience designing and building high performance data applications with Hadoop, Spark, Kafka, Hive or other equivalent technologies Proficiency in some of the following languages: Scala, Java, Python, Bash Deep understanding of design principles of distributed systems and familiar with mainstream big data related technologies and distributed frameworks Experience with SQL and NoSQL systems Experience with automated testing systems Mentorship, collaboration, and communication skills Knowledge of data modelling, data warehousing, ETL processes, and business intelligence reporting tools Experience optimizing performance with large data sets Experience working with CI/CD, containerization, and virtualization tools such as Gitlab, Jenkins, Kubernetes, Docker Comprehensive health, dental, and vision plans at no cost to you Time off and flexible work schedules Retirement plan with a 5% company match Stock options and equity packages Generous parental leave Monthly wellness stipend plus fitness discounts and quarterly wellness group activities Home office stipend Community engagement opportunities and donation-matching program Annual virtual company retreats and regular community-led team events COVID-19 guidance: We have re-opened offices in various cities following local guidelines, but are continuing to maintain a flexible work environment. 
ScrapedJobID1047:
Design and build large and complex data sets, from spurious sources while thinking strategically about uses of data and how data use interacts with data design. Design and implement statistical data quality procedures for new data sources. Communicate findings to business leaders in a way that can influence how an organization approaches a business challenge Develop algorithms/software for accessing and handling data appropriately. Implement and hand off data checking and updating procedures to teams. Visualize and report data findings creatively in a variety of visual formats that appropriately provides insights to the organization. Train others on what data is available and how to use various sources Previous Telecommunications data analysis experience is an asset; emphasis on location data and time series analytics Master’s Degree (or higher) in Computer Science, Statistics, Applied Math, Engineering or other quantitative field; With a solid foundation in modeling, statistics, analytics and math Minimum of 5 years of hands-on data analytics experience in a corporate environment; Comfortable working with large, complex data sets from varying sources; Experience in team leadership. Highly motivated with the ability to work on a multiple projects simultaneously; Team player, creative, entrepreneurial, willing to experiment, persistent and structured. Working with structured and unstructured data sets;
Leading analytics projects to support the strategic product direction, sales and customer efforts;
Performing hypothesis testing and develop predictive model;
Evaluating and providing input on potential business intelligence solutions.
Applying statistical principles to data analytics;
Comfortable in statistical analysis, clustering and data mining techniques to identify trends and insights
Developing end-end to models/ projects and automation in production environment. Leading analytics projects to support the strategic product direction, sales and customer efforts; Performing hypothesis testing and develop predictive model; Evaluating and providing input on potential business intelligence solutions. Applying statistical principles to data analytics; Comfortable in statistical analysis, clustering and data mining techniques to identify trends and insights Developing end-end to models/ projects and automation in production environment. Thorough understanding of relational database design; High proficiency in SQL. Fluent programming in Python, Hive, or SAS Extensive experience in Google Cloud Platform, BigQuery, JupyterLab, docker container and workspace set up. Knowledgeable about common supervised and unsupervised Machine Learning approaches (eg. feature engineering, classification, regression, clustering, NLP, time series forecasting, etc. "Tensorflow”, “Deep Learning” and synthetic tabular data generation is a strong asset. 
ScrapedJobID1048:
Square Enix Montréal est à la recherche d’un·e Analyste en chef, passionné·e par les jeux et l’expérience utilisateur, pour prendre en charge l’activité analytique sur l’un des jeux mobiles en cours de développement au sein de la division mobile de Square Enix West. Rôle de leadership au sein de l'équipe de production : porter et déployer la vision BI et analytique au sein du projet, participer à l'amélioration continue des processus décisionnels, éduquer les équipes de productions et de marketing sur ce qu’il est possible de faire au niveau analytique et data science. Manager un·e Data Analyst Junior déjà en place : coordonner les tâches et priorités coté BI en interaction avec l’équipe du jeu (Product Manager, Game Designer, etc); Participer à la mise en place de bonnes pratiques et à la création de processus et produits transverse à l’ensemble des équipes BI en production Définir les spécifications de la collecte d'information et apporter du support aux programmeurs lors de l'implémentation du système de collecte de données; Participer au processus de vérification de qualité des données en collaboration avec l'équipe QA; Créer des modèles analytiques, tableaux de bord et rapports d'analyse personnalisés; Présenter, sous forme de storytelling, les insights générés au travers des analyses, à tout type d'audience; Fournir des recommandations opérationnelles en termes de design et de monétisation; Diplôme universitaire en statistiques, mathématiques, génie informatique, génie logiciel ou l’équivalent; 5+ années d’expérience en tant qu’analyste de données, idéalement en partie dans le domaine du jeu mobile; Maitrise du SQL, Python est un plus; Maitrise du Data Mining et des statistiques; Excellente maitrise de l’analyse de données et de la génération d’insights impactants; Maitrise d’outils de Reporting (Looker, Tableau, PowerBI, Amplitude ou équivalent); Maitrise des systèmes de collection de données de type Events; Bonne connaissance des systèmes de base de données dans le cloud BigQuery, Snowflake, Redshift ou équivalent; Expérience en coaching et mentoring est un plus; Connaissance des plateformes analytiques comme Amplitude, deltaDNA, Mixpanel etc. est un plus. Capacité à résoudre des problèmes complexes; Grande habileté pour expliquer des phénomènes complexes de façon claire et complexe à tout type d’audience (anglais et français) Rigoureux et précis; Axé sur l’impact opérationnel, débrouillard et capable de prendre de l’initiative; Être capable de s’adapter dans un environnement où les priorités peuvent changer régulièrement; De l’ambition et de la passion pour les jeux vidéo mobiles sont essentielles! Square Enix Montréal is looking for a Lead Data Analyst, passionate about games and user experience, to take charge of the analytical activity on one of the mobile games under development within the mobile division of Square Enix West. Leadership role within the production team: carry and deploy the BI and analytical vision within the project, participate in the continuous improvement of decision-making processes, educate the production and marketing teams on what is possible to do at the analytical and data science level. Manage a junior data analyst already in place: coordinate tasks and priorities on the BI side in interaction with the game team (product manager, game designers, etc.); Participate in the implementation of best practices and the creation of processes and products across all BI teams in production Define the specifications of the information collection and provide support to programmers during the implementation of the data collection system; Participate in the data quality verification process in collaboration with the QA team; Create analytical models, dashboards and personalized analysis reports; Present, in the form of storytelling, the insights generated through analyzes, to any type of audience; Provide operational recommendations in terms of design and monetization; University degree in statistics, mathematics, computer engineering, software engineering or equivalent; 5+ years of experience as a data analyst, ideally partly in the field of mobile gaming; Proficiency in SQL, Python is a plus; Mastery of Data Mining and statistics; Excellent knowledge of data analysis and the generation of impactful insights; Proficiency in reporting tools (Looker, Table, PowerBI, Amplitude or equivalent); Mastery of Events type data collection systems; Good knowledge of BigQuery, Snowflake, Redshift or equivalent cloud database systems; Coaching and mentoring experience is a plus; Knowledge of analytical platforms such as Amplitude, deltaDNA, Mixpanel etc. is a plus. Ability to solve complex problems; Great ability to explain complex phenomena in a clear and complex manner to any type of audience (English and French) Rigorous and precise; Operational impact oriented, resourceful and able to take initiative; Be able to adapt in an environment where priorities can change regularly; Ambition and passion for mobile video games are essential! 
ScrapedJobID1049:
Bonus pay Commission pay Casual dress Flexible schedule Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? or Are you willing to relocate? Yes 
ScrapedJobID1050:
Assist with the design, development, implementation and maintenance of complex data systems and solutions both on premise as well as in the cloud using Azure / AWS/ Google Understanding how data is used to drive business outcomes Defining the data architecture framework, standards and principles, including modeling, metadata, security, master data such as clients, vendors, and product codes Defining data flows capturing which parts of the organization generate data, which require data to function, how data flows are managed, and how data changes in transition Migrate data from legacy systems to new technology solutions Design conceptual and logical data models and flowcharts Develop control structures to ensure the accuracy and quality of data as it flows from source systems to users Finding and implementing creative solutions for data quality and coverage issues Helping establish data governance programs that take into account data volume / coverage, data quality, tools, integration, acquisition of new sources, flows and pipelines, regulatory considerations Partnering to identify and define key business terms, rules, quality requirements, critical data elements, KPI’s and encouraging consistency across the enterprise Bachelor’s degree in computer science, engineering, business, finance or a related area of study 9+ years’ experience as a Data Modeler/ Data Architect, in an integrated business and IT collaborative environment. Excellent analytical and problem-solving skills Extreme attention to detail Good process mapping skills Strong knowledge of data modelling, data quality & data governance best practices and tools Experience with waterfall and agile methodologies Ability to build a sense of trust and rapport with the team and partners A self-starter attitude, a strong desire to learn as you go, and the belief that you can make a meaningful contribution to your immediate team, the business users that you serve, and to the organization 
ScrapedJobID1051:
Work on ROCm stack packaging solution for individual and enterprise level deployment on distributed cloud infrastructure Debug Machine Learning/ High Performance Computing related issues on Radeon Open Compute Stack (ROCm) Develop test contents for sophisticated Machine Learning algorithms on distributed nodes Port High Performance computing application on ROCm Reproduce field defects and develop appropriate tests to prevent future issues. Design, develop and deploy testing tools and automation libraries vital to perform testing. Be responsible for the adoption of tooling and industry standard methodologies by means of advocacy and outreach to help our development communities’ level up. Languages: Python, C, C++, Linux Shell scripting. Frameworks/Libraries: TensorFlow, PyTorch, ONNXRT Tools: Prior experience with Linux, Docker, LLVM compilers, GNU make /CMAKE, Jenkins, Git/Gerrit Understanding of High-Performance Computing application, Machine learning and GPU Programming, MPI Parallel Programming 
ScrapedJobID1052:
Creation and optimization of advanced analytics tools and regular reporting of insights derived from them to internal and external audiences, including senior leadership Uncover long-term opportunities based on research and analysis of our store performance to create actionable strategic insights Drive companywide efficiencies through standardization of systems, processes and analytics frameworks Major stakeholder in companywide development execution system rollout implementing process improvements and new analytical frameworks Build strong working relationships and influence cross-functional teams, including but not limited to; Regional Development Teams, IT, FP&A, Global Business Services (GBS) Develops and delivers presentations both internally and externally to executive level leadership Bachelors or Master's degree in the fields of Business, Economics, Data Science or equivalent field required 5+ years relevant work experience, 2+ year's experience working in analytics, project management and/or FP&A experience preferred Strong understanding of the fundamentals of statistical modelling, data science and analytics Advanced analytical skillset with ability to transform data into action plans, advanced proficiency excel modeling and super user of data visualization software (Smartsheet, Power BI, VBA, etc.) Experience collaborating with cross-functional teams (Technology, Finance, Business Development) to drive results/projects demonstrating effective communication, influencing and organizational skills Start-up mentality with ability to perform under pressure and adapt to a fast-paced environment working with a lean team Honesty, high integrity, personal accountability, ownership mentality and a passion for the success of the company, the team, and personal career growth Knowledge in one or more general-purpose programming languages (SQL, Python, Java, etc.) 
ScrapedJobID1053:

ScrapedJobID1054:
Lead - Master’s degree in mathematics, computer science, engineering, physics, statistics, economics, computational sciences or a related quantitative discipline and 5+ years of analytical experience in an industrial or commercial setting OR PhD degree with at least 3+ years of industry experience DS- Master’s degree in mathematics, computer science, engineering, physics, statistics, economics, computational sciences or a related quantitative discipline and 3+ years of analytical experience in an industrial or commercial setting OR PhD degree with industry experience Experience AI/ML/NLP modelling of complex datasets. Advanced software development skills in at least two of the standard data

science languages (such as Python, R, Scala, C++, Julia) and strong data

manipulations skills (e.g. SQL, NoSQL, graph, etc.) Knowledge of SQL and relational databases, query authoring (SQL) and designing variety of databases (e.g. Postgres SQL) Comfortable working in cloud and high-performance compute environments (e.g. AWS, Apache Spark) Disciplined AI/ML deployment (MLOps, CI/CD) and Agile delivery Experience in coordination of delivery teams and providing feedback to their management Excellent written and verbal communication, business analysis, and consultancy skills Graph- Experience AI/ML modelling of complex datasets, network analysis or

direct experience in creating and maintaining graph data models. Experience

with a variety of graph technologies Knowledge of graph databases like Neo4J (Cypher, causal clusters), JanusGraph (Gremlin, GraphML), AWS Neptune, OrientDB. xpertise in machine learning/deep learning-based graph algorithms relevant to link prediction, ranking/recommendation, completion, community detection, node embedding, etc. Familiarity with Deep Learning, neural network architectures including CNNs,

RNNs, Embeddings, Transfer Learning, Attention-based Networks, Statistical

Learning, Restricted Boltzmann Machines (RBMs), Belief Networks, and

Reinforcement Learning Deep experience in developing models for private sector or industrial setting e.g. Lead data science area deliverables for digital products / programs / initiatives including the allocation of work within the team, monitors the quantitative and qualitative achievements of the team, and reports results Work as an individual contributor, providing data science expertise to digital

products / programs / initiatives. Apply in-depth experience with both statistical and modern data science

approaches, including unsupervised, supervised, regression algorithms. Apply advanced techniques such as neural networks, deep learning, NLP and federated learning. Build models, algorithms, simulations and experiments by writing highly

optimized code and using state-of-the art machine learning technologies. Collaborate cross-functionally in teams involved in data driven analytics to

maximize impact of graph-based capabilities Build and manage support models incorporated into digital or AI products; Work with Infrastructure and Ops teams to ensure appropriate architecture and tooling Capacity to mentor junior personnel Be able to apply in-depth experience with both statistical and modern data

science approaches to business cases and knowledge management tasks Strong written and verbal communication skills - ability to communicate complex ideas up to people of varying technical skills Work with developers, engineers, and MLOps to deliver AI/ML solutions for new products/services 
ScrapedJobID1055:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID1056:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1057:
Develop the global business analytics strategy and action plan. Own the GFA Data and AI platform, define the data strategy and roadmap, drive platform integration with advisory assets, manage vendor data contracts and expansion of the platform to meet business needs. Establish and lead the global Analytics community of practitioners to drive adoption of data and analytics offerings within the practice, increase collaboration and sharing of analytics-oriented solutions on emerging client issues and best practices. Proactively engage with MF colleagues to communicate vision, create enthusiasm and followership, and assess progress related to analytics adoption. Supervise technology leads and product managers on the data platform expansion and predictive model development. Ensure development protocols and QRM policies are incorporated in the overall solution design. Lead discussions with DTTL procurement, Global Privacy, QRM, and vendors on data licenses, establish data governance, and access strategy in alignment with contracts. Collaborate with Deloitte Technology engagement and delivery leaders to articulate platform strategy and delivery approaches ensuring alignment and commitment. Build a dynamic team across delivery centers, member firms and Deloitte Technology to lead development and rollout of innovative analytics assets Facilitate discussions with stakeholders to ensure business needs and objectives are clearly understood and analytics solutions meet the expressed needs and expectations of the business. Communicate progress on a periodic basis to senior business leaders as requested. Build relationships and collaborate with peers and stakeholders across Global technology, MF business, and delivery centers. Bachelor’s or master’s degree in Computer Science, Information Systems or a related technical discipline. Certification in data science and cloud-based analytics technologies. 10+ years of related experience in leading analytics-oriented solutions. Experience in building and supporting a cloud hosted data platform for the business or service line, experience in advanced technologies including cloud analytics capabilities, AI, data science and engineering, NLP, NLG etc. Proficiency in business intelligence and data analytics tools including Tableau, Power BI, Alteryx, Azure Databricks, Azure Data Factory etc. Experience in software development methodologies such as SAFE, agile, etc. Ability to be a leader who is dynamic, proactive, and decisive, adapts well to change and ambiguity, has exceptional leadership and management skills to lead global virtual teams through influence Demonstrated proficiency in facilitating, delegating, and motivating cross functional groups or activities. Highly developed communications skills, motivational, team player, strategic and creative, excellent project management, and advanced MS Office skills. Able to communicate effectively in English with media and/or in front of large audiences; International experience preferred; important to have a strong network outside of home country through client engagements or roles. Willingness to travel internationally (2-4 times per year). Lead the way: Deloitte is not only leading the profession, but reinventing it for the future. We’re also committed to creating opportunity and leading the way to a more sustainable world. Serve with integrity: Deloitte has earned the trust of employees, clients, regulators, and the public for 175 years. Upholding that trust is our single most important responsibility. Take care of each other: We look out for one another and prioritize respect, fairness, development, and well-being. Foster inclusion: We are at our best when we foster an inclusive culture and embrace diversity in all forms. We know this attracts top talent, enables innovation, and helps us deliver well-rounded client solutions. Collaborate for measurable impact: We approach our work with a collaborative mind¬set, teaming across businesses, geographies, and skill sets to deliver tangible, measurable, attributable impact. 
ScrapedJobID1058:
Lead the translation of marketing requests and questions into analytical problems. Requests can be strategic or tactical in nature, including but not limited to targeting, segmentation, list generation and automation, development of dashboards, reports, and measurement. Responsible for the extraction, review, and preparation of complex operational and customer behavior information from a variety of databases (SQL, GCP, etc). Use Cloud based Python/Scala environment to process big data, conduct analysis, and visualizing the results. Generate meaningful insights to solve business problems, identify new opportunities and drive strategy. Build presentations to clearly articulate insights, while simplifying complex data and processes for various levels of audiences including senior management Support the execution of loyalty campaigns at Loblaws Work collaboratively with business partners in marketing, digital and tech teams. Synthesize large amounts of data from multiple sources, including customer transaction data, consumer & syndicated research, market share, and campaign results. Extrapolate and interpret appropriate information to deliver value-added recommendations University Degree in Data Science, Computer Science, Statistics, Mathematics, Economics, Engineering, Business or other relevant field 3-5 years related work experience in an analytical role. Experience ideally in Retail, Loyalty, CPG industry, Consumer Finance, Telecommunications, or Consulting Programming skills in various languages (Python, Spark, PySpark, SQL, R, Hive). Advanced SQL is mandatory. Advanced Python is preferred. Experience with cloud platforms (i.e. GCP and Azure) is preferred. Experience with building models on big data is preferred. Ability to synthesize large amounts of data into insights Strong ability to build presentations and present complex ideas in a clear, articulate way Strong interpersonal skills and comfortable leading discussions and collaborating with cross functional teams Demonstrate strong business acumen Strong skills in Microsoft Office suite (Excel, Powerpoint) Strong attention to detail Curiosity and willingness to ask questions 
ScrapedJobID1059:
real-time visibility on how Ubisoft titles are played; an understanding of the habits and preferences of the people playing them. Design, prototype, build and maintain APIs, tools, code and a scalable infrastructure for operating Merlin's machine learning pipeline at scale. Synch up with your team to discuss work-in-progress, ideas, and blockers; plan and prioritize; overcome issues; etc. Be a key member of the team, participate in the decisions and implementations to improve the platform’s quality. Work closely with Data Scientists to design and implement the optimal environment for their maximized efficiency. Advocate for automation and monitoring at all steps of the ML pipeline and help to define best practices based on personal industry experience and research. Stay current on technological advancements to help develop yourself, the platform and position Ubisoft as a leader of the domain. Experience in Software/Data engineering (or related experience). Experience with modern infrastructure, tools and cloud technology (e.g. AWS, EMR, Docker, Kubernetes, Terraform, etc.). Knowledge of Python, Java. Experience with big data technologies, like Kafka, S3, Spark, and Hive. Experience building and interacting with REST APIs. Familiar with GitLab and its CI/CD tool. A constant desire to grow and learn. Strong communication and collaboration skills. Ability to navigate between the big picture and the micro details. You love being responsible for owning and improving a new, fast-growing platform. You are curious and like asking questions until you fully understand why/what you are doing. A desire to see teammates succeed together. Experience with maintaining architectures for end-to-end Machine Learning in the cloud. Familiarity with industry standards such as MLFlow, Airflow... Knowledge of additional programming languages like Scala. Exposure to automated testing and CI/CD in the ML context. Good understanding of ML concepts. An understanding of the video game industry. Your CV, highlighting your background and skills 
ScrapedJobID1060:
BS, MS in Computer Science, or related technical discipline 5+ year’s experience in the marketing technology space Strong working knowledge of cloud warehouses such as BigQuery Experience with Azure Strong data engineering skills with distributed computing background and proven experience in delivering large scale data platforms · Good grasp of analytics, measurement, reporting, and business intelligence including modeling, insights generation and data science Hands-on technologist with deep expertise in big data eco-system for data integration, data storage, compute framework, analytics, and advanced visualization. (i.e. ETL Tools, Streaming Tools, No-SQL data bases, Spark, Reporting Tools, AI/ML Platforms) Hands-on experience in GA360, CRM platforms (Salesforce), and /or Customer Data Platforms (e.g. Amperity), and /or user and product analytics (GA, Adobe), and /or DSP Experience with Power BI, Tableau, SQL, and data programming languages Python and/or R required Certifications for any of the cloud services like Azure or any Machine Learning/Advanced Analytics Courses is an asset 
ScrapedJobID1061:
Problem Solver: You are curious and love exploring multiple approaches to find the most efficient, scalable solution and solve a problem Collaborative: You work well with other people Passionate: You have a passion for Big Data and an interest in the latest trends and developments constantly researching new tools and data technologies Self-starter: You are comfortable helping your team get things done Leadership: You can mentor the team on the design, and implementation of our solutions Design, implement, and create customized pipelines for ingestion that are robust using Kafka. Work with Terabytes of data and data aggregation. Identify, design, and implement system performance improvements Identify, design, and implement internal process improvements Automate manual processes and optimize data delivery Guide and mentor team members Identify and assess potential solutions for technical and business suitability Bachelor/Master degree in Data Science, Computer Science, Computer/Electrical Engineering or related field 7+ years of work experience in a software engineering environment Experience working in Agile methodologies 3+ years of work experience designing and building high performance data applications with Hadoop, Spark, Kafka, Hive or other equivalent technologies Proficiency in some of the following languages: Scala, Java, Python, Bash Deep understanding of design principles of distributed systems and familiar with mainstream big data related technologies and distributed frameworks Experience with SQL and NoSQL systems Experience with automated testing systems Mentorship, collaboration, and communication skills Knowledge of data modelling, data warehousing, ETL processes, and business intelligence reporting tools Experience optimizing performance with large data sets Experience working with CI/CD, containerization, and virtualization tools such as Gitlab, Jenkins, Kubernetes, Docker Comprehensive health, dental, and vision plans at no cost to you Time off and flexible work schedules Retirement plan with a 5% company match Stock options and equity packages Generous parental leave Monthly wellness stipend plus fitness discounts and quarterly wellness group activities Home office stipend Community engagement opportunities and donation-matching program Annual virtual company retreats and regular community-led team events COVID-19 guidance: We have re-opened offices in various cities following local guidelines, but are continuing to maintain a flexible work environment. 
ScrapedJobID1062:
Design and build large and complex data sets, from spurious sources while thinking strategically about uses of data and how data use interacts with data design. Design and implement statistical data quality procedures for new data sources. Communicate findings to business leaders in a way that can influence how an organization approaches a business challenge Develop algorithms/software for accessing and handling data appropriately. Implement and hand off data checking and updating procedures to teams. Visualize and report data findings creatively in a variety of visual formats that appropriately provides insights to the organization. Train others on what data is available and how to use various sources Previous Telecommunications data analysis experience is an asset; emphasis on location data and time series analytics Master’s Degree (or higher) in Computer Science, Statistics, Applied Math, Engineering or other quantitative field; With a solid foundation in modeling, statistics, analytics and math Minimum of 5 years of hands-on data analytics experience in a corporate environment; Comfortable working with large, complex data sets from varying sources; Experience in team leadership. Highly motivated with the ability to work on a multiple projects simultaneously; Team player, creative, entrepreneurial, willing to experiment, persistent and structured. Working with structured and unstructured data sets;
Leading analytics projects to support the strategic product direction, sales and customer efforts;
Performing hypothesis testing and develop predictive model;
Evaluating and providing input on potential business intelligence solutions.
Applying statistical principles to data analytics;
Comfortable in statistical analysis, clustering and data mining techniques to identify trends and insights
Developing end-end to models/ projects and automation in production environment. Leading analytics projects to support the strategic product direction, sales and customer efforts; Performing hypothesis testing and develop predictive model; Evaluating and providing input on potential business intelligence solutions. Applying statistical principles to data analytics; Comfortable in statistical analysis, clustering and data mining techniques to identify trends and insights Developing end-end to models/ projects and automation in production environment. Thorough understanding of relational database design; High proficiency in SQL. Fluent programming in Python, Hive, or SAS Extensive experience in Google Cloud Platform, BigQuery, JupyterLab, docker container and workspace set up. Knowledgeable about common supervised and unsupervised Machine Learning approaches (eg. feature engineering, classification, regression, clustering, NLP, time series forecasting, etc. "Tensorflow”, “Deep Learning” and synthetic tabular data generation is a strong asset. 
ScrapedJobID1063:
Square Enix Montréal est à la recherche d’un·e Analyste en chef, passionné·e par les jeux et l’expérience utilisateur, pour prendre en charge l’activité analytique sur l’un des jeux mobiles en cours de développement au sein de la division mobile de Square Enix West. Rôle de leadership au sein de l'équipe de production : porter et déployer la vision BI et analytique au sein du projet, participer à l'amélioration continue des processus décisionnels, éduquer les équipes de productions et de marketing sur ce qu’il est possible de faire au niveau analytique et data science. Manager un·e Data Analyst Junior déjà en place : coordonner les tâches et priorités coté BI en interaction avec l’équipe du jeu (Product Manager, Game Designer, etc); Participer à la mise en place de bonnes pratiques et à la création de processus et produits transverse à l’ensemble des équipes BI en production Définir les spécifications de la collecte d'information et apporter du support aux programmeurs lors de l'implémentation du système de collecte de données; Participer au processus de vérification de qualité des données en collaboration avec l'équipe QA; Créer des modèles analytiques, tableaux de bord et rapports d'analyse personnalisés; Présenter, sous forme de storytelling, les insights générés au travers des analyses, à tout type d'audience; Fournir des recommandations opérationnelles en termes de design et de monétisation; Diplôme universitaire en statistiques, mathématiques, génie informatique, génie logiciel ou l’équivalent; 5+ années d’expérience en tant qu’analyste de données, idéalement en partie dans le domaine du jeu mobile; Maitrise du SQL, Python est un plus; Maitrise du Data Mining et des statistiques; Excellente maitrise de l’analyse de données et de la génération d’insights impactants; Maitrise d’outils de Reporting (Looker, Tableau, PowerBI, Amplitude ou équivalent); Maitrise des systèmes de collection de données de type Events; Bonne connaissance des systèmes de base de données dans le cloud BigQuery, Snowflake, Redshift ou équivalent; Expérience en coaching et mentoring est un plus; Connaissance des plateformes analytiques comme Amplitude, deltaDNA, Mixpanel etc. est un plus. Capacité à résoudre des problèmes complexes; Grande habileté pour expliquer des phénomènes complexes de façon claire et complexe à tout type d’audience (anglais et français) Rigoureux et précis; Axé sur l’impact opérationnel, débrouillard et capable de prendre de l’initiative; Être capable de s’adapter dans un environnement où les priorités peuvent changer régulièrement; De l’ambition et de la passion pour les jeux vidéo mobiles sont essentielles! Square Enix Montréal is looking for a Lead Data Analyst, passionate about games and user experience, to take charge of the analytical activity on one of the mobile games under development within the mobile division of Square Enix West. Leadership role within the production team: carry and deploy the BI and analytical vision within the project, participate in the continuous improvement of decision-making processes, educate the production and marketing teams on what is possible to do at the analytical and data science level. Manage a junior data analyst already in place: coordinate tasks and priorities on the BI side in interaction with the game team (product manager, game designers, etc.); Participate in the implementation of best practices and the creation of processes and products across all BI teams in production Define the specifications of the information collection and provide support to programmers during the implementation of the data collection system; Participate in the data quality verification process in collaboration with the QA team; Create analytical models, dashboards and personalized analysis reports; Present, in the form of storytelling, the insights generated through analyzes, to any type of audience; Provide operational recommendations in terms of design and monetization; University degree in statistics, mathematics, computer engineering, software engineering or equivalent; 5+ years of experience as a data analyst, ideally partly in the field of mobile gaming; Proficiency in SQL, Python is a plus; Mastery of Data Mining and statistics; Excellent knowledge of data analysis and the generation of impactful insights; Proficiency in reporting tools (Looker, Table, PowerBI, Amplitude or equivalent); Mastery of Events type data collection systems; Good knowledge of BigQuery, Snowflake, Redshift or equivalent cloud database systems; Coaching and mentoring experience is a plus; Knowledge of analytical platforms such as Amplitude, deltaDNA, Mixpanel etc. is a plus. Ability to solve complex problems; Great ability to explain complex phenomena in a clear and complex manner to any type of audience (English and French) Rigorous and precise; Operational impact oriented, resourceful and able to take initiative; Be able to adapt in an environment where priorities can change regularly; Ambition and passion for mobile video games are essential! 
ScrapedJobID1064:
Bonus pay Commission pay Casual dress Flexible schedule Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? or Are you willing to relocate? Yes 
ScrapedJobID1065:
Assist with the design, development, implementation and maintenance of complex data systems and solutions both on premise as well as in the cloud using Azure / AWS/ Google Understanding how data is used to drive business outcomes Defining the data architecture framework, standards and principles, including modeling, metadata, security, master data such as clients, vendors, and product codes Defining data flows capturing which parts of the organization generate data, which require data to function, how data flows are managed, and how data changes in transition Migrate data from legacy systems to new technology solutions Design conceptual and logical data models and flowcharts Develop control structures to ensure the accuracy and quality of data as it flows from source systems to users Finding and implementing creative solutions for data quality and coverage issues Helping establish data governance programs that take into account data volume / coverage, data quality, tools, integration, acquisition of new sources, flows and pipelines, regulatory considerations Partnering to identify and define key business terms, rules, quality requirements, critical data elements, KPI’s and encouraging consistency across the enterprise Bachelor’s degree in computer science, engineering, business, finance or a related area of study 9+ years’ experience as a Data Modeler/ Data Architect, in an integrated business and IT collaborative environment. Excellent analytical and problem-solving skills Extreme attention to detail Good process mapping skills Strong knowledge of data modelling, data quality & data governance best practices and tools Experience with waterfall and agile methodologies Ability to build a sense of trust and rapport with the team and partners A self-starter attitude, a strong desire to learn as you go, and the belief that you can make a meaningful contribution to your immediate team, the business users that you serve, and to the organization 
ScrapedJobID1066:
Work on ROCm stack packaging solution for individual and enterprise level deployment on distributed cloud infrastructure Debug Machine Learning/ High Performance Computing related issues on Radeon Open Compute Stack (ROCm) Develop test contents for sophisticated Machine Learning algorithms on distributed nodes Port High Performance computing application on ROCm Reproduce field defects and develop appropriate tests to prevent future issues. Design, develop and deploy testing tools and automation libraries vital to perform testing. Be responsible for the adoption of tooling and industry standard methodologies by means of advocacy and outreach to help our development communities’ level up. Languages: Python, C, C++, Linux Shell scripting. Frameworks/Libraries: TensorFlow, PyTorch, ONNXRT Tools: Prior experience with Linux, Docker, LLVM compilers, GNU make /CMAKE, Jenkins, Git/Gerrit Understanding of High-Performance Computing application, Machine learning and GPU Programming, MPI Parallel Programming 
ScrapedJobID1067:
Creation and optimization of advanced analytics tools and regular reporting of insights derived from them to internal and external audiences, including senior leadership Uncover long-term opportunities based on research and analysis of our store performance to create actionable strategic insights Drive companywide efficiencies through standardization of systems, processes and analytics frameworks Major stakeholder in companywide development execution system rollout implementing process improvements and new analytical frameworks Build strong working relationships and influence cross-functional teams, including but not limited to; Regional Development Teams, IT, FP&A, Global Business Services (GBS) Develops and delivers presentations both internally and externally to executive level leadership Bachelors or Master's degree in the fields of Business, Economics, Data Science or equivalent field required 5+ years relevant work experience, 2+ year's experience working in analytics, project management and/or FP&A experience preferred Strong understanding of the fundamentals of statistical modelling, data science and analytics Advanced analytical skillset with ability to transform data into action plans, advanced proficiency excel modeling and super user of data visualization software (Smartsheet, Power BI, VBA, etc.) Experience collaborating with cross-functional teams (Technology, Finance, Business Development) to drive results/projects demonstrating effective communication, influencing and organizational skills Start-up mentality with ability to perform under pressure and adapt to a fast-paced environment working with a lean team Honesty, high integrity, personal accountability, ownership mentality and a passion for the success of the company, the team, and personal career growth Knowledge in one or more general-purpose programming languages (SQL, Python, Java, etc.) 
ScrapedJobID1068:

ScrapedJobID1069:
Lead - Master’s degree in mathematics, computer science, engineering, physics, statistics, economics, computational sciences or a related quantitative discipline and 5+ years of analytical experience in an industrial or commercial setting OR PhD degree with at least 3+ years of industry experience DS- Master’s degree in mathematics, computer science, engineering, physics, statistics, economics, computational sciences or a related quantitative discipline and 3+ years of analytical experience in an industrial or commercial setting OR PhD degree with industry experience Experience AI/ML/NLP modelling of complex datasets. Advanced software development skills in at least two of the standard data

science languages (such as Python, R, Scala, C++, Julia) and strong data

manipulations skills (e.g. SQL, NoSQL, graph, etc.) Knowledge of SQL and relational databases, query authoring (SQL) and designing variety of databases (e.g. Postgres SQL) Comfortable working in cloud and high-performance compute environments (e.g. AWS, Apache Spark) Disciplined AI/ML deployment (MLOps, CI/CD) and Agile delivery Experience in coordination of delivery teams and providing feedback to their management Excellent written and verbal communication, business analysis, and consultancy skills Graph- Experience AI/ML modelling of complex datasets, network analysis or

direct experience in creating and maintaining graph data models. Experience

with a variety of graph technologies Knowledge of graph databases like Neo4J (Cypher, causal clusters), JanusGraph (Gremlin, GraphML), AWS Neptune, OrientDB. xpertise in machine learning/deep learning-based graph algorithms relevant to link prediction, ranking/recommendation, completion, community detection, node embedding, etc. Familiarity with Deep Learning, neural network architectures including CNNs,

RNNs, Embeddings, Transfer Learning, Attention-based Networks, Statistical

Learning, Restricted Boltzmann Machines (RBMs), Belief Networks, and

Reinforcement Learning Deep experience in developing models for private sector or industrial setting e.g. Lead data science area deliverables for digital products / programs / initiatives including the allocation of work within the team, monitors the quantitative and qualitative achievements of the team, and reports results Work as an individual contributor, providing data science expertise to digital

products / programs / initiatives. Apply in-depth experience with both statistical and modern data science

approaches, including unsupervised, supervised, regression algorithms. Apply advanced techniques such as neural networks, deep learning, NLP and federated learning. Build models, algorithms, simulations and experiments by writing highly

optimized code and using state-of-the art machine learning technologies. Collaborate cross-functionally in teams involved in data driven analytics to

maximize impact of graph-based capabilities Build and manage support models incorporated into digital or AI products; Work with Infrastructure and Ops teams to ensure appropriate architecture and tooling Capacity to mentor junior personnel Be able to apply in-depth experience with both statistical and modern data

science approaches to business cases and knowledge management tasks Strong written and verbal communication skills - ability to communicate complex ideas up to people of varying technical skills Work with developers, engineers, and MLOps to deliver AI/ML solutions for new products/services 
ScrapedJobID1070:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID1071:
Must be fluently bilingual in Spanish / English 3+ years of hands-on experience with Big Data ecosystem tools (e.g. Hive, Pig, Sqoop, Spark, Kafka) 3+ years of experience hands on with SQL & Python 2+ years of experience cleaning, transforming and visualizing large data sets working with various data formats (e.g. unstructured logs, XML, JSON, flat files, audio, image) Natural Language Processing Experience - preferably demonstrated in recent projects Solid SQL skills for querying relational databases (e.g. SQL Server, DB2, MySQL) 3+ years of experience with NoSQL databases (e.g., Hbase, Cassandra, Druid) Production experience with experimental design, statistical analysis, machine learning and predictive modeling (e.g. cross-sell, upsell, attrition, acquisition and lookalike models) Experience using and implementing visualization tools like PowerBI or Tableau Working experience with machine learning and other AI techniques for strategy design Monday to Friday machine learning: 1 year (preferred) Spanish (required) Temporarily due to COVID-19 
ScrapedJobID1072:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1073:
Develop the global business analytics strategy and action plan. Own the GFA Data and AI platform, define the data strategy and roadmap, drive platform integration with advisory assets, manage vendor data contracts and expansion of the platform to meet business needs. Establish and lead the global Analytics community of practitioners to drive adoption of data and analytics offerings within the practice, increase collaboration and sharing of analytics-oriented solutions on emerging client issues and best practices. Proactively engage with MF colleagues to communicate vision, create enthusiasm and followership, and assess progress related to analytics adoption. Supervise technology leads and product managers on the data platform expansion and predictive model development. Ensure development protocols and QRM policies are incorporated in the overall solution design. Lead discussions with DTTL procurement, Global Privacy, QRM, and vendors on data licenses, establish data governance, and access strategy in alignment with contracts. Collaborate with Deloitte Technology engagement and delivery leaders to articulate platform strategy and delivery approaches ensuring alignment and commitment. Build a dynamic team across delivery centers, member firms and Deloitte Technology to lead development and rollout of innovative analytics assets Facilitate discussions with stakeholders to ensure business needs and objectives are clearly understood and analytics solutions meet the expressed needs and expectations of the business. Communicate progress on a periodic basis to senior business leaders as requested. Build relationships and collaborate with peers and stakeholders across Global technology, MF business, and delivery centers. Bachelor’s or master’s degree in Computer Science, Information Systems or a related technical discipline. Certification in data science and cloud-based analytics technologies. 10+ years of related experience in leading analytics-oriented solutions. Experience in building and supporting a cloud hosted data platform for the business or service line, experience in advanced technologies including cloud analytics capabilities, AI, data science and engineering, NLP, NLG etc. Proficiency in business intelligence and data analytics tools including Tableau, Power BI, Alteryx, Azure Databricks, Azure Data Factory etc. Experience in software development methodologies such as SAFE, agile, etc. Ability to be a leader who is dynamic, proactive, and decisive, adapts well to change and ambiguity, has exceptional leadership and management skills to lead global virtual teams through influence Demonstrated proficiency in facilitating, delegating, and motivating cross functional groups or activities. Highly developed communications skills, motivational, team player, strategic and creative, excellent project management, and advanced MS Office skills. Able to communicate effectively in English with media and/or in front of large audiences; International experience preferred; important to have a strong network outside of home country through client engagements or roles. Willingness to travel internationally (2-4 times per year). Lead the way: Deloitte is not only leading the profession, but reinventing it for the future. We’re also committed to creating opportunity and leading the way to a more sustainable world. Serve with integrity: Deloitte has earned the trust of employees, clients, regulators, and the public for 175 years. Upholding that trust is our single most important responsibility. Take care of each other: We look out for one another and prioritize respect, fairness, development, and well-being. Foster inclusion: We are at our best when we foster an inclusive culture and embrace diversity in all forms. We know this attracts top talent, enables innovation, and helps us deliver well-rounded client solutions. Collaborate for measurable impact: We approach our work with a collaborative mind¬set, teaming across businesses, geographies, and skill sets to deliver tangible, measurable, attributable impact. 
ScrapedJobID1074:
real-time visibility on how Ubisoft titles are played; an understanding of the habits and preferences of the people playing them. Design, prototype, build and maintain APIs, tools, code and a scalable infrastructure for operating Merlin's machine learning pipeline at scale. Synch up with your team to discuss work-in-progress, ideas, and blockers; plan and prioritize; overcome issues; etc. Be a key member of the team, participate in the decisions and implementations to improve the platform’s quality. Work closely with Data Scientists to design and implement the optimal environment for their maximized efficiency. Advocate for automation and monitoring at all steps of the ML pipeline and help to define best practices based on personal industry experience and research. Stay current on technological advancements to help develop yourself, the platform and position Ubisoft as a leader of the domain. Experience in Software/Data engineering (or related experience). Experience with modern infrastructure, tools and cloud technology (e.g. AWS, EMR, Docker, Kubernetes, Terraform, etc.). Knowledge of Python, Java. Experience with big data technologies, like Kafka, S3, Spark, and Hive. Experience building and interacting with REST APIs. Familiar with GitLab and its CI/CD tool. A constant desire to grow and learn. Strong communication and collaboration skills. Ability to navigate between the big picture and the micro details. You love being responsible for owning and improving a new, fast-growing platform. You are curious and like asking questions until you fully understand why/what you are doing. A desire to see teammates succeed together. Experience with maintaining architectures for end-to-end Machine Learning in the cloud. Familiarity with industry standards such as MLFlow, Airflow... Knowledge of additional programming languages like Scala. Exposure to automated testing and CI/CD in the ML context. Good understanding of ML concepts. An understanding of the video game industry. Your CV, highlighting your background and skills 
ScrapedJobID1075:
BS, MS in Computer Science, or related technical discipline 5+ year’s experience in the marketing technology space Strong working knowledge of cloud warehouses such as BigQuery Experience with Azure Strong data engineering skills with distributed computing background and proven experience in delivering large scale data platforms · Good grasp of analytics, measurement, reporting, and business intelligence including modeling, insights generation and data science Hands-on technologist with deep expertise in big data eco-system for data integration, data storage, compute framework, analytics, and advanced visualization. (i.e. ETL Tools, Streaming Tools, No-SQL data bases, Spark, Reporting Tools, AI/ML Platforms) Hands-on experience in GA360, CRM platforms (Salesforce), and /or Customer Data Platforms (e.g. Amperity), and /or user and product analytics (GA, Adobe), and /or DSP Experience with Power BI, Tableau, SQL, and data programming languages Python and/or R required Certifications for any of the cloud services like Azure or any Machine Learning/Advanced Analytics Courses is an asset 
ScrapedJobID1076:
Problem Solver: You are curious and love exploring multiple approaches to find the most efficient, scalable solution and solve a problem Collaborative: You work well with other people Passionate: You have a passion for Big Data and an interest in the latest trends and developments constantly researching new tools and data technologies Self-starter: You are comfortable helping your team get things done Leadership: You can mentor the team on the design, and implementation of our solutions Design, implement, and create customized pipelines for ingestion that are robust using Kafka. Work with Terabytes of data and data aggregation. Identify, design, and implement system performance improvements Identify, design, and implement internal process improvements Automate manual processes and optimize data delivery Guide and mentor team members Identify and assess potential solutions for technical and business suitability Bachelor/Master degree in Data Science, Computer Science, Computer/Electrical Engineering or related field 7+ years of work experience in a software engineering environment Experience working in Agile methodologies 3+ years of work experience designing and building high performance data applications with Hadoop, Spark, Kafka, Hive or other equivalent technologies Proficiency in some of the following languages: Scala, Java, Python, Bash Deep understanding of design principles of distributed systems and familiar with mainstream big data related technologies and distributed frameworks Experience with SQL and NoSQL systems Experience with automated testing systems Mentorship, collaboration, and communication skills Knowledge of data modelling, data warehousing, ETL processes, and business intelligence reporting tools Experience optimizing performance with large data sets Experience working with CI/CD, containerization, and virtualization tools such as Gitlab, Jenkins, Kubernetes, Docker Comprehensive health, dental, and vision plans at no cost to you Time off and flexible work schedules Retirement plan with a 5% company match Stock options and equity packages Generous parental leave Monthly wellness stipend plus fitness discounts and quarterly wellness group activities Home office stipend Community engagement opportunities and donation-matching program Annual virtual company retreats and regular community-led team events COVID-19 guidance: We have re-opened offices in various cities following local guidelines, but are continuing to maintain a flexible work environment. 
ScrapedJobID1077:
Design and build large and complex data sets, from spurious sources while thinking strategically about uses of data and how data use interacts with data design. Design and implement statistical data quality procedures for new data sources. Communicate findings to business leaders in a way that can influence how an organization approaches a business challenge Develop algorithms/software for accessing and handling data appropriately. Implement and hand off data checking and updating procedures to teams. Visualize and report data findings creatively in a variety of visual formats that appropriately provides insights to the organization. Train others on what data is available and how to use various sources Previous Telecommunications data analysis experience is an asset; emphasis on location data and time series analytics Master’s Degree (or higher) in Computer Science, Statistics, Applied Math, Engineering or other quantitative field; With a solid foundation in modeling, statistics, analytics and math Minimum of 5 years of hands-on data analytics experience in a corporate environment; Comfortable working with large, complex data sets from varying sources; Experience in team leadership. Highly motivated with the ability to work on a multiple projects simultaneously; Team player, creative, entrepreneurial, willing to experiment, persistent and structured. Working with structured and unstructured data sets;
Leading analytics projects to support the strategic product direction, sales and customer efforts;
Performing hypothesis testing and develop predictive model;
Evaluating and providing input on potential business intelligence solutions.
Applying statistical principles to data analytics;
Comfortable in statistical analysis, clustering and data mining techniques to identify trends and insights
Developing end-end to models/ projects and automation in production environment. Leading analytics projects to support the strategic product direction, sales and customer efforts; Performing hypothesis testing and develop predictive model; Evaluating and providing input on potential business intelligence solutions. Applying statistical principles to data analytics; Comfortable in statistical analysis, clustering and data mining techniques to identify trends and insights Developing end-end to models/ projects and automation in production environment. Thorough understanding of relational database design; High proficiency in SQL. Fluent programming in Python, Hive, or SAS Extensive experience in Google Cloud Platform, BigQuery, JupyterLab, docker container and workspace set up. Knowledgeable about common supervised and unsupervised Machine Learning approaches (eg. feature engineering, classification, regression, clustering, NLP, time series forecasting, etc. "Tensorflow”, “Deep Learning” and synthetic tabular data generation is a strong asset. 
ScrapedJobID1078:
Square Enix Montréal est à la recherche d’un·e Analyste en chef, passionné·e par les jeux et l’expérience utilisateur, pour prendre en charge l’activité analytique sur l’un des jeux mobiles en cours de développement au sein de la division mobile de Square Enix West. Rôle de leadership au sein de l'équipe de production : porter et déployer la vision BI et analytique au sein du projet, participer à l'amélioration continue des processus décisionnels, éduquer les équipes de productions et de marketing sur ce qu’il est possible de faire au niveau analytique et data science. Manager un·e Data Analyst Junior déjà en place : coordonner les tâches et priorités coté BI en interaction avec l’équipe du jeu (Product Manager, Game Designer, etc); Participer à la mise en place de bonnes pratiques et à la création de processus et produits transverse à l’ensemble des équipes BI en production Définir les spécifications de la collecte d'information et apporter du support aux programmeurs lors de l'implémentation du système de collecte de données; Participer au processus de vérification de qualité des données en collaboration avec l'équipe QA; Créer des modèles analytiques, tableaux de bord et rapports d'analyse personnalisés; Présenter, sous forme de storytelling, les insights générés au travers des analyses, à tout type d'audience; Fournir des recommandations opérationnelles en termes de design et de monétisation; Diplôme universitaire en statistiques, mathématiques, génie informatique, génie logiciel ou l’équivalent; 5+ années d’expérience en tant qu’analyste de données, idéalement en partie dans le domaine du jeu mobile; Maitrise du SQL, Python est un plus; Maitrise du Data Mining et des statistiques; Excellente maitrise de l’analyse de données et de la génération d’insights impactants; Maitrise d’outils de Reporting (Looker, Tableau, PowerBI, Amplitude ou équivalent); Maitrise des systèmes de collection de données de type Events; Bonne connaissance des systèmes de base de données dans le cloud BigQuery, Snowflake, Redshift ou équivalent; Expérience en coaching et mentoring est un plus; Connaissance des plateformes analytiques comme Amplitude, deltaDNA, Mixpanel etc. est un plus. Capacité à résoudre des problèmes complexes; Grande habileté pour expliquer des phénomènes complexes de façon claire et complexe à tout type d’audience (anglais et français) Rigoureux et précis; Axé sur l’impact opérationnel, débrouillard et capable de prendre de l’initiative; Être capable de s’adapter dans un environnement où les priorités peuvent changer régulièrement; De l’ambition et de la passion pour les jeux vidéo mobiles sont essentielles! Square Enix Montréal is looking for a Lead Data Analyst, passionate about games and user experience, to take charge of the analytical activity on one of the mobile games under development within the mobile division of Square Enix West. Leadership role within the production team: carry and deploy the BI and analytical vision within the project, participate in the continuous improvement of decision-making processes, educate the production and marketing teams on what is possible to do at the analytical and data science level. Manage a junior data analyst already in place: coordinate tasks and priorities on the BI side in interaction with the game team (product manager, game designers, etc.); Participate in the implementation of best practices and the creation of processes and products across all BI teams in production Define the specifications of the information collection and provide support to programmers during the implementation of the data collection system; Participate in the data quality verification process in collaboration with the QA team; Create analytical models, dashboards and personalized analysis reports; Present, in the form of storytelling, the insights generated through analyzes, to any type of audience; Provide operational recommendations in terms of design and monetization; University degree in statistics, mathematics, computer engineering, software engineering or equivalent; 5+ years of experience as a data analyst, ideally partly in the field of mobile gaming; Proficiency in SQL, Python is a plus; Mastery of Data Mining and statistics; Excellent knowledge of data analysis and the generation of impactful insights; Proficiency in reporting tools (Looker, Table, PowerBI, Amplitude or equivalent); Mastery of Events type data collection systems; Good knowledge of BigQuery, Snowflake, Redshift or equivalent cloud database systems; Coaching and mentoring experience is a plus; Knowledge of analytical platforms such as Amplitude, deltaDNA, Mixpanel etc. is a plus. Ability to solve complex problems; Great ability to explain complex phenomena in a clear and complex manner to any type of audience (English and French) Rigorous and precise; Operational impact oriented, resourceful and able to take initiative; Be able to adapt in an environment where priorities can change regularly; Ambition and passion for mobile video games are essential! 
ScrapedJobID1079:
Bonus pay Commission pay Casual dress Flexible schedule Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? or Are you willing to relocate? Yes 
ScrapedJobID1080:
Assist with the design, development, implementation and maintenance of complex data systems and solutions both on premise as well as in the cloud using Azure / AWS/ Google Understanding how data is used to drive business outcomes Defining the data architecture framework, standards and principles, including modeling, metadata, security, master data such as clients, vendors, and product codes Defining data flows capturing which parts of the organization generate data, which require data to function, how data flows are managed, and how data changes in transition Migrate data from legacy systems to new technology solutions Design conceptual and logical data models and flowcharts Develop control structures to ensure the accuracy and quality of data as it flows from source systems to users Finding and implementing creative solutions for data quality and coverage issues Helping establish data governance programs that take into account data volume / coverage, data quality, tools, integration, acquisition of new sources, flows and pipelines, regulatory considerations Partnering to identify and define key business terms, rules, quality requirements, critical data elements, KPI’s and encouraging consistency across the enterprise Bachelor’s degree in computer science, engineering, business, finance or a related area of study 9+ years’ experience as a Data Modeler/ Data Architect, in an integrated business and IT collaborative environment. Excellent analytical and problem-solving skills Extreme attention to detail Good process mapping skills Strong knowledge of data modelling, data quality & data governance best practices and tools Experience with waterfall and agile methodologies Ability to build a sense of trust and rapport with the team and partners A self-starter attitude, a strong desire to learn as you go, and the belief that you can make a meaningful contribution to your immediate team, the business users that you serve, and to the organization 
ScrapedJobID1081:

ScrapedJobID1082:
Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. AWS Cloud (certification is an asset) AWS services like AWS glue or other AWS services Python programming language. Big Data technologies (like a Spark, hive/HDFS, PySpark, Hadoop) SQL and NoSQL databases, including Postgres and Cassandra. Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. AWS cloud services: EC2, EMR, RDS, Redshift Stream-processing systems: Storm, Spark-Streaming, etc. Object-oriented/object function scripting languages: Java, C++, Scala, etc. 
ScrapedJobID1083:
Manage and contribute to the delivery of reporting and analytics solutions, mainly in Looker Understand business needs and technical requirements to meet those needs Lead and develop your team of analysts Set and achieve challenging goals for yourself and your team (OKRs) Foster a culture of data-driven decision making throughout the company Keep up with the latest data industry tools and techniques Top-notch communication (verbal and written) and interpersonal skills Excellent math and statistical analysis skills Proficiency in the presentation and visualization of numbers and statistical data Ability to understand business imperatives and drivers, find relevant data correlations, and create processes by which the data correlations are translated to information flows that help drive the business 5+ years developing and coaching analytics teams 5+ years of quantitative analysis work experience 5+ years of experience handling, manipulating and analyzing data and creating analytical reports Strong expertise with an SQL language, database structures, and data lake architectures Experience with Looker Experience with Snowflake Proficiency with Python An understanding of the principles, tools, and processes of data science Post-secondary education in a technical field, or B.S./M.S. 
ScrapedJobID1084:
Linux GPU driver development in support of Machine Learning and Data Centre applications Contributes to software projects of significant technical importance Solves sophisticated non-recurring problems that leads to development and implementation Debug, analyze and resolve quality and certification issues as reported by Customers and QA Write detailed design notes for new features Coordinate closely with peers and colleagues to ensure timely and effective communication of all assigned work activities Coordinate with developers in the open-source development community Proficient in C and C++ programming Excellent debugging and trouble-shooting skills Strong general Linux systems administration, software development, and troubleshooting knowledge and experience. Linux kernel development experience, either core kernel development or device driver development. PC architecture knowledge Strong oral and written communication skills Experience with Linux containers kernel level implementation (cgroups, namespaces) Familiarity with Linux networking and network/cluster management Familiarity with Linux GPU driver development (kernel and user-mode), ideally on AMD hardware. Familiarity with compute, graphics, or multimedia GPU application development using APIs such as OpenCL, OpenGL, and VAAPI. Proven track record of contributions to open-source projects Familiarity with Linux security subsystems such as selinux and/or AppArmor Bachelor's degree or Master’s in Computer Science or related degree with validated experience 
ScrapedJobID1085:
Overseeing the development of software to clean and investigate large, messy data sets of numerical and textual data Networking with various teams to explore internal and external data sources and APIs to help uncover new trends and improve analysis Designing and contributing to highly scalable data pipelines, tools, and products to enable the analyst community to fully leverage the power of AWS Working with your team to analyze large swaths of data in order to optimize various business programs Managing and developing talent to drive a highly performant and engaged team Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, you’re not afraid to blurt out your disruptive idea. You know how the latest tech works, yet you are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. Crafty: You know how to get things done. You can navigate a large organization, motivate people, and influence your peers. Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Inspiring: You have a passion for developing people and take great pride in your management system. You know how to deliver through others while paving the way for their growth. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook and all the monitors you want! You can travel to a relevant conference of your choice annually - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours, dress code and environment Bachelor’s Degree in a quantitative field At least 5 year of experience in open source programming languages for large scale data analysis (Python, Scala, or Java) At least 5 year of experience with version control system like Git and GitHub. At least 5 year of experience with relational databases and programming in SQL At least 2 years in lead positions (managing people/owning products/architecting and driving an agenda) Master’s Degree or PhD Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) Experience with CICD tools Experience with Machine Learning workflows 5+ years experience in Python 5+ years’ experience with SQL 3+ years in lead positions (managing people/owning products/architecting and driving an agenda) 
ScrapedJobID1086:
You'll play a pivotal part in informing and delivering upon our data strategy, by providing sales and marketing performance data, creating custom dashboards and visualization, and supporting marketing and financial strategies Providing Advance analytical insights to the team and help them improve marketing strategies Provide technical leadership to internal team members and various stakeholders Operationalize and support our underlying data systems, improving our system reliability, accuracy and stability You are analytical and outcome-oriented with a proven ability to translate technical considerations into business implications as well as to synthesize data into actionable insights You are well-versed with Business Intelligence/ Market Intelligence processes and other marketing technologies You have demonstrated the ability to successfully deliver complex projects involving people, process, technology, and change management You have experience with agile ways of working and a bias for action to break down barriers to get results fast with a test and learn mindset You can assemble large complex datasets across multiple databases and sources by building automated pipelines (ETL) Strong analytic skills related to working with unstructured datasets. Strong Business Acumen Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. SAS knowledge Business Intelligence/ Market Intelligence processes and other marketing technologies understanding Technical or data-driven educational background (computer science, engineering, statistics, data science) and/or Masters of Business Administration (MBA) degree 5+ years of progressive and relevant work experience Takes ownership, initiates improvements, and is self-directed Able to effectively engage stakeholders to establish cross functional alignment for projects Prior telecommunications expertise B2B marketing Python experience Hive / Spark / Nifi experience Experience with cloud (GCP Amazon or Azure) Data Science / Modeling experience or working in a Data Science team 
ScrapedJobID1087:
Leads and drives a customer focused culture throughout their team to deepen client relationships and leverage broader Bank relationships, systems and knowledge. Support development of Analytic tools such as SOFIA to enable Portfolio Management efforts Ensures data flows are designed and tested to capture accurate and reliable information from source systems on a timely basis Acts as a subject matter expert for Commercial Banking data such as Salesforce, Loan and Deposit systems, HR data, EFT etc. Participates in working sessions with key stakeholders to ensure solutions provided are efficient and optimal for users Facilitate monitoring of results and benefits from the Analytic tools Provides leading edge solutions to Business Banking stakeholders on Business Intelligence/Analytics Proactively implements leading edge business intelligence tools for MIS (e.g. Tableau, Power BI) Ensures appropriate infrastructure is in place for Business Banking teams to access reports on an on-demand basis (e.g. through Salesforce) Explores new business intelligence tools and infrastructure in the industry on an ongoing basis to provide best in class Business Intelligence solutions Ensures ongoing improvements in automation and process improvements to cut down cycle time for report generation and availability Supports Analytics and Business Intelligence to drive sales effectiveness, client advocacy, pricing, product development, financial planning, AML and compliance needs and mandate for Business Banking Ensures Sales teams and Business Bank leadership teams have appropriate amount of drill down capability to measure and manage their portfolios/business performance Manages key stakeholder relationships in relation to delivery of Business intelligence and Analytics Works collaboratively with members of the Commercial Analytics, Data Science and Analytics team in CID&A and GRM, IT&S, Salesforce and other teams to develop data infrastructure, Business Intelligence and Analytic solutions Works proactively with development teams in Salesforce and other areas to improve infrastructure required to enhance efficiencies for end users and for the Analytics teams Understands how the Bank’s risk appetite and risk culture should be considered in day-to-day activities and decisions. Creates an environment in which his/her team pursues effective and efficient operations of his/her respective areas in accordance with Scotiabank’s Values, its Code of Conduct and the Global Sales Principles, while ensuring the adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with respect to operational, compliance, AML/ATF/sanctions and conduct risk. Builds a high-performance environment and implements a people strategy that attracts, retains, develops and motivates their team by fostering an inclusive work environment; communicating vison/values/business strategy and managing succession and development planning for the team. Develops team expertise in data mining and strong analytics capabilities Bachelor's Degree in Computer Science, Finance, Economics or Statistics Master’s degree in Computer Science – preferred 3+ years of data engineering and software experience 3+ years’ experience in Data Visualization, Business Intelligence using Tableau and/or Power BI 3+ years experience in building data pipelines and/or data warehousing Enjoy discovering and learning new technologies Detailed experience in the following: Unix, Mainframe, SQL, SAS, Python other programming tools Experience accessing, compiling and analyzing large volumes of data into usable form Excellent verbal and written communication skills are required Strong prioritizing, analytical, presentation, project management and planning skills Effective strategic thinking, organizational know-how and influencing skills are critical for success High degree of knowledge of commercial products and profit drivers The role requires a high degree of collaboration across wide ranging groups: CID&A, GRM Analytics, Global Banking & Markets (GBM); GBP; Finance, Wealth Management, Retail Small Business, and various Commercial Banking areas. Works with various partners using influence and negotiation skills to ensure objectives are met. Strong technical skills in Math, Computer Science or related fields Excellent design and delivery capabilities Ability to work non-standard work hours as required 
ScrapedJobID1088:
collaborate with Product and other engineers to define, design, and build platform and web applications contribute across the entire software development lifecycle, including requirements definition, design, development, testing, deployment, and operations be a technical leader in your squad, helping to drive technical decisions, prioritizations, and tradeoffs mentor / guide other engineers and help improve technical and other practices within the squad Collaborate cross-functionally with Product Managers, Designers, and other engineers, including Machine Learning, Front-End/Full Stack, DevOps, and QA Leverage your knowledge to design, build, and deliver scalable and resilient software Drive technical decisions, prioritizations, and tradeoffs within the squad Creatively solve functional challenges with the Product team even when the initial answer is not fully defined Creatively solve technical challenges in the face of competing tradeoffs Design easy-to-use interfaces that will be leveraged by other developers, including APIs for 3rd-party developers Ensure product quality and code quality by writing automated tests and performing thorough code reviews and design reviews Minimum 5 years of experience solving backend software engineering challenges Experience in building enterprise-grade systems and scalable distributed systems Proven technical leadership abilities Proven mentorship and ownership abilities Strong ability to reason about engineering approaches to a problem Strong software architecture and design experience Comfortable learning and implementing new technologies Experience with database systems, including SQL and/or NoSQL solutions Track record of shipping high-quality code Experience in an Agile and DevOps environment Within your first 30 days: You will get acquainted and eventually be fully comfortable navigating the full codebase, the technology stack, the development processes and org structure within the company. You will learn the product and will make your first significant, user-impacting contributions to one of our products. You will get to know our ML domain, codebase, and practical applications. Within your first quarter and beyond: You will be an integral part of the team and a driven, focused self-starter who can navigate a certain amount of ambiguity, and who is not afraid to take a sizable chunk of functionality, analyze it, break it down, implement it and then assume ownership and responsibility over it. You will be taking an active role in discussions about possible solutions, different approaches, API designs and more. Top notch medical and dental coverage for you and your family 30 days of paid leave annually to help nurture work-life symbiosis Stock options Wellness stipend Pre-tax transportation and commuter benefits 6-month parental leave (or double salary to pay for your partner's unpaid leave) Free travel for any person accompanying a breastfeeding mother and her baby on a business trip A dependent care stipend up to $3,000 (USD) per month, per child, under the age of 21 for a maximum of $6,000 (USD) per month total Budget to attend conferences, train, and further your education $1,250 (CAD) one-time-use WFH stipend and $95 (CAD) monthly WFH stipend Relocation assistance 
ScrapedJobID1089:

ScrapedJobID1090:
Operate as a thought leader and visionary, with the ability to guide, influence and inspire peak performance, innovation and adoption of AI-enabled technologies across the Axon value chain Grow and lead a world-class team of research scientists that deliver novel, strategic AI solutions with diverse, industry-leading skills in deep learning, computer vision, natural language processing and more Collaborate with tech and product teams on sourcing data and model building strategies from experimentation and implementation to deployment and continuous improvement Bring your industry, research expertise and deep knowledge of the state-of-the-art in your field to challenge existing assumptions and introduce new machine learning algorithms, statistical approachers and training workflows Develop a collaborative and inclusive team that fosters a culture of ownership, experimentation, and innovation while joining forces with product teams to deliver working solutions for our Customers A Ph.D. Degree in Computer Science, Machine Learning, Statistics, Applied Mathematics or an equivalent highly technical field 7+ years of modeling experience in one or more the following areas: Natural Language Processing/Understanding (NLP/NLU), Computer Vision (CV) and Acoustic Event Detection 4+ years in a leadership/management role; with a solid track record capable of building and leading science teams Hands on experience developing, scaling and implementing machine learning using relevant programming languages (such as Python), state of the art deep learning frameworks and big data tools Working knowledge of advanced ML techniques: Multi-task Learning, Transfer Learning, Reinforcement Learning as well as Unsupervised and Semi-supervised Learning Track record of publications and contributions to the machine learning community at large Experience with designing and shipping software products that leverage machine learning at scale Excellent problem solving skills and ability to dive into learning algorithms, evaluation metrics, model architecture, code, test plans, project plans, deployments and operations Comfort communicating and interacting with scientists, engineers and product managers as well as understanding and translating the science of AI and Machine Learning to a more general audience 9+ years of modeling experience in the areas of NLP, CV, Sensor Fusion and Acoustic Event Detection Demonstrated knowledge and experience with distributed machine learning and deploying models at scale in cloud environments (such as AWS, Microsoft Azure and Google Cloud) Familiarity with IoT/Edge AI and optimizing ML models to run on-device with constrained compute, power and latency budgets Previous Experience leading multiple geographically distributed teams Competitive salary and 401K with employer match Discretionary paid time off Robust parental leave policy An award-winning office/working environment Ride along with police officers to see them use our technology and get inspired And more... 
ScrapedJobID1091:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1092:
Develop & implement advanced analytics roadmap (40%) Create and own the roadmap for advanced analytics use cases by securing buy-in across all stakeholders and ensuring alignment with the business’s top priorities and expected outcomes, assess progress and recalibrate when required Manage these advanced analytics projects and pipeline. Run multiple projects, oversee prioritization and ensure projects are aligned with strategic priorities Prepare presentation materials as required and support in the presentation of opportunities to VPs, SVPs and CEO Own ongoing evaluation of appropriate partners, tools, methodologies and analytical techniques to ensure that our measurement solutions are most complete, integrated, advanced and on par with latest industry trends Apply analytical thought leadership to problem solving (30%) Assess and diagnose information needs, design and define suitable analytical solutions to generate meaningful insights that address business problems Present key insights and recommendations based on research and data analysis Own forecasting for customer & deposit growth Use quantitative methods (i.e., Excel models) to develop insights that support decision making on new products & initiatives Use SQL to source necessary data for ongoing understanding of customer behaviour and to support internal consulting projects Develop familiarity with internal systems & processes, and gather relevant data from various internal sources Establish repeatable processes / methodology that enable quicker turnaround on analysis Brainstorm, structure and create problem solving processes for a range of strategic and tactical customer-facing topics (e.g., identifying fraud applications, cross-selling mortgages, features on prepaid card, digital ID solutions, etc.) Enable ongoing understanding of customers through design and maintenance of executive dashboards and metrics Perform ad-hoc analysis for various business units Manage cross-functional collaboration & team development (30%) Facilitate cross-functional collaboration by leading a diverse team of analytics resources to deliver quality analysis, interpretation of findings and clear articulation of results and insights to internal business partners Support Payments in assessing product features and customer needs to determine prioritization of features for Minimum Viable Product (MVP) and future build Support Product in assessing performance & developing better understanding of customer adoption through A/B testing Support Marketing, Customer Experience (CX) and Contact Center in planning & evaluating marketing campaigns and meeting their customer insights needs Support Fraud & AML by optimizing rule performance and improving customer experience Potentially manage 1 – 3 direct reports, including skills development, mentoring, career growth through regular structured and ad-hoc feedback 8+ years’ work experience in Analytics, Strategy, Data Science roles, ideally in Financial services Bachelor’s degree in Engineering, Computer Science, Commerce, Management. MBA or other graduate degree a plus Minimum 4 years of people management experience Strong business acumen and passion for understanding and solving problems for consumers of financial services using rigorous data-driven methods and advanced analytical approaches Subject Matter expert at building, modifying, and running Excel based business scenarios and predictive models (able to teach others) Experience synthesizing analyses and preparing power point presentations for C-Suite level executives or Board of Directors Strong understanding of the financial services landscape, particularly with respect to retail banking, card programs, and marketing analytics Experience, confidence, and maturity managing internal stakeholders across all levels of the organization, including VPs, SVPs, and CEO Experience leading projects and managing tasks of more junior team members, as well as supporting their growth and development Expert in MS Office (Excel, Access, PowerPoint), MySQL, Tableau, Python / R, and statistics (regression analysis, correlations, etc.) Strong attention to detail and time management skills Good verbal and written communication skills Project management experience 
ScrapedJobID1093:
Lead the team responsible for driving AI/ML adoption across Rogers Establish data science as a discipline and drive adoption of the data enablers across the organization Work across Rogers technology and business teams to further develop the AI/ML vision and strategy that outlines a target operating model and roadmap to maximize the value of information assets via their creation, access and use. Develop the technology, tools and enablers that will deliver the desired business outcomes. Establish frameworks and policies around use of AI/ML at Rogers, in particular ethics framework. Develop and deliver ML algorithms and data science approaches for the business Establish strategic industry partnerships to drive innovation Deliver ML Ops and guard rails for deployment to ensure consistent use of AI across Rogers and align to security and data standards Manage onboarding of talent, serve as a talent pipeline by establishing onboarding and skilling journeys Bachelor’s degree in Computer Science, Engineering, Data Science, Applied Mathematics or a related field Extensive experience working with data technologies, including pipelines, data lakes, data warehouse, analytics tools, machine learning, visualization and business intelligence Experience developing and deploying AI/ML models to address specific industry challenges Understanding of cloud, data, security and AI/ML and ML Ops with proven experience establishing strategy and frameworks to drive adoption and solid understanding of data security and privacy Collaborative by nature and comfortable running a COE model and shared services Experience developing business cases and strategy and an ability to drive strategy through to execution and operations Large program delivery experience, working across different teams and organization Proven leader with ability to motivate a team to achieve outstanding results Extraordinary team player that thrives in a fast-paced environment where quality, innovation, speed of decision making and execution are critical to organizational success Supports and strengthens the corporate brand and company culture Executive presence, with the ability to navigate difficult situations and build relationships via persuasive negotiator skills Brings a high degree of initiative, is able to work in an ever changing environment, and is able to manage ambiguity and relentless focus on prioritizing and balancing multiple stakeholder goals Our people are at the heart of our success Our customers come first. They inspire everything we do We do what’s right, each and every day We believe in the power of new ideas We work as one team, with one vision We give back to our communities and protect our environment 
ScrapedJobID1094:
By delivering an award-winning product, conceptualized and developed by award-winning leaders, that result in award-winning customer employee experiences By hiring highly innovative, diverse talent that fully embraces and embodies our core values in everything they do: Customer Focus, Equity, Shared Ambition, Agility, Transparency, Optimism By using modern technology, such as voice-activation with Dayforce Assistant and access to your money as soon as you earn it with Dayforce Wallet to stay in rhythm with the evolving demands of our 4 million global users As a ML Engineer, you join a high performing agile team, responsible for building new models, updating current modules, and adding new features to our products, as well as other duties as assigned. The selected candidate will have prior experience with ML deployment, Python, and have used Linux or Git. Prior SQL knowledge is also desired. Our machine learning team works on challenging problems related to text mining, predictive model building and validation, data normalization and other data science activities. Your impact will be evident through your effective participation in the entire lifecycle of our software including design, analysis, prototyping, development, testing and support of our products. You will work closely and collaborate with implementation partners, to envision and deliver the required functionality. Encouragement to be the best version of yourself at and away from work: YOUnity diversity and inclusion programs Amazing time away from work programs Support for your total well-being through our Live Well, Work Well programs targeting all aspects of your life Recognition for your contributions through excellent pay, perks, and rewards Giving where you’re living: volunteer days, Ceridian sponsored events, and our very own charity, Ceridian Cares Opportunities to fuel your career growth through numerous internal and external programs and events Expertise in building and configuring production-ready machine learning systems. Expertise in using machine learning libraries in Python, or similar. Experience with complex SQL using PostgreSQL, or similar. Experience in consuming and building APIs in Node.js, Python, or similar. A passion for software development that often extends beyond your work An understanding of Linux systems A high level of comfort using Git and Github A desire to learn new technologies and techniques Nice to have: projects or contributions on github we can see 
ScrapedJobID1095:
Develop the global business analytics strategy and action plan. Own the GFA Data and AI platform, define the data strategy and roadmap, drive platform integration with advisory assets, manage vendor data contracts and expansion of the platform to meet business needs. Establish and lead the global Analytics community of practitioners to drive adoption of data and analytics offerings within the practice, increase collaboration and sharing of analytics-oriented solutions on emerging client issues and best practices. Proactively engage with MF colleagues to communicate vision, create enthusiasm and followership, and assess progress related to analytics adoption. Supervise technology leads and product managers on the data platform expansion and predictive model development. Ensure development protocols and QRM policies are incorporated in the overall solution design. Lead discussions with DTTL procurement, Global Privacy, QRM, and vendors on data licenses, establish data governance, and access strategy in alignment with contracts. Collaborate with Deloitte Technology engagement and delivery leaders to articulate platform strategy and delivery approaches ensuring alignment and commitment. Build a dynamic team across delivery centers, member firms and Deloitte Technology to lead development and rollout of innovative analytics assets Facilitate discussions with stakeholders to ensure business needs and objectives are clearly understood and analytics solutions meet the expressed needs and expectations of the business. Communicate progress on a periodic basis to senior business leaders as requested. Build relationships and collaborate with peers and stakeholders across Global technology, MF business, and delivery centers. Bachelor’s or master’s degree in Computer Science, Information Systems or a related technical discipline. Certification in data science and cloud-based analytics technologies. 10+ years of related experience in leading analytics-oriented solutions. Experience in building and supporting a cloud hosted data platform for the business or service line, experience in advanced technologies including cloud analytics capabilities, AI, data science and engineering, NLP, NLG etc. Proficiency in business intelligence and data analytics tools including Tableau, Power BI, Alteryx, Azure Databricks, Azure Data Factory etc. Experience in software development methodologies such as SAFE, agile, etc. Ability to be a leader who is dynamic, proactive, and decisive, adapts well to change and ambiguity, has exceptional leadership and management skills to lead global virtual teams through influence Demonstrated proficiency in facilitating, delegating, and motivating cross functional groups or activities. Highly developed communications skills, motivational, team player, strategic and creative, excellent project management, and advanced MS Office skills. Able to communicate effectively in English with media and/or in front of large audiences; International experience preferred; important to have a strong network outside of home country through client engagements or roles. Willingness to travel internationally (2-4 times per year). Lead the way: Deloitte is not only leading the profession, but reinventing it for the future. We’re also committed to creating opportunity and leading the way to a more sustainable world. Serve with integrity: Deloitte has earned the trust of employees, clients, regulators, and the public for 175 years. Upholding that trust is our single most important responsibility. Take care of each other: We look out for one another and prioritize respect, fairness, development, and well-being. Foster inclusion: We are at our best when we foster an inclusive culture and embrace diversity in all forms. We know this attracts top talent, enables innovation, and helps us deliver well-rounded client solutions. Collaborate for measurable impact: We approach our work with a collaborative mind¬set, teaming across businesses, geographies, and skill sets to deliver tangible, measurable, attributable impact. 
ScrapedJobID1096:
Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. AWS Cloud (certification is an asset) AWS services like AWS glue or other AWS services Python programming language. Big Data technologies (like a Spark, hive/HDFS, PySpark, Hadoop) SQL and NoSQL databases, including Postgres and Cassandra. Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. AWS cloud services: EC2, EMR, RDS, Redshift Stream-processing systems: Storm, Spark-Streaming, etc. Object-oriented/object function scripting languages: Java, C++, Scala, etc. 
ScrapedJobID1097:
Manage and contribute to the delivery of reporting and analytics solutions, mainly in Looker Understand business needs and technical requirements to meet those needs Lead and develop your team of analysts Set and achieve challenging goals for yourself and your team (OKRs) Foster a culture of data-driven decision making throughout the company Keep up with the latest data industry tools and techniques Top-notch communication (verbal and written) and interpersonal skills Excellent math and statistical analysis skills Proficiency in the presentation and visualization of numbers and statistical data Ability to understand business imperatives and drivers, find relevant data correlations, and create processes by which the data correlations are translated to information flows that help drive the business 5+ years developing and coaching analytics teams 5+ years of quantitative analysis work experience 5+ years of experience handling, manipulating and analyzing data and creating analytical reports Strong expertise with an SQL language, database structures, and data lake architectures Experience with Looker Experience with Snowflake Proficiency with Python An understanding of the principles, tools, and processes of data science Post-secondary education in a technical field, or B.S./M.S. 
ScrapedJobID1098:
Linux GPU driver development in support of Machine Learning and Data Centre applications Contributes to software projects of significant technical importance Solves sophisticated non-recurring problems that leads to development and implementation Debug, analyze and resolve quality and certification issues as reported by Customers and QA Write detailed design notes for new features Coordinate closely with peers and colleagues to ensure timely and effective communication of all assigned work activities Coordinate with developers in the open-source development community Proficient in C and C++ programming Excellent debugging and trouble-shooting skills Strong general Linux systems administration, software development, and troubleshooting knowledge and experience. Linux kernel development experience, either core kernel development or device driver development. PC architecture knowledge Strong oral and written communication skills Experience with Linux containers kernel level implementation (cgroups, namespaces) Familiarity with Linux networking and network/cluster management Familiarity with Linux GPU driver development (kernel and user-mode), ideally on AMD hardware. Familiarity with compute, graphics, or multimedia GPU application development using APIs such as OpenCL, OpenGL, and VAAPI. Proven track record of contributions to open-source projects Familiarity with Linux security subsystems such as selinux and/or AppArmor Bachelor's degree or Master’s in Computer Science or related degree with validated experience 
ScrapedJobID1099:
Overseeing the development of software to clean and investigate large, messy data sets of numerical and textual data Networking with various teams to explore internal and external data sources and APIs to help uncover new trends and improve analysis Designing and contributing to highly scalable data pipelines, tools, and products to enable the analyst community to fully leverage the power of AWS Working with your team to analyze large swaths of data in order to optimize various business programs Managing and developing talent to drive a highly performant and engaged team Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, you’re not afraid to blurt out your disruptive idea. You know how the latest tech works, yet you are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. Crafty: You know how to get things done. You can navigate a large organization, motivate people, and influence your peers. Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Inspiring: You have a passion for developing people and take great pride in your management system. You know how to deliver through others while paving the way for their growth. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook and all the monitors you want! You can travel to a relevant conference of your choice annually - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours, dress code and environment Bachelor’s Degree in a quantitative field At least 5 year of experience in open source programming languages for large scale data analysis (Python, Scala, or Java) At least 5 year of experience with version control system like Git and GitHub. At least 5 year of experience with relational databases and programming in SQL At least 2 years in lead positions (managing people/owning products/architecting and driving an agenda) Master’s Degree or PhD Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) Experience with CICD tools Experience with Machine Learning workflows 5+ years experience in Python 5+ years’ experience with SQL 3+ years in lead positions (managing people/owning products/architecting and driving an agenda) 
ScrapedJobID1100:
You'll play a pivotal part in informing and delivering upon our data strategy, by providing sales and marketing performance data, creating custom dashboards and visualization, and supporting marketing and financial strategies Providing Advance analytical insights to the team and help them improve marketing strategies Provide technical leadership to internal team members and various stakeholders Operationalize and support our underlying data systems, improving our system reliability, accuracy and stability You are analytical and outcome-oriented with a proven ability to translate technical considerations into business implications as well as to synthesize data into actionable insights You are well-versed with Business Intelligence/ Market Intelligence processes and other marketing technologies You have demonstrated the ability to successfully deliver complex projects involving people, process, technology, and change management You have experience with agile ways of working and a bias for action to break down barriers to get results fast with a test and learn mindset You can assemble large complex datasets across multiple databases and sources by building automated pipelines (ETL) Strong analytic skills related to working with unstructured datasets. Strong Business Acumen Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. SAS knowledge Business Intelligence/ Market Intelligence processes and other marketing technologies understanding Technical or data-driven educational background (computer science, engineering, statistics, data science) and/or Masters of Business Administration (MBA) degree 5+ years of progressive and relevant work experience Takes ownership, initiates improvements, and is self-directed Able to effectively engage stakeholders to establish cross functional alignment for projects Prior telecommunications expertise B2B marketing Python experience Hive / Spark / Nifi experience Experience with cloud (GCP Amazon or Azure) Data Science / Modeling experience or working in a Data Science team 
ScrapedJobID1101:
Leads and drives a customer focused culture throughout their team to deepen client relationships and leverage broader Bank relationships, systems and knowledge. Support development of Analytic tools such as SOFIA to enable Portfolio Management efforts Ensures data flows are designed and tested to capture accurate and reliable information from source systems on a timely basis Acts as a subject matter expert for Commercial Banking data such as Salesforce, Loan and Deposit systems, HR data, EFT etc. Participates in working sessions with key stakeholders to ensure solutions provided are efficient and optimal for users Facilitate monitoring of results and benefits from the Analytic tools Provides leading edge solutions to Business Banking stakeholders on Business Intelligence/Analytics Proactively implements leading edge business intelligence tools for MIS (e.g. Tableau, Power BI) Ensures appropriate infrastructure is in place for Business Banking teams to access reports on an on-demand basis (e.g. through Salesforce) Explores new business intelligence tools and infrastructure in the industry on an ongoing basis to provide best in class Business Intelligence solutions Ensures ongoing improvements in automation and process improvements to cut down cycle time for report generation and availability Supports Analytics and Business Intelligence to drive sales effectiveness, client advocacy, pricing, product development, financial planning, AML and compliance needs and mandate for Business Banking Ensures Sales teams and Business Bank leadership teams have appropriate amount of drill down capability to measure and manage their portfolios/business performance Manages key stakeholder relationships in relation to delivery of Business intelligence and Analytics Works collaboratively with members of the Commercial Analytics, Data Science and Analytics team in CID&A and GRM, IT&S, Salesforce and other teams to develop data infrastructure, Business Intelligence and Analytic solutions Works proactively with development teams in Salesforce and other areas to improve infrastructure required to enhance efficiencies for end users and for the Analytics teams Understands how the Bank’s risk appetite and risk culture should be considered in day-to-day activities and decisions. Creates an environment in which his/her team pursues effective and efficient operations of his/her respective areas in accordance with Scotiabank’s Values, its Code of Conduct and the Global Sales Principles, while ensuring the adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with respect to operational, compliance, AML/ATF/sanctions and conduct risk. Builds a high-performance environment and implements a people strategy that attracts, retains, develops and motivates their team by fostering an inclusive work environment; communicating vison/values/business strategy and managing succession and development planning for the team. Develops team expertise in data mining and strong analytics capabilities Bachelor's Degree in Computer Science, Finance, Economics or Statistics Master’s degree in Computer Science – preferred 3+ years of data engineering and software experience 3+ years’ experience in Data Visualization, Business Intelligence using Tableau and/or Power BI 3+ years experience in building data pipelines and/or data warehousing Enjoy discovering and learning new technologies Detailed experience in the following: Unix, Mainframe, SQL, SAS, Python other programming tools Experience accessing, compiling and analyzing large volumes of data into usable form Excellent verbal and written communication skills are required Strong prioritizing, analytical, presentation, project management and planning skills Effective strategic thinking, organizational know-how and influencing skills are critical for success High degree of knowledge of commercial products and profit drivers The role requires a high degree of collaboration across wide ranging groups: CID&A, GRM Analytics, Global Banking & Markets (GBM); GBP; Finance, Wealth Management, Retail Small Business, and various Commercial Banking areas. Works with various partners using influence and negotiation skills to ensure objectives are met. Strong technical skills in Math, Computer Science or related fields Excellent design and delivery capabilities Ability to work non-standard work hours as required 
ScrapedJobID1102:
collaborate with Product and other engineers to define, design, and build platform and web applications contribute across the entire software development lifecycle, including requirements definition, design, development, testing, deployment, and operations be a technical leader in your squad, helping to drive technical decisions, prioritizations, and tradeoffs mentor / guide other engineers and help improve technical and other practices within the squad Collaborate cross-functionally with Product Managers, Designers, and other engineers, including Machine Learning, Front-End/Full Stack, DevOps, and QA Leverage your knowledge to design, build, and deliver scalable and resilient software Drive technical decisions, prioritizations, and tradeoffs within the squad Creatively solve functional challenges with the Product team even when the initial answer is not fully defined Creatively solve technical challenges in the face of competing tradeoffs Design easy-to-use interfaces that will be leveraged by other developers, including APIs for 3rd-party developers Ensure product quality and code quality by writing automated tests and performing thorough code reviews and design reviews Minimum 5 years of experience solving backend software engineering challenges Experience in building enterprise-grade systems and scalable distributed systems Proven technical leadership abilities Proven mentorship and ownership abilities Strong ability to reason about engineering approaches to a problem Strong software architecture and design experience Comfortable learning and implementing new technologies Experience with database systems, including SQL and/or NoSQL solutions Track record of shipping high-quality code Experience in an Agile and DevOps environment Within your first 30 days: You will get acquainted and eventually be fully comfortable navigating the full codebase, the technology stack, the development processes and org structure within the company. You will learn the product and will make your first significant, user-impacting contributions to one of our products. You will get to know our ML domain, codebase, and practical applications. Within your first quarter and beyond: You will be an integral part of the team and a driven, focused self-starter who can navigate a certain amount of ambiguity, and who is not afraid to take a sizable chunk of functionality, analyze it, break it down, implement it and then assume ownership and responsibility over it. You will be taking an active role in discussions about possible solutions, different approaches, API designs and more. Top notch medical and dental coverage for you and your family 30 days of paid leave annually to help nurture work-life symbiosis Stock options Wellness stipend Pre-tax transportation and commuter benefits 6-month parental leave (or double salary to pay for your partner's unpaid leave) Free travel for any person accompanying a breastfeeding mother and her baby on a business trip A dependent care stipend up to $3,000 (USD) per month, per child, under the age of 21 for a maximum of $6,000 (USD) per month total Budget to attend conferences, train, and further your education $1,250 (CAD) one-time-use WFH stipend and $95 (CAD) monthly WFH stipend Relocation assistance 
ScrapedJobID1103:
Develop a deep understanding of the markets in each country and their data and analytical needs. Provide guidance to internal collaborators on advanced analytics Co-lead GAA's capability/product strategy, synthesizing business needs and advanced analytics expertise into capability/product roadmaps. Lead the development and deployment of strategic capabilities/products built around advanced analytics that create tangible business value. Coordinate across CoE roles and other business functions (sales, marketing, IT, external vendors, etc.) required to efficiently and effectively deliver new analytics capabilities/products Coordinate across markets the development of analytics capabilities to improve commonalities and efficiencies Collaborate with the Data & Insights Specialist on business adoption, and embedding analytics into business processes Find opportunities to evolve analytics capabilities/products and to use them across countries and brands Instil a culture of continuous improvement to refine and enhance existing capabilities. Monitor the external environment to stay up to date on leading advanced analytic capabilities, both within and outside of pharma, which can be applied within the organization. Oversee multiple capability related projects across different countries and markets. Extensive hands-on experience in application of advanced analytics and statistical methods on large and disparate datasets preferably in the context of Omnichannel marketing, specifically: Statistical Analysis and Modelling: (e.g. Design of Experiments, Time Series Analysis, Regression Analysis, Bayesian methods, etc), Machine Learning and Artificial Intelligence Extensive experience in deploying (and maintaining) production-grade advanced analytics capabilities. This includes not only the delivery of solutions but also the building of the business ecosystem (processes, organizational structure, change management, etc.) necessary. Strong organizational skills and time management; ability to manage diverse range of simultaneous projects. Strong leadership and interpersonal skills with demonstrated ability to work collaboratively with a significant number of business leaders and cross-functional business partners. Strong communication and influencing skills. Pharma commercial domain understanding. Experience with omnichannel analytics Experience with Agile methodology within an IT/business environment. Strategic and critical thinking with the ability to engage, build and maintain credibility with Commercial Leadership Team. Quantitative Master's or PhD degree from an accredited college or university is required in one of the following or related fields: Engineering, Operations Research, Management Science, Economics, Statistics, Math, Physics, Computer Science or Data Science. Cambridge, UK Gothenburg, Sweden Gaithersburg, US 
ScrapedJobID1104:

ScrapedJobID1105:
Operate as a thought leader and visionary, with the ability to guide, influence and inspire peak performance, innovation and adoption of AI-enabled technologies across the Axon value chain Grow and lead a world-class team of research scientists that deliver novel, strategic AI solutions with diverse, industry-leading skills in deep learning, computer vision, natural language processing and more Collaborate with tech and product teams on sourcing data and model building strategies from experimentation and implementation to deployment and continuous improvement Bring your industry, research expertise and deep knowledge of the state-of-the-art in your field to challenge existing assumptions and introduce new machine learning algorithms, statistical approachers and training workflows Develop a collaborative and inclusive team that fosters a culture of ownership, experimentation, and innovation while joining forces with product teams to deliver working solutions for our Customers A Ph.D. Degree in Computer Science, Machine Learning, Statistics, Applied Mathematics or an equivalent highly technical field 7+ years of modeling experience in one or more the following areas: Natural Language Processing/Understanding (NLP/NLU), Computer Vision (CV) and Acoustic Event Detection 4+ years in a leadership/management role; with a solid track record capable of building and leading science teams Hands on experience developing, scaling and implementing machine learning using relevant programming languages (such as Python), state of the art deep learning frameworks and big data tools Working knowledge of advanced ML techniques: Multi-task Learning, Transfer Learning, Reinforcement Learning as well as Unsupervised and Semi-supervised Learning Track record of publications and contributions to the machine learning community at large Experience with designing and shipping software products that leverage machine learning at scale Excellent problem solving skills and ability to dive into learning algorithms, evaluation metrics, model architecture, code, test plans, project plans, deployments and operations Comfort communicating and interacting with scientists, engineers and product managers as well as understanding and translating the science of AI and Machine Learning to a more general audience 9+ years of modeling experience in the areas of NLP, CV, Sensor Fusion and Acoustic Event Detection Demonstrated knowledge and experience with distributed machine learning and deploying models at scale in cloud environments (such as AWS, Microsoft Azure and Google Cloud) Familiarity with IoT/Edge AI and optimizing ML models to run on-device with constrained compute, power and latency budgets Previous Experience leading multiple geographically distributed teams Competitive salary and 401K with employer match Discretionary paid time off Robust parental leave policy An award-winning office/working environment Ride along with police officers to see them use our technology and get inspired And more... 
ScrapedJobID1106:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1107:
Develop & implement advanced analytics roadmap (40%) Create and own the roadmap for advanced analytics use cases by securing buy-in across all stakeholders and ensuring alignment with the business’s top priorities and expected outcomes, assess progress and recalibrate when required Manage these advanced analytics projects and pipeline. Run multiple projects, oversee prioritization and ensure projects are aligned with strategic priorities Prepare presentation materials as required and support in the presentation of opportunities to VPs, SVPs and CEO Own ongoing evaluation of appropriate partners, tools, methodologies and analytical techniques to ensure that our measurement solutions are most complete, integrated, advanced and on par with latest industry trends Apply analytical thought leadership to problem solving (30%) Assess and diagnose information needs, design and define suitable analytical solutions to generate meaningful insights that address business problems Present key insights and recommendations based on research and data analysis Own forecasting for customer & deposit growth Use quantitative methods (i.e., Excel models) to develop insights that support decision making on new products & initiatives Use SQL to source necessary data for ongoing understanding of customer behaviour and to support internal consulting projects Develop familiarity with internal systems & processes, and gather relevant data from various internal sources Establish repeatable processes / methodology that enable quicker turnaround on analysis Brainstorm, structure and create problem solving processes for a range of strategic and tactical customer-facing topics (e.g., identifying fraud applications, cross-selling mortgages, features on prepaid card, digital ID solutions, etc.) Enable ongoing understanding of customers through design and maintenance of executive dashboards and metrics Perform ad-hoc analysis for various business units Manage cross-functional collaboration & team development (30%) Facilitate cross-functional collaboration by leading a diverse team of analytics resources to deliver quality analysis, interpretation of findings and clear articulation of results and insights to internal business partners Support Payments in assessing product features and customer needs to determine prioritization of features for Minimum Viable Product (MVP) and future build Support Product in assessing performance & developing better understanding of customer adoption through A/B testing Support Marketing, Customer Experience (CX) and Contact Center in planning & evaluating marketing campaigns and meeting their customer insights needs Support Fraud & AML by optimizing rule performance and improving customer experience Potentially manage 1 – 3 direct reports, including skills development, mentoring, career growth through regular structured and ad-hoc feedback 8+ years’ work experience in Analytics, Strategy, Data Science roles, ideally in Financial services Bachelor’s degree in Engineering, Computer Science, Commerce, Management. MBA or other graduate degree a plus Minimum 4 years of people management experience Strong business acumen and passion for understanding and solving problems for consumers of financial services using rigorous data-driven methods and advanced analytical approaches Subject Matter expert at building, modifying, and running Excel based business scenarios and predictive models (able to teach others) Experience synthesizing analyses and preparing power point presentations for C-Suite level executives or Board of Directors Strong understanding of the financial services landscape, particularly with respect to retail banking, card programs, and marketing analytics Experience, confidence, and maturity managing internal stakeholders across all levels of the organization, including VPs, SVPs, and CEO Experience leading projects and managing tasks of more junior team members, as well as supporting their growth and development Expert in MS Office (Excel, Access, PowerPoint), MySQL, Tableau, Python / R, and statistics (regression analysis, correlations, etc.) Strong attention to detail and time management skills Good verbal and written communication skills Project management experience 
ScrapedJobID1108:
Lead the team responsible for driving AI/ML adoption across Rogers Establish data science as a discipline and drive adoption of the data enablers across the organization Work across Rogers technology and business teams to further develop the AI/ML vision and strategy that outlines a target operating model and roadmap to maximize the value of information assets via their creation, access and use. Develop the technology, tools and enablers that will deliver the desired business outcomes. Establish frameworks and policies around use of AI/ML at Rogers, in particular ethics framework. Develop and deliver ML algorithms and data science approaches for the business Establish strategic industry partnerships to drive innovation Deliver ML Ops and guard rails for deployment to ensure consistent use of AI across Rogers and align to security and data standards Manage onboarding of talent, serve as a talent pipeline by establishing onboarding and skilling journeys Bachelor’s degree in Computer Science, Engineering, Data Science, Applied Mathematics or a related field Extensive experience working with data technologies, including pipelines, data lakes, data warehouse, analytics tools, machine learning, visualization and business intelligence Experience developing and deploying AI/ML models to address specific industry challenges Understanding of cloud, data, security and AI/ML and ML Ops with proven experience establishing strategy and frameworks to drive adoption and solid understanding of data security and privacy Collaborative by nature and comfortable running a COE model and shared services Experience developing business cases and strategy and an ability to drive strategy through to execution and operations Large program delivery experience, working across different teams and organization Proven leader with ability to motivate a team to achieve outstanding results Extraordinary team player that thrives in a fast-paced environment where quality, innovation, speed of decision making and execution are critical to organizational success Supports and strengthens the corporate brand and company culture Executive presence, with the ability to navigate difficult situations and build relationships via persuasive negotiator skills Brings a high degree of initiative, is able to work in an ever changing environment, and is able to manage ambiguity and relentless focus on prioritizing and balancing multiple stakeholder goals Our people are at the heart of our success Our customers come first. They inspire everything we do We do what’s right, each and every day We believe in the power of new ideas We work as one team, with one vision We give back to our communities and protect our environment 
ScrapedJobID1109:
By delivering an award-winning product, conceptualized and developed by award-winning leaders, that result in award-winning customer employee experiences By hiring highly innovative, diverse talent that fully embraces and embodies our core values in everything they do: Customer Focus, Equity, Shared Ambition, Agility, Transparency, Optimism By using modern technology, such as voice-activation with Dayforce Assistant and access to your money as soon as you earn it with Dayforce Wallet to stay in rhythm with the evolving demands of our 4 million global users As a ML Engineer, you join a high performing agile team, responsible for building new models, updating current modules, and adding new features to our products, as well as other duties as assigned. The selected candidate will have prior experience with ML deployment, Python, and have used Linux or Git. Prior SQL knowledge is also desired. Our machine learning team works on challenging problems related to text mining, predictive model building and validation, data normalization and other data science activities. Your impact will be evident through your effective participation in the entire lifecycle of our software including design, analysis, prototyping, development, testing and support of our products. You will work closely and collaborate with implementation partners, to envision and deliver the required functionality. Encouragement to be the best version of yourself at and away from work: YOUnity diversity and inclusion programs Amazing time away from work programs Support for your total well-being through our Live Well, Work Well programs targeting all aspects of your life Recognition for your contributions through excellent pay, perks, and rewards Giving where you’re living: volunteer days, Ceridian sponsored events, and our very own charity, Ceridian Cares Opportunities to fuel your career growth through numerous internal and external programs and events Expertise in building and configuring production-ready machine learning systems. Expertise in using machine learning libraries in Python, or similar. Experience with complex SQL using PostgreSQL, or similar. Experience in consuming and building APIs in Node.js, Python, or similar. A passion for software development that often extends beyond your work An understanding of Linux systems A high level of comfort using Git and Github A desire to learn new technologies and techniques Nice to have: projects or contributions on github we can see 
ScrapedJobID1110:
Develop the global business analytics strategy and action plan. Own the GFA Data and AI platform, define the data strategy and roadmap, drive platform integration with advisory assets, manage vendor data contracts and expansion of the platform to meet business needs. Establish and lead the global Analytics community of practitioners to drive adoption of data and analytics offerings within the practice, increase collaboration and sharing of analytics-oriented solutions on emerging client issues and best practices. Proactively engage with MF colleagues to communicate vision, create enthusiasm and followership, and assess progress related to analytics adoption. Supervise technology leads and product managers on the data platform expansion and predictive model development. Ensure development protocols and QRM policies are incorporated in the overall solution design. Lead discussions with DTTL procurement, Global Privacy, QRM, and vendors on data licenses, establish data governance, and access strategy in alignment with contracts. Collaborate with Deloitte Technology engagement and delivery leaders to articulate platform strategy and delivery approaches ensuring alignment and commitment. Build a dynamic team across delivery centers, member firms and Deloitte Technology to lead development and rollout of innovative analytics assets Facilitate discussions with stakeholders to ensure business needs and objectives are clearly understood and analytics solutions meet the expressed needs and expectations of the business. Communicate progress on a periodic basis to senior business leaders as requested. Build relationships and collaborate with peers and stakeholders across Global technology, MF business, and delivery centers. Bachelor’s or master’s degree in Computer Science, Information Systems or a related technical discipline. Certification in data science and cloud-based analytics technologies. 10+ years of related experience in leading analytics-oriented solutions. Experience in building and supporting a cloud hosted data platform for the business or service line, experience in advanced technologies including cloud analytics capabilities, AI, data science and engineering, NLP, NLG etc. Proficiency in business intelligence and data analytics tools including Tableau, Power BI, Alteryx, Azure Databricks, Azure Data Factory etc. Experience in software development methodologies such as SAFE, agile, etc. Ability to be a leader who is dynamic, proactive, and decisive, adapts well to change and ambiguity, has exceptional leadership and management skills to lead global virtual teams through influence Demonstrated proficiency in facilitating, delegating, and motivating cross functional groups or activities. Highly developed communications skills, motivational, team player, strategic and creative, excellent project management, and advanced MS Office skills. Able to communicate effectively in English with media and/or in front of large audiences; International experience preferred; important to have a strong network outside of home country through client engagements or roles. Willingness to travel internationally (2-4 times per year). Lead the way: Deloitte is not only leading the profession, but reinventing it for the future. We’re also committed to creating opportunity and leading the way to a more sustainable world. Serve with integrity: Deloitte has earned the trust of employees, clients, regulators, and the public for 175 years. Upholding that trust is our single most important responsibility. Take care of each other: We look out for one another and prioritize respect, fairness, development, and well-being. Foster inclusion: We are at our best when we foster an inclusive culture and embrace diversity in all forms. We know this attracts top talent, enables innovation, and helps us deliver well-rounded client solutions. Collaborate for measurable impact: We approach our work with a collaborative mind¬set, teaming across businesses, geographies, and skill sets to deliver tangible, measurable, attributable impact. 
ScrapedJobID1111:
3+ years experience in a Data Engineering or Analytics role managing data pipelines Strong skills in Python, SQL, Airflow, Data Modeling and ETL pipelines Familiarity with: Snowflake, AWS Redshift, or BigQuery Experience working with Data Science and Machine Learning teams as stakeholders A passion for programming and solving problems with code A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience A love for technology, and an insatiable curiosity for new tools to tackle real problems We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process. We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners. We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy. We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality. 
ScrapedJobID1112:
Generate meaningful insights to solve sometimes ambiguous business/customer problems identify new opportunities to drive member growth and digital engagement of PC Optimum Deep dive into customer journeys to understand and empathize with customer pain points and identify opportunities with respect to customer engagement, business strategy, and experience with our Loyalty program Oversee the extraction, review, and preparation of complex operational and customer behavior information from a variety of databases (SQL, GCP, etc). Synthesize large amounts of data from multiple sources, including customer transaction data, consumer & syndicated research, market share, and campaign results. Use Cloud based Python/Scala environment to process big data, conduct analysis, and visualizing the results. Build presentations to clearly articulate insights, while simplifying complex data and processes for various levels of audiences including senior management Provide leadership and coaching to ensure a high performing team with appropriate skills and capacity required to enable the organization’s objectives with the goal of enabling customer centric decision making Collaborate and be strategic lead across cross-functional pods of Loblaw Digital, Marketing, Loblaw Technology, DI&A, Operations, and the Customer COE to see strategy through to execution Develop short term and long term strategies paired with realistic go to market executional plans that is centered in customer centricity. Support the execution of loyalty campaigns at Loblaws, analyze results, and loop back on how to improve University Degree in Data Science, Computer Science, Statistics, Mathematics, Economics, Engineering, Business or other relevant field 5+ years related work experience in an analytical role. Experience ideally in Retail, Loyalty, CPG industry, Consumer Finance, Telecommunications, or Consulting A Passion for advocating for the customer and helping teams deliver exceptional customer experiences Programming skills in various languages (Python, Spark, PySpark, SQL, R, Hive). AdvancedSQL is mandatory. Advanced Python is preferred. Experience with cloud platforms (i.e. GCP and Azure) is preferred. Strong skills in Microsoft Office suite (Excel, Powerpoint) Experience with building models on big data is preferred Ability to synthesize large amounts of data into insights Strong ability to build presentations and present complex ideas in a clear, articulate way Self-starter: demonstrated initiative and willingness to take ownership and learn A creative and curious thinker who is comfortable working with ambiguity, ability to multi-task, prioritize workload and work in a fast-paced environment Strong interpersonal skills with the ability to build and maintain strong working relationships with cross functional teams; able to effectively communicate issues, actively engage and influence, and work collaboratively as a team member Showcase leadership and availability to coach high performing team Effective organizational skills with a strong attention to detail while managing multiple projects or workstreams 
ScrapedJobID1113:
Recognition programs to showcase your talent! To be part of a company that takes a stand on issues affecting people, the environment, and our partners Summer Fridays (because Summer is for fun) Purchase discount on merchandise sold in all our divisions. Family & Friends events with discounts on our products Subsidized cafeteria & daycare Subsidized public transportation, carpooling network and free parking On campus gym with access to a trainer Flex schedules and telecommuting Sick days Attractive total compensation! Collaborate and work closely with internal teams (buying, distribution, product design, e-commerce etc.) to identify business performance gaps and analytical opportunities Extract, mine and analyze data from various sources to provide actionable business insights, build visualizations and presentations to communicate findings Develop, implement and monitor Advanced Analytics / ML solutions to improve customer experience, drive marketing effectiveness, optimize supply chain and inventory, etc. Work with business teams to assist with data related technical issues and support their data infrastructure needs Collaborate with our Data Team to develop the data platform, identify data quality issues, build or enhance data flows, identify, profile and acquire new data sources Design, conduct and analyze complex experiments Build and maintain large datasets for self-service analytics Graduate degree in statistics, mathematics, computer science or related field 3+ years of work experience in data analytics and machine learning Expert level proficiency in data analysis, querying and crunching data from multiple systems and data transformation approaches Capable of translating analysis results into business recommendations and preparing presentations for various stakeholders Knowledge of R, Python, SQL, etc. Experience with AWS / Redshift or Google Cloud / Big Query to move and access large amounts of structured and unstructured data Experience developing and implementing machine learning models such as clustering, classification, forecasting, etc. Knowledge of techniques such as generalized linear model/regression, random forest, boosting, trees, time-series and forecasting, text mining, neural networks, etc. Experience designing datasets and visualizations with tools like Power BI, Tableau, Qlik, etc. Experience designing and analyzing experiments (A plus) Experience analyzing data from third-party providers, including Google Analytics, Site Catalyst, Coremetrics, AdWords, Crimson Hexagon, Facebook etc. (A Plus) 
ScrapedJobID1114:
Design and build large and complex data sets, from spurious sources while thinking strategically about uses of data and how data use interacts with data design. Design and implement statistical data quality procedures for new data sources. Communicate findings to business leaders in a way that can influence how an organization approaches a business challenge Develop algorithms/software for accessing and handling data appropriately. Implement and hand off data checking and updating procedures to teams. Visualize and report data findings creatively in a variety of visual formats that appropriately provides insights to the organization. Train others on what data is available and how to use various sources Previous Telecommunications data analysis experience is an asset; emphasis on location data and time series analytics Master’s Degree (or higher) in Computer Science, Statistics, Applied Math, Engineering or other quantitative field; With a solid foundation in modeling, statistics, analytics and math Minimum of 5 years of hands-on data analytics experience in a corporate environment; Comfortable working with large, complex data sets from varying sources; Experience in team leadership. Highly motivated with the ability to work on a multiple projects simultaneously; Team player, creative, entrepreneurial, willing to experiment, persistent and structured. Working with structured and unstructured data sets;
Leading analytics projects to support the strategic product direction, sales and customer efforts;
Performing hypothesis testing and develop predictive model;
Evaluating and providing input on potential business intelligence solutions.
Applying statistical principles to data analytics;
Comfortable in statistical analysis, clustering and data mining techniques to identify trends and insights
Developing end-end to models/ projects and automation in production environment. Leading analytics projects to support the strategic product direction, sales and customer efforts; Performing hypothesis testing and develop predictive model; Evaluating and providing input on potential business intelligence solutions. Applying statistical principles to data analytics; Comfortable in statistical analysis, clustering and data mining techniques to identify trends and insights Developing end-end to models/ projects and automation in production environment. Thorough understanding of relational database design; High proficiency in SQL. Fluent programming in Python, Hive, or SAS Extensive experience in Google Cloud Platform, BigQuery, JupyterLab, docker container and workspace set up. Knowledgeable about common supervised and unsupervised Machine Learning approaches (eg. feature engineering, classification, regression, clustering, NLP, time series forecasting, etc. "Tensorflow”, “Deep Learning” and synthetic tabular data generation is a strong asset. 
ScrapedJobID1115:
Define BI ramp-up strategy (including BI workflow, report hierarchy and catalog) and plan for engagement with business units Work with stakeholders to define business requirements for BI technology infrastructure including Data warehouse (DWH) platform and play a proactive part in the successful implementation of the platform Working as a trusted business partner, provide accurate, timely and actionable information in the form of reports, dashboards, etc. Make sure a robust end-to-end client engagement model (ingestion and prioritization to delivery and servicing) is implemented using appropriate tool Serve as primary client contact during all phases of the BI project from problem definition through presentation, appropriately managing client expectations throughout the project Apply business strategy while driving technology strategy, balancing short term and long term needs to ensure that the architecture can scale and evolve accordingly Accountable for the overall management of BI projects, including profitability, timeliness, quality, and client value Recruit, train, develop, and supervise managers and/or analyst-level employees Ensure accuracy of data and deliverables of direct reports with comprehensive policies and processes Create an environment where BI professionals can develop their skills and grow their careers through taking on increased responsibility and adding value to the organization Advanced Degree (PhD or Master’s) required (Data Science, Computer Science, Information Technology, Economics, Statistics, Information Systems, Applied Math, Business Administration, or any other related field) 12+ years of financial services experience Working knowledge of data extraction and reporting principles: mapping, collecting data from multiple data systems on premises and cloud-based data sources Understanding of and experience using data management and reporting concepts for analyzing data, drawing conclusions, and developing actionable recommendations for business units Experience working with and creating reports and dashboards using all relevant data to inform decisions Experience using analytics techniques to contribute to company growth efforts, increasing revenue and other key business outcomes Strong problem solving, quantitative and analytical abilities Strong ability to plan and manage numerous processes, people, and projects simultaneously Excellent communication, collaboration, and delegation skills Hands on experience with BI tools like Power BI, Tableau, Cognos, etc. Solid SQL skills for querying relational databases (e.g., SQL Server, DB2, MySQL) Good Excel, Word, and PowerPoint skills Strong analytical and problem-solving capabilities Strong results orientation Exhibits solid communication skills, both written and verbal with ability to communicate and articulate technical information into layperson terms Initiative and organizational skills Excellent team management & mentoring skills Able to adapt and quickly develop in-depth technical understanding of new/different applications Should have the ability to work independently and identify priorities for completion of multiple tasks/projects under pressure Ability to prioritize and follow-up on work Excellent organizational skills Detail oriented Sense of humor 
ScrapedJobID1116:
Take a hands-on role in several projects, including the Fundamental Review of the Trading Book (FRTB), data solutions for capital optimization, and data quality control processes. Prototype new approaches and enhance existing methodologies to advance market data management and data quality control. Develop production level code and collaborate with IT team for integration into daily bank processes. Assist team members for various ad-hoc analyses, data methodology, documentation, reporting, preparation of materials. Execute model runs on a regular basis for reporting and perform corresponding analyses. Communicate with model developers, trading desks, risk teams, and business lines to enhance data quality control and data management for capital optimization Become an active member of the team including our D&I initiatives and communities. Solid quantitative background and problem-solving skills with a keen interest in Data Science, Finance, Economics, Market Risk, Derivatives Pricing, Risk management or Regulations. Advanced degree in a mathematics, economics, or scientific discipline (e.g., Mathematics, Finance, Statistics, Physics, Engineering, Biology, Economics, etc.). Master’s degrees or PhDs are a bonus. Experience in code development in Python or other formal programing will be important to support day-day activity. Effective communication (written and oral), specifically the ability to summarize complex ideas in simple terms; you enjoy working in collaborations. The opportunity to join a forward-thinking company surrounded by a collaborative team of innovative thinkers. A rewarding career path with diverse opportunities for professional development. Internal development to support your growth and enhance your skills. A competitive compensation and benefits package. An organization committed to making a difference in our communities– for you and our customers. We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!

This position is located Downtown, Toronto. This is a contract role. 
ScrapedJobID1117:
Be part of a team with a high profile and a multitude of challenges to take on. Develop and evolve the AI platform architecture and integration models with our systems and market tools. Collaborate with members of various technical teams to develop solutions that address the constraints of our systems, data warehouses and environments. Develop scalable and robust architectures that can support the growing volumes of our AI environment. Provide solutions that meet our security and data protection standards. Ensure the architecture is aligned with our corporate vision and objectives, while being able to propose new approaches. Passionate about creating software that uses artificial intelligence, able to interact with teams of software developers, data scientists and researchers. An agent of change with up-to-the-minute awareness of new AI technologies and approaches on the market. Able to take a business problem and turn it into a technological solution. Comfortable working in complex and constantly changing environments, and with multidisciplinary teams. Excellent at explaining your ideas to various stakeholders. Well organized, with a good sense of how to manage priorities. A very good communicator who is able to cope with stress. Bilingual A bachelor’s degree in information technology/software engineering or any equivalent combination of education and experience. At least 5 years' experience in an architecture role. At least 10 years' experience in software engineering. Knowledge of SOA/REST, DevOps, Micro-services, Cloud services (PaaS and SaaS), Docker, Security/OWASP, Python and Java and Agile/Lean practices. Skills in machine learning/AI Hands-on experience delivering solutions using AI An award-winning, inspiring workplace that supports its people and recognizes great work (Canada’s Top 100 Employers, Aon Platinum Best Employers, LinkedIn Top Company, Glassdoor Best Place to Work & Top CEO, Indeed Top-Rated Workplaces) Stimulating, challenging projects and development opportunities to help you grow your skills and career Flexibility in how and where you work A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A casual ‘dress for your day’ culture that encourages you to be yourself A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID1118:
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. 2+ years of non-internship professional software development experience Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design Bachelor’s degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline 1+ years of experience as a data/software developer/scientist or related technical job A passion for improving customer experience Excellent verbal and written communication skills and technical writing skills Graduate degree in a related technical field 2+ years of experience as a data/software developer/scientist or related technical job Experience with Agile Development Experience with statistical modeling or machine learning (Classification, Collaborative Filtering) Experience with AWS services A love of music! 
ScrapedJobID1119:
Experience leading a technical team, including managing tasks and processes Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline 3+ years of Software Development experience with modern programming languages (Python, C/C++, Julia) Experience with at least one deep learning framework (TensorFlow, PyTorch, MXNet …) Experience working in version control such as git Experience in big data architectures and pipelines to build and deploy models Experience in building machine learning models optimized for speed, accuracy, scalability, reliability and resiliency Ability to perform complex data analysis and present findings to stakeholders Master’s degree in Computer Science, Computer Engineering or related technical discipline Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations Experience with prototyping machine learning solutions (e.g. Kaggle, demos, hackathons) Experience working with cloud platforms (e.g. AWS, Azure …) Experience with web development for demonstrations Strong communication skills Competitive salary Health and lifestyle benefits Positive & creative work environment in a great location Leadership role on an expanding team with opportunities for career growth 
ScrapedJobID1120:
Own the development and expansion of multiple models, leveraging machine learning Identify new opportunities and insights from the data (where can the models be improved? what is the projected ROI of a proposed modification?); continue to evolve models Architect and build technical platforms for our algorithmic engines to run at scale Work cross-functionally with Marketing and Engineering, and collaboratively with teammates Leverage the knowledge of state-of-the-art methodology and industry best practices to raise the technical standard of the team and Wayfair Data Science community Minimum 4 years of industry experience in a data science or ML Engineering role or 3 years of industry experience with Ph.D. in a quantitative field (e.g., economics, physics, neuroscience) Proficiency in Python Solid experience building Machine Learning (ML) models, preferably also productionalizing models (e.g., Airflow) Experience working with big data tools such as SQL, Spark, Hadoop, Hive, etc. Strong written and verbal communication skills, ability to synthesize conclusions for non-experts, and desire to influence business decisions A bias towards critical thinking, creatively solving problems from a customer-centric lens, and an intuitive sense for how the work aligns closely with business objectives Intellectual curiosity and enthusiastic about continuous learning Looking to make a big impact in a growing organization 
ScrapedJobID1121:
Lead a team that applies state of the art data science and machine learning techniques to transform how we interact with current and prospective business customers Drive significant business growth and impact by collaborating with Marketing, Sales, Storefront, Profit Management, Product, and Engineering teams to scope, develop, and deploy holistic data science solutions to power end-to-end B2B customer experience and drive significant business growth and impact Manage a broad portfolio of existing initiatives and evolve them to be scalable, platform-oriented data science products. These include, but are not limited to, models and frameworks for contact personalization, customer targeting across touchpoints, tailored experience for large project shoppers, and intelligent sales discount recommendation system. Lead the design and development of intelligent products that leverage a wide variety of data sources - e.g. 1st- and 3rd-party data on customer behavior, order history, firmographic information, sales call recordings and transcripts, etc. - to improve customer targeting and agent productivity Master’s degree in Computer Science, Engineering, or related quantitative fields; PhD preferred 4+ years of experience leading multi-disciplinary technical teams comprised of data scientists and engineers of varied levels of experience Thorough command of general data science and machine learning techniques Relevant experience designing and implementing customer-facing systems that are scalable, fast, and resilient Track record of delivering large cross-functional projects and managing multiple stakeholders with competing priorities Good understanding of experimental techniques for the design of A/B tests to measure the impact Communication skills that can influence across organizations and at all levels 
ScrapedJobID1122:
Implementing, training, and optimizing models developed by our ML Science team Developing high-performance, scalable, and maintainable inference services that communicate with the rest of our tech stack Working with Infra teams to build data collection pipelines, manage data QA, and develop code for data visualization and data cleansing to build robust datasets Turning unfamiliar research code into bulletproof, production-ready software Working with edge hardware to test and tune the latency and performance of our services Building pipelines for continuous model improvement Experience with computer vision; experience developing and deploying deep learning algorithms; you’ve previously deployed machine learning models on scalable systems Strong grasp of statistical machine learning, linear algebra, and deep learning for computer vision Excellent C++11/14/17 and Python skills; familiarity with TensorFlow Ability to rapidly learn and work with unfamiliar code Understanding of CI/CD patterns and best practices Ability to write well-tested code Highly flexible and capable of working across the stack Great communication skills You love the idea of joining a fast growing series-A startup. You are proactive about solving problems and take initiative to build tools that will help everyone in the company. You love to thoughtfully help a team member or a customer in need. Innovation - We have an ambitious vision, and any change, especially the zealous kind, requires big ideas. Integrity - We trust each other, and that trust is the foundation on which our relationships both internally and externally are built. Continuous Improvement - We see everything as improvable, and work at finding ways to do so, and enjoy moving toward our goals. Accountability - Our teammates have intrinsic enjoyment in taking ownership and delivering on what they say they will. Customer Focus - We care the most about what benefits our customers and partners. 
ScrapedJobID1123:
Developing and supporting digital marketing campaigns, including paid Search Engine Marketing (SEM) and paid Social Media campaigns Acting as a subject matter expert for Search Engine Optimization (SEO) best practices, including ongoing technical audits of all digital properties Build Digital Results Report for clients for monthly review that encompasses all digital activities and important data KPI’s. Develop an understanding of what impact these KPI’s have on clients’ business. Manage effectiveness of Service Work Plan retention marketing Using available programs; plan, execute, and generate report on a targeted email marketing campaigns Act as a Data Scientist with regards to all the digital information we have available to us for our clients and communicate this data Oversee and manage all syndicated contents that includes various online platforms to promote business and products Working collaboratively across departments to understand company goals to develop customer acquisition, nurturing, and retention programs Study clients’ business and create a presentation based on potential and missed opportunity on the digital platform. Demonstrate to client your plan for their growth. Must be able to perform cold calls effectively and book appointments for consultation Visit businesses to generate new leads and perform updates on existing clients Requires travel 20%-50%%+ travel Bachelor’s degree or Diploma in Marketing, Business, Public Relations or 2-3 years of proven experience in sales, marketing, or communication Ability to put together effective, comprehensive, and multi-channelled marketing campaigns Have a high understanding of effective content for social media sites including Facebook, Twitter, and Instagram Manage, collaborate, and develop marketing and video assets Understanding of Google Analytics, Conversion Rate Optimization, User Experience (UX) Knowledge and Compliance with all provincial/federal advertising standards (CASL etc.) is a must. Graphical design understanding for digital properties and Point of Sale materials Excellent organizational, communication and leadership abilities. Team-oriented, relationship builder with a positive attitude. Strong oral/written communications skills. Strong organizational and multi-tasking skills with a high attention to detail Strong Proficiency in working with multiple software programs Automotive industry experience/ knowledge considered an asset. Must have valid driver’s license Passion for selling and building new relationships is a MUST. Bonus pay Commission pay Dental care Extended health care Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? No 
ScrapedJobID1124:
Product Strategy: Develop and articulate a compelling product vision and strategy for your product and segment, incorporating feedback and learnings from Medchart experience to date, customer and partner team feedback, and primary research about the market, customers, competitors, and key industry trends Product Discovery: work closely with customers and cross functional teams to own the identification of new customer problems and solutions, driving execution to achieve quantifiable customer outcomes Business Value & Viability: partner with commercial teams and executive leadership to demonstrate the viability of new initiatives in your roadmap, continually growing business value delivered to customers Product Development: collaborate with your design, engineering, and data science leads to deliver on your roadmap, launching and continually iterating solutions to core customer problems Commercialization & GTM: work with cross functional partners in Sales, Marketing, Finance, and Operations to develop and execute go-to-market plans for new product releases Thought Leadership: Become an expert in your customers and most important business problems, evangelizing Medchart’s solutions internally and externally in client conversations, events, and internal company forums 3+ years of product management experience working directly with software developers to deliver customer solutions, ideally in a B2B/SaaS company 2+ years of experience developing and shipping products using AI/ML; familiar with developing products that utilize entity recognition and natural language processing primarily. Demonstrated leadership skills working with cross-functional teams to solve important customer business problems An entrepreneurial spirit: you are mission-oriented, proactive, and a passionate problem solver who thrives in dynamic, early stage environments Exceptional written and verbal communicator, with a highly analytical, data-driven approach Demonstrated behaviors that reinforce Medchart values: Hunger, Humility, and Care Based in Toronto/Waterloo, or willing to travel regularly (long-term) BS in Computer Science, Engineering or related technical or quantitative discipline Prior experience with Marketplace/SaaS offerings, with a focus on complex customer data environments Exposure to Healthcare-specific data technical and regulatory practices Technical background in Computer Science, or hands on experience as a software engineer An opportunity to have an outsized impact at an early stage technology company focused on solving critically important and valuable consumer healthcare data challenges Amazing culture powered by an inspired, highly-collaborative team that believes in Medchart core values: Hunger, Humility, and Care Excellent visibility, growth, and personal development potential, working closely with company founders and executive leadership Fantastic office location and amenities, including standing desks and the option to choose your own tech Highly competitive compensation and benefits in a rapidly-growing, mission-driven early stage company 
ScrapedJobID1125:
Bachelor’s in computer science or equivalent 5 years’ software development experience 2+ years' experience running medium to large/complex projects with multiple internal/external dependencies Expertise in working with at least one machine learning or deep learning framework, such as Pandas, Sklearn, TensorFlow Experienced in working with ETL pipelines Computer science fundamentals: data structures, algorithms, performance complexity, and implications of computer architecture on software performance (e.g., I/O and memory tuning). Strong analytical and problem-solving skills Ability to understand and execute on the company’s mission and values Maintain a high degree of ethical standard and trustworthiness Baccalauréat en informatique ou équivalent. 5 ans d'expérience en développement de logiciels Plus de 2 ans d'expérience dans la gestion de projets de taille moyenne à grande/complexe avec de multiples dépendances internes/externes. Expertise dans l'utilisation d'au moins un cadre d'apprentissage automatique ou d'apprentissage profond, tel que Pandas, Sklearn, TensorFlow. Expérience de travail avec des pipelines ETL Principes fondamentaux de l'informatique : structures de données, algorithmes, complexité des performances et implications de l'architecture informatique sur les performances des logiciels (par exemple, réglage des E/S et de la mémoire). Compétences solides en matière d'analyse et de résolution de problèmes Capacité à comprendre et à mettre en œuvre la mission et les valeurs de l'entreprise. Maintenir un haut degré d'éthique et de fiabilité. 
ScrapedJobID1126:
Recognition programs to showcase your talent! To be part of a company that takes a stand on issues affecting people, the environment, and our partners Summer Fridays (because Summer is for fun) Purchase discount on merchandise sold in all our divisions. Family & Friends events with discounts on our products Subsidized cafeteria & daycare Subsidized public transportation, carpooling network and free parking On campus gym with access to a trainer Flex schedules and telecommuting Sick days Attractive total compensation! Collaborate and work closely with internal teams (buying, distribution, product design, e-commerce etc.) to identify business performance gaps and analytical opportunities Extract, mine and analyze data from various sources to provide actionable business insights, build visualizations and presentations to communicate findings Develop, implement and monitor Advanced Analytics / ML solutions to improve customer experience, drive marketing effectiveness, optimize supply chain and inventory, etc. Work with business teams to assist with data related technical issues and support their data infrastructure needs Collaborate with our Data Team to develop the data platform, identify data quality issues, build or enhance data flows, identify, profile and acquire new data sources Design, conduct and analyze complex experiments Build and maintain large datasets for self-service analytics Graduate degree in statistics, mathematics, computer science or related field 3+ years of work experience in data analytics and machine learning Expert level proficiency in data analysis, querying and crunching data from multiple systems and data transformation approaches Capable of translating analysis results into business recommendations and preparing presentations for various stakeholders Knowledge of R, Python, SQL, etc. Experience with AWS / Redshift or Google Cloud / Big Query to move and access large amounts of structured and unstructured data Experience developing and implementing machine learning models such as clustering, classification, forecasting, etc. Knowledge of techniques such as generalized linear model/regression, random forest, boosting, trees, time-series and forecasting, text mining, neural networks, etc. Experience designing datasets and visualizations with tools like Power BI, Tableau, Qlik, etc. Experience designing and analyzing experiments (A plus) Experience analyzing data from third-party providers, including Google Analytics, Site Catalyst, Coremetrics, AdWords, Crimson Hexagon, Facebook etc. (A Plus) 
ScrapedJobID1127:
Design and build large and complex data sets, from spurious sources while thinking strategically about uses of data and how data use interacts with data design. Design and implement statistical data quality procedures for new data sources. Communicate findings to business leaders in a way that can influence how an organization approaches a business challenge Develop algorithms/software for accessing and handling data appropriately. Implement and hand off data checking and updating procedures to teams. Visualize and report data findings creatively in a variety of visual formats that appropriately provides insights to the organization. Train others on what data is available and how to use various sources Previous Telecommunications data analysis experience is an asset; emphasis on location data and time series analytics Master’s Degree (or higher) in Computer Science, Statistics, Applied Math, Engineering or other quantitative field; With a solid foundation in modeling, statistics, analytics and math Minimum of 5 years of hands-on data analytics experience in a corporate environment; Comfortable working with large, complex data sets from varying sources; Experience in team leadership. Highly motivated with the ability to work on a multiple projects simultaneously; Team player, creative, entrepreneurial, willing to experiment, persistent and structured. Working with structured and unstructured data sets;
Leading analytics projects to support the strategic product direction, sales and customer efforts;
Performing hypothesis testing and develop predictive model;
Evaluating and providing input on potential business intelligence solutions.
Applying statistical principles to data analytics;
Comfortable in statistical analysis, clustering and data mining techniques to identify trends and insights
Developing end-end to models/ projects and automation in production environment. Leading analytics projects to support the strategic product direction, sales and customer efforts; Performing hypothesis testing and develop predictive model; Evaluating and providing input on potential business intelligence solutions. Applying statistical principles to data analytics; Comfortable in statistical analysis, clustering and data mining techniques to identify trends and insights Developing end-end to models/ projects and automation in production environment. Thorough understanding of relational database design; High proficiency in SQL. Fluent programming in Python, Hive, or SAS Extensive experience in Google Cloud Platform, BigQuery, JupyterLab, docker container and workspace set up. Knowledgeable about common supervised and unsupervised Machine Learning approaches (eg. feature engineering, classification, regression, clustering, NLP, time series forecasting, etc. "Tensorflow”, “Deep Learning” and synthetic tabular data generation is a strong asset. 
ScrapedJobID1128:
Define BI ramp-up strategy (including BI workflow, report hierarchy and catalog) and plan for engagement with business units Work with stakeholders to define business requirements for BI technology infrastructure including Data warehouse (DWH) platform and play a proactive part in the successful implementation of the platform Working as a trusted business partner, provide accurate, timely and actionable information in the form of reports, dashboards, etc. Make sure a robust end-to-end client engagement model (ingestion and prioritization to delivery and servicing) is implemented using appropriate tool Serve as primary client contact during all phases of the BI project from problem definition through presentation, appropriately managing client expectations throughout the project Apply business strategy while driving technology strategy, balancing short term and long term needs to ensure that the architecture can scale and evolve accordingly Accountable for the overall management of BI projects, including profitability, timeliness, quality, and client value Recruit, train, develop, and supervise managers and/or analyst-level employees Ensure accuracy of data and deliverables of direct reports with comprehensive policies and processes Create an environment where BI professionals can develop their skills and grow their careers through taking on increased responsibility and adding value to the organization Advanced Degree (PhD or Master’s) required (Data Science, Computer Science, Information Technology, Economics, Statistics, Information Systems, Applied Math, Business Administration, or any other related field) 12+ years of financial services experience Working knowledge of data extraction and reporting principles: mapping, collecting data from multiple data systems on premises and cloud-based data sources Understanding of and experience using data management and reporting concepts for analyzing data, drawing conclusions, and developing actionable recommendations for business units Experience working with and creating reports and dashboards using all relevant data to inform decisions Experience using analytics techniques to contribute to company growth efforts, increasing revenue and other key business outcomes Strong problem solving, quantitative and analytical abilities Strong ability to plan and manage numerous processes, people, and projects simultaneously Excellent communication, collaboration, and delegation skills Hands on experience with BI tools like Power BI, Tableau, Cognos, etc. Solid SQL skills for querying relational databases (e.g., SQL Server, DB2, MySQL) Good Excel, Word, and PowerPoint skills Strong analytical and problem-solving capabilities Strong results orientation Exhibits solid communication skills, both written and verbal with ability to communicate and articulate technical information into layperson terms Initiative and organizational skills Excellent team management & mentoring skills Able to adapt and quickly develop in-depth technical understanding of new/different applications Should have the ability to work independently and identify priorities for completion of multiple tasks/projects under pressure Ability to prioritize and follow-up on work Excellent organizational skills Detail oriented Sense of humor 
ScrapedJobID1129:
Take a hands-on role in several projects, including the Fundamental Review of the Trading Book (FRTB), data solutions for capital optimization, and data quality control processes. Prototype new approaches and enhance existing methodologies to advance market data management and data quality control. Develop production level code and collaborate with IT team for integration into daily bank processes. Assist team members for various ad-hoc analyses, data methodology, documentation, reporting, preparation of materials. Execute model runs on a regular basis for reporting and perform corresponding analyses. Communicate with model developers, trading desks, risk teams, and business lines to enhance data quality control and data management for capital optimization Become an active member of the team including our D&I initiatives and communities. Solid quantitative background and problem-solving skills with a keen interest in Data Science, Finance, Economics, Market Risk, Derivatives Pricing, Risk management or Regulations. Advanced degree in a mathematics, economics, or scientific discipline (e.g., Mathematics, Finance, Statistics, Physics, Engineering, Biology, Economics, etc.). Master’s degrees or PhDs are a bonus. Experience in code development in Python or other formal programing will be important to support day-day activity. Effective communication (written and oral), specifically the ability to summarize complex ideas in simple terms; you enjoy working in collaborations. The opportunity to join a forward-thinking company surrounded by a collaborative team of innovative thinkers. A rewarding career path with diverse opportunities for professional development. Internal development to support your growth and enhance your skills. A competitive compensation and benefits package. An organization committed to making a difference in our communities– for you and our customers. We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!

This position is located Downtown, Toronto. This is a contract role. 
ScrapedJobID1130:
Be part of a team with a high profile and a multitude of challenges to take on. Develop and evolve the AI platform architecture and integration models with our systems and market tools. Collaborate with members of various technical teams to develop solutions that address the constraints of our systems, data warehouses and environments. Develop scalable and robust architectures that can support the growing volumes of our AI environment. Provide solutions that meet our security and data protection standards. Ensure the architecture is aligned with our corporate vision and objectives, while being able to propose new approaches. Passionate about creating software that uses artificial intelligence, able to interact with teams of software developers, data scientists and researchers. An agent of change with up-to-the-minute awareness of new AI technologies and approaches on the market. Able to take a business problem and turn it into a technological solution. Comfortable working in complex and constantly changing environments, and with multidisciplinary teams. Excellent at explaining your ideas to various stakeholders. Well organized, with a good sense of how to manage priorities. A very good communicator who is able to cope with stress. Bilingual A bachelor’s degree in information technology/software engineering or any equivalent combination of education and experience. At least 5 years' experience in an architecture role. At least 10 years' experience in software engineering. Knowledge of SOA/REST, DevOps, Micro-services, Cloud services (PaaS and SaaS), Docker, Security/OWASP, Python and Java and Agile/Lean practices. Skills in machine learning/AI Hands-on experience delivering solutions using AI An award-winning, inspiring workplace that supports its people and recognizes great work (Canada’s Top 100 Employers, Aon Platinum Best Employers, LinkedIn Top Company, Glassdoor Best Place to Work & Top CEO, Indeed Top-Rated Workplaces) Stimulating, challenging projects and development opportunities to help you grow your skills and career Flexibility in how and where you work A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A casual ‘dress for your day’ culture that encourages you to be yourself A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID1131:
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. 2+ years of non-internship professional software development experience Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design Bachelor’s degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline 1+ years of experience as a data/software developer/scientist or related technical job A passion for improving customer experience Excellent verbal and written communication skills and technical writing skills Graduate degree in a related technical field 2+ years of experience as a data/software developer/scientist or related technical job Experience with Agile Development Experience with statistical modeling or machine learning (Classification, Collaborative Filtering) Experience with AWS services A love of music! 
ScrapedJobID1132:
Experience leading a technical team, including managing tasks and processes Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline 3+ years of Software Development experience with modern programming languages (Python, C/C++, Julia) Experience with at least one deep learning framework (TensorFlow, PyTorch, MXNet …) Experience working in version control such as git Experience in big data architectures and pipelines to build and deploy models Experience in building machine learning models optimized for speed, accuracy, scalability, reliability and resiliency Ability to perform complex data analysis and present findings to stakeholders Master’s degree in Computer Science, Computer Engineering or related technical discipline Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations Experience with prototyping machine learning solutions (e.g. Kaggle, demos, hackathons) Experience working with cloud platforms (e.g. AWS, Azure …) Experience with web development for demonstrations Strong communication skills Competitive salary Health and lifestyle benefits Positive & creative work environment in a great location Leadership role on an expanding team with opportunities for career growth 
ScrapedJobID1133:
Own the development and expansion of multiple models, leveraging machine learning Identify new opportunities and insights from the data (where can the models be improved? what is the projected ROI of a proposed modification?); continue to evolve models Architect and build technical platforms for our algorithmic engines to run at scale Work cross-functionally with Marketing and Engineering, and collaboratively with teammates Leverage the knowledge of state-of-the-art methodology and industry best practices to raise the technical standard of the team and Wayfair Data Science community Minimum 4 years of industry experience in a data science or ML Engineering role or 3 years of industry experience with Ph.D. in a quantitative field (e.g., economics, physics, neuroscience) Proficiency in Python Solid experience building Machine Learning (ML) models, preferably also productionalizing models (e.g., Airflow) Experience working with big data tools such as SQL, Spark, Hadoop, Hive, etc. Strong written and verbal communication skills, ability to synthesize conclusions for non-experts, and desire to influence business decisions A bias towards critical thinking, creatively solving problems from a customer-centric lens, and an intuitive sense for how the work aligns closely with business objectives Intellectual curiosity and enthusiastic about continuous learning Looking to make a big impact in a growing organization 
ScrapedJobID1134:
Lead a team that applies state of the art data science and machine learning techniques to transform how we interact with current and prospective business customers Drive significant business growth and impact by collaborating with Marketing, Sales, Storefront, Profit Management, Product, and Engineering teams to scope, develop, and deploy holistic data science solutions to power end-to-end B2B customer experience and drive significant business growth and impact Manage a broad portfolio of existing initiatives and evolve them to be scalable, platform-oriented data science products. These include, but are not limited to, models and frameworks for contact personalization, customer targeting across touchpoints, tailored experience for large project shoppers, and intelligent sales discount recommendation system. Lead the design and development of intelligent products that leverage a wide variety of data sources - e.g. 1st- and 3rd-party data on customer behavior, order history, firmographic information, sales call recordings and transcripts, etc. - to improve customer targeting and agent productivity Master’s degree in Computer Science, Engineering, or related quantitative fields; PhD preferred 4+ years of experience leading multi-disciplinary technical teams comprised of data scientists and engineers of varied levels of experience Thorough command of general data science and machine learning techniques Relevant experience designing and implementing customer-facing systems that are scalable, fast, and resilient Track record of delivering large cross-functional projects and managing multiple stakeholders with competing priorities Good understanding of experimental techniques for the design of A/B tests to measure the impact Communication skills that can influence across organizations and at all levels 
ScrapedJobID1135:
Implementing, training, and optimizing models developed by our ML Science team Developing high-performance, scalable, and maintainable inference services that communicate with the rest of our tech stack Working with Infra teams to build data collection pipelines, manage data QA, and develop code for data visualization and data cleansing to build robust datasets Turning unfamiliar research code into bulletproof, production-ready software Working with edge hardware to test and tune the latency and performance of our services Building pipelines for continuous model improvement Experience with computer vision; experience developing and deploying deep learning algorithms; you’ve previously deployed machine learning models on scalable systems Strong grasp of statistical machine learning, linear algebra, and deep learning for computer vision Excellent C++11/14/17 and Python skills; familiarity with TensorFlow Ability to rapidly learn and work with unfamiliar code Understanding of CI/CD patterns and best practices Ability to write well-tested code Highly flexible and capable of working across the stack Great communication skills You love the idea of joining a fast growing series-A startup. You are proactive about solving problems and take initiative to build tools that will help everyone in the company. You love to thoughtfully help a team member or a customer in need. Innovation - We have an ambitious vision, and any change, especially the zealous kind, requires big ideas. Integrity - We trust each other, and that trust is the foundation on which our relationships both internally and externally are built. Continuous Improvement - We see everything as improvable, and work at finding ways to do so, and enjoy moving toward our goals. Accountability - Our teammates have intrinsic enjoyment in taking ownership and delivering on what they say they will. Customer Focus - We care the most about what benefits our customers and partners. 
ScrapedJobID1136:
Developing and supporting digital marketing campaigns, including paid Search Engine Marketing (SEM) and paid Social Media campaigns Acting as a subject matter expert for Search Engine Optimization (SEO) best practices, including ongoing technical audits of all digital properties Build Digital Results Report for clients for monthly review that encompasses all digital activities and important data KPI’s. Develop an understanding of what impact these KPI’s have on clients’ business. Manage effectiveness of Service Work Plan retention marketing Using available programs; plan, execute, and generate report on a targeted email marketing campaigns Act as a Data Scientist with regards to all the digital information we have available to us for our clients and communicate this data Oversee and manage all syndicated contents that includes various online platforms to promote business and products Working collaboratively across departments to understand company goals to develop customer acquisition, nurturing, and retention programs Study clients’ business and create a presentation based on potential and missed opportunity on the digital platform. Demonstrate to client your plan for their growth. Must be able to perform cold calls effectively and book appointments for consultation Visit businesses to generate new leads and perform updates on existing clients Requires travel 20%-50%%+ travel Bachelor’s degree or Diploma in Marketing, Business, Public Relations or 2-3 years of proven experience in sales, marketing, or communication Ability to put together effective, comprehensive, and multi-channelled marketing campaigns Have a high understanding of effective content for social media sites including Facebook, Twitter, and Instagram Manage, collaborate, and develop marketing and video assets Understanding of Google Analytics, Conversion Rate Optimization, User Experience (UX) Knowledge and Compliance with all provincial/federal advertising standards (CASL etc.) is a must. Graphical design understanding for digital properties and Point of Sale materials Excellent organizational, communication and leadership abilities. Team-oriented, relationship builder with a positive attitude. Strong oral/written communications skills. Strong organizational and multi-tasking skills with a high attention to detail Strong Proficiency in working with multiple software programs Automotive industry experience/ knowledge considered an asset. Must have valid driver’s license Passion for selling and building new relationships is a MUST. Bonus pay Commission pay Dental care Extended health care Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? No 
ScrapedJobID1137:
Product Strategy: Develop and articulate a compelling product vision and strategy for your product and segment, incorporating feedback and learnings from Medchart experience to date, customer and partner team feedback, and primary research about the market, customers, competitors, and key industry trends Product Discovery: work closely with customers and cross functional teams to own the identification of new customer problems and solutions, driving execution to achieve quantifiable customer outcomes Business Value & Viability: partner with commercial teams and executive leadership to demonstrate the viability of new initiatives in your roadmap, continually growing business value delivered to customers Product Development: collaborate with your design, engineering, and data science leads to deliver on your roadmap, launching and continually iterating solutions to core customer problems Commercialization & GTM: work with cross functional partners in Sales, Marketing, Finance, and Operations to develop and execute go-to-market plans for new product releases Thought Leadership: Become an expert in your customers and most important business problems, evangelizing Medchart’s solutions internally and externally in client conversations, events, and internal company forums 3+ years of product management experience working directly with software developers to deliver customer solutions, ideally in a B2B/SaaS company 2+ years of experience developing and shipping products using AI/ML; familiar with developing products that utilize entity recognition and natural language processing primarily. Demonstrated leadership skills working with cross-functional teams to solve important customer business problems An entrepreneurial spirit: you are mission-oriented, proactive, and a passionate problem solver who thrives in dynamic, early stage environments Exceptional written and verbal communicator, with a highly analytical, data-driven approach Demonstrated behaviors that reinforce Medchart values: Hunger, Humility, and Care Based in Toronto/Waterloo, or willing to travel regularly (long-term) BS in Computer Science, Engineering or related technical or quantitative discipline Prior experience with Marketplace/SaaS offerings, with a focus on complex customer data environments Exposure to Healthcare-specific data technical and regulatory practices Technical background in Computer Science, or hands on experience as a software engineer An opportunity to have an outsized impact at an early stage technology company focused on solving critically important and valuable consumer healthcare data challenges Amazing culture powered by an inspired, highly-collaborative team that believes in Medchart core values: Hunger, Humility, and Care Excellent visibility, growth, and personal development potential, working closely with company founders and executive leadership Fantastic office location and amenities, including standing desks and the option to choose your own tech Highly competitive compensation and benefits in a rapidly-growing, mission-driven early stage company 
ScrapedJobID1138:
Own and contribute to the ML Pipeline development lifecycle from Data wrangling, Feature development, Training and tuning ML model with Data Scientist, Deploy and manage the Inference Pipeline. Develop a reusable code and pattern to scale the ML Pipeline to new business use cases and create a self service platform. Partner closely with the ML Platform team, Infrastructure team, and similar teams to ensure the Data science org has the data, computing resources, and workflows/abstractions needed to do our best work. Contribute to the roadmap, and project execution with cross-functional stakeholders and Eng partner teams. Define and advance MLOps best practices within data science and product teams Be obsessed with the customer and maintain a customer-centric lens in how we frame, approach, and ultimately solve every problem we work on. Contribute to SME initiative and code review in support of spreading best practices 4+ years experience as a ML Engineer, Data Engineer, Data Scientist with strong engineering skills and a passion for working on turning reference implementations into production-ready software. Proficiency in at least one high-level programming language (Python, Java, Scala or equivalent) used both for ML and automation tasks. Experience with Python ML ecosystem (numpy, pandas, sklearn, XGBoost, etc.) and Apache Spark Ecosystem (Spark SQL, MLlib/Spark ML) Hands-on experience building scalable ML & big data processing pipelines with big data tools such as Hadoop, Hive, SQL, Spark and GCP cloud services such as DataProc, BigQuery, GCS etc. Experience with automated data pipeline and workflow management tools, i.e. Airflow. Strong sense of ownership and growth mindset. Experience with basic software engineering tools, e.g., git, CI/CD environment (such as Jenkins or Buildkite), PyPi, Docker, Kubernetes, unit testing, and general object-oriented design. PhD or MSc or Bsc in Computer Science / Operations Research / Statistics or other quantitative fields Experience with common ML frameworks/libraries such as Vowel wabbit, Tensorflow, PyTorch is preferred. Experience with Cloud Services such as AWS SageMaker/GCP AI Platform. Deploying and scaling ML solutions using open-source frameworks (MLFlow, TFX, H2O, etc.) 
ScrapedJobID1139:
Ongoing practice and process development looking for ways to improve and streamline company processes to not only deliver a superior service to our clients, but also to improve our efficiency and profitability. Mentoring/managing Data Science team members Partner with your Group Director to educate clients on the value of adding Data Science products to their business, capturing & defining needs and solutions Synthesize business needs and create business/functional design documents which can be used to build analysis and data models around. Assess data for validity in terms of predictive capabilities, required feature engineering, opportunities for data widening, or alignment to business requirements Develops, implements, and supports methodologies, standards, and tools for analysis and data science work. Build cooperative, productive relationships with clients and vendors by utilizing excellent communication skills, while also interacting effectively internally and externally. Research, prototype, and explore future, non-standard analytics approaches that push the limits of current analysis output. This will include exploring novel machine learning techniques which enable our teams to tackle segmentation, clustering, and predictive models used in a wide variety of areas. Bachelor’s degree in Mathematics, Statistics, Business Analysis or related 5+ years’ experience as an Analyst / Data Scientist 2+ years’ of managerial and leadership experience Advanced knowledge of R, Python or SAS for model development Previous experience with web analytics tools such as Adobe Marketing Cloud, Google Analytics Extensive experience with statistical modelling techniques Experience connecting Tableau or other visualization systems and using for dashboarding or analysis Self-motivated and ability to work independently in meeting deadlines Exceptional written and verbal communication skills and is comfortable working with remote teams Previous experience with marketing analytics including database marketing techniques, campaign lift, attribution and media mix modelling Familiarity with analyzing data for digital marketing and ecommerce, as well as all other non-digital aspects of a business SQL skills A solid knowledge of ETL tools Understanding of how to deal with larger data sets and parallel computing problem 
ScrapedJobID1140:
Clearly communicate project statuses with leaders and project teams Engage in quality assurance processes to create a high standard of accuracy Ensure exception and error handling techniques are used Use understanding of business rules to enhance logic used in reporting and analysis Seek out new technology and processes to improve team ability and reach Verbally and visually present reporting and analysis findings to leaders and stakeholders of various levels Submit work for quality assurance with a low number of errors Prioritize multiple projects within own work stream to deliver with little impact to timelines Manage relationships with data source providers for issues and support Consistently incorporate reconciliation in published reports and datasets Prove or disprove relationships between variables (causal) Forecast business measures with confidence and accuracy Assist with development planning with other team members Take on and seek out opportunities to mentor and coach Champion best practices in quality and reliability Over 8 years relevant industry experience within a telecom, client services or technology environment Undergraduate degree in a field linked to data engineering, business analytics, applied mathematics, computer science, IT, computer applications, or related field Ability to create reporting and analysis solutions that are delivered within scope, expected timelines and of high quality Demonstrated solid critical thinking and problem-solving skills Expert ability to identify issues and make difficult decisions, knowing when to escalate when required Strong ability to develop strategic relationships across the organization in a collaborative and foster trust from others Committed to personal and team excellence and ability to operate in a dynamic and constantly changing environment 
ScrapedJobID1141:
Manage and contribute to the delivery of reporting and analytics solutions, mainly in Looker Understand business needs and technical requirements to meet those needs Lead and develop your team of analysts Set and achieve challenging goals for yourself and your team (OKRs) Foster a culture of data-driven decision making throughout the company Keep up with the latest data industry tools and techniques Top-notch communication (verbal and written) and interpersonal skills Excellent math and statistical analysis skills Proficiency in the presentation and visualization of numbers and statistical data Ability to understand business imperatives and drivers, find relevant data correlations, and create processes by which the data correlations are translated to information flows that help drive the business 5+ years developing and coaching analytics teams 5+ years of quantitative analysis work experience 5+ years of experience handling, manipulating and analyzing data and creating analytical reports Strong expertise with an SQL language, database structures, and data lake architectures Experience with Looker Experience with Snowflake Proficiency with Python An understanding of the principles, tools, and processes of data science Post-secondary education in a technical field, or B.S./M.S. 
ScrapedJobID1142:
Advise on the best technologies and frameworks to monitor performance for the team's and client's needs. Show your analysis through presentations and communication with technical and non-technical people. Develop performance measuring frameworks to track goals, user needs and work with KPIs. Work with marketing software and tools such as Google Analytics, Google Tag Manager, Google Search Console, Adobe Analytics, Hubspot, Salesforce Marketing Cloud, Facebook Ads, Google Ads, and LinkedIn Ads. Oversee the analytics, data layer, and tag management solution for accurate and efficient data capture. Help conceptualize, design, build and automate reports/dashboards that provide insights into client audiences. Manage ongoing audience data and KPI reporting on a weekly/monthly/quarterly basis, delivering insights and recommendations to both business and content teams. Provide data-driven feedback and actionable insights to our content teams regarding content/topic performance onsite & off-platform (social media, blog, video, etc..) As needed, work with developers for tracking needs and implementation 1-3+ years of experience working with or close to marketing data 1-3+ years of experience working directly with Google Analytics data Proven ability to manage, understand, discuss, and work with analytics accounts, goals, properties, dashboards, reports, segments, and custom channel/content groupings Experience using visualization tools, in particular Google Data Studio - expertise in Tableau a bonus Hands-on experience with Google Tag Manager; experience and expertise in web tagging concepts and the ability to lead tagging strategy highly desired A high degree of comfort with Excel and/or Google Sheets spreadsheet concepts A degree in marketing or statistics Entrepreneurial ability to diagnose web data tracking issues and propose solutions Ability to work with a fluid team at a fast pace Interest in statistical programming/query languages (R, Python, SQL) Understanding of data science processes and ability to implement these in an Agile environment Excellent communication skills and ability to simplify advanced statistical concepts for a layman audience Strong understanding of advertising data and advertising concepts HTML, Javascript, and other web development expertise Working knowledge of APIs, data connectors, and other pipelines Experience with UX/testing technologies such as Hotjar, Google Optimize An understanding of SEO and technical SEO concepts, search data CRM and email software marketing data Prior experience with project/workflow management software (we use Asana) 
ScrapedJobID1143:
Linux GPU driver development in support of Machine Learning and Data Centre applications Contributes to software projects of significant technical importance Solves sophisticated non-recurring problems that leads to development and implementation Debug, analyze and resolve quality and certification issues as reported by Customers and QA Write detailed design notes for new features Coordinate closely with peers and colleagues to ensure timely and effective communication of all assigned work activities Coordinate with developers in the open-source development community Proficient in C and C++ programming Excellent debugging and trouble-shooting skills Strong general Linux systems administration, software development, and troubleshooting knowledge and experience. Linux kernel development experience, either core kernel development or device driver development. PC architecture knowledge Strong oral and written communication skills Experience with Linux containers kernel level implementation (cgroups, namespaces) Familiarity with Linux networking and network/cluster management Familiarity with Linux GPU driver development (kernel and user-mode), ideally on AMD hardware. Familiarity with compute, graphics, or multimedia GPU application development using APIs such as OpenCL, OpenGL, and VAAPI. Proven track record of contributions to open-source projects Familiarity with Linux security subsystems such as selinux and/or AppArmor Bachelor's degree or Master’s in Computer Science or related degree with validated experience 
ScrapedJobID1144:
Overseeing the development of software to clean and investigate large, messy data sets of numerical and textual data Networking with various teams to explore internal and external data sources and APIs to help uncover new trends and improve analysis Designing and contributing to highly scalable data pipelines, tools, and products to enable the analyst community to fully leverage the power of AWS Working with your team to analyze large swaths of data in order to optimize various business programs Managing and developing talent to drive a highly performant and engaged team Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, you’re not afraid to blurt out your disruptive idea. You know how the latest tech works, yet you are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. Crafty: You know how to get things done. You can navigate a large organization, motivate people, and influence your peers. Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Inspiring: You have a passion for developing people and take great pride in your management system. You know how to deliver through others while paving the way for their growth. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook and all the monitors you want! You can travel to a relevant conference of your choice annually - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours, dress code and environment Bachelor’s Degree in a quantitative field At least 5 year of experience in open source programming languages for large scale data analysis (Python, Scala, or Java) At least 5 year of experience with version control system like Git and GitHub. At least 5 year of experience with relational databases and programming in SQL At least 2 years in lead positions (managing people/owning products/architecting and driving an agenda) Master’s Degree or PhD Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) Experience with CICD tools Experience with Machine Learning workflows 5+ years experience in Python 5+ years’ experience with SQL 3+ years in lead positions (managing people/owning products/architecting and driving an agenda) 
ScrapedJobID1145:
You'll play a pivotal part in informing and delivering upon our data strategy, by providing sales and marketing performance data, creating custom dashboards and visualization, and supporting marketing and financial strategies Providing Advance analytical insights to the team and help them improve marketing strategies Provide technical leadership to internal team members and various stakeholders Operationalize and support our underlying data systems, improving our system reliability, accuracy and stability You are analytical and outcome-oriented with a proven ability to translate technical considerations into business implications as well as to synthesize data into actionable insights You are well-versed with Business Intelligence/ Market Intelligence processes and other marketing technologies You have demonstrated the ability to successfully deliver complex projects involving people, process, technology, and change management You have experience with agile ways of working and a bias for action to break down barriers to get results fast with a test and learn mindset You can assemble large complex datasets across multiple databases and sources by building automated pipelines (ETL) Strong analytic skills related to working with unstructured datasets. Strong Business Acumen Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. SAS knowledge Business Intelligence/ Market Intelligence processes and other marketing technologies understanding Technical or data-driven educational background (computer science, engineering, statistics, data science) and/or Masters of Business Administration (MBA) degree 5+ years of progressive and relevant work experience Takes ownership, initiates improvements, and is self-directed Able to effectively engage stakeholders to establish cross functional alignment for projects Prior telecommunications expertise B2B marketing Python experience Hive / Spark / Nifi experience Experience with cloud (GCP Amazon or Azure) Data Science / Modeling experience or working in a Data Science team 
ScrapedJobID1146:
Leads and drives a customer focused culture throughout their team to deepen client relationships and leverage broader Bank relationships, systems and knowledge. Support development of Analytic tools such as SOFIA to enable Portfolio Management efforts Ensures data flows are designed and tested to capture accurate and reliable information from source systems on a timely basis Acts as a subject matter expert for Commercial Banking data such as Salesforce, Loan and Deposit systems, HR data, EFT etc. Participates in working sessions with key stakeholders to ensure solutions provided are efficient and optimal for users Facilitate monitoring of results and benefits from the Analytic tools Provides leading edge solutions to Business Banking stakeholders on Business Intelligence/Analytics Proactively implements leading edge business intelligence tools for MIS (e.g. Tableau, Power BI) Ensures appropriate infrastructure is in place for Business Banking teams to access reports on an on-demand basis (e.g. through Salesforce) Explores new business intelligence tools and infrastructure in the industry on an ongoing basis to provide best in class Business Intelligence solutions Ensures ongoing improvements in automation and process improvements to cut down cycle time for report generation and availability Supports Analytics and Business Intelligence to drive sales effectiveness, client advocacy, pricing, product development, financial planning, AML and compliance needs and mandate for Business Banking Ensures Sales teams and Business Bank leadership teams have appropriate amount of drill down capability to measure and manage their portfolios/business performance Manages key stakeholder relationships in relation to delivery of Business intelligence and Analytics Works collaboratively with members of the Commercial Analytics, Data Science and Analytics team in CID&A and GRM, IT&S, Salesforce and other teams to develop data infrastructure, Business Intelligence and Analytic solutions Works proactively with development teams in Salesforce and other areas to improve infrastructure required to enhance efficiencies for end users and for the Analytics teams Understands how the Bank’s risk appetite and risk culture should be considered in day-to-day activities and decisions. Creates an environment in which his/her team pursues effective and efficient operations of his/her respective areas in accordance with Scotiabank’s Values, its Code of Conduct and the Global Sales Principles, while ensuring the adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with respect to operational, compliance, AML/ATF/sanctions and conduct risk. Builds a high-performance environment and implements a people strategy that attracts, retains, develops and motivates their team by fostering an inclusive work environment; communicating vison/values/business strategy and managing succession and development planning for the team. Develops team expertise in data mining and strong analytics capabilities Bachelor's Degree in Computer Science, Finance, Economics or Statistics Master’s degree in Computer Science – preferred 3+ years of data engineering and software experience 3+ years’ experience in Data Visualization, Business Intelligence using Tableau and/or Power BI 3+ years experience in building data pipelines and/or data warehousing Enjoy discovering and learning new technologies Detailed experience in the following: Unix, Mainframe, SQL, SAS, Python other programming tools Experience accessing, compiling and analyzing large volumes of data into usable form Excellent verbal and written communication skills are required Strong prioritizing, analytical, presentation, project management and planning skills Effective strategic thinking, organizational know-how and influencing skills are critical for success High degree of knowledge of commercial products and profit drivers The role requires a high degree of collaboration across wide ranging groups: CID&A, GRM Analytics, Global Banking & Markets (GBM); GBP; Finance, Wealth Management, Retail Small Business, and various Commercial Banking areas. Works with various partners using influence and negotiation skills to ensure objectives are met. Strong technical skills in Math, Computer Science or related fields Excellent design and delivery capabilities Ability to work non-standard work hours as required 
ScrapedJobID1147:
collaborate with Product and other engineers to define, design, and build platform and web applications contribute across the entire software development lifecycle, including requirements definition, design, development, testing, deployment, and operations be a technical leader in your squad, helping to drive technical decisions, prioritizations, and tradeoffs mentor / guide other engineers and help improve technical and other practices within the squad Collaborate cross-functionally with Product Managers, Designers, and other engineers, including Machine Learning, Front-End/Full Stack, DevOps, and QA Leverage your knowledge to design, build, and deliver scalable and resilient software Drive technical decisions, prioritizations, and tradeoffs within the squad Creatively solve functional challenges with the Product team even when the initial answer is not fully defined Creatively solve technical challenges in the face of competing tradeoffs Design easy-to-use interfaces that will be leveraged by other developers, including APIs for 3rd-party developers Ensure product quality and code quality by writing automated tests and performing thorough code reviews and design reviews Minimum 5 years of experience solving backend software engineering challenges Experience in building enterprise-grade systems and scalable distributed systems Proven technical leadership abilities Proven mentorship and ownership abilities Strong ability to reason about engineering approaches to a problem Strong software architecture and design experience Comfortable learning and implementing new technologies Experience with database systems, including SQL and/or NoSQL solutions Track record of shipping high-quality code Experience in an Agile and DevOps environment Within your first 30 days: You will get acquainted and eventually be fully comfortable navigating the full codebase, the technology stack, the development processes and org structure within the company. You will learn the product and will make your first significant, user-impacting contributions to one of our products. You will get to know our ML domain, codebase, and practical applications. Within your first quarter and beyond: You will be an integral part of the team and a driven, focused self-starter who can navigate a certain amount of ambiguity, and who is not afraid to take a sizable chunk of functionality, analyze it, break it down, implement it and then assume ownership and responsibility over it. You will be taking an active role in discussions about possible solutions, different approaches, API designs and more. Top notch medical and dental coverage for you and your family 30 days of paid leave annually to help nurture work-life symbiosis Stock options Wellness stipend Pre-tax transportation and commuter benefits 6-month parental leave (or double salary to pay for your partner's unpaid leave) Free travel for any person accompanying a breastfeeding mother and her baby on a business trip A dependent care stipend up to $3,000 (USD) per month, per child, under the age of 21 for a maximum of $6,000 (USD) per month total Budget to attend conferences, train, and further your education $1,250 (CAD) one-time-use WFH stipend and $95 (CAD) monthly WFH stipend Relocation assistance 
ScrapedJobID1148:

ScrapedJobID1149:
Operate as a thought leader and visionary, with the ability to guide, influence and inspire peak performance, innovation and adoption of AI-enabled technologies across the Axon value chain Grow and lead a world-class team of research scientists that deliver novel, strategic AI solutions with diverse, industry-leading skills in deep learning, computer vision, natural language processing and more Collaborate with tech and product teams on sourcing data and model building strategies from experimentation and implementation to deployment and continuous improvement Bring your industry, research expertise and deep knowledge of the state-of-the-art in your field to challenge existing assumptions and introduce new machine learning algorithms, statistical approachers and training workflows Develop a collaborative and inclusive team that fosters a culture of ownership, experimentation, and innovation while joining forces with product teams to deliver working solutions for our Customers A Ph.D. Degree in Computer Science, Machine Learning, Statistics, Applied Mathematics or an equivalent highly technical field 7+ years of modeling experience in one or more the following areas: Natural Language Processing/Understanding (NLP/NLU), Computer Vision (CV) and Acoustic Event Detection 4+ years in a leadership/management role; with a solid track record capable of building and leading science teams Hands on experience developing, scaling and implementing machine learning using relevant programming languages (such as Python), state of the art deep learning frameworks and big data tools Working knowledge of advanced ML techniques: Multi-task Learning, Transfer Learning, Reinforcement Learning as well as Unsupervised and Semi-supervised Learning Track record of publications and contributions to the machine learning community at large Experience with designing and shipping software products that leverage machine learning at scale Excellent problem solving skills and ability to dive into learning algorithms, evaluation metrics, model architecture, code, test plans, project plans, deployments and operations Comfort communicating and interacting with scientists, engineers and product managers as well as understanding and translating the science of AI and Machine Learning to a more general audience 9+ years of modeling experience in the areas of NLP, CV, Sensor Fusion and Acoustic Event Detection Demonstrated knowledge and experience with distributed machine learning and deploying models at scale in cloud environments (such as AWS, Microsoft Azure and Google Cloud) Familiarity with IoT/Edge AI and optimizing ML models to run on-device with constrained compute, power and latency budgets Previous Experience leading multiple geographically distributed teams Competitive salary and 401K with employer match Discretionary paid time off Robust parental leave policy An award-winning office/working environment Ride along with police officers to see them use our technology and get inspired And more... 
ScrapedJobID1150:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1151:
Develop & implement advanced analytics roadmap (40%) Create and own the roadmap for advanced analytics use cases by securing buy-in across all stakeholders and ensuring alignment with the business’s top priorities and expected outcomes, assess progress and recalibrate when required Manage these advanced analytics projects and pipeline. Run multiple projects, oversee prioritization and ensure projects are aligned with strategic priorities Prepare presentation materials as required and support in the presentation of opportunities to VPs, SVPs and CEO Own ongoing evaluation of appropriate partners, tools, methodologies and analytical techniques to ensure that our measurement solutions are most complete, integrated, advanced and on par with latest industry trends Apply analytical thought leadership to problem solving (30%) Assess and diagnose information needs, design and define suitable analytical solutions to generate meaningful insights that address business problems Present key insights and recommendations based on research and data analysis Own forecasting for customer & deposit growth Use quantitative methods (i.e., Excel models) to develop insights that support decision making on new products & initiatives Use SQL to source necessary data for ongoing understanding of customer behaviour and to support internal consulting projects Develop familiarity with internal systems & processes, and gather relevant data from various internal sources Establish repeatable processes / methodology that enable quicker turnaround on analysis Brainstorm, structure and create problem solving processes for a range of strategic and tactical customer-facing topics (e.g., identifying fraud applications, cross-selling mortgages, features on prepaid card, digital ID solutions, etc.) Enable ongoing understanding of customers through design and maintenance of executive dashboards and metrics Perform ad-hoc analysis for various business units Manage cross-functional collaboration & team development (30%) Facilitate cross-functional collaboration by leading a diverse team of analytics resources to deliver quality analysis, interpretation of findings and clear articulation of results and insights to internal business partners Support Payments in assessing product features and customer needs to determine prioritization of features for Minimum Viable Product (MVP) and future build Support Product in assessing performance & developing better understanding of customer adoption through A/B testing Support Marketing, Customer Experience (CX) and Contact Center in planning & evaluating marketing campaigns and meeting their customer insights needs Support Fraud & AML by optimizing rule performance and improving customer experience Potentially manage 1 – 3 direct reports, including skills development, mentoring, career growth through regular structured and ad-hoc feedback 8+ years’ work experience in Analytics, Strategy, Data Science roles, ideally in Financial services Bachelor’s degree in Engineering, Computer Science, Commerce, Management. MBA or other graduate degree a plus Minimum 4 years of people management experience Strong business acumen and passion for understanding and solving problems for consumers of financial services using rigorous data-driven methods and advanced analytical approaches Subject Matter expert at building, modifying, and running Excel based business scenarios and predictive models (able to teach others) Experience synthesizing analyses and preparing power point presentations for C-Suite level executives or Board of Directors Strong understanding of the financial services landscape, particularly with respect to retail banking, card programs, and marketing analytics Experience, confidence, and maturity managing internal stakeholders across all levels of the organization, including VPs, SVPs, and CEO Experience leading projects and managing tasks of more junior team members, as well as supporting their growth and development Expert in MS Office (Excel, Access, PowerPoint), MySQL, Tableau, Python / R, and statistics (regression analysis, correlations, etc.) Strong attention to detail and time management skills Good verbal and written communication skills Project management experience 
ScrapedJobID1152:
Lead the team responsible for driving AI/ML adoption across Rogers Establish data science as a discipline and drive adoption of the data enablers across the organization Work across Rogers technology and business teams to further develop the AI/ML vision and strategy that outlines a target operating model and roadmap to maximize the value of information assets via their creation, access and use. Develop the technology, tools and enablers that will deliver the desired business outcomes. Establish frameworks and policies around use of AI/ML at Rogers, in particular ethics framework. Develop and deliver ML algorithms and data science approaches for the business Establish strategic industry partnerships to drive innovation Deliver ML Ops and guard rails for deployment to ensure consistent use of AI across Rogers and align to security and data standards Manage onboarding of talent, serve as a talent pipeline by establishing onboarding and skilling journeys Bachelor’s degree in Computer Science, Engineering, Data Science, Applied Mathematics or a related field Extensive experience working with data technologies, including pipelines, data lakes, data warehouse, analytics tools, machine learning, visualization and business intelligence Experience developing and deploying AI/ML models to address specific industry challenges Understanding of cloud, data, security and AI/ML and ML Ops with proven experience establishing strategy and frameworks to drive adoption and solid understanding of data security and privacy Collaborative by nature and comfortable running a COE model and shared services Experience developing business cases and strategy and an ability to drive strategy through to execution and operations Large program delivery experience, working across different teams and organization Proven leader with ability to motivate a team to achieve outstanding results Extraordinary team player that thrives in a fast-paced environment where quality, innovation, speed of decision making and execution are critical to organizational success Supports and strengthens the corporate brand and company culture Executive presence, with the ability to navigate difficult situations and build relationships via persuasive negotiator skills Brings a high degree of initiative, is able to work in an ever changing environment, and is able to manage ambiguity and relentless focus on prioritizing and balancing multiple stakeholder goals Our people are at the heart of our success Our customers come first. They inspire everything we do We do what’s right, each and every day We believe in the power of new ideas We work as one team, with one vision We give back to our communities and protect our environment 
ScrapedJobID1153:
By delivering an award-winning product, conceptualized and developed by award-winning leaders, that result in award-winning customer employee experiences By hiring highly innovative, diverse talent that fully embraces and embodies our core values in everything they do: Customer Focus, Equity, Shared Ambition, Agility, Transparency, Optimism By using modern technology, such as voice-activation with Dayforce Assistant and access to your money as soon as you earn it with Dayforce Wallet to stay in rhythm with the evolving demands of our 4 million global users As a ML Engineer, you join a high performing agile team, responsible for building new models, updating current modules, and adding new features to our products, as well as other duties as assigned. The selected candidate will have prior experience with ML deployment, Python, and have used Linux or Git. Prior SQL knowledge is also desired. Our machine learning team works on challenging problems related to text mining, predictive model building and validation, data normalization and other data science activities. Your impact will be evident through your effective participation in the entire lifecycle of our software including design, analysis, prototyping, development, testing and support of our products. You will work closely and collaborate with implementation partners, to envision and deliver the required functionality. Encouragement to be the best version of yourself at and away from work: YOUnity diversity and inclusion programs Amazing time away from work programs Support for your total well-being through our Live Well, Work Well programs targeting all aspects of your life Recognition for your contributions through excellent pay, perks, and rewards Giving where you’re living: volunteer days, Ceridian sponsored events, and our very own charity, Ceridian Cares Opportunities to fuel your career growth through numerous internal and external programs and events Expertise in building and configuring production-ready machine learning systems. Expertise in using machine learning libraries in Python, or similar. Experience with complex SQL using PostgreSQL, or similar. Experience in consuming and building APIs in Node.js, Python, or similar. A passion for software development that often extends beyond your work An understanding of Linux systems A high level of comfort using Git and Github A desire to learn new technologies and techniques Nice to have: projects or contributions on github we can see 
ScrapedJobID1154:
Develop the global business analytics strategy and action plan. Own the GFA Data and AI platform, define the data strategy and roadmap, drive platform integration with advisory assets, manage vendor data contracts and expansion of the platform to meet business needs. Establish and lead the global Analytics community of practitioners to drive adoption of data and analytics offerings within the practice, increase collaboration and sharing of analytics-oriented solutions on emerging client issues and best practices. Proactively engage with MF colleagues to communicate vision, create enthusiasm and followership, and assess progress related to analytics adoption. Supervise technology leads and product managers on the data platform expansion and predictive model development. Ensure development protocols and QRM policies are incorporated in the overall solution design. Lead discussions with DTTL procurement, Global Privacy, QRM, and vendors on data licenses, establish data governance, and access strategy in alignment with contracts. Collaborate with Deloitte Technology engagement and delivery leaders to articulate platform strategy and delivery approaches ensuring alignment and commitment. Build a dynamic team across delivery centers, member firms and Deloitte Technology to lead development and rollout of innovative analytics assets Facilitate discussions with stakeholders to ensure business needs and objectives are clearly understood and analytics solutions meet the expressed needs and expectations of the business. Communicate progress on a periodic basis to senior business leaders as requested. Build relationships and collaborate with peers and stakeholders across Global technology, MF business, and delivery centers. Bachelor’s or master’s degree in Computer Science, Information Systems or a related technical discipline. Certification in data science and cloud-based analytics technologies. 10+ years of related experience in leading analytics-oriented solutions. Experience in building and supporting a cloud hosted data platform for the business or service line, experience in advanced technologies including cloud analytics capabilities, AI, data science and engineering, NLP, NLG etc. Proficiency in business intelligence and data analytics tools including Tableau, Power BI, Alteryx, Azure Databricks, Azure Data Factory etc. Experience in software development methodologies such as SAFE, agile, etc. Ability to be a leader who is dynamic, proactive, and decisive, adapts well to change and ambiguity, has exceptional leadership and management skills to lead global virtual teams through influence Demonstrated proficiency in facilitating, delegating, and motivating cross functional groups or activities. Highly developed communications skills, motivational, team player, strategic and creative, excellent project management, and advanced MS Office skills. Able to communicate effectively in English with media and/or in front of large audiences; International experience preferred; important to have a strong network outside of home country through client engagements or roles. Willingness to travel internationally (2-4 times per year). Lead the way: Deloitte is not only leading the profession, but reinventing it for the future. We’re also committed to creating opportunity and leading the way to a more sustainable world. Serve with integrity: Deloitte has earned the trust of employees, clients, regulators, and the public for 175 years. Upholding that trust is our single most important responsibility. Take care of each other: We look out for one another and prioritize respect, fairness, development, and well-being. Foster inclusion: We are at our best when we foster an inclusive culture and embrace diversity in all forms. We know this attracts top talent, enables innovation, and helps us deliver well-rounded client solutions. Collaborate for measurable impact: We approach our work with a collaborative mind¬set, teaming across businesses, geographies, and skill sets to deliver tangible, measurable, attributable impact. 
ScrapedJobID1155:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID1156:
Design, modify, implement, test, and provide operational support for enterprise software products and platforms, including software infrastructure and development tools for the Data Develop, operate and drive scalable and resilient data platform to address the business requirements Create new opportunities in this space for Data Science as a Service (DSaaS) platform with new feature capabilities and new offerings that drive customer and business value Ensure industry best practices around data pipelines, metadata management, data quality, data governance and data privacy Strong knowledge of AWS cloud infrastructure computer, networking, storage and other AWS cloud services Proven experience with AWS services such as Data Pipeline, Step Functions, Batch, Lambda, CloudFormation, CloudWatch, EC2, EMR, SNS, IAM, ELB, EC2, S3, Redshift, Glue Experience with Big Data tech stack, including Hadoop, Python, Spark, PySpark, Scala, and Hive, and NoSQL data stores Knowledge and previous experience with Unix and Linux Experience working with large datasets and large-scale distributed computing Working knowledge of building out data marts, data warehouses, and data lakes Experience on ETL data pipelines development and performance tuning Experience with manipulating and transforming data Experience on columnar databases like Redshift, Redshift Spector Working knowledge of containers and container orchestration Proficiency using Kubeflow This individual must have strong knowledge of healthcare data, analytics & workflows, excellent problem-solving & project management capabilities, and a proven ability to design & drive Big Data platform. Excellent critical thinking, verbal and written communications skills Knowledge and experience in the healthcare industry is a plus Demonstrates strong drive to learn and advocate for development best practices. Prescription Drugs Vision Care – frames, lenses, contact lenses, eye exam, eye surgery Paramedical Services Dental Basic Services 1–5 Calendar Years of Service 120 hours 5+ Calendar Years of Service 160 hours 100% of contributions up to 3% of base salary Plus a 50% match on the next 2% contribution This role may be located anywhere in Canada – remote opportunity/home office. 
ScrapedJobID1157:
Work with senior leadership to architect Wayfair’s Machine Learning platforms and ensure that we deliver the right functionality, in a timely manner Leverage your deep knowledge of distributed systems engineering to build Wayfair’s next generation Machine Learning capabilities Design scalable systems using Python, Go, Kubernetes, Kafka, GCP, Airflow, and other technologies Think outside of the current technology/stack limitations to push the boundaries on what is possible and deliver feasible solutions collaboratively Champion open source solutions and Google Cloud native technologies, and their application to our use cases Develop end to end software solutions that power the full range of Machine Learning initiatives at Wayfair Partner with product leaders to understand technical pain points for data scientists and other engineers and translate them into clear and robust engineering solutions Promote a culture of engineering excellence and strengthen the technical expertise of our engineering and product teams 3+ years of experience in software engineering and designing systems at scale 1+ years of experience in Linux-based development, and Python development while leading engineering teams Strong understanding of containerization (Docker, etc.), and associated software engineering best practices Excellent communication skills with demonstrated experience driving teams forward and ability to influence technical decisions to line up with the company’s strategy Hands-on experience driving software development within high-growth environments at scale Excellent organizational, analytical, and hypothesis- driven critical thinking skills to transform data into actionable insights Mix of start-up and large-company experience working on Machine Learning solutions Familiarity with Machine Learning platforms offered by Google Cloud and how to implement them on a large scale 
ScrapedJobID1158:
Experience leading a technical team, including managing tasks and processes Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline 3+ years of Software Development experience with modern programming languages (Python, C/C++, Julia) Experience with at least one deep learning framework (TensorFlow, PyTorch, MXNet …) Experience working in version control such as git Experience in big data architectures and pipelines to build and deploy models Experience in building machine learning models optimized for speed, accuracy, scalability, reliability and resiliency Ability to perform complex data analysis and present findings to stakeholders Master’s degree in Computer Science, Computer Engineering or related technical discipline Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations Experience with prototyping machine learning solutions (e.g. Kaggle, demos, hackathons) Experience working with cloud platforms (e.g. AWS, Azure …) Experience with web development for demonstrations Strong communication skills Competitive salary Health and lifestyle benefits Positive & creative work environment in a great location Leadership role on an expanding team with opportunities for career growth 
ScrapedJobID1159:
Own the development and expansion of multiple models, leveraging machine learning Identify new opportunities and insights from the data (where can the models be improved? what is the projected ROI of a proposed modification?); continue to evolve models Architect and build technical platforms for our algorithmic engines to run at scale Work cross-functionally with Marketing and Engineering, and collaboratively with teammates Leverage the knowledge of state-of-the-art methodology and industry best practices to raise the technical standard of the team and Wayfair Data Science community Minimum 4 years of industry experience in a data science or ML Engineering role or 3 years of industry experience with Ph.D. in a quantitative field (e.g., economics, physics, neuroscience) Proficiency in Python Solid experience building Machine Learning (ML) models, preferably also productionalizing models (e.g., Airflow) Experience working with big data tools such as SQL, Spark, Hadoop, Hive, etc. Strong written and verbal communication skills, ability to synthesize conclusions for non-experts, and desire to influence business decisions A bias towards critical thinking, creatively solving problems from a customer-centric lens, and an intuitive sense for how the work aligns closely with business objectives Intellectual curiosity and enthusiastic about continuous learning Looking to make a big impact in a growing organization 
ScrapedJobID1160:
Réaliser le développement des rapports et tableaux de bord dans le respect des Modifier les rapports et tableaux de bord existants afin de répondre aux besoins Effectuer les essais et l"assurance qualité des développements avant la mise en Assurer la performance des rapports et tableaux de bord développées Assurer le support de premier niveau des produits informationnels Travailler en étroite collaboration avec les équipes de gestion de l"information afin Assurer le lien avec l"équipe de l"entrepôt de données afin de spécifier les besoins et Participer au profilage des données des systèmes sources Tester les extractions et les requêtes afin d"assurer la qualité des données Créer des tables de faits, de dimensions, et des vues pouvant être utilisées dans les Créer des champs calculés directement dans les bases de données pour supporter Participer aux discussions et aux ateliers de gouvernance Proposer et utiliser les définitions et le lexique d"entreprise Assurer la conformité et l"alignement des indicateurs clefs de performance Recueillir les besoins d"affaires et ceux des clients et utilisateurs Organiser et conduire des séances de travail afin de développer et proposer des Effectuer l"analyse détaillée des besoins et rédiger les spécifications détaillées afin de Participer et conduire des réunions et des revues d"avancement des projets avec les Analyser, cartographier et schématiser les systèmes et les processus d"affaires Créer et supporter la mise en place d"une architecture des données Proposer les meilleures solutions possibles afin d"atteindre les objectifs de l"unité Proposer des indicateurs clefs de performance pertinents Rédiger la documentation des produits informationnels afin d"en permettre une Supporter le déploiement du portail web pour la diffusion des différents rapports et Mettre en place une structure temporaire pour le traitement et la transformation des Supporter l"automatisation des tâches de rafraichissement des données, des rapports Proposer et développer des solutions numériques afin de permettre le suivi des Participer aux initiatives en science des données (apprentissage machine, prévision, Diplôme universitaire en génie, en science informatique, en intelligence d"affaires ou en Diplôme universitaire de 2e cycle en intelligence d"affaires, en science des données, ou Idéalement 1 à 4 ans d"expérience, mais ouvert aux nouveaux diplômés Maîtrise du français et de l"anglais parlé et écrit Expérience de travail dans le secteur manufacturier ou aérospatial un atout Maîtrise de la suite Microsoft 365 Maîtrise avancée du logiciel Power BI Bonne compréhension des besoins d"affaires, des systèmes et des architectures dans un Expérience dans le développement et l"utilisation de modèles relationnels et Bonnes connaissances SQL (fonctions de fenêtre, requêtes imbriquées, tables Expérience de programmation dans un contexte d"analyse de données (ex. VBA, Python, Connaissances de base de SAP, PLM, Jupyter et HDFS un atout Connaissance de la méthodologie agile Connaissance des plateformes en gestion de projets et partage de codes (ex. Azure Le poste est présentement offert en télétravail. Un retour au bureau sera possible lorsque L"horaire de travail est flexible Une analyse de cas sera demandée aux candidats présélectionnés afin de valider les Develop reports and dashboards in compliance with Modify existing reports and dashboards to meet needs Perform tests and quality assurance of developments before implementation Ensure the performance of reports and dashboards developed Provide first level support for information products Work closely with information management teams to Liaise with the data warehouse team in order to specify the needs and Participate in the profiling of data from source systems Test extractions and queries to ensure data quality Create tables of facts, dimensions, and views that can be used in Create calculated fields directly in the databases to support Participate in governance discussions and workshops Propose and use the definitions and the business lexicon Ensure compliance and alignment of key performance indicators Collect business needs and those of customers and users Organize and lead working sessions in order to develop and propose Perform detailed needs analysis and write detailed specifications in order to Participate and lead meetings and project progress reviews with Analyze, map and map systems and business processes Create and support the implementation of a data architecture Propose the best possible solutions in order to achieve the objectives of the unit Propose relevant key performance indicators Write the documentation of information products in order to allow Support the deployment of the web portal for the distribution of the various reports and Set up a temporary structure for the processing and transformation of Support the automation of data refresh tasks, reports Propose and develop digital solutions to allow the monitoring of Participate in data science initiatives (machine learning, forecasting, University degree in engineering, computer science, business intelligence or 2nd year university diploma Ideally 1 to 4 years of experience, but open to new graduates Fluency in spoken and written French and English Work experience in the manufacturing or aerospace sector an asset Proficiency in the Microsoft 365 suite Advanced knowledge of Power BI software Good understanding of business needs, systems and architectures in a Good SQL knowledge (window functions, nested queries, tables Programming experience in a data analysis context (eg VBA, Python, Basic knowledge of SAP, PLM, Jupyter and HDFS an asset Knowledge of agile methodology Knowledge of project management and code sharing platforms (eg Azure The position is currently offered by telecommuting. A return to the office will be possible when The work schedule is flexible A case analysis will be requested from shortlisted candidates in order to validate the 
ScrapedJobID1161:
Own and contribute to the ML Pipeline development lifecycle from Data wrangling, Feature development, Training and tuning ML model with Data Scientist, Deploy and manage the Inference Pipeline. Develop a reusable code and pattern to scale the ML Pipeline to new business use cases and create a self service platform. Partner closely with the ML Platform team, Infrastructure team, and similar teams to ensure the Data science org has the data, computing resources, and workflows/abstractions needed to do our best work. Contribute to the roadmap, and project execution with cross-functional stakeholders and Eng partner teams. Define and advance MLOps best practices within data science and product teams Be obsessed with the customer and maintain a customer-centric lens in how we frame, approach, and ultimately solve every problem we work on. Contribute to SME initiative and code review in support of spreading best practices 4+ years experience as a ML Engineer, Data Engineer, Data Scientist with strong engineering skills and a passion for working on turning reference implementations into production-ready software. Proficiency in at least one high-level programming language (Python, Java, Scala or equivalent) used both for ML and automation tasks. Experience with Python ML ecosystem (numpy, pandas, sklearn, XGBoost, etc.) and Apache Spark Ecosystem (Spark SQL, MLlib/Spark ML) Hands-on experience building scalable ML & big data processing pipelines with big data tools such as Hadoop, Hive, SQL, Spark and GCP cloud services such as DataProc, BigQuery, GCS etc. Experience with automated data pipeline and workflow management tools, i.e. Airflow. Strong sense of ownership and growth mindset. Experience with basic software engineering tools, e.g., git, CI/CD environment (such as Jenkins or Buildkite), PyPi, Docker, Kubernetes, unit testing, and general object-oriented design. PhD or MSc or Bsc in Computer Science / Operations Research / Statistics or other quantitative fields Experience with common ML frameworks/libraries such as Vowel wabbit, Tensorflow, PyTorch is preferred. Experience with Cloud Services such as AWS SageMaker/GCP AI Platform. Deploying and scaling ML solutions using open-source frameworks (MLFlow, TFX, H2O, etc.) 
ScrapedJobID1162:
Generate meaningful insights to solve sometimes ambiguous business/customer problems identify new opportunities to drive member growth and digital engagement of PC Optimum Deep dive into customer journeys to understand and empathize with customer pain points and identify opportunities with respect to customer engagement, business strategy, and experience with our Loyalty program Oversee the extraction, review, and preparation of complex operational and customer behavior information from a variety of databases (SQL, GCP, etc). Synthesize large amounts of data from multiple sources, including customer transaction data, consumer & syndicated research, market share, and campaign results. Use Cloud based Python/Scala environment to process big data, conduct analysis, and visualizing the results. Build presentations to clearly articulate insights, while simplifying complex data and processes for various levels of audiences including senior management Provide leadership and coaching to ensure a high performing team with appropriate skills and capacity required to enable the organization’s objectives with the goal of enabling customer centric decision making Collaborate and be strategic lead across cross-functional pods of Loblaw Digital, Marketing, Loblaw Technology, DI&A, Operations, and the Customer COE to see strategy through to execution Develop short term and long term strategies paired with realistic go to market executional plans that is centered in customer centricity. Support the execution of loyalty campaigns at Loblaws, analyze results, and loop back on how to improve University Degree in Data Science, Computer Science, Statistics, Mathematics, Economics, Engineering, Business or other relevant field 5+ years related work experience in an analytical role. Experience ideally in Retail, Loyalty, CPG industry, Consumer Finance, Telecommunications, or Consulting A Passion for advocating for the customer and helping teams deliver exceptional customer experiences Programming skills in various languages (Python, Spark, PySpark, SQL, R, Hive). AdvancedSQL is mandatory. Advanced Python is preferred. Experience with cloud platforms (i.e. GCP and Azure) is preferred. Strong skills in Microsoft Office suite (Excel, Powerpoint) Experience with building models on big data is preferred Ability to synthesize large amounts of data into insights Strong ability to build presentations and present complex ideas in a clear, articulate way Self-starter: demonstrated initiative and willingness to take ownership and learn A creative and curious thinker who is comfortable working with ambiguity, ability to multi-task, prioritize workload and work in a fast-paced environment Strong interpersonal skills with the ability to build and maintain strong working relationships with cross functional teams; able to effectively communicate issues, actively engage and influence, and work collaboratively as a team member Showcase leadership and availability to coach high performing team Effective organizational skills with a strong attention to detail while managing multiple projects or workstreams 
ScrapedJobID1163:
Developing and supporting digital marketing campaigns, including paid Search Engine Marketing (SEM) and paid Social Media campaigns Acting as a subject matter expert for Search Engine Optimization (SEO) best practices, including ongoing technical audits of all digital properties Build Digital Results Report for clients for monthly review that encompasses all digital activities and important data KPI’s. Develop an understanding of what impact these KPI’s have on clients’ business. Manage effectiveness of Service Work Plan retention marketing Using available programs; plan, execute, and generate report on a targeted email marketing campaigns Act as a Data Scientist with regards to all the digital information we have available to us for our clients and communicate this data Oversee and manage all syndicated contents that includes various online platforms to promote business and products Working collaboratively across departments to understand company goals to develop customer acquisition, nurturing, and retention programs Study clients’ business and create a presentation based on potential and missed opportunity on the digital platform. Demonstrate to client your plan for their growth. Must be able to perform cold calls effectively and book appointments for consultation Visit businesses to generate new leads and perform updates on existing clients Requires travel 20%-50%%+ travel Bachelor’s degree or Diploma in Marketing, Business, Public Relations or 2-3 years of proven experience in sales, marketing, or communication Ability to put together effective, comprehensive, and multi-channelled marketing campaigns Have a high understanding of effective content for social media sites including Facebook, Twitter, and Instagram Manage, collaborate, and develop marketing and video assets Understanding of Google Analytics, Conversion Rate Optimization, User Experience (UX) Knowledge and Compliance with all provincial/federal advertising standards (CASL etc.) is a must. Graphical design understanding for digital properties and Point of Sale materials Excellent organizational, communication and leadership abilities. Team-oriented, relationship builder with a positive attitude. Strong oral/written communications skills. Strong organizational and multi-tasking skills with a high attention to detail Strong Proficiency in working with multiple software programs Automotive industry experience/ knowledge considered an asset. Must have valid driver’s license Passion for selling and building new relationships is a MUST. Bonus pay Commission pay Dental care Extended health care Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? No 
ScrapedJobID1164:
Dynamic personalization: Serve content, propose products, promote services, or execute actions Dynamic customer cohort creation: Determine cohorts of similar behavior or tuned to specific KPIs Scalable actions across segments of customers Usage-based/behavior-based pricing models: Insurance based on behavior Abnormality and fraud detection: Identify and prevent unauthorized activity Security and remediation: Detect issues and alert responders in exponentially less time than traditional security through intelligent analyses Network performance: Monitor and respond to network performance issues faster IoT analytics: Unify disparate data sources to reduce costs and improve performance IOT TCO: Reduces the cost of installation by reducing tuning and maintenance Architect, build, test, deploy distributed, scalable, and resilient Spark/Scala/Kafka Big Data processing, and Machine Learning model pipelines for batch, micro-batch, and streaming workloads sets into Cerebri AI’s proprietary data stores for use in machine learning modeling Develop and maintain data ontologies for key market segments Collaborate with data scientists to develop automated orchestration of model pipelines to solve Cerebri AI business use case objectives Collaborate with clients to develop pipeline infrastructure, and to ask appropriate questions to gain a deep understanding of client data Deploy fully containerized Docker/Kubernetes Data processing, and Machine Learning model pipelines into Azure, AWS, GCP cloud environments and on-premise systems as necessary Document Detailed Designs (including source to target mappings) and Code for Data Quality frameworks that can measure and maintain Data Completeness, Data Integrity, and Data Validity between interfacing systems Ensure all solutions comply with the highest levels of security, privacy, and data governance requirements as outlined by Cerebri and Client legal and information security guidelines, law enforcement, and privacy legislation, including data anonymization, encryption, and security in transit and at rest, etc. Train and mentor junior team members Acts as a Subject Matter Expert and a Thought Leader, continuously following industry trends, the latest competitive developments, and delivering papers and presentations at major industry conferences and events. A degree in Computer Science, Engineering, AI, Machine Learning, BI, MIS, or an equivalent technology field Minimum 2 years of Production programming experience in Scala, Spark, PySpark, Big Data, Python Minimum 2 years of Production experience with the Hadoop Big Data platform Able to program and understand data science and data engineering ideas in Python and translate into modular, functional components in Scala Streaming and micro-batch application development experience would be an asset, including Kafka, Storm, NiFi, Spark Streaming, Confluent or equivalent Proficiency with Linux/Unix operating systems, utilities, and tools Experience working directly with relational database structures and flat files Ability to write efficient database queries, functions, and views to include complex joins and the identification and development of custom indices Knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, continuous integration and development, and operations. Experience deploying containerized Docker/Kubernetes applications Experience with Microsoft Azure or similar cloud computing solutions Big Data application architecture experience and in-depth understanding of the Big Data ecosystem, applications, services, and design patterns Production systems integration experience Good verbal and written communication skills, with both technical and non-technical stakeholders Experience in business intelligence visualization tools such as Grafana, Superset, Redash or Tableau. Master’s degree or higher in a relevant quantitative subject Experience with the Atlassian suite (JIRA, Confluence, BitBucket). Any other related experience with Big Data, artificial intelligence, natural language processing, machine learning and/or deep learning, predictive analytics Familiar with automated machine learning (AutoML) concepts would be an asset Experience with Breeze would be an asset 
ScrapedJobID1165:
Design, development and evaluation of highly innovative models Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation Work closely with software engineering teams to drive real-time model implementations and new feature creations Analyze internal behavior tracking data and forecast Wish demand Implement the strategies and set up A/B test experiments to gauge the impact, and reiterate Propose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process Create & own dashboards and analytical reports to track progress & share learnings Bachelor's or advanced degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics or similar) 3+ years of hands-on experience in predictive modeling and analysis 3+ years experience writing complex SQL queries in a business environment 2+ years in Python A/B test experience Experience collaborating with business & eng teams Analytical mindset and ability to see the big picture and influence others Detail-oriented and must have an aptitude for solving unstructured problems Ability to work effectively in a multi-task, high volume environment Ability to be adaptable and flexible in responding to deadlines and workflow fluctuations Experience operating in a Unix/Linux environment Strong presentation skills 
ScrapedJobID1166:
Product Strategy: Develop and articulate a compelling product vision and strategy for your product and segment, incorporating feedback and learnings from Medchart experience to date, customer and partner team feedback, and primary research about the market, customers, competitors, and key industry trends Product Discovery: work closely with customers and cross functional teams to own the identification of new customer problems and solutions, driving execution to achieve quantifiable customer outcomes Business Value & Viability: partner with commercial teams and executive leadership to demonstrate the viability of new initiatives in your roadmap, continually growing business value delivered to customers Product Development: collaborate with your design, engineering, and data science leads to deliver on your roadmap, launching and continually iterating solutions to core customer problems Commercialization & GTM: work with cross functional partners in Sales, Marketing, Finance, and Operations to develop and execute go-to-market plans for new product releases Thought Leadership: Become an expert in your customers and most important business problems, evangelizing Medchart’s solutions internally and externally in client conversations, events, and internal company forums 3+ years of product management experience working directly with software developers to deliver customer solutions, ideally in a B2B/SaaS company 2+ years of experience developing and shipping products using AI/ML; familiar with developing products that utilize entity recognition and natural language processing primarily. Demonstrated leadership skills working with cross-functional teams to solve important customer business problems An entrepreneurial spirit: you are mission-oriented, proactive, and a passionate problem solver who thrives in dynamic, early stage environments Exceptional written and verbal communicator, with a highly analytical, data-driven approach Demonstrated behaviors that reinforce Medchart values: Hunger, Humility, and Care Based in Toronto/Waterloo, or willing to travel regularly (long-term) BS in Computer Science, Engineering or related technical or quantitative discipline Prior experience with Marketplace/SaaS offerings, with a focus on complex customer data environments Exposure to Healthcare-specific data technical and regulatory practices Technical background in Computer Science, or hands on experience as a software engineer An opportunity to have an outsized impact at an early stage technology company focused on solving critically important and valuable consumer healthcare data challenges Amazing culture powered by an inspired, highly-collaborative team that believes in Medchart core values: Hunger, Humility, and Care Excellent visibility, growth, and personal development potential, working closely with company founders and executive leadership Fantastic office location and amenities, including standing desks and the option to choose your own tech Highly competitive compensation and benefits in a rapidly-growing, mission-driven early stage company 
ScrapedJobID1167:
Lead a team that applies state of the art data science and machine learning techniques to transform how we interact with current and prospective business customers Drive significant business growth and impact by collaborating with Marketing, Sales, Storefront, Profit Management, Product, and Engineering teams to scope, develop, and deploy holistic data science solutions to power end-to-end B2B customer experience and drive significant business growth and impact Manage a broad portfolio of existing initiatives and evolve them to be scalable, platform-oriented data science products. These include, but are not limited to, models and frameworks for contact personalization, customer targeting across touchpoints, tailored experience for large project shoppers, and intelligent sales discount recommendation system. Lead the design and development of intelligent products that leverage a wide variety of data sources - e.g. 1st- and 3rd-party data on customer behavior, order history, firmographic information, sales call recordings and transcripts, etc. - to improve customer targeting and agent productivity Master’s degree in Computer Science, Engineering, or related quantitative fields; PhD preferred 4+ years of experience leading multi-disciplinary technical teams comprised of data scientists and engineers of varied levels of experience Thorough command of general data science and machine learning techniques Relevant experience designing and implementing customer-facing systems that are scalable, fast, and resilient Track record of delivering large cross-functional projects and managing multiple stakeholders with competing priorities Good understanding of experimental techniques for the design of A/B tests to measure the impact Communication skills that can influence across organizations and at all levels 
ScrapedJobID1168:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID1169:
Recognition programs to showcase your talent! To be part of a company that takes a stand on issues affecting people, the environment, and our partners Summer Fridays (because Summer is for fun) Purchase discount on merchandise sold in all our divisions. Family & Friends events with discounts on our products Subsidized cafeteria & daycare Subsidized public transportation, carpooling network and free parking On campus gym with access to a trainer Flex schedules and telecommuting Sick days Attractive total compensation! Collaborate and work closely with internal teams (buying, distribution, product design, e-commerce etc.) to identify business performance gaps and analytical opportunities Extract, mine and analyze data from various sources to provide actionable business insights, build visualizations and presentations to communicate findings Develop, implement and monitor Advanced Analytics / ML solutions to improve customer experience, drive marketing effectiveness, optimize supply chain and inventory, etc. Work with business teams to assist with data related technical issues and support their data infrastructure needs Collaborate with our Data Team to develop the data platform, identify data quality issues, build or enhance data flows, identify, profile and acquire new data sources Design, conduct and analyze complex experiments Build and maintain large datasets for self-service analytics Graduate degree in statistics, mathematics, computer science or related field 3+ years of work experience in data analytics and machine learning Expert level proficiency in data analysis, querying and crunching data from multiple systems and data transformation approaches Capable of translating analysis results into business recommendations and preparing presentations for various stakeholders Knowledge of R, Python, SQL, etc. Experience with AWS / Redshift or Google Cloud / Big Query to move and access large amounts of structured and unstructured data Experience developing and implementing machine learning models such as clustering, classification, forecasting, etc. Knowledge of techniques such as generalized linear model/regression, random forest, boosting, trees, time-series and forecasting, text mining, neural networks, etc. Experience designing datasets and visualizations with tools like Power BI, Tableau, Qlik, etc. Experience designing and analyzing experiments (A plus) Experience analyzing data from third-party providers, including Google Analytics, Site Catalyst, Coremetrics, AdWords, Crimson Hexagon, Facebook etc. (A Plus) 
ScrapedJobID1170:
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. 2+ years of non-internship professional software development experience Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design Bachelor’s degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline 1+ years of experience as a data/software developer/scientist or related technical job A passion for improving customer experience Excellent verbal and written communication skills and technical writing skills Graduate degree in a related technical field 2+ years of experience as a data/software developer/scientist or related technical job Experience with Agile Development Experience with statistical modeling or machine learning (Classification, Collaborative Filtering) Experience with AWS services A love of music! 
ScrapedJobID1171:
Develop and maintain algorithms, data pipelines, automated processes, and services to create a data science solution that are customer focused Extract mission-critical insights from datasets Innovate and bring creative ideas to building mission critical customer facing products that depend on ML solutions Work with product and business teams to identify solutions and best practices Create scalable models that drive business decisions and enable our customers’ success Design and develop processes and systems which analyze and generate actionable insights from diverse data sources Develop tools to monitor models for evolving performance and accuracy Mentor team members in the areas of technical expertise and career building Contribute to best practices around feature extraction, model development, and knowledge sharing among multiple data science teams Directly contribute to architecture planning Been in the ML engineering game for some time. You have a Bachelors/Masters and 4+ years of industry experience Proven ability to architect data science solutions to complex problems and delivering solutions in customer facing products Experience delivering solutions that analyzes big datasets using tools such as Apache Spark Experience delivering solutions that analyzes time-series data Strong programming skills in Python A strong command of SQL and working with multiple relational databases and data warehouses (Redshift, Postgres, Athena, Snowflake, etc…) Experience in end-to-end machine learning project life cycle Experience working with unstructured data Are scrappy when extracting useful insights with partial data A solid experience in working with software development teams and using source version control tools like Git Experience deploying deep learning models Experience with frameworks for in-production ML code (e.g. Kedro) Developing and deploying using Docker With some of the AWS services (e.g. EC2, S3, Sage Maker, Cloudwatch) With accessing data from other datastores in the AWS ecosystem such as ElasticSearch, S3, and DynamoDB The BEST team. Remote-first culture. International Meetups. Access to Jungle Scout tools & experts. Performance Bonus. Flexible Vacation. Comprehensive Health Benefits & Retirement Program. 
ScrapedJobID1172:
Stay abreast of innovations and publications in the field of operations research and business intelligence systems. Research and solve complex scheduling, resource allocation and pricing scenarios involved in operations optimization. Analyze raw operational data and design algorithms that can automatically and consistently generate operational recommendations for clients. Contribute to the invention of novel solutions to client’s operational problems by collaboratively working with product managers, co-developers, and our client success team. Utilize efficient algorithm design in a parallelized fashion capable of crunching gigabytes of operations data in minutes and scaling up with client growth. Build dashboards that transform operational data into visualizations that are intuitive and actionable Contribute refinements to our existing product through the development of new features as well as refactoring existing code to make it more efficient and object-oriented. Advance your knowledge of new software tools, agile programming methods, business intelligence technologies and share your knowledge with the development team, thus catalyzing process / technology changes to help us be more effective. Languages: C#, JavaScript, TypeScript Frameworks: .NET Core, Angular Web Server: IIS, NGINX Databases: MS SQL, Azure SQL Infrastructure: Azure, Docker, Kubernetes, GitLab Logistics engine: algorithms for discrete optimization problems Operation Systems: Windows, Linux Development Processes: Agile, CI/CD 2+ years of experience in Software Development, preferably with high performance algorithms or data intensive applications. A deep and intuitive understanding of Algorithms and Data Structures. Ability to process, assimilate, and explain complex and abstract concepts from research publications. Operations Research or Management Engineering Mathematical Optimization Data Science / Machine Learning Master’s Degree or PhD in Applied Mathematics/ Management Science/ Operations Research/ Computer Science / Engineering, or related technical discipline. Base salary of $80K - $115K + performance-based bonus or stock options Work-Life Balance: Flex time, work from home days and travel incentives. Set-up: Standing / adjustable desks, massage chair & quiet rooms, employee lounge with Xbox, Switch & PS4. Benefits Plan: Fitness allowance, dental/prescription/vision, massage & physio, and healthcare spending account. Food & Fun: Fully stocked kitchen, fancy coffee machine, team lunches, long weekend bottle draws and monthly employee events. 
ScrapedJobID1173:
Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. AWS Cloud (certification is an asset) AWS services like AWS glue or other AWS services Python programming language. Big Data technologies (like a Spark, hive/HDFS, PySpark, Hadoop) SQL and NoSQL databases, including Postgres and Cassandra. Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. AWS cloud services: EC2, EMR, RDS, Redshift Stream-processing systems: Storm, Spark-Streaming, etc. Object-oriented/object function scripting languages: Java, C++, Scala, etc. 
ScrapedJobID1174:
Work on ROCm stack packaging solution for individual and enterprise level deployment on distributed cloud infrastructure Debug Machine Learning/ High Performance Computing related issues on Radeon Open Compute Stack (ROCm) Develop test contents for sophisticated Machine Learning algorithms on distributed nodes Port High Performance computing application on ROCm Reproduce field defects and develop appropriate tests to prevent future issues. Design, develop and deploy testing tools and automation libraries vital to perform testing. Be responsible for the adoption of tooling and industry standard methodologies by means of advocacy and outreach to help our development communities’ level up. Languages: Python, C, C++, Linux Shell scripting. Frameworks/Libraries: TensorFlow, PyTorch, ONNXRT Tools: Prior experience with Linux, Docker, LLVM compilers, GNU make /CMAKE, Jenkins, Git/Gerrit Understanding of High-Performance Computing application, Machine learning and GPU Programming, MPI Parallel Programming 
ScrapedJobID1175:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1176:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID1177:
Overseeing the development of software to clean and investigate large, messy data sets of numerical and textual data Networking with various teams to explore internal and external data sources and APIs to help uncover new trends and improve analysis Designing and contributing to highly scalable data pipelines, tools, and products to enable the analyst community to fully leverage the power of AWS Working with your team to analyze large swaths of data in order to optimize various business programs Managing and developing talent to drive a highly performant and engaged team Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, you’re not afraid to blurt out your disruptive idea. You know how the latest tech works, yet you are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. Crafty: You know how to get things done. You can navigate a large organization, motivate people, and influence your peers. Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Inspiring: You have a passion for developing people and take great pride in your management system. You know how to deliver through others while paving the way for their growth. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook and all the monitors you want! You can travel to a relevant conference of your choice annually - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours, dress code and environment Bachelor’s Degree in a quantitative field At least 5 year of experience in open source programming languages for large scale data analysis (Python, Scala, or Java) At least 5 year of experience with version control system like Git and GitHub. At least 5 year of experience with relational databases and programming in SQL At least 2 years in lead positions (managing people/owning products/architecting and driving an agenda) Master’s Degree or PhD Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) Experience with CICD tools Experience with Machine Learning workflows 5+ years experience in Python 5+ years’ experience with SQL 3+ years in lead positions (managing people/owning products/architecting and driving an agenda) 
ScrapedJobID1178:
By delivering an award-winning product, conceptualized and developed by award-winning leaders, that result in award-winning customer employee experiences By hiring highly innovative, diverse talent that fully embraces and embodies our core values in everything they do: Customer Focus, Equity, Shared Ambition, Agility, Transparency, Optimism By using modern technology, such as voice-activation with Dayforce Assistant and access to your money as soon as you earn it with Dayforce Wallet to stay in rhythm with the evolving demands of our 4 million global users As a ML Engineer, you join a high performing agile team, responsible for building new models, updating current modules, and adding new features to our products, as well as other duties as assigned. The selected candidate will have prior experience with ML deployment, Python, and have used Linux or Git. Prior SQL knowledge is also desired. Our machine learning team works on challenging problems related to text mining, predictive model building and validation, data normalization and other data science activities. Your impact will be evident through your effective participation in the entire lifecycle of our software including design, analysis, prototyping, development, testing and support of our products. You will work closely and collaborate with implementation partners, to envision and deliver the required functionality. Encouragement to be the best version of yourself at and away from work: YOUnity diversity and inclusion programs Amazing time away from work programs Support for your total well-being through our Live Well, Work Well programs targeting all aspects of your life Recognition for your contributions through excellent pay, perks, and rewards Giving where you’re living: volunteer days, Ceridian sponsored events, and our very own charity, Ceridian Cares Opportunities to fuel your career growth through numerous internal and external programs and events Expertise in building and configuring production-ready machine learning systems. Expertise in using machine learning libraries in Python, or similar. Experience with complex SQL using PostgreSQL, or similar. Experience in consuming and building APIs in Node.js, Python, or similar. A passion for software development that often extends beyond your work An understanding of Linux systems A high level of comfort using Git and Github A desire to learn new technologies and techniques Nice to have: projects or contributions on github we can see 
ScrapedJobID1179:
Design and deployment of n-tier application and security design, documentation, and configuration for medium and large corporate implementations to the cloud. Coordinate the development and integration of large enterprise applications, Software defined storage, infrastructure, virtualization, technology roadmap, data architecture roadmap, data product roadmap. Direct cooperation with development teams on providing guidance about product development, roadmap and backlog Enhance platform capabilities, including data processing task automation, integration and deployment of analysis pipelines for internal use Knowledge and practical experience in data products development, that includes data processing and modelling techniques, tools, metadata structures, data lakes, and data dictionaries. BS/BA in computer sciences, mathematics, life sciences or related degrees Graduate degree in Data Science or other quantitative field is preferred Practical (ie. development) and conceptual (on the solution architecture level) knowledge and relevant experience on the front-end application development and integration with 3rd party tools and platforms (eg. Tibco Spotfire, Tableau, etc.) Product Ownership experience and skills, ie. ability to work directly with business users to determine the product direction and backlog Ability to translate business requirements into functional requirements Ability to perform Solution Architect role for web-based applications (both JS and TS) in the cloud environment Experience with AWS cloud infrastructure services Defined standards and lead implementation of software development processes Strong SAAS skills Monday to Friday front-end application development: 5 years (preferred) AWS cloud infrastructure service: 5 years (preferred) SaaS: 5 years (preferred) 
ScrapedJobID1180:
collaborate with Product and other engineers to define, design, and build platform and web applications contribute across the entire software development lifecycle, including requirements definition, design, development, testing, deployment, and operations be a technical leader in your squad, helping to drive technical decisions, prioritizations, and tradeoffs mentor / guide other engineers and help improve technical and other practices within the squad Collaborate cross-functionally with Product Managers, Designers, and other engineers, including Machine Learning, Front-End/Full Stack, DevOps, and QA Leverage your knowledge to design, build, and deliver scalable and resilient software Drive technical decisions, prioritizations, and tradeoffs within the squad Creatively solve functional challenges with the Product team even when the initial answer is not fully defined Creatively solve technical challenges in the face of competing tradeoffs Design easy-to-use interfaces that will be leveraged by other developers, including APIs for 3rd-party developers Ensure product quality and code quality by writing automated tests and performing thorough code reviews and design reviews Minimum 5 years of experience solving backend software engineering challenges Experience in building enterprise-grade systems and scalable distributed systems Proven technical leadership abilities Proven mentorship and ownership abilities Strong ability to reason about engineering approaches to a problem Strong software architecture and design experience Comfortable learning and implementing new technologies Experience with database systems, including SQL and/or NoSQL solutions Track record of shipping high-quality code Experience in an Agile and DevOps environment Within your first 30 days: You will get acquainted and eventually be fully comfortable navigating the full codebase, the technology stack, the development processes and org structure within the company. You will learn the product and will make your first significant, user-impacting contributions to one of our products. You will get to know our ML domain, codebase, and practical applications. Within your first quarter and beyond: You will be an integral part of the team and a driven, focused self-starter who can navigate a certain amount of ambiguity, and who is not afraid to take a sizable chunk of functionality, analyze it, break it down, implement it and then assume ownership and responsibility over it. You will be taking an active role in discussions about possible solutions, different approaches, API designs and more. Top notch medical and dental coverage for you and your family 30 days of paid leave annually to help nurture work-life symbiosis Stock options Wellness stipend Pre-tax transportation and commuter benefits 6-month parental leave (or double salary to pay for your partner's unpaid leave) Free travel for any person accompanying a breastfeeding mother and her baby on a business trip A dependent care stipend up to $3,000 (USD) per month, per child, under the age of 21 for a maximum of $6,000 (USD) per month total Budget to attend conferences, train, and further your education $1,250 (CAD) one-time-use WFH stipend and $95 (CAD) monthly WFH stipend Relocation assistance 
ScrapedJobID1181:
Linux GPU driver development in support of Machine Learning and Data Centre applications Contributes to software projects of significant technical importance Solves sophisticated non-recurring problems that leads to development and implementation Debug, analyze and resolve quality and certification issues as reported by Customers and QA Write detailed design notes for new features Coordinate closely with peers and colleagues to ensure timely and effective communication of all assigned work activities Coordinate with developers in the open-source development community Proficient in C and C++ programming Excellent debugging and trouble-shooting skills Strong general Linux systems administration, software development, and troubleshooting knowledge and experience. Linux kernel development experience, either core kernel development or device driver development. PC architecture knowledge Strong oral and written communication skills Experience with Linux containers kernel level implementation (cgroups, namespaces) Familiarity with Linux networking and network/cluster management Familiarity with Linux GPU driver development (kernel and user-mode), ideally on AMD hardware. Familiarity with compute, graphics, or multimedia GPU application development using APIs such as OpenCL, OpenGL, and VAAPI. Proven track record of contributions to open-source projects Familiarity with Linux security subsystems such as selinux and/or AppArmor Bachelor's degree or Master’s in Computer Science or related degree with validated experience 
ScrapedJobID1182:
Responsible for server side applications Analysis, Design & Development. Collaborate with business partners on the trading floor to create performant applications that deliver real time insights on millions of data points. Responsible for creating high throughput applications leveraging existing Citi Big data framework, Part of an innovative team pursing boundaries to create innovative data visualization solutions. Ability to take initiative to research, learn and recommend emerging technologies. Be part of a dynamic group working towards a common goal. Work with developers onshore, offshore and matrix teams to implement a business solution Proficiency in Java or Python. Experience with customer analytics. Relish tackling new challenges, paying attention to details, and growing professionally. Basic shell commands and shell scripting. Adapts machine learning and deep learning technologies to the finance products Strong familiarity with machine learning and statistical techniques Knowledge and experience of distributed computing Knowledge of advanced statistical techniques and concepts. Extensive hand-coding expertise in Core Java development Experience with PySpark/Pandas and related data analytics libraries Adapts machine learning and deep learning technologies to the finance products Experience with messaging systems like Kafka & EMS (Solace, Tibco) Experience in Hadoop framework with good understanding of HDFS, Hive, HBase, Spark 
ScrapedJobID1183:
Lead the team responsible for driving AI/ML adoption across Rogers Establish data science as a discipline and drive adoption of the data enablers across the organization Work across Rogers technology and business teams to further develop the AI/ML vision and strategy that outlines a target operating model and roadmap to maximize the value of information assets via their creation, access and use. Develop the technology, tools and enablers that will deliver the desired business outcomes. Establish frameworks and policies around use of AI/ML at Rogers, in particular ethics framework. Develop and deliver ML algorithms and data science approaches for the business Establish strategic industry partnerships to drive innovation Deliver ML Ops and guard rails for deployment to ensure consistent use of AI across Rogers and align to security and data standards Manage onboarding of talent, serve as a talent pipeline by establishing onboarding and skilling journeys Bachelor’s degree in Computer Science, Engineering, Data Science, Applied Mathematics or a related field Extensive experience working with data technologies, including pipelines, data lakes, data warehouse, analytics tools, machine learning, visualization and business intelligence Experience developing and deploying AI/ML models to address specific industry challenges Understanding of cloud, data, security and AI/ML and ML Ops with proven experience establishing strategy and frameworks to drive adoption and solid understanding of data security and privacy Collaborative by nature and comfortable running a COE model and shared services Experience developing business cases and strategy and an ability to drive strategy through to execution and operations Large program delivery experience, working across different teams and organization Proven leader with ability to motivate a team to achieve outstanding results Extraordinary team player that thrives in a fast-paced environment where quality, innovation, speed of decision making and execution are critical to organizational success Supports and strengthens the corporate brand and company culture Executive presence, with the ability to navigate difficult situations and build relationships via persuasive negotiator skills Brings a high degree of initiative, is able to work in an ever changing environment, and is able to manage ambiguity and relentless focus on prioritizing and balancing multiple stakeholder goals Our people are at the heart of our success Our customers come first. They inspire everything we do We do what’s right, each and every day We believe in the power of new ideas We work as one team, with one vision We give back to our communities and protect our environment 
ScrapedJobID1184:

ScrapedJobID1185:
Lead the translation of marketing requests and questions into analytical problems. Requests can be strategic or tactical in nature, including but not limited to targeting, segmentation, list generation and automation, development of dashboards, reports, and measurement. Responsible for the extraction, review, and preparation of complex operational and customer behavior information from a variety of databases (SQL, GCP, etc). Use Cloud based Python/Scala environment to process big data, conduct analysis, and visualizing the results. Generate meaningful insights to solve business problems, identify new opportunities and drive strategy. Build presentations to clearly articulate insights, while simplifying complex data and processes for various levels of audiences including senior management Support the execution of loyalty campaigns at Loblaws Work collaboratively with business partners in marketing, digital and tech teams. Synthesize large amounts of data from multiple sources, including customer transaction data, consumer & syndicated research, market share, and campaign results. Extrapolate and interpret appropriate information to deliver value-added recommendations University Degree in Data Science, Computer Science, Statistics, Mathematics, Economics, Engineering, Business or other relevant field 3-5 years related work experience in an analytical role. Experience ideally in Retail, Loyalty, CPG industry, Consumer Finance, Telecommunications, or Consulting Programming skills in various languages (Python, Spark, PySpark, SQL, R, Hive). Advanced SQL is mandatory. Advanced Python is preferred. Experience with cloud platforms (i.e. GCP and Azure) is preferred. Experience with building models on big data is preferred. Ability to synthesize large amounts of data into insights Strong ability to build presentations and present complex ideas in a clear, articulate way Strong interpersonal skills and comfortable leading discussions and collaborating with cross functional teams Demonstrate strong business acumen Strong skills in Microsoft Office suite (Excel, Powerpoint) Strong attention to detail Curiosity and willingness to ask questions 
ScrapedJobID1186:
Develop and maintain algorithms, data pipelines, automated processes, and services to create a data science solution that are customer focused Extract mission-critical insights from datasets Innovate and bring creative ideas to building mission critical customer facing products that depend on ML solutions Work with product and business teams to identify solutions and best practices Create scalable models that drive business decisions and enable our customers’ success Design and develop processes and systems which analyze and generate actionable insights from diverse data sources Develop tools to monitor models for evolving performance and accuracy Mentor team members in the areas of technical expertise and career building Contribute to best practices around feature extraction, model development, and knowledge sharing among multiple data science teams Directly contribute to architecture planning Been in the ML engineering game for some time. You have a Bachelors/Masters and 4+ years of industry experience Proven ability to architect data science solutions to complex problems and delivering solutions in customer facing products Experience delivering solutions that analyzes big datasets using tools such as Apache Spark Experience delivering solutions that analyzes time-series data Strong programming skills in Python A strong command of SQL and working with multiple relational databases and data warehouses (Redshift, Postgres, Athena, Snowflake, etc…) Experience in end-to-end machine learning project life cycle Experience working with unstructured data Are scrappy when extracting useful insights with partial data A solid experience in working with software development teams and using source version control tools like Git Experience deploying deep learning models Experience with frameworks for in-production ML code (e.g. Kedro) Developing and deploying using Docker With some of the AWS services (e.g. EC2, S3, Sage Maker, Cloudwatch) With accessing data from other datastores in the AWS ecosystem such as ElasticSearch, S3, and DynamoDB The BEST team. Remote-first culture. International Meetups. Access to Jungle Scout tools & experts. Performance Bonus. Flexible Vacation. Comprehensive Health Benefits & Retirement Program. 
ScrapedJobID1187:
Stay abreast of innovations and publications in the field of operations research and business intelligence systems. Research and solve complex scheduling, resource allocation and pricing scenarios involved in operations optimization. Analyze raw operational data and design algorithms that can automatically and consistently generate operational recommendations for clients. Contribute to the invention of novel solutions to client’s operational problems by collaboratively working with product managers, co-developers, and our client success team. Utilize efficient algorithm design in a parallelized fashion capable of crunching gigabytes of operations data in minutes and scaling up with client growth. Build dashboards that transform operational data into visualizations that are intuitive and actionable Contribute refinements to our existing product through the development of new features as well as refactoring existing code to make it more efficient and object-oriented. Advance your knowledge of new software tools, agile programming methods, business intelligence technologies and share your knowledge with the development team, thus catalyzing process / technology changes to help us be more effective. Languages: C#, JavaScript, TypeScript Frameworks: .NET Core, Angular Web Server: IIS, NGINX Databases: MS SQL, Azure SQL Infrastructure: Azure, Docker, Kubernetes, GitLab Logistics engine: algorithms for discrete optimization problems Operation Systems: Windows, Linux Development Processes: Agile, CI/CD 2+ years of experience in Software Development, preferably with high performance algorithms or data intensive applications. A deep and intuitive understanding of Algorithms and Data Structures. Ability to process, assimilate, and explain complex and abstract concepts from research publications. Operations Research or Management Engineering Mathematical Optimization Data Science / Machine Learning Master’s Degree or PhD in Applied Mathematics/ Management Science/ Operations Research/ Computer Science / Engineering, or related technical discipline. Base salary of $80K - $115K + performance-based bonus or stock options Work-Life Balance: Flex time, work from home days and travel incentives. Set-up: Standing / adjustable desks, massage chair & quiet rooms, employee lounge with Xbox, Switch & PS4. Benefits Plan: Fitness allowance, dental/prescription/vision, massage & physio, and healthcare spending account. Food & Fun: Fully stocked kitchen, fancy coffee machine, team lunches, long weekend bottle draws and monthly employee events. 
ScrapedJobID1188:
Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. AWS Cloud (certification is an asset) AWS services like AWS glue or other AWS services Python programming language. Big Data technologies (like a Spark, hive/HDFS, PySpark, Hadoop) SQL and NoSQL databases, including Postgres and Cassandra. Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. AWS cloud services: EC2, EMR, RDS, Redshift Stream-processing systems: Storm, Spark-Streaming, etc. Object-oriented/object function scripting languages: Java, C++, Scala, etc. 
ScrapedJobID1189:
Work on ROCm stack packaging solution for individual and enterprise level deployment on distributed cloud infrastructure Debug Machine Learning/ High Performance Computing related issues on Radeon Open Compute Stack (ROCm) Develop test contents for sophisticated Machine Learning algorithms on distributed nodes Port High Performance computing application on ROCm Reproduce field defects and develop appropriate tests to prevent future issues. Design, develop and deploy testing tools and automation libraries vital to perform testing. Be responsible for the adoption of tooling and industry standard methodologies by means of advocacy and outreach to help our development communities’ level up. Languages: Python, C, C++, Linux Shell scripting. Frameworks/Libraries: TensorFlow, PyTorch, ONNXRT Tools: Prior experience with Linux, Docker, LLVM compilers, GNU make /CMAKE, Jenkins, Git/Gerrit Understanding of High-Performance Computing application, Machine learning and GPU Programming, MPI Parallel Programming 
ScrapedJobID1190:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1191:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID1192:
Overseeing the development of software to clean and investigate large, messy data sets of numerical and textual data Networking with various teams to explore internal and external data sources and APIs to help uncover new trends and improve analysis Designing and contributing to highly scalable data pipelines, tools, and products to enable the analyst community to fully leverage the power of AWS Working with your team to analyze large swaths of data in order to optimize various business programs Managing and developing talent to drive a highly performant and engaged team Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, you’re not afraid to blurt out your disruptive idea. You know how the latest tech works, yet you are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. Crafty: You know how to get things done. You can navigate a large organization, motivate people, and influence your peers. Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Inspiring: You have a passion for developing people and take great pride in your management system. You know how to deliver through others while paving the way for their growth. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook and all the monitors you want! You can travel to a relevant conference of your choice annually - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours, dress code and environment Bachelor’s Degree in a quantitative field At least 5 year of experience in open source programming languages for large scale data analysis (Python, Scala, or Java) At least 5 year of experience with version control system like Git and GitHub. At least 5 year of experience with relational databases and programming in SQL At least 2 years in lead positions (managing people/owning products/architecting and driving an agenda) Master’s Degree or PhD Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) Experience with CICD tools Experience with Machine Learning workflows 5+ years experience in Python 5+ years’ experience with SQL 3+ years in lead positions (managing people/owning products/architecting and driving an agenda) 
ScrapedJobID1193:
By delivering an award-winning product, conceptualized and developed by award-winning leaders, that result in award-winning customer employee experiences By hiring highly innovative, diverse talent that fully embraces and embodies our core values in everything they do: Customer Focus, Equity, Shared Ambition, Agility, Transparency, Optimism By using modern technology, such as voice-activation with Dayforce Assistant and access to your money as soon as you earn it with Dayforce Wallet to stay in rhythm with the evolving demands of our 4 million global users As a ML Engineer, you join a high performing agile team, responsible for building new models, updating current modules, and adding new features to our products, as well as other duties as assigned. The selected candidate will have prior experience with ML deployment, Python, and have used Linux or Git. Prior SQL knowledge is also desired. Our machine learning team works on challenging problems related to text mining, predictive model building and validation, data normalization and other data science activities. Your impact will be evident through your effective participation in the entire lifecycle of our software including design, analysis, prototyping, development, testing and support of our products. You will work closely and collaborate with implementation partners, to envision and deliver the required functionality. Encouragement to be the best version of yourself at and away from work: YOUnity diversity and inclusion programs Amazing time away from work programs Support for your total well-being through our Live Well, Work Well programs targeting all aspects of your life Recognition for your contributions through excellent pay, perks, and rewards Giving where you’re living: volunteer days, Ceridian sponsored events, and our very own charity, Ceridian Cares Opportunities to fuel your career growth through numerous internal and external programs and events Expertise in building and configuring production-ready machine learning systems. Expertise in using machine learning libraries in Python, or similar. Experience with complex SQL using PostgreSQL, or similar. Experience in consuming and building APIs in Node.js, Python, or similar. A passion for software development that often extends beyond your work An understanding of Linux systems A high level of comfort using Git and Github A desire to learn new technologies and techniques Nice to have: projects or contributions on github we can see 
ScrapedJobID1194:
Design and deployment of n-tier application and security design, documentation, and configuration for medium and large corporate implementations to the cloud. Coordinate the development and integration of large enterprise applications, Software defined storage, infrastructure, virtualization, technology roadmap, data architecture roadmap, data product roadmap. Direct cooperation with development teams on providing guidance about product development, roadmap and backlog Enhance platform capabilities, including data processing task automation, integration and deployment of analysis pipelines for internal use Knowledge and practical experience in data products development, that includes data processing and modelling techniques, tools, metadata structures, data lakes, and data dictionaries. BS/BA in computer sciences, mathematics, life sciences or related degrees Graduate degree in Data Science or other quantitative field is preferred Practical (ie. development) and conceptual (on the solution architecture level) knowledge and relevant experience on the front-end application development and integration with 3rd party tools and platforms (eg. Tibco Spotfire, Tableau, etc.) Product Ownership experience and skills, ie. ability to work directly with business users to determine the product direction and backlog Ability to translate business requirements into functional requirements Ability to perform Solution Architect role for web-based applications (both JS and TS) in the cloud environment Experience with AWS cloud infrastructure services Defined standards and lead implementation of software development processes Strong SAAS skills Monday to Friday front-end application development: 5 years (preferred) AWS cloud infrastructure service: 5 years (preferred) SaaS: 5 years (preferred) 
ScrapedJobID1195:
You are a highly effective and customer-obsessed advanced analytics professional You are passionate about product innovation and creating a step change leveraging the power of cloud, big data and advanced analytics You have experience working on data-intensive projects, using modern data platforms and tools and advanced analytics methods and approaches You are comfortable working with minimal direction and exercising considerable latitude in determining objectives and leading other data scientists Be a courageous safety leader, adhere to and sponsor safety and environmental rules and procedures Actively seek and assess opportunities to apply advanced analytics to optimize performance across Teck’s operations in North and South Americas Partner with and elevate a team of data scientists, providing leadership through consulting and coaching on a regular basis Lead end-to-end design and implementation of Machine Learning and Data Analytics solutions for 2-3 use cases at a time to optimize productivity, safety and sustainability:
Work with a variety of business stakeholders to identify and prioritize use cases
Identify, profile and analyze large, complex, multi-dimensional datasets with a variety of tools to draw relevant insights
Use data science techniques to find data patterns, anomalies and optimization opportunities through analytical solutions
Solve complex business problems by designing, developing and implementing sustainable advanced analytics solutions
Plan model operationalization and rollout of solutions to business users
Plan projects and communicate project status, emerging issues, and next steps to relevant stakeholders in the organization Work with a variety of business stakeholders to identify and prioritize use cases Identify, profile and analyze large, complex, multi-dimensional datasets with a variety of tools to draw relevant insights Use data science techniques to find data patterns, anomalies and optimization opportunities through analytical solutions Solve complex business problems by designing, developing and implementing sustainable advanced analytics solutions Plan model operationalization and rollout of solutions to business users Plan projects and communicate project status, emerging issues, and next steps to relevant stakeholders in the organization Identify new ways of piloting models, actively sourcing and incorporating feedback with learnings from the field Provide expert guidance on Teck’s data, systems and environment to external partners and vendors providing data science and data engineering services Write highly optimized and reusable code extending our internal data science toolkit and contributing to an enterprise-wide platform for advanced analytics called Galileo Support hiring and onboarding of new data scientists in collaboration with Manager of Data Science and HR team Willingness to travel up to 40% of the time to Teck’s operations across North and South Americas PhD or Master’s degree in the field of Computer Science, Machine Learning, Applied Statistics, Mathematics or equivalent 7+ years of relevant industry work experience developing advanced analytics solutions A deep understanding of a variety of statistical modelling and machine learning approaches and ability to apply them to business problems Demonstrated proficiency with programming languages such as Python, R, SQL Experience with popular machine learning frameworks, libraries and utilities Experience with popular optimization framework and libraries (Gurobi, IBM Cplex, etc.) Experience working with large data sets and distributed computing tools Experience with a wide range of data collection systems including edge computing technologies Working knowledge of at least one enterprise-grade cloud computing platforms such as Microsoft Azure, Amazon Web Services or Google Cloud Platform Exceptional organizational and time management skills with the ability to meet deadlines and balance multiple projects Excellent analytical and critical thinking skills, combined with the ability to present your ideas clearly and compellingly to both technical and non-technical audiences Demonstrated ability to work well as part of agile, multidisciplinary teams Strong interpersonal skills and previous experience coaching and mentoring data scientists Interest in gaining the knowledge of mining industry and systems used in engineering, operations, process control and maintenance functions Experience or education in mineral processing, maintenance, process control or supply chain would be an asset Experience with real-time systems that support Asset Health, Dispatch and/or Processing workflows would be an asset 
ScrapedJobID1196:
collaborate with Product and other engineers to define, design, and build platform and web applications contribute across the entire software development lifecycle, including requirements definition, design, development, testing, deployment, and operations be a technical leader in your squad, helping to drive technical decisions, prioritizations, and tradeoffs mentor / guide other engineers and help improve technical and other practices within the squad Collaborate cross-functionally with Product Managers, Designers, and other engineers, including Machine Learning, Front-End/Full Stack, DevOps, and QA Leverage your knowledge to design, build, and deliver scalable and resilient software Drive technical decisions, prioritizations, and tradeoffs within the squad Creatively solve functional challenges with the Product team even when the initial answer is not fully defined Creatively solve technical challenges in the face of competing tradeoffs Design easy-to-use interfaces that will be leveraged by other developers, including APIs for 3rd-party developers Ensure product quality and code quality by writing automated tests and performing thorough code reviews and design reviews Minimum 5 years of experience solving backend software engineering challenges Experience in building enterprise-grade systems and scalable distributed systems Proven technical leadership abilities Proven mentorship and ownership abilities Strong ability to reason about engineering approaches to a problem Strong software architecture and design experience Comfortable learning and implementing new technologies Experience with database systems, including SQL and/or NoSQL solutions Track record of shipping high-quality code Experience in an Agile and DevOps environment Within your first 30 days: You will get acquainted and eventually be fully comfortable navigating the full codebase, the technology stack, the development processes and org structure within the company. You will learn the product and will make your first significant, user-impacting contributions to one of our products. You will get to know our ML domain, codebase, and practical applications. Within your first quarter and beyond: You will be an integral part of the team and a driven, focused self-starter who can navigate a certain amount of ambiguity, and who is not afraid to take a sizable chunk of functionality, analyze it, break it down, implement it and then assume ownership and responsibility over it. You will be taking an active role in discussions about possible solutions, different approaches, API designs and more. Top notch medical and dental coverage for you and your family 30 days of paid leave annually to help nurture work-life symbiosis Stock options Wellness stipend Pre-tax transportation and commuter benefits 6-month parental leave (or double salary to pay for your partner's unpaid leave) Free travel for any person accompanying a breastfeeding mother and her baby on a business trip A dependent care stipend up to $3,000 (USD) per month, per child, under the age of 21 for a maximum of $6,000 (USD) per month total Budget to attend conferences, train, and further your education $1,250 (CAD) one-time-use WFH stipend and $95 (CAD) monthly WFH stipend Relocation assistance 
ScrapedJobID1197:
Linux GPU driver development in support of Machine Learning and Data Centre applications Contributes to software projects of significant technical importance Solves sophisticated non-recurring problems that leads to development and implementation Debug, analyze and resolve quality and certification issues as reported by Customers and QA Write detailed design notes for new features Coordinate closely with peers and colleagues to ensure timely and effective communication of all assigned work activities Coordinate with developers in the open-source development community Proficient in C and C++ programming Excellent debugging and trouble-shooting skills Strong general Linux systems administration, software development, and troubleshooting knowledge and experience. Linux kernel development experience, either core kernel development or device driver development. PC architecture knowledge Strong oral and written communication skills Experience with Linux containers kernel level implementation (cgroups, namespaces) Familiarity with Linux networking and network/cluster management Familiarity with Linux GPU driver development (kernel and user-mode), ideally on AMD hardware. Familiarity with compute, graphics, or multimedia GPU application development using APIs such as OpenCL, OpenGL, and VAAPI. Proven track record of contributions to open-source projects Familiarity with Linux security subsystems such as selinux and/or AppArmor Bachelor's degree or Master’s in Computer Science or related degree with validated experience 
ScrapedJobID1198:
Responsible for server side applications Analysis, Design & Development. Collaborate with business partners on the trading floor to create performant applications that deliver real time insights on millions of data points. Responsible for creating high throughput applications leveraging existing Citi Big data framework, Part of an innovative team pursing boundaries to create innovative data visualization solutions. Ability to take initiative to research, learn and recommend emerging technologies. Be part of a dynamic group working towards a common goal. Work with developers onshore, offshore and matrix teams to implement a business solution Proficiency in Java or Python. Experience with customer analytics. Relish tackling new challenges, paying attention to details, and growing professionally. Basic shell commands and shell scripting. Adapts machine learning and deep learning technologies to the finance products Strong familiarity with machine learning and statistical techniques Knowledge and experience of distributed computing Knowledge of advanced statistical techniques and concepts. Extensive hand-coding expertise in Core Java development Experience with PySpark/Pandas and related data analytics libraries Adapts machine learning and deep learning technologies to the finance products Experience with messaging systems like Kafka & EMS (Solace, Tibco) Experience in Hadoop framework with good understanding of HDFS, Hive, HBase, Spark 
ScrapedJobID1199:
Lead the team responsible for driving AI/ML adoption across Rogers Establish data science as a discipline and drive adoption of the data enablers across the organization Work across Rogers technology and business teams to further develop the AI/ML vision and strategy that outlines a target operating model and roadmap to maximize the value of information assets via their creation, access and use. Develop the technology, tools and enablers that will deliver the desired business outcomes. Establish frameworks and policies around use of AI/ML at Rogers, in particular ethics framework. Develop and deliver ML algorithms and data science approaches for the business Establish strategic industry partnerships to drive innovation Deliver ML Ops and guard rails for deployment to ensure consistent use of AI across Rogers and align to security and data standards Manage onboarding of talent, serve as a talent pipeline by establishing onboarding and skilling journeys Bachelor’s degree in Computer Science, Engineering, Data Science, Applied Mathematics or a related field Extensive experience working with data technologies, including pipelines, data lakes, data warehouse, analytics tools, machine learning, visualization and business intelligence Experience developing and deploying AI/ML models to address specific industry challenges Understanding of cloud, data, security and AI/ML and ML Ops with proven experience establishing strategy and frameworks to drive adoption and solid understanding of data security and privacy Collaborative by nature and comfortable running a COE model and shared services Experience developing business cases and strategy and an ability to drive strategy through to execution and operations Large program delivery experience, working across different teams and organization Proven leader with ability to motivate a team to achieve outstanding results Extraordinary team player that thrives in a fast-paced environment where quality, innovation, speed of decision making and execution are critical to organizational success Supports and strengthens the corporate brand and company culture Executive presence, with the ability to navigate difficult situations and build relationships via persuasive negotiator skills Brings a high degree of initiative, is able to work in an ever changing environment, and is able to manage ambiguity and relentless focus on prioritizing and balancing multiple stakeholder goals Our people are at the heart of our success Our customers come first. They inspire everything we do We do what’s right, each and every day We believe in the power of new ideas We work as one team, with one vision We give back to our communities and protect our environment 
ScrapedJobID1200:

ScrapedJobID1201:
As part of the development of the development and implementation the governance processes, understand stakeholder requests, define objectives, develop detailed project plans, develop strategies to mitigate and quantify risks. Support the development and implementation the governance processes to validate and syndicate changes to reference data across Oracle / SAS Modules that are approved by business. Understand business processes and systems as well as the various data flows, develop them if necessary, and establish new mapping tables, while ensuring their consistency and precision, in connection with conversion, integration, the mapping, transformation and analysis of financial data. Capture and track the measures and metrics related to the governance of data and report out any anomalies. Support the establishment of data quality management best practices, standards, guidelines & processes and ensure adherence across the organization through regular audits. Contribute to strong data analysis and solutioning in the data governance domain enabling stakeholders to manage, control and leverage quality information within and across business units and functional domains. This includes maintaining various dashboards, capability metrics and provision of reporting to identify trends, potential issues, support solutioning. Perform security and maintenance of EDMCS. Execute the loading of reference data into Oracle for new and existing dimensional data, execute create and change requests. Work with technical lead teams regarding customization and integration of finance applications. Interface and co-ordinate with the applicable functional business units to action changes to the master data files. With the team, act as an advisory role to the business team on future process models, product launches, support of acquisitions, changes in organizational structure. Execute requests for mass maintenance of reference data to ensure the appropriate standards and governance rules are maintained. Perform on-going 52-109 controls related to the data management and reporting (access, security, change management etc.). Act as support or back-up to the development and automation of reports defined as part of the current project. Bachelor's Degree in Accounting/Finance or equivalent experience. CPA Certified Public Accountant (asset). Experience and knowledge of integration / conversion and mapping of financial data. Experience in master data management strategies, data governance and/or data steward or equivalent experience (an asset). 3 to 4 years of relevant experience. Experience with 52-109/SOX controls Excellent oral/written communication skills. Strong analytical and problem-solving skills. Strong negotiation skills and ability to persuade, influence and motivate from a wide variety of functional background. Demonstrated ability to manage multiple priorities. An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID1202:

ScrapedJobID1203:
Architect implementation of scalable AI and machine learning algorithms Write efficient, performant, and maintainable code in Java, Kotlin, C/C++, Go, and/or SQL Efficiently store and retrieve large volumes of data for ML training and algorithm development Develop feature processing for machine learning models in TensorFlow and others Implement processing algorithms on real-time sensor data Collaborate closely with data scientists to invent algorithms Sense, understand, and derive insight into human motion while exercising Deliver personalized real-time feedback Dynamically adjust resistance to optimize training effectiveness and safety BS or higher degree in engineering field or equivalent experience Strong knowledge of Python and one of Java, C/C++, Kotlin, or Go Experience with databases, SQL or NoSQL Experience with signal processing or machine learning algorithms Team player with high integrity Open to feedback and constantly striving to improve High degree of self-awareness Experience with gyros and accelerometers, computer vision, machine learning, or control theory 
ScrapedJobID1204:
Diverse and inspiring colleagues and approachable leaders Stimulating work in a fast-paced, intellectually challenging environment Accelerated exposure and responsibility Global career development opportunities Being motivated every day by CPP Investments’ important social purpose and unshakable principles A deeply rooted culture of Integrity, Partnership and High Performance Develop and implement the next generation Analytics roadmap, prioritizing deliverables and products aligned to approved initiatives and firm-wide strategic priorities. Build and lead a team of highly impactful Data Science and advanced analytics resources. Determining priorities, providing development and growth opportunities and championing team across the organization. Work closely with departments across CPP Investments to understand investment needs for enterprise analytical products. Strengthen and forge relationships with key partners across the organization. Lead the development and execution of prototypes and products from an advanced analytics and data science perspective. Execution focused delivering value through Analytics. Lead the enterprise Development of data models and algorithms techniques for the use of financial market structure modeling. Bachelor’s degree, with a technology or business emphasis, or equivalent education and experience. Advanced degree preferred. Strong understanding of the investment lifecycle and proven track record of building analytical products for investment funds. Extensive background in analytical modeling, AI techniques. Track record in building and deploying data science products. Strong sense of teamwork Ability to create solutions to fit a diverse and complex environment Adaptable to new technologies and challenges not previously encountered Able to build strong relationships and communicate effectively with a diverse set of stakeholders, including business leaders, operational staff and technical engineers Proven project management experience Excellent written and oral communication skills, with the ability to work with both technical and business users Self-motivated with acute attention to detail Innovative and proactive Exemplify CPP Investments’ Guiding Principles of Integrity, High Performance and Partnership 
ScrapedJobID1205:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID1206:
Lead, manage and mentor the Machine Learning Engineers on your team Collaborate with our Engineering teams to help build production features that leverage our machine learning technologies Develop infrastructure for rapid machine learning feature prototyping, deployment, and evaluation with customers Build and optimize data lakes and feature stores to feed research projects Apply best practices for ETL and batch processing of database, log, image, and HTML data. Participate in large-scale project planning and stakeholder education 5 or more years of experience working with MLOps or Machine Learning Engineering Experience leading major projects and managing team members Experience deploying machine learning models in production, and with production architecture, monitoring and logging Excellent communication and emotional intelligence is required Exceptional experience programming with Python and the associated data science/machine learning packages (e.g. scikit-learn, pandas, xgboost, numpy, scipy) Management of databases (we principally use MySQL, Postgres, and DynamoDB) Cloud infrastructure, preferably AWS, especially S3, and CloudFormation Running services in Docker environments Experience with web technologies, including APIs (we use REST and GraphQL) Linux administration and command line tools Agile development, version control, and code review processes Big Data ETL (we principally use PySpark) 
ScrapedJobID1207:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID1208:

ScrapedJobID1209:
Design, modify, implement, test, and provide operational support for enterprise software products and platforms, including software infrastructure and development tools for the Data Develop, operate and drive scalable and resilient data platform to address the business requirements Create new opportunities in this space for Data Science as a Service (DSaaS) platform with new feature capabilities and new offerings that drive customer and business value Ensure industry best practices around data pipelines, metadata management, data quality, data governance and data privacy Strong knowledge of AWS cloud infrastructure computer, networking, storage and other AWS cloud services Proven experience with AWS services such as Data Pipeline, Step Functions, Batch, Lambda, CloudFormation, CloudWatch, EC2, EMR, SNS, IAM, ELB, EC2, S3, Redshift, Glue Experience with Big Data tech stack, including Hadoop, Python, Spark, PySpark, Scala, and Hive, and NoSQL data stores Knowledge and previous experience with Unix and Linux Experience working with large datasets and large-scale distributed computing Working knowledge of building out data marts, data warehouses, and data lakes Experience on ETL data pipelines development and performance tuning Experience with manipulating and transforming data Experience on columnar databases like Redshift, Redshift Spector Working knowledge of containers and container orchestration Proficiency using Kubeflow This individual must have strong knowledge of healthcare data, analytics & workflows, excellent problem-solving & project management capabilities, and a proven ability to design & drive Big Data platform. Excellent critical thinking, verbal and written communications skills Knowledge and experience in the healthcare industry is a plus Demonstrates strong drive to learn and advocate for development best practices. Prescription Drugs Vision Care – frames, lenses, contact lenses, eye exam, eye surgery Paramedical Services Dental Basic Services 1–5 Calendar Years of Service 120 hours 5+ Calendar Years of Service 160 hours 100% of contributions up to 3% of base salary Plus a 50% match on the next 2% contribution This role may be located anywhere in Canada – remote opportunity/home office. 
ScrapedJobID1210:
Work with senior leadership to architect Wayfair’s Machine Learning platforms and ensure that we deliver the right functionality, in a timely manner Leverage your deep knowledge of distributed systems engineering to build Wayfair’s next generation Machine Learning capabilities Design scalable systems using Python, Go, Kubernetes, Kafka, GCP, Airflow, and other technologies Think outside of the current technology/stack limitations to push the boundaries on what is possible and deliver feasible solutions collaboratively Champion open source solutions and Google Cloud native technologies, and their application to our use cases Develop end to end software solutions that power the full range of Machine Learning initiatives at Wayfair Partner with product leaders to understand technical pain points for data scientists and other engineers and translate them into clear and robust engineering solutions Promote a culture of engineering excellence and strengthen the technical expertise of our engineering and product teams 3+ years of experience in software engineering and designing systems at scale 1+ years of experience in Linux-based development, and Python development while leading engineering teams Strong understanding of containerization (Docker, etc.), and associated software engineering best practices Excellent communication skills with demonstrated experience driving teams forward and ability to influence technical decisions to line up with the company’s strategy Hands-on experience driving software development within high-growth environments at scale Excellent organizational, analytical, and hypothesis- driven critical thinking skills to transform data into actionable insights Mix of start-up and large-company experience working on Machine Learning solutions Familiarity with Machine Learning platforms offered by Google Cloud and how to implement them on a large scale 
ScrapedJobID1211:
Experience leading a technical team, including managing tasks and processes Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline 3+ years of Software Development experience with modern programming languages (Python, C/C++, Julia) Experience with at least one deep learning framework (TensorFlow, PyTorch, MXNet …) Experience working in version control such as git Experience in big data architectures and pipelines to build and deploy models Experience in building machine learning models optimized for speed, accuracy, scalability, reliability and resiliency Ability to perform complex data analysis and present findings to stakeholders Master’s degree in Computer Science, Computer Engineering or related technical discipline Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations Experience with prototyping machine learning solutions (e.g. Kaggle, demos, hackathons) Experience working with cloud platforms (e.g. AWS, Azure …) Experience with web development for demonstrations Strong communication skills Competitive salary Health and lifestyle benefits Positive & creative work environment in a great location Leadership role on an expanding team with opportunities for career growth 
ScrapedJobID1212:
Own the development and expansion of multiple models, leveraging machine learning Identify new opportunities and insights from the data (where can the models be improved? what is the projected ROI of a proposed modification?); continue to evolve models Architect and build technical platforms for our algorithmic engines to run at scale Work cross-functionally with Marketing and Engineering, and collaboratively with teammates Leverage the knowledge of state-of-the-art methodology and industry best practices to raise the technical standard of the team and Wayfair Data Science community Minimum 4 years of industry experience in a data science or ML Engineering role or 3 years of industry experience with Ph.D. in a quantitative field (e.g., economics, physics, neuroscience) Proficiency in Python Solid experience building Machine Learning (ML) models, preferably also productionalizing models (e.g., Airflow) Experience working with big data tools such as SQL, Spark, Hadoop, Hive, etc. Strong written and verbal communication skills, ability to synthesize conclusions for non-experts, and desire to influence business decisions A bias towards critical thinking, creatively solving problems from a customer-centric lens, and an intuitive sense for how the work aligns closely with business objectives Intellectual curiosity and enthusiastic about continuous learning Looking to make a big impact in a growing organization 
ScrapedJobID1213:
Own and contribute to the ML Pipeline development lifecycle from Data wrangling, Feature development, Training and tuning ML model with Data Scientist, Deploy and manage the Inference Pipeline. Develop a reusable code and pattern to scale the ML Pipeline to new business use cases and create a self service platform. Partner closely with the ML Platform team, Infrastructure team, and similar teams to ensure the Data science org has the data, computing resources, and workflows/abstractions needed to do our best work. Contribute to the roadmap, and project execution with cross-functional stakeholders and Eng partner teams. Define and advance MLOps best practices within data science and product teams Be obsessed with the customer and maintain a customer-centric lens in how we frame, approach, and ultimately solve every problem we work on. Contribute to SME initiative and code review in support of spreading best practices 4+ years experience as a ML Engineer, Data Engineer, Data Scientist with strong engineering skills and a passion for working on turning reference implementations into production-ready software. Proficiency in at least one high-level programming language (Python, Java, Scala or equivalent) used both for ML and automation tasks. Experience with Python ML ecosystem (numpy, pandas, sklearn, XGBoost, etc.) and Apache Spark Ecosystem (Spark SQL, MLlib/Spark ML) Hands-on experience building scalable ML & big data processing pipelines with big data tools such as Hadoop, Hive, SQL, Spark and GCP cloud services such as DataProc, BigQuery, GCS etc. Experience with automated data pipeline and workflow management tools, i.e. Airflow. Strong sense of ownership and growth mindset. Experience with basic software engineering tools, e.g., git, CI/CD environment (such as Jenkins or Buildkite), PyPi, Docker, Kubernetes, unit testing, and general object-oriented design. PhD or MSc or Bsc in Computer Science / Operations Research / Statistics or other quantitative fields Experience with common ML frameworks/libraries such as Vowel wabbit, Tensorflow, PyTorch is preferred. Experience with Cloud Services such as AWS SageMaker/GCP AI Platform. Deploying and scaling ML solutions using open-source frameworks (MLFlow, TFX, H2O, etc.) 
ScrapedJobID1214:
Generate meaningful insights to solve sometimes ambiguous business/customer problems identify new opportunities to drive member growth and digital engagement of PC Optimum Deep dive into customer journeys to understand and empathize with customer pain points and identify opportunities with respect to customer engagement, business strategy, and experience with our Loyalty program Oversee the extraction, review, and preparation of complex operational and customer behavior information from a variety of databases (SQL, GCP, etc). Synthesize large amounts of data from multiple sources, including customer transaction data, consumer & syndicated research, market share, and campaign results. Use Cloud based Python/Scala environment to process big data, conduct analysis, and visualizing the results. Build presentations to clearly articulate insights, while simplifying complex data and processes for various levels of audiences including senior management Provide leadership and coaching to ensure a high performing team with appropriate skills and capacity required to enable the organization’s objectives with the goal of enabling customer centric decision making Collaborate and be strategic lead across cross-functional pods of Loblaw Digital, Marketing, Loblaw Technology, DI&A, Operations, and the Customer COE to see strategy through to execution Develop short term and long term strategies paired with realistic go to market executional plans that is centered in customer centricity. Support the execution of loyalty campaigns at Loblaws, analyze results, and loop back on how to improve University Degree in Data Science, Computer Science, Statistics, Mathematics, Economics, Engineering, Business or other relevant field 5+ years related work experience in an analytical role. Experience ideally in Retail, Loyalty, CPG industry, Consumer Finance, Telecommunications, or Consulting A Passion for advocating for the customer and helping teams deliver exceptional customer experiences Programming skills in various languages (Python, Spark, PySpark, SQL, R, Hive). AdvancedSQL is mandatory. Advanced Python is preferred. Experience with cloud platforms (i.e. GCP and Azure) is preferred. Strong skills in Microsoft Office suite (Excel, Powerpoint) Experience with building models on big data is preferred Ability to synthesize large amounts of data into insights Strong ability to build presentations and present complex ideas in a clear, articulate way Self-starter: demonstrated initiative and willingness to take ownership and learn A creative and curious thinker who is comfortable working with ambiguity, ability to multi-task, prioritize workload and work in a fast-paced environment Strong interpersonal skills with the ability to build and maintain strong working relationships with cross functional teams; able to effectively communicate issues, actively engage and influence, and work collaboratively as a team member Showcase leadership and availability to coach high performing team Effective organizational skills with a strong attention to detail while managing multiple projects or workstreams 
ScrapedJobID1215:
Developing and supporting digital marketing campaigns, including paid Search Engine Marketing (SEM) and paid Social Media campaigns Acting as a subject matter expert for Search Engine Optimization (SEO) best practices, including ongoing technical audits of all digital properties Build Digital Results Report for clients for monthly review that encompasses all digital activities and important data KPI’s. Develop an understanding of what impact these KPI’s have on clients’ business. Manage effectiveness of Service Work Plan retention marketing Using available programs; plan, execute, and generate report on a targeted email marketing campaigns Act as a Data Scientist with regards to all the digital information we have available to us for our clients and communicate this data Oversee and manage all syndicated contents that includes various online platforms to promote business and products Working collaboratively across departments to understand company goals to develop customer acquisition, nurturing, and retention programs Study clients’ business and create a presentation based on potential and missed opportunity on the digital platform. Demonstrate to client your plan for their growth. Must be able to perform cold calls effectively and book appointments for consultation Visit businesses to generate new leads and perform updates on existing clients Requires travel 20%-50%%+ travel Bachelor’s degree or Diploma in Marketing, Business, Public Relations or 2-3 years of proven experience in sales, marketing, or communication Ability to put together effective, comprehensive, and multi-channelled marketing campaigns Have a high understanding of effective content for social media sites including Facebook, Twitter, and Instagram Manage, collaborate, and develop marketing and video assets Understanding of Google Analytics, Conversion Rate Optimization, User Experience (UX) Knowledge and Compliance with all provincial/federal advertising standards (CASL etc.) is a must. Graphical design understanding for digital properties and Point of Sale materials Excellent organizational, communication and leadership abilities. Team-oriented, relationship builder with a positive attitude. Strong oral/written communications skills. Strong organizational and multi-tasking skills with a high attention to detail Strong Proficiency in working with multiple software programs Automotive industry experience/ knowledge considered an asset. Must have valid driver’s license Passion for selling and building new relationships is a MUST. Bonus pay Commission pay Dental care Extended health care Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? No 
ScrapedJobID1216:
Take a hands-on role in several projects, including the Fundamental Review of the Trading Book (FRTB), data solutions for capital optimization, and data quality control processes. Prototype new approaches and enhance existing methodologies to advance market data management and data quality control. Develop production level code and collaborate with IT team for integration into daily bank processes. Assist team members for various ad-hoc analyses, data methodology, documentation, reporting, preparation of materials. Execute model runs on a regular basis for reporting and perform corresponding analyses. Communicate with model developers, trading desks, risk teams, and business lines to enhance data quality control and data management for capital optimization Become an active member of the team including our D&I initiatives and communities. Solid quantitative background and problem-solving skills with a keen interest in Data Science, Finance, Economics, Market Risk, Derivatives Pricing, Risk management or Regulations. Advanced degree in a mathematics, economics, or scientific discipline (e.g., Mathematics, Finance, Statistics, Physics, Engineering, Biology, Economics, etc.). Master’s degrees or PhDs are a bonus. Experience in code development in Python or other formal programing will be important to support day-day activity. Effective communication (written and oral), specifically the ability to summarize complex ideas in simple terms; you enjoy working in collaborations. The opportunity to join a forward-thinking company surrounded by a collaborative team of innovative thinkers. A rewarding career path with diverse opportunities for professional development. Internal development to support your growth and enhance your skills. A competitive compensation and benefits package. An organization committed to making a difference in our communities– for you and our customers. We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success! 
ScrapedJobID1217:
Lead, manage and mentor the Machine Learning Engineers on your team Collaborate with our Engineering teams to help build production features that leverage our machine learning technologies Develop infrastructure for rapid machine learning feature prototyping, deployment, and evaluation with customers Build and optimize data lakes and feature stores to feed research projects Apply best practices for ETL and batch processing of database, log, image, and HTML data. Participate in large-scale project planning and stakeholder education 5 or more years of experience working with MLOps or Machine Learning Engineering Experience leading major projects and managing team members Experience deploying machine learning models in production, and with production architecture, monitoring and logging Excellent communication and emotional intelligence is required Exceptional experience programming with Python and the associated data science/machine learning packages (e.g. scikit-learn, pandas, xgboost, numpy, scipy) Management of databases (we principally use MySQL, Postgres, and DynamoDB) Cloud infrastructure, preferably AWS, especially S3, and CloudFormation Running services in Docker environments Experience with web technologies, including APIs (we use REST and GraphQL) Linux administration and command line tools Agile development, version control, and code review processes Big Data ETL (we principally use PySpark) 
ScrapedJobID1218:
Developing and supporting digital marketing campaigns, including paid Search Engine Marketing (SEM) and paid Social Media campaigns Acting as a subject matter expert for Search Engine Optimization (SEO) best practices, including ongoing technical audits of all digital properties Build Digital Results Report for clients for monthly review that encompasses all digital activities and important data KPI’s. Develop an understanding of what impact these KPI’s have on clients’ business. Manage effectiveness of Service Work Plan retention marketing Using available programs; plan, execute, and generate report on a targeted email marketing campaigns Act as a Data Scientist with regards to all the digital information we have available to us for our clients and communicate this data Oversee and manage all syndicated contents that includes various online platforms to promote business and products Working collaboratively across departments to understand company goals to develop customer acquisition, nurturing, and retention programs Study clients’ business and create a presentation based on potential and missed opportunity on the digital platform. Demonstrate to client your plan for their growth. Must be able to perform cold calls effectively and book appointments for consultation Visit businesses to generate new leads and perform updates on existing clients Requires travel 20%-50%%+ travel Bachelor’s degree or Diploma in Marketing, Business, Public Relations or 2-3 years of proven experience in sales, marketing, or communication Ability to put together effective, comprehensive, and multi-channelled marketing campaigns Have a high understanding of effective content for social media sites including Facebook, Twitter, and Instagram Manage, collaborate, and develop marketing and video assets Understanding of Google Analytics, Conversion Rate Optimization, User Experience (UX) Knowledge and Compliance with all provincial/federal advertising standards (CASL etc.) is a must. Graphical design understanding for digital properties and Point of Sale materials Excellent organizational, communication and leadership abilities. Team-oriented, relationship builder with a positive attitude. Strong oral/written communications skills. Strong organizational and multi-tasking skills with a high attention to detail Strong Proficiency in working with multiple software programs Automotive industry experience/ knowledge considered an asset. Must have valid driver’s license Passion for selling and building new relationships is a MUST. Bonus pay Commission pay Dental care Extended health care Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? No 
ScrapedJobID1219:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID1220:
Own the development and expansion of multiple models, leveraging machine learning Identify new opportunities and insights from the data (where can the models be improved? what is the projected ROI of a proposed modification?); continue to evolve models Architect and build technical platforms for our algorithmic engines to run at scale Work cross-functionally with Marketing and Engineering, and collaboratively with teammates Leverage the knowledge of state-of-the-art methodology and industry best practices to raise the technical standard of the team and Wayfair Data Science community Minimum 4 years of industry experience in a data science or ML Engineering role or 3 years of industry experience with Ph.D. in a quantitative field (e.g., economics, physics, neuroscience) Proficiency in Python Solid experience building Machine Learning (ML) models, preferably also productionalizing models (e.g., Airflow) Experience working with big data tools such as SQL, Spark, Hadoop, Hive, etc. Strong written and verbal communication skills, ability to synthesize conclusions for non-experts, and desire to influence business decisions A bias towards critical thinking, creatively solving problems from a customer-centric lens, and an intuitive sense for how the work aligns closely with business objectives Intellectual curiosity and enthusiastic about continuous learning Looking to make a big impact in a growing organization 
ScrapedJobID1221:
Lead a team that applies state of the art data science and machine learning techniques to transform how we interact with current and prospective business customers Drive significant business growth and impact by collaborating with Marketing, Sales, Storefront, Profit Management, Product, and Engineering teams to scope, develop, and deploy holistic data science solutions to power end-to-end B2B customer experience and drive significant business growth and impact Manage a broad portfolio of existing initiatives and evolve them to be scalable, platform-oriented data science products. These include, but are not limited to, models and frameworks for contact personalization, customer targeting across touchpoints, tailored experience for large project shoppers, and intelligent sales discount recommendation system. Lead the design and development of intelligent products that leverage a wide variety of data sources - e.g. 1st- and 3rd-party data on customer behavior, order history, firmographic information, sales call recordings and transcripts, etc. - to improve customer targeting and agent productivity Master’s degree in Computer Science, Engineering, or related quantitative fields; PhD preferred 4+ years of experience leading multi-disciplinary technical teams comprised of data scientists and engineers of varied levels of experience Thorough command of general data science and machine learning techniques Relevant experience designing and implementing customer-facing systems that are scalable, fast, and resilient Track record of delivering large cross-functional projects and managing multiple stakeholders with competing priorities Good understanding of experimental techniques for the design of A/B tests to measure the impact Communication skills that can influence across organizations and at all levels 
ScrapedJobID1222:
Provide the Data Intelligence and Governance team with data analyses from researching systems and processes, profiling data via SQL queries, and validating data quality requirements. Identify and partner with data stewardship across the organization to operationalize the Data Governance framework. Champion data governance initiatives by promoting ideas into action; including developing and implementing data quality rules, communication, and adoption strategy. Oversee data quality management and data quality issue prioritization. Assist in developing data governance policies, processes, and documentation. Support corporate data quality initiatives through recommendation for solutions and leadership around data validation. Analyze and understand corporate data across data domains, on both source and target levels. Collaborate with other data analysts from cross-functional teams to address data quality issues and educate data stewardship on data governance principles. Identify new opportunities for data governance continually. Coordinates with various stakeholders and leaders across business functions to apply established data governance framework (training and education, developing data stewardship, data custodian roles, data dictionary, definitions and documentation, approval, and sign-off protocols). Are proficient in data analysis (preferably within software development, data delivery, and data analytics settings). Have a post-secondary degree in Data Science, Computing, Mathematics or Healthcare Informatics (preferably master’s level). Have 5+ years of experience in data management or data governance Are highly knowledgeable in databases and adept in SQL. Have hands-on experience in data visualization tools such as PowerBI. Are experienced with CRM tools such as SalesForce and NetSuite. Are exceptional at rapport building and creative problem solving. Have strong organizational, planning, and prioritization skills. Are goal-oriented, positive, a self-starter, with strong analytical skills. Are a data detective with excellent communication, known for collaborating and your ability to communicate complex data findings to various audiences. Demonstrate a proven track record of delivering results while guiding and facilitating business partners in solving data quality issues. Able to work independently and manage multiple commitments and responsibilities 
ScrapedJobID1223:
Architect implementation of scalable AI and machine learning algorithms Write efficient, performant, and maintainable code in Java, Kotlin, C/C++, Go, and/or SQL Efficiently store and retrieve large volumes of data for ML training and algorithm development Develop feature processing for machine learning models in TensorFlow and others Implement processing algorithms on real-time sensor data Collaborate closely with data scientists to invent algorithms Sense, understand, and derive insight into human motion while exercising Deliver personalized real-time feedback Dynamically adjust resistance to optimize training effectiveness and safety BS or higher degree in engineering field or equivalent experience Strong knowledge of Python and one of Java, C/C++, Kotlin, or Go Experience with databases, SQL or NoSQL Experience with signal processing or machine learning algorithms Team player with high integrity Open to feedback and constantly striving to improve High degree of self-awareness Experience with gyros and accelerometers, computer vision, machine learning, or control theory 
ScrapedJobID1224:

ScrapedJobID1225:
Diverse and inspiring colleagues and approachable leaders Stimulating work in a fast-paced, intellectually challenging environment Accelerated exposure and responsibility Global career development opportunities Being motivated every day by CPP Investments’ important social purpose and unshakable principles A deeply rooted culture of Integrity, Partnership and High Performance Develop and implement the next generation Analytics roadmap, prioritizing deliverables and products aligned to approved initiatives and firm-wide strategic priorities. Build and lead a team of highly impactful Data Science and advanced analytics resources. Determining priorities, providing development and growth opportunities and championing team across the organization. Work closely with departments across CPP Investments to understand investment needs for enterprise analytical products. Strengthen and forge relationships with key partners across the organization. Lead the development and execution of prototypes and products from an advanced analytics and data science perspective. Execution focused delivering value through Analytics. Lead the enterprise Development of data models and algorithms techniques for the use of financial market structure modeling. Bachelor’s degree, with a technology or business emphasis, or equivalent education and experience. Advanced degree preferred. Strong understanding of the investment lifecycle and proven track record of building analytical products for investment funds. Extensive background in analytical modeling, AI techniques. Track record in building and deploying data science products. Strong sense of teamwork Ability to create solutions to fit a diverse and complex environment Adaptable to new technologies and challenges not previously encountered Able to build strong relationships and communicate effectively with a diverse set of stakeholders, including business leaders, operational staff and technical engineers Proven project management experience Excellent written and oral communication skills, with the ability to work with both technical and business users Self-motivated with acute attention to detail Innovative and proactive Exemplify CPP Investments’ Guiding Principles of Integrity, High Performance and Partnership 
ScrapedJobID1226:

ScrapedJobID1227:

ScrapedJobID1228:
Experience with business analytics products like ThoughtSpot and Tableau Knowledge of one or more database technologies (Snowflake, SQL Server, etc.) Extensive understanding of global corporate business processes and their relationship to technology Excellent problem-solving abilities, strong written, verbal, and presentation skills Thrive in a dynamic environment, maintaining composure and a positive attitude Demonstrable understanding of development processes and agile methodologies Successful track record managing solutions from requirements analysis, to feature definition to deployment Proactively initiates, develops, and identifies opportunities to improve data quality Successful interaction with offshore team members is important Proficiency in writing Advanced SQLs, experience with data science tools and technologies is a plus Bachelor’s degree in Computer Science, Information Technology, or related field Experience in building advanced data visualizations using ThoughtSpot and Tableau 6+ years of IT experience with dimensional modeling, data investigation, optimization & using Cloud Databases Experience utilizing, and optimizing the use of, multiple large data sets Prior experience in the facilitating conversations to translate business requirements into the technical data requirements needed to develop solutions Excellent organization, time management, and communication skills Ability to work independently with strong attention to detail and accuracy Willingness and ability to adapt to rapid business and organizational change 
ScrapedJobID1229:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID1230:
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. 2+ years of non-internship professional software development experience Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design Bachelor’s degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline 1+ years of experience as a data/software developer/scientist or related technical job A passion for improving customer experience Excellent verbal and written communication skills and technical writing skills Graduate degree in a related technical field 2+ years of experience as a data/software developer/scientist or related technical job Experience with Agile Development Experience with statistical modeling or machine learning (Classification, Collaborative Filtering) Experience with AWS services A love of music! 
ScrapedJobID1231:
Stay abreast of innovations and publications in the field of operations research and business intelligence systems. Research and solve complex scheduling, resource allocation and pricing scenarios involved in operations optimization. Analyze raw operational data and design algorithms that can automatically and consistently generate operational recommendations for clients. Contribute to the invention of novel solutions to client’s operational problems by collaboratively working with product managers, co-developers, and our client success team. Utilize efficient algorithm design in a parallelized fashion capable of crunching gigabytes of operations data in minutes and scaling up with client growth. Build dashboards that transform operational data into visualizations that are intuitive and actionable Contribute refinements to our existing product through the development of new features as well as refactoring existing code to make it more efficient and object-oriented. Advance your knowledge of new software tools, agile programming methods, business intelligence technologies and share your knowledge with the development team, thus catalyzing process / technology changes to help us be more effective. Languages: C#, JavaScript, TypeScript Frameworks: .NET Core, Angular Web Server: IIS, NGINX Databases: MS SQL, Azure SQL Infrastructure: Azure, Docker, Kubernetes, GitLab Logistics engine: algorithms for discrete optimization problems Operation Systems: Windows, Linux Development Processes: Agile, CI/CD 2+ years of experience in Software Development, preferably with high performance algorithms or data intensive applications. A deep and intuitive understanding of Algorithms and Data Structures. Ability to process, assimilate, and explain complex and abstract concepts from research publications. Operations Research or Management Engineering Mathematical Optimization Data Science / Machine Learning Master’s Degree or PhD in Applied Mathematics/ Management Science/ Operations Research/ Computer Science / Engineering, or related technical discipline. Base salary of $80K - $115K + performance-based bonus or stock options Work-Life Balance: Flex time, work from home days and travel incentives. Set-up: Standing / adjustable desks, massage chair & quiet rooms, employee lounge with Xbox, Switch & PS4. Benefits Plan: Fitness allowance, dental/prescription/vision, massage & physio, and healthcare spending account. Food & Fun: Fully stocked kitchen, fancy coffee machine, team lunches, long weekend bottle draws and monthly employee events. 
ScrapedJobID1232:
Linux GPU driver development in support of Machine Learning and Data Centre applications Contributes to software projects of significant technical importance Solves sophisticated non-recurring problems that leads to development and implementation Debug, analyze and resolve quality and certification issues as reported by Customers and QA Write detailed design notes for new features Coordinate closely with peers and colleagues to ensure timely and effective communication of all assigned work activities Coordinate with developers in the open-source development community Proficient in C and C++ programming Excellent debugging and trouble-shooting skills Strong general Linux systems administration, software development, and troubleshooting knowledge and experience. Linux kernel development experience, either core kernel development or device driver development. PC architecture knowledge Strong oral and written communication skills Experience with Linux containers kernel level implementation (cgroups, namespaces) Familiarity with Linux networking and network/cluster management Familiarity with Linux GPU driver development (kernel and user-mode), ideally on AMD hardware. Familiarity with compute, graphics, or multimedia GPU application development using APIs such as OpenCL, OpenGL, and VAAPI. Proven track record of contributions to open-source projects Familiarity with Linux security subsystems such as selinux and/or AppArmor Bachelor's degree or Master’s in Computer Science or related degree with validated experience 
ScrapedJobID1233:
By delivering an award-winning product, conceptualized and developed by award-winning leaders, that result in award-winning customer employee experiences By hiring highly innovative, diverse talent that fully embraces and embodies our core values in everything they do: Customer Focus, Equity, Shared Ambition, Agility, Transparency, Optimism By using modern technology, such as voice-activation with Dayforce Assistant and access to your money as soon as you earn it with Dayforce Wallet to stay in rhythm with the evolving demands of our 4 million global users As a ML Engineer, you join a high performing agile team, responsible for building new models, updating current modules, and adding new features to our products, as well as other duties as assigned. The selected candidate will have prior experience with ML deployment, Python, and have used Linux or Git. Prior SQL knowledge is also desired. Our machine learning team works on challenging problems related to text mining, predictive model building and validation, data normalization and other data science activities. Your impact will be evident through your effective participation in the entire lifecycle of our software including design, analysis, prototyping, development, testing and support of our products. You will work closely and collaborate with implementation partners, to envision and deliver the required functionality. Encouragement to be the best version of yourself at and away from work: YOUnity diversity and inclusion programs Amazing time away from work programs Support for your total well-being through our Live Well, Work Well programs targeting all aspects of your life Recognition for your contributions through excellent pay, perks, and rewards Giving where you’re living: volunteer days, Ceridian sponsored events, and our very own charity, Ceridian Cares Opportunities to fuel your career growth through numerous internal and external programs and events Expertise in building and configuring production-ready machine learning systems. Expertise in using machine learning libraries in Python, or similar. Experience with complex SQL using PostgreSQL, or similar. Experience in consuming and building APIs in Node.js, Python, or similar. A passion for software development that often extends beyond your work An understanding of Linux systems A high level of comfort using Git and Github A desire to learn new technologies and techniques Nice to have: projects or contributions on github we can see 
ScrapedJobID1234:
Develop and maintain algorithms, data pipelines, automated processes, and services to create a data science solution that are customer focused Extract mission-critical insights from datasets Innovate and bring creative ideas to building mission critical customer facing products that depend on ML solutions Work with product and business teams to identify solutions and best practices Create scalable models that drive business decisions and enable our customers’ success Design and develop processes and systems which analyze and generate actionable insights from diverse data sources Develop tools to monitor models for evolving performance and accuracy Mentor team members in the areas of technical expertise and career building Contribute to best practices around feature extraction, model development, and knowledge sharing among multiple data science teams Directly contribute to architecture planning Been in the ML engineering game for some time. You have a Bachelors/Masters and 4+ years of industry experience Proven ability to architect data science solutions to complex problems and delivering solutions in customer facing products Experience delivering solutions that analyzes big datasets using tools such as Apache Spark Experience delivering solutions that analyzes time-series data Strong programming skills in Python A strong command of SQL and working with multiple relational databases and data warehouses (Redshift, Postgres, Athena, Snowflake, etc…) Experience in end-to-end machine learning project life cycle Experience working with unstructured data Are scrappy when extracting useful insights with partial data A solid experience in working with software development teams and using source version control tools like Git Experience deploying deep learning models Experience with frameworks for in-production ML code (e.g. Kedro) Developing and deploying using Docker With some of the AWS services (e.g. EC2, S3, Sage Maker, Cloudwatch) With accessing data from other datastores in the AWS ecosystem such as ElasticSearch, S3, and DynamoDB The BEST team. Remote-first culture. International Meetups. Access to Jungle Scout tools & experts. Performance Bonus. Flexible Vacation. Comprehensive Health Benefits & Retirement Program. 
ScrapedJobID1235:
Develop a deep understanding of the markets in each country and their data and analytical needs. Provide guidance to internal collaborators on advanced analytics Co-lead GAA's capability/product strategy, synthesizing business needs and advanced analytics expertise into capability/product roadmaps. Lead the development and deployment of strategic capabilities/products built around advanced analytics that create tangible business value. Coordinate across CoE roles and other business functions (sales, marketing, IT, external vendors, etc.) required to efficiently and effectively deliver new analytics capabilities/products Coordinate across markets the development of analytics capabilities to improve commonalities and efficiencies Collaborate with the Data & Insights Specialist on business adoption, and embedding analytics into business processes Find opportunities to evolve analytics capabilities/products and to use them across countries and brands Instil a culture of continuous improvement to refine and enhance existing capabilities. Monitor the external environment to stay up to date on leading advanced analytic capabilities, both within and outside of pharma, which can be applied within the organization. Oversee multiple capability related projects across different countries and markets. Extensive hands-on experience in application of advanced analytics and statistical methods on large and disparate datasets preferably in the context of Omnichannel marketing, specifically: Statistical Analysis and Modelling: (e.g. Design of Experiments, Time Series Analysis, Regression Analysis, Bayesian methods, etc), Machine Learning and Artificial Intelligence Extensive experience in deploying (and maintaining) production-grade advanced analytics capabilities. This includes not only the delivery of solutions but also the building of the business ecosystem (processes, organizational structure, change management, etc.) necessary. Strong organizational skills and time management; ability to manage diverse range of simultaneous projects. Strong leadership and interpersonal skills with demonstrated ability to work collaboratively with a significant number of business leaders and cross-functional business partners. Strong communication and influencing skills. Pharma commercial domain understanding. Experience with omnichannel analytics Experience with Agile methodology within an IT/business environment. Strategic and critical thinking with the ability to engage, build and maintain credibility with Commercial Leadership Team. Quantitative Master's or PhD degree from an accredited college or university is required in one of the following or related fields: Engineering, Operations Research, Management Science, Economics, Statistics, Math, Physics, Computer Science or Data Science. Cambridge, UK Gothenburg, Sweden Gaithersburg, US 
ScrapedJobID1236:
Collaborate with our digital stakeholders to define KPIs, reporting requirements, and overall measurement strategy for our digital and mobile customer journeys Translate business requirements into technical specifications for custom digital analytics implementation using a combination of data layer, processing rules, SAINT classification, report suite configuration, custom JavaScript, JSON and applicable integrations with other systems Manage daily operations and implementation of TD's analytics stack (Adobe Analytics, Adobe Target, Adobe Audience Manager, Adobe Launch, Adobe Mobile Services, Ensighten) and 3rd party marketing tags (DoubleClick, Rakuten, Facebook, etc.) Develop and own all implementation documents such as SDR, Data Layer specifications, custom JavaScript Ensure the timely delivery and accuracy of documentation and technical coding (HTML, JavaScript, ActionScript) via our Tag Management System Collaborate with technology teams on implementation of analytics solutions, including guidance on data layer implementation and troubleshooting, data feeds and integrations with other systems Keep abreast of product updates (Adobe, Ensighten), best practices and proactively follow up with required changes in our implementation and appropriate communications Provide consultative service, training and validation support to quality assurance/testing teams. 4+ years' experience in analytics, with digital experience preferred 5+ years' experience of web development including JavaScript, jQuery and Angular Strong understanding of JSON structures and best practices Strong understanding of Native Mobile development standards Strong understanding of JavaScript & Node.js & DOM manipulation, web markup, including HTML5 and CSS3 Expertise with tag management tools (DTM, Adobe Launch, Tealium, Ensighten) and their configuration All-hands experience in implementing/troubleshooting/deploying the Adobe stack, Google 360 and/or 3rd party marketing tags using DTM or Adobe Launch or Ensighten Expert level knowledge in developing Adobe Analytics Solution Design Reference (SDR) Understanding of Adobe Analytics processing rules, SAINT classifications, report suite configuration, and data feeds Experience architecting a Data Layer Specification and guiding the development team on implementation and troubleshooting Experience debugging Adobe Analytics utilizing browser network calls, extensions, and tools such as Fiddler, Charles or Omnibug Ability to own and work independently on assigned deliverables, but also collaborate with multiple team members and stakeholders when necessary Solid communications skills – verbal and written Strong time-management skills and ability to work on multiple projects at once 
ScrapedJobID1237:

ScrapedJobID1238:
Responsible for server side applications Analysis, Design & Development. Collaborate with business partners on the trading floor to create performant applications that deliver real time insights on millions of data points. Responsible for creating high throughput applications leveraging existing Citi Big data framework, Part of an innovative team pursing boundaries to create innovative data visualization solutions. Ability to take initiative to research, learn and recommend emerging technologies. Be part of a dynamic group working towards a common goal. Work with developers onshore, offshore and matrix teams to implement a business solution Proficiency in Java or Python. Experience with customer analytics. Relish tackling new challenges, paying attention to details, and growing professionally. Basic shell commands and shell scripting. Adapts machine learning and deep learning technologies to the finance products Strong familiarity with machine learning and statistical techniques Knowledge and experience of distributed computing Knowledge of advanced statistical techniques and concepts. Extensive hand-coding expertise in Core Java development Experience with PySpark/Pandas and related data analytics libraries Adapts machine learning and deep learning technologies to the finance products Experience with messaging systems like Kafka & EMS (Solace, Tibco) Experience in Hadoop framework with good understanding of HDFS, Hive, HBase, Spark 
ScrapedJobID1239:
Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. AWS Cloud (certification is an asset) AWS services like AWS glue or other AWS services Python programming language. Big Data technologies (like a Spark, hive/HDFS, PySpark, Hadoop) SQL and NoSQL databases, including Postgres and Cassandra. Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. AWS cloud services: EC2, EMR, RDS, Redshift Stream-processing systems: Storm, Spark-Streaming, etc. Object-oriented/object function scripting languages: Java, C++, Scala, etc. 
ScrapedJobID1240:
Bachelor’s degree in Data Science or Business Administration, MA or MBA preferred. Professional-level, current, subject matter expertise in various topics in Excel, Power Query and Power BI. Experience with adult instruction and/or training, with proven track record of online communication. Proficiency with MS suite, ability to connect to online hubs with reliable devices and internet access. Experience with online learning platforms such as D2L, Blackboard, and Moodle. 3-5 years teaching experience required. Documented experience working as an Instructor in a post-secondary or industry setting within a team environment is an asset. Ability to excel under pressure and ‘think on your feet’. Professional competence preparing, developing, delivering and administering post-secondary courses. Excellent English-language communication (written and verbal), and interpersonal and people-management skills. Demonstrated ability to deliver in class and within an online learning platform. Ability to motivate adult learners to achieve academic success. An established network of relevant professional contacts. Please note: These are the minimum required qualifications. Being a part of BC’s Top 100 Employers, and a member of the CCDI. A generous Total Compensation package which includes extended health and dental benefits and a superb pension plan. Access to Professional Development Funds and opportunities for career development. Increase your knowledge with Tuition waivers for BCIT courses. Enjoy discounted access to our fitness facilities (including classes like Yoga and Zumba). Additional Wellness and Employee Assistance programs. 
ScrapedJobID1241:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1242:

ScrapedJobID1243:
Overseeing the development of software to clean and investigate large, messy data sets of numerical and textual data Networking with various teams to explore internal and external data sources and APIs to help uncover new trends and improve analysis Designing and contributing to highly scalable data pipelines, tools, and products to enable the analyst community to fully leverage the power of AWS Working with your team to analyze large swaths of data in order to optimize various business programs Managing and developing talent to drive a highly performant and engaged team Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, you’re not afraid to blurt out your disruptive idea. You know how the latest tech works, yet you are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. Crafty: You know how to get things done. You can navigate a large organization, motivate people, and influence your peers. Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Inspiring: You have a passion for developing people and take great pride in your management system. You know how to deliver through others while paving the way for their growth. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook and all the monitors you want! You can travel to a relevant conference of your choice annually - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours, dress code and environment Bachelor’s Degree in a quantitative field At least 5 year of experience in open source programming languages for large scale data analysis (Python, Scala, or Java) At least 5 year of experience with version control system like Git and GitHub. At least 5 year of experience with relational databases and programming in SQL At least 2 years in lead positions (managing people/owning products/architecting and driving an agenda) Master’s Degree or PhD Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) Experience with CICD tools Experience with Machine Learning workflows 5+ years experience in Python 5+ years’ experience with SQL 3+ years in lead positions (managing people/owning products/architecting and driving an agenda) 
ScrapedJobID1244:
Work on ROCm stack packaging solution for individual and enterprise level deployment on distributed cloud infrastructure Debug Machine Learning/ High Performance Computing related issues on Radeon Open Compute Stack (ROCm) Develop test contents for sophisticated Machine Learning algorithms on distributed nodes Port High Performance computing application on ROCm Reproduce field defects and develop appropriate tests to prevent future issues. Design, develop and deploy testing tools and automation libraries vital to perform testing. Be responsible for the adoption of tooling and industry standard methodologies by means of advocacy and outreach to help our development communities’ level up. Languages: Python, C, C++, Linux Shell scripting. Frameworks/Libraries: TensorFlow, PyTorch, ONNXRT Tools: Prior experience with Linux, Docker, LLVM compilers, GNU make /CMAKE, Jenkins, Git/Gerrit Understanding of High-Performance Computing application, Machine learning and GPU Programming, MPI Parallel Programming 
ScrapedJobID1245:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID1246:
Linux GPU driver development in support of Machine Learning and Data Centre applications Contributes to software projects of significant technical importance Solves sophisticated non-recurring problems that leads to development and implementation Debug, analyze and resolve quality and certification issues as reported by Customers and QA Write detailed design notes for new features Coordinate closely with peers and colleagues to ensure timely and effective communication of all assigned work activities Coordinate with developers in the open-source development community Proficient in C and C++ programming Excellent debugging and trouble-shooting skills Strong general Linux systems administration, software development, and troubleshooting knowledge and experience. Linux kernel development experience, either core kernel development or device driver development. PC architecture knowledge Strong oral and written communication skills Experience with Linux containers kernel level implementation (cgroups, namespaces) Familiarity with Linux networking and network/cluster management Familiarity with Linux GPU driver development (kernel and user-mode), ideally on AMD hardware. Familiarity with compute, graphics, or multimedia GPU application development using APIs such as OpenCL, OpenGL, and VAAPI. Proven track record of contributions to open-source projects Familiarity with Linux security subsystems such as selinux and/or AppArmor Bachelor's degree or Master’s in Computer Science or related degree with validated experience 
ScrapedJobID1247:
By delivering an award-winning product, conceptualized and developed by award-winning leaders, that result in award-winning customer employee experiences By hiring highly innovative, diverse talent that fully embraces and embodies our core values in everything they do: Customer Focus, Equity, Shared Ambition, Agility, Transparency, Optimism By using modern technology, such as voice-activation with Dayforce Assistant and access to your money as soon as you earn it with Dayforce Wallet to stay in rhythm with the evolving demands of our 4 million global users As a ML Engineer, you join a high performing agile team, responsible for building new models, updating current modules, and adding new features to our products, as well as other duties as assigned. The selected candidate will have prior experience with ML deployment, Python, and have used Linux or Git. Prior SQL knowledge is also desired. Our machine learning team works on challenging problems related to text mining, predictive model building and validation, data normalization and other data science activities. Your impact will be evident through your effective participation in the entire lifecycle of our software including design, analysis, prototyping, development, testing and support of our products. You will work closely and collaborate with implementation partners, to envision and deliver the required functionality. Encouragement to be the best version of yourself at and away from work: YOUnity diversity and inclusion programs Amazing time away from work programs Support for your total well-being through our Live Well, Work Well programs targeting all aspects of your life Recognition for your contributions through excellent pay, perks, and rewards Giving where you’re living: volunteer days, Ceridian sponsored events, and our very own charity, Ceridian Cares Opportunities to fuel your career growth through numerous internal and external programs and events Expertise in building and configuring production-ready machine learning systems. Expertise in using machine learning libraries in Python, or similar. Experience with complex SQL using PostgreSQL, or similar. Experience in consuming and building APIs in Node.js, Python, or similar. A passion for software development that often extends beyond your work An understanding of Linux systems A high level of comfort using Git and Github A desire to learn new technologies and techniques Nice to have: projects or contributions on github we can see 
ScrapedJobID1248:
Develop and maintain algorithms, data pipelines, automated processes, and services to create a data science solution that are customer focused Extract mission-critical insights from datasets Innovate and bring creative ideas to building mission critical customer facing products that depend on ML solutions Work with product and business teams to identify solutions and best practices Create scalable models that drive business decisions and enable our customers’ success Design and develop processes and systems which analyze and generate actionable insights from diverse data sources Develop tools to monitor models for evolving performance and accuracy Mentor team members in the areas of technical expertise and career building Contribute to best practices around feature extraction, model development, and knowledge sharing among multiple data science teams Directly contribute to architecture planning Been in the ML engineering game for some time. You have a Bachelors/Masters and 4+ years of industry experience Proven ability to architect data science solutions to complex problems and delivering solutions in customer facing products Experience delivering solutions that analyzes big datasets using tools such as Apache Spark Experience delivering solutions that analyzes time-series data Strong programming skills in Python A strong command of SQL and working with multiple relational databases and data warehouses (Redshift, Postgres, Athena, Snowflake, etc…) Experience in end-to-end machine learning project life cycle Experience working with unstructured data Are scrappy when extracting useful insights with partial data A solid experience in working with software development teams and using source version control tools like Git Experience deploying deep learning models Experience with frameworks for in-production ML code (e.g. Kedro) Developing and deploying using Docker With some of the AWS services (e.g. EC2, S3, Sage Maker, Cloudwatch) With accessing data from other datastores in the AWS ecosystem such as ElasticSearch, S3, and DynamoDB The BEST team. Remote-first culture. International Meetups. Access to Jungle Scout tools & experts. Performance Bonus. Flexible Vacation. Comprehensive Health Benefits & Retirement Program. 
ScrapedJobID1249:
Réaliser le développement des rapports et tableaux de bord dans le respect des Modifier les rapports et tableaux de bord existants afin de répondre aux besoins Effectuer les essais et l"assurance qualité des développements avant la mise en Assurer la performance des rapports et tableaux de bord développées Assurer le support de premier niveau des produits informationnels Travailler en étroite collaboration avec les équipes de gestion de l"information afin Assurer le lien avec l"équipe de l"entrepôt de données afin de spécifier les besoins et Participer au profilage des données des systèmes sources Tester les extractions et les requêtes afin d"assurer la qualité des données Créer des tables de faits, de dimensions, et des vues pouvant être utilisées dans les Créer des champs calculés directement dans les bases de données pour supporter Participer aux discussions et aux ateliers de gouvernance Proposer et utiliser les définitions et le lexique d"entreprise Assurer la conformité et l"alignement des indicateurs clefs de performance Recueillir les besoins d"affaires et ceux des clients et utilisateurs Organiser et conduire des séances de travail afin de développer et proposer des Effectuer l"analyse détaillée des besoins et rédiger les spécifications détaillées afin de Participer et conduire des réunions et des revues d"avancement des projets avec les Analyser, cartographier et schématiser les systèmes et les processus d"affaires Créer et supporter la mise en place d"une architecture des données Proposer les meilleures solutions possibles afin d"atteindre les objectifs de l"unité Proposer des indicateurs clefs de performance pertinents Rédiger la documentation des produits informationnels afin d"en permettre une Supporter le déploiement du portail web pour la diffusion des différents rapports et Mettre en place une structure temporaire pour le traitement et la transformation des Supporter l"automatisation des tâches de rafraichissement des données, des rapports Proposer et développer des solutions numériques afin de permettre le suivi des Participer aux initiatives en science des données (apprentissage machine, prévision, Diplôme universitaire en génie, en science informatique, en intelligence d"affaires ou en Diplôme universitaire de 2e cycle en intelligence d"affaires, en science des données, ou Idéalement 1 à 4 ans d"expérience, mais ouvert aux nouveaux diplômés Maîtrise du français et de l"anglais parlé et écrit Expérience de travail dans le secteur manufacturier ou aérospatial un atout Maîtrise de la suite Microsoft 365 Maîtrise avancée du logiciel Power BI Bonne compréhension des besoins d"affaires, des systèmes et des architectures dans un Expérience dans le développement et l"utilisation de modèles relationnels et Bonnes connaissances SQL (fonctions de fenêtre, requêtes imbriquées, tables Expérience de programmation dans un contexte d"analyse de données (ex. VBA, Python, Connaissances de base de SAP, PLM, Jupyter et HDFS un atout Connaissance de la méthodologie agile Connaissance des plateformes en gestion de projets et partage de codes (ex. Azure Le poste est présentement offert en télétravail. Un retour au bureau sera possible lorsque L"horaire de travail est flexible Une analyse de cas sera demandée aux candidats présélectionnés afin de valider les Develop reports and dashboards in compliance with Modify existing reports and dashboards to meet needs Perform tests and quality assurance of developments before implementation Ensure the performance of reports and dashboards developed Provide first level support for information products Work closely with information management teams to Liaise with the data warehouse team in order to specify the needs and Participate in the profiling of data from source systems Test extractions and queries to ensure data quality Create tables of facts, dimensions, and views that can be used in Create calculated fields directly in the databases to support Participate in governance discussions and workshops Propose and use the definitions and the business lexicon Ensure compliance and alignment of key performance indicators Collect business needs and those of customers and users Organize and lead working sessions in order to develop and propose Perform detailed needs analysis and write detailed specifications in order to Participate and lead meetings and project progress reviews with Analyze, map and map systems and business processes Create and support the implementation of a data architecture Propose the best possible solutions in order to achieve the objectives of the unit Propose relevant key performance indicators Write the documentation of information products in order to allow Support the deployment of the web portal for the distribution of the various reports and Set up a temporary structure for the processing and transformation of Support the automation of data refresh tasks, reports Propose and develop digital solutions to allow the monitoring of Participate in data science initiatives (machine learning, forecasting, University degree in engineering, computer science, business intelligence or 2nd year university diploma Ideally 1 to 4 years of experience, but open to new graduates Fluency in spoken and written French and English Work experience in the manufacturing or aerospace sector an asset Proficiency in the Microsoft 365 suite Advanced knowledge of Power BI software Good understanding of business needs, systems and architectures in a Good SQL knowledge (window functions, nested queries, tables Programming experience in a data analysis context (eg VBA, Python, Basic knowledge of SAP, PLM, Jupyter and HDFS an asset Knowledge of agile methodology Knowledge of project management and code sharing platforms (eg Azure The position is currently offered by telecommuting. A return to the office will be possible when The work schedule is flexible A case analysis will be requested from shortlisted candidates in order to validate the 
ScrapedJobID1250:
Collaborate with our digital stakeholders to define KPIs, reporting requirements, and overall measurement strategy for our digital and mobile customer journeys Translate business requirements into technical specifications for custom digital analytics implementation using a combination of data layer, processing rules, SAINT classification, report suite configuration, custom JavaScript, JSON and applicable integrations with other systems Manage daily operations and implementation of TD's analytics stack (Adobe Analytics, Adobe Target, Adobe Audience Manager, Adobe Launch, Adobe Mobile Services, Ensighten) and 3rd party marketing tags (DoubleClick, Rakuten, Facebook, etc.) Develop and own all implementation documents such as SDR, Data Layer specifications, custom JavaScript Ensure the timely delivery and accuracy of documentation and technical coding (HTML, JavaScript, ActionScript) via our Tag Management System Collaborate with technology teams on implementation of analytics solutions, including guidance on data layer implementation and troubleshooting, data feeds and integrations with other systems Keep abreast of product updates (Adobe, Ensighten), best practices and proactively follow up with required changes in our implementation and appropriate communications Provide consultative service, training and validation support to quality assurance/testing teams. 4+ years' experience in analytics, with digital experience preferred 5+ years' experience of web development including JavaScript, jQuery and Angular Strong understanding of JSON structures and best practices Strong understanding of Native Mobile development standards Strong understanding of JavaScript & Node.js & DOM manipulation, web markup, including HTML5 and CSS3 Expertise with tag management tools (DTM, Adobe Launch, Tealium, Ensighten) and their configuration All-hands experience in implementing/troubleshooting/deploying the Adobe stack, Google 360 and/or 3rd party marketing tags using DTM or Adobe Launch or Ensighten Expert level knowledge in developing Adobe Analytics Solution Design Reference (SDR) Understanding of Adobe Analytics processing rules, SAINT classifications, report suite configuration, and data feeds Experience architecting a Data Layer Specification and guiding the development team on implementation and troubleshooting Experience debugging Adobe Analytics utilizing browser network calls, extensions, and tools such as Fiddler, Charles or Omnibug Ability to own and work independently on assigned deliverables, but also collaborate with multiple team members and stakeholders when necessary Solid communications skills – verbal and written Strong time-management skills and ability to work on multiple projects at once 
ScrapedJobID1251:

ScrapedJobID1252:
Responsible for server side applications Analysis, Design & Development. Collaborate with business partners on the trading floor to create performant applications that deliver real time insights on millions of data points. Responsible for creating high throughput applications leveraging existing Citi Big data framework, Part of an innovative team pursing boundaries to create innovative data visualization solutions. Ability to take initiative to research, learn and recommend emerging technologies. Be part of a dynamic group working towards a common goal. Work with developers onshore, offshore and matrix teams to implement a business solution Proficiency in Java or Python. Experience with customer analytics. Relish tackling new challenges, paying attention to details, and growing professionally. Basic shell commands and shell scripting. Adapts machine learning and deep learning technologies to the finance products Strong familiarity with machine learning and statistical techniques Knowledge and experience of distributed computing Knowledge of advanced statistical techniques and concepts. Extensive hand-coding expertise in Core Java development Experience with PySpark/Pandas and related data analytics libraries Adapts machine learning and deep learning technologies to the finance products Experience with messaging systems like Kafka & EMS (Solace, Tibco) Experience in Hadoop framework with good understanding of HDFS, Hive, HBase, Spark 
ScrapedJobID1253:
Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. AWS Cloud (certification is an asset) AWS services like AWS glue or other AWS services Python programming language. Big Data technologies (like a Spark, hive/HDFS, PySpark, Hadoop) SQL and NoSQL databases, including Postgres and Cassandra. Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. AWS cloud services: EC2, EMR, RDS, Redshift Stream-processing systems: Storm, Spark-Streaming, etc. Object-oriented/object function scripting languages: Java, C++, Scala, etc. 
ScrapedJobID1254:
Bachelor’s degree in Data Science or Business Administration, MA or MBA preferred. Professional-level, current, subject matter expertise in various topics in Excel, Power Query and Power BI. Experience with adult instruction and/or training, with proven track record of online communication. Proficiency with MS suite, ability to connect to online hubs with reliable devices and internet access. Experience with online learning platforms such as D2L, Blackboard, and Moodle. 3-5 years teaching experience required. Documented experience working as an Instructor in a post-secondary or industry setting within a team environment is an asset. Ability to excel under pressure and ‘think on your feet’. Professional competence preparing, developing, delivering and administering post-secondary courses. Excellent English-language communication (written and verbal), and interpersonal and people-management skills. Demonstrated ability to deliver in class and within an online learning platform. Ability to motivate adult learners to achieve academic success. An established network of relevant professional contacts. Please note: These are the minimum required qualifications. Being a part of BC’s Top 100 Employers, and a member of the CCDI. A generous Total Compensation package which includes extended health and dental benefits and a superb pension plan. Access to Professional Development Funds and opportunities for career development. Increase your knowledge with Tuition waivers for BCIT courses. Enjoy discounted access to our fitness facilities (including classes like Yoga and Zumba). Additional Wellness and Employee Assistance programs. 
ScrapedJobID1255:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1256:

ScrapedJobID1257:
Overseeing the development of software to clean and investigate large, messy data sets of numerical and textual data Networking with various teams to explore internal and external data sources and APIs to help uncover new trends and improve analysis Designing and contributing to highly scalable data pipelines, tools, and products to enable the analyst community to fully leverage the power of AWS Working with your team to analyze large swaths of data in order to optimize various business programs Managing and developing talent to drive a highly performant and engaged team Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, you’re not afraid to blurt out your disruptive idea. You know how the latest tech works, yet you are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. Crafty: You know how to get things done. You can navigate a large organization, motivate people, and influence your peers. Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Inspiring: You have a passion for developing people and take great pride in your management system. You know how to deliver through others while paving the way for their growth. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook and all the monitors you want! You can travel to a relevant conference of your choice annually - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours, dress code and environment Bachelor’s Degree in a quantitative field At least 5 year of experience in open source programming languages for large scale data analysis (Python, Scala, or Java) At least 5 year of experience with version control system like Git and GitHub. At least 5 year of experience with relational databases and programming in SQL At least 2 years in lead positions (managing people/owning products/architecting and driving an agenda) Master’s Degree or PhD Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) Experience with CICD tools Experience with Machine Learning workflows 5+ years experience in Python 5+ years’ experience with SQL 3+ years in lead positions (managing people/owning products/architecting and driving an agenda) 
ScrapedJobID1258:
Work on ROCm stack packaging solution for individual and enterprise level deployment on distributed cloud infrastructure Debug Machine Learning/ High Performance Computing related issues on Radeon Open Compute Stack (ROCm) Develop test contents for sophisticated Machine Learning algorithms on distributed nodes Port High Performance computing application on ROCm Reproduce field defects and develop appropriate tests to prevent future issues. Design, develop and deploy testing tools and automation libraries vital to perform testing. Be responsible for the adoption of tooling and industry standard methodologies by means of advocacy and outreach to help our development communities’ level up. Languages: Python, C, C++, Linux Shell scripting. Frameworks/Libraries: TensorFlow, PyTorch, ONNXRT Tools: Prior experience with Linux, Docker, LLVM compilers, GNU make /CMAKE, Jenkins, Git/Gerrit Understanding of High-Performance Computing application, Machine learning and GPU Programming, MPI Parallel Programming 
ScrapedJobID1259:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID1260:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID1261:
Architect, design and evaluate novel approaches for solving complex business problems using machine learning techniques with high-volume real-time data streams Own the machine and present analyses and machine learning concepts to a broad technical audience initiate and drive projects to completion with minimal guidance Large data sets with low to mid-level analytical complexity Small data sets with high analytical complexity Data structures containing complex relationship patterns Data with low signal to noise Unstructured DataAlgorithm development with application to solving human problems Previous involvement in software development and/or distributed computing projects is a plus 2+ years of experience in building and deploying machine learning solutions at a production scale 1+ years of experience in software development at the production level, with proficiency in Python or Scala preferred Working knowledge of PyTorch, Tensorflow, or other similar frameworks Bachelor's or Master's degree or equivalent in Computer Science, Engineering, Mathematics or related field Flexibility to WFH For the third year in a row, we are proud to announce that we have been certified as a Great Place to Work We were also certified as one of the Best Workplaces for Mental Wellness in 2020 We are an open work environment that fosters collaboration, ownership, creativity, and urgency We ensure flexible hours outside of our core working hours Enrolment in the Group Health Benefits plan right from day 1, no waiting period Team building events Fuel for the day: Weekly delivery of groceries, and all types of snacks Catered lunches and desserts on a monthly basis Daily fun in the office with our competitive games of Ping Pong, Pool, Smash Bros competitions, or FIFA And of course, an unlimited amount of freshly made coffee and tea! We’re pretty serious about our coffee beans Online learning through the platform, UDEMY 
ScrapedJobID1262:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID1263:
Take a hands-on role in several projects, including the Fundamental Review of the Trading Book (FRTB), data solutions for capital optimization, and data quality control processes. Prototype new approaches and enhance existing methodologies to advance market data management and data quality control. Develop production level code and collaborate with IT team for integration into daily bank processes. Assist team members for various ad-hoc analyses, data methodology, documentation, reporting, preparation of materials. Execute model runs on a regular basis for reporting and perform corresponding analyses. Communicate with model developers, trading desks, risk teams, and business lines to enhance data quality control and data management for capital optimization Become an active member of the team including our D&I initiatives and communities. Solid quantitative background and problem-solving skills with a keen interest in Data Science, Finance, Economics, Market Risk, Derivatives Pricing, Risk management or Regulations. Advanced degree in a mathematics, economics, or scientific discipline (e.g., Mathematics, Finance, Statistics, Physics, Engineering, Biology, Economics, etc.). Master’s degrees or PhDs are a bonus. Experience in code development in Python or other formal programing will be important to support day-day activity. Effective communication (written and oral), specifically the ability to summarize complex ideas in simple terms; you enjoy working in collaborations. The opportunity to join a forward-thinking company surrounded by a collaborative team of innovative thinkers. A rewarding career path with diverse opportunities for professional development. Internal development to support your growth and enhance your skills. A competitive compensation and benefits package. An organization committed to making a difference in our communities– for you and our customers. We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success! 
ScrapedJobID1264:
Clearly communicate project statuses with leaders and project teams Engage in quality assurance processes to create a high standard of accuracy Ensure exception and error handling techniques are used Use understanding of business rules to enhance logic used in reporting and analysis Seek out new technology and processes to improve team ability and reach Verbally and visually present reporting and analysis findings to leaders and stakeholders of various levels Submit work for quality assurance with a low number of errors Prioritize multiple projects within own work stream to deliver with little impact to timelines Manage relationships with data source providers for issues and support Consistently incorporate reconciliation in published reports and datasets Prove or disprove relationships between variables (causal) Forecast business measures with confidence and accuracy Assist with development planning with other team members Take on and seek out opportunities to mentor and coach Champion best practices in quality and reliability Over 8 years relevant industry experience within a telecom, client services or technology environment Undergraduate degree in a field linked to data engineering, business analytics, applied mathematics, computer science, IT, computer applications, or related field Ability to create reporting and analysis solutions that are delivered within scope, expected timelines and of high quality Demonstrated solid critical thinking and problem-solving skills Expert ability to identify issues and make difficult decisions, knowing when to escalate when required Strong ability to develop strategic relationships across the organization in a collaborative and foster trust from others Committed to personal and team excellence and ability to operate in a dynamic and constantly changing environment 
ScrapedJobID1265:
Developing and supporting digital marketing campaigns, including paid Search Engine Marketing (SEM) and paid Social Media campaigns Acting as a subject matter expert for Search Engine Optimization (SEO) best practices, including ongoing technical audits of all digital properties Build Digital Results Report for clients for monthly review that encompasses all digital activities and important data KPI’s. Develop an understanding of what impact these KPI’s have on clients’ business. Manage effectiveness of Service Work Plan retention marketing Using available programs; plan, execute, and generate report on a targeted email marketing campaigns Act as a Data Scientist with regards to all the digital information we have available to us for our clients and communicate this data Oversee and manage all syndicated contents that includes various online platforms to promote business and products Working collaboratively across departments to understand company goals to develop customer acquisition, nurturing, and retention programs Study clients’ business and create a presentation based on potential and missed opportunity on the digital platform. Demonstrate to client your plan for their growth. Must be able to perform cold calls effectively and book appointments for consultation Visit businesses to generate new leads and perform updates on existing clients Requires travel 20%-50%%+ travel Bachelor’s degree or Diploma in Marketing, Business, Public Relations or 2-3 years of proven experience in sales, marketing, or communication Ability to put together effective, comprehensive, and multi-channelled marketing campaigns Have a high understanding of effective content for social media sites including Facebook, Twitter, and Instagram Manage, collaborate, and develop marketing and video assets Understanding of Google Analytics, Conversion Rate Optimization, User Experience (UX) Knowledge and Compliance with all provincial/federal advertising standards (CASL etc.) is a must. Graphical design understanding for digital properties and Point of Sale materials Excellent organizational, communication and leadership abilities. Team-oriented, relationship builder with a positive attitude. Strong oral/written communications skills. Strong organizational and multi-tasking skills with a high attention to detail Strong Proficiency in working with multiple software programs Automotive industry experience/ knowledge considered an asset. Must have valid driver’s license Passion for selling and building new relationships is a MUST. Bonus pay Commission pay Dental care Extended health care Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? No 
ScrapedJobID1266:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID1267:
Own the development and expansion of multiple models, leveraging machine learning Identify new opportunities and insights from the data (where can the models be improved? what is the projected ROI of a proposed modification?); continue to evolve models Architect and build technical platforms for our algorithmic engines to run at scale Work cross-functionally with Marketing and Engineering, and collaboratively with teammates Leverage the knowledge of state-of-the-art methodology and industry best practices to raise the technical standard of the team and Wayfair Data Science community Minimum 4 years of industry experience in a data science or ML Engineering role or 3 years of industry experience with Ph.D. in a quantitative field (e.g., economics, physics, neuroscience) Proficiency in Python Solid experience building Machine Learning (ML) models, preferably also productionalizing models (e.g., Airflow) Experience working with big data tools such as SQL, Spark, Hadoop, Hive, etc. Strong written and verbal communication skills, ability to synthesize conclusions for non-experts, and desire to influence business decisions A bias towards critical thinking, creatively solving problems from a customer-centric lens, and an intuitive sense for how the work aligns closely with business objectives Intellectual curiosity and enthusiastic about continuous learning Looking to make a big impact in a growing organization 
ScrapedJobID1268:
Lead a team that applies state of the art data science and machine learning techniques to transform how we interact with current and prospective business customers Drive significant business growth and impact by collaborating with Marketing, Sales, Storefront, Profit Management, Product, and Engineering teams to scope, develop, and deploy holistic data science solutions to power end-to-end B2B customer experience and drive significant business growth and impact Manage a broad portfolio of existing initiatives and evolve them to be scalable, platform-oriented data science products. These include, but are not limited to, models and frameworks for contact personalization, customer targeting across touchpoints, tailored experience for large project shoppers, and intelligent sales discount recommendation system. Lead the design and development of intelligent products that leverage a wide variety of data sources - e.g. 1st- and 3rd-party data on customer behavior, order history, firmographic information, sales call recordings and transcripts, etc. - to improve customer targeting and agent productivity Master’s degree in Computer Science, Engineering, or related quantitative fields; PhD preferred 4+ years of experience leading multi-disciplinary technical teams comprised of data scientists and engineers of varied levels of experience Thorough command of general data science and machine learning techniques Relevant experience designing and implementing customer-facing systems that are scalable, fast, and resilient Track record of delivering large cross-functional projects and managing multiple stakeholders with competing priorities Good understanding of experimental techniques for the design of A/B tests to measure the impact Communication skills that can influence across organizations and at all levels 
ScrapedJobID1269:
Provide the Data Intelligence and Governance team with data analyses from researching systems and processes, profiling data via SQL queries, and validating data quality requirements. Identify and partner with data stewardship across the organization to operationalize the Data Governance framework. Champion data governance initiatives by promoting ideas into action; including developing and implementing data quality rules, communication, and adoption strategy. Oversee data quality management and data quality issue prioritization. Assist in developing data governance policies, processes, and documentation. Support corporate data quality initiatives through recommendation for solutions and leadership around data validation. Analyze and understand corporate data across data domains, on both source and target levels. Collaborate with other data analysts from cross-functional teams to address data quality issues and educate data stewardship on data governance principles. Identify new opportunities for data governance continually. Coordinates with various stakeholders and leaders across business functions to apply established data governance framework (training and education, developing data stewardship, data custodian roles, data dictionary, definitions and documentation, approval, and sign-off protocols). Are proficient in data analysis (preferably within software development, data delivery, and data analytics settings). Have a post-secondary degree in Data Science, Computing, Mathematics or Healthcare Informatics (preferably master’s level). Have 5+ years of experience in data management or data governance Are highly knowledgeable in databases and adept in SQL. Have hands-on experience in data visualization tools such as PowerBI. Are experienced with CRM tools such as SalesForce and NetSuite. Are exceptional at rapport building and creative problem solving. Have strong organizational, planning, and prioritization skills. Are goal-oriented, positive, a self-starter, with strong analytical skills. Are a data detective with excellent communication, known for collaborating and your ability to communicate complex data findings to various audiences. Demonstrate a proven track record of delivering results while guiding and facilitating business partners in solving data quality issues. Able to work independently and manage multiple commitments and responsibilities 
ScrapedJobID1270:
Architect implementation of scalable AI and machine learning algorithms Write efficient, performant, and maintainable code in Java, Kotlin, C/C++, Go, and/or SQL Efficiently store and retrieve large volumes of data for ML training and algorithm development Develop feature processing for machine learning models in TensorFlow and others Implement processing algorithms on real-time sensor data Collaborate closely with data scientists to invent algorithms Sense, understand, and derive insight into human motion while exercising Deliver personalized real-time feedback Dynamically adjust resistance to optimize training effectiveness and safety BS or higher degree in engineering field or equivalent experience Strong knowledge of Python and one of Java, C/C++, Kotlin, or Go Experience with databases, SQL or NoSQL Experience with signal processing or machine learning algorithms Team player with high integrity Open to feedback and constantly striving to improve High degree of self-awareness Experience with gyros and accelerometers, computer vision, machine learning, or control theory 
ScrapedJobID1271:

ScrapedJobID1272:
Diverse and inspiring colleagues and approachable leaders Stimulating work in a fast-paced, intellectually challenging environment Accelerated exposure and responsibility Global career development opportunities Being motivated every day by CPP Investments’ important social purpose and unshakable principles A deeply rooted culture of Integrity, Partnership and High Performance Develop and implement the next generation Analytics roadmap, prioritizing deliverables and products aligned to approved initiatives and firm-wide strategic priorities. Build and lead a team of highly impactful Data Science and advanced analytics resources. Determining priorities, providing development and growth opportunities and championing team across the organization. Work closely with departments across CPP Investments to understand investment needs for enterprise analytical products. Strengthen and forge relationships with key partners across the organization. Lead the development and execution of prototypes and products from an advanced analytics and data science perspective. Execution focused delivering value through Analytics. Lead the enterprise Development of data models and algorithms techniques for the use of financial market structure modeling. Bachelor’s degree, with a technology or business emphasis, or equivalent education and experience. Advanced degree preferred. Strong understanding of the investment lifecycle and proven track record of building analytical products for investment funds. Extensive background in analytical modeling, AI techniques. Track record in building and deploying data science products. Strong sense of teamwork Ability to create solutions to fit a diverse and complex environment Adaptable to new technologies and challenges not previously encountered Able to build strong relationships and communicate effectively with a diverse set of stakeholders, including business leaders, operational staff and technical engineers Proven project management experience Excellent written and oral communication skills, with the ability to work with both technical and business users Self-motivated with acute attention to detail Innovative and proactive Exemplify CPP Investments’ Guiding Principles of Integrity, High Performance and Partnership 
ScrapedJobID1273:

ScrapedJobID1274:

ScrapedJobID1275:
Experience with business analytics products like ThoughtSpot and Tableau Knowledge of one or more database technologies (Snowflake, SQL Server, etc.) Extensive understanding of global corporate business processes and their relationship to technology Excellent problem-solving abilities, strong written, verbal, and presentation skills Thrive in a dynamic environment, maintaining composure and a positive attitude Demonstrable understanding of development processes and agile methodologies Successful track record managing solutions from requirements analysis, to feature definition to deployment Proactively initiates, develops, and identifies opportunities to improve data quality Successful interaction with offshore team members is important Proficiency in writing Advanced SQLs, experience with data science tools and technologies is a plus Bachelor’s degree in Computer Science, Information Technology, or related field Experience in building advanced data visualizations using ThoughtSpot and Tableau 6+ years of IT experience with dimensional modeling, data investigation, optimization & using Cloud Databases Experience utilizing, and optimizing the use of, multiple large data sets Prior experience in the facilitating conversations to translate business requirements into the technical data requirements needed to develop solutions Excellent organization, time management, and communication skills Ability to work independently with strong attention to detail and accuracy Willingness and ability to adapt to rapid business and organizational change 
ScrapedJobID1276:
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. 2+ years of non-internship professional software development experience Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design Bachelor’s degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline 1+ years of experience as a data/software developer/scientist or related technical job A passion for improving customer experience Excellent verbal and written communication skills and technical writing skills Graduate degree in a related technical field 2+ years of experience as a data/software developer/scientist or related technical job Experience with Agile Development Experience with statistical modeling or machine learning (Classification, Collaborative Filtering) Experience with AWS services A love of music! 
ScrapedJobID1277:
Developing and supporting digital marketing campaigns, including paid Search Engine Marketing (SEM) and paid Social Media campaigns Acting as a subject matter expert for Search Engine Optimization (SEO) best practices, including ongoing technical audits of all digital properties Build Digital Results Report for clients for monthly review that encompasses all digital activities and important data KPI’s. Develop an understanding of what impact these KPI’s have on clients’ business. Manage effectiveness of Service Work Plan retention marketing Using available programs; plan, execute, and generate report on a targeted email marketing campaigns Act as a Data Scientist with regards to all the digital information we have available to us for our clients and communicate this data Oversee and manage all syndicated contents that includes various online platforms to promote business and products Working collaboratively across departments to understand company goals to develop customer acquisition, nurturing, and retention programs Study clients’ business and create a presentation based on potential and missed opportunity on the digital platform. Demonstrate to client your plan for their growth. Must be able to perform cold calls effectively and book appointments for consultation Visit businesses to generate new leads and perform updates on existing clients Requires travel 20%-50%%+ travel Bachelor’s degree or Diploma in Marketing, Business, Public Relations or 2-3 years of proven experience in sales, marketing, or communication Ability to put together effective, comprehensive, and multi-channelled marketing campaigns Have a high understanding of effective content for social media sites including Facebook, Twitter, and Instagram Manage, collaborate, and develop marketing and video assets Understanding of Google Analytics, Conversion Rate Optimization, User Experience (UX) Knowledge and Compliance with all provincial/federal advertising standards (CASL etc.) is a must. Graphical design understanding for digital properties and Point of Sale materials Excellent organizational, communication and leadership abilities. Team-oriented, relationship builder with a positive attitude. Strong oral/written communications skills. Strong organizational and multi-tasking skills with a high attention to detail Strong Proficiency in working with multiple software programs Automotive industry experience/ knowledge considered an asset. Must have valid driver’s license Passion for selling and building new relationships is a MUST. Bonus pay Commission pay Dental care Extended health care Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? No 
ScrapedJobID1278:
31% women, 57% BIPOC, 14% LGBTQIA+ 49% of our people were born in countries other than where our offices are located. Our team members collectively speak 19 different languages. 59% of our people speak more than one language In the past year Architech has increased the number of women in our technology function by 200%. We strive to do even better as our multi-year strategic plan unfolds. We analyzed salaries by gender of persons in the same role and are delighted to report a 0% gender pay gap in our delivery and technology roles! Build scalable, reliable, resilient, secure systems that are built open source with cloud first architecture. Implement responsible web and/or mobile design principles using the latest technologies. Work in an Agile team with Designers and Product Owners to continuously iterate and build feedback into the solution. Be part of the team that architects and delivers the nuances within our overall technical strategy. Commit to our ever-evolving CI/CD chain and working templates. Work with technologies such as AWS and our partner technologies within projects including Azure, DotCMS and Red Hat. Approach new projects with the client needs and users in mind. Be open to learn and absorb the rapid changes in the engineering industry. 5+ years of professional experience in a software engineering role, building large-scale software systems. Strong expertise in Node.js is a must have. Knowledge of Python, Scala, Java, including object-oriented design. Be willing to work with many teams, trying new methods and helping others learn new way. Gitflow workflow and CI/CD pipeline experience. Experience with cloud environments such as GCP, Azure, or AWS. Excellent understanding of software development life cycle and/or agile development environment. Excellent communication skills, both written and oral. Be passionate about providing inclusive and accessible experiences to our partners, including seeing products and features through the lens of Accessibility first and championing this vision across our teams. Post-secondary degree or diploma in Computer Science or related program. Knowledge of HTML / CSS / Javascript / Jquery /TypeScript/AJAX, is an asset. Knowledge of Machine Learning frameworks (Pytorch/TensorFlow) and algorithms such as pricing analytics, predictive modeling is an asset. Nano degree in Data Science is an asset. Exposure to PHP Framework. 
ScrapedJobID1279:
Define and drive the science vision for a platform-based solution for evaluating the long-term, incremental value of our millions of offerings. Lead R&D effort to develop innovative causal inference approaches that will extend current capabilities and scale our platform to new use cases. Work highly cross-functionally with business leadership, stakeholders, and partner data science and engineering teams to drive the integration of model outputs into company-wide business decision-making and existing production systems. Developing robust solutions to infer or recover causal relationships from observational data, in a way that minimizes self-selection or third-variable problems. Scope and prioritize new business or stakeholders needs, balancing between delivering MVP solutions and working towards long term platform development Develop and own communication strategy for both technical and business stakeholders (including product roadmap, planning, executive documentation, and progress updates) Act as a subject matter expert and thought leader on experimentation and causal inference techniques; research industry trends and best practices and bring them to life at Wayfair. Engage in the interview process and otherwise develop, grow, and mentor junior scientists; provide mentorship and technical guidance to develop your team as well to influence broader DS organization. Advanced degree (Master or PhD) in Economics, Statistics or other quantitative field with an emphasis on causal inference and/or experimental design. 5+ years of experience working as a professional data or research scientist. Consistent track record of autonomous delivery of DS/ML projects that drive measurable business impact. Collaborative team player who wants to see themselves and others thrive. Expertise in causal inference and interest in bringing best-in-class solutions to e-commerce space. Takes a customer-centric approach to ideation and problem-solving Track-record of influencing non-technical stakeholders on strategic direction by leveraging data-driven insights; excellent written and verbal communication. Strategic thinker with a customer-centric mindset and a desire for creative problem solving, looking to make a big impact in a growing organization Proficient in one or more programming languages, e.g. Python, R, etc. Nice-to-haves: Experience with GCP (BigQuery, GCS, Dataproc, Notebooks), Airflow, and containerization (Docker) Experience building scalable data processing pipelines with big data tools such as Hadoop, Hive, SQL, Spark, etc. 
ScrapedJobID1280:
Design, development and evaluation of highly innovative models Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation Work closely with software engineering teams to drive real-time model implementations and new feature creations Analyze internal behavior tracking data and forecast Wish demand Implement the strategies and set up A/B test experiments to gauge the impact, and reiterate Propose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process Create & own dashboards and analytical reports to track progress & share learnings Bachelor's or advanced degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics or similar) 3+ years of hands-on experience in predictive modeling and analysis 3+ years experience writing complex SQL queries in a business environment 2+ years in Python A/B test experience Experience collaborating with business & eng teams Analytical mindset and ability to see the big picture and influence others Detail-oriented and must have an aptitude for solving unstructured problems Ability to work effectively in a multi-task, high volume environment Ability to be adaptable and flexible in responding to deadlines and workflow fluctuations Experience operating in a Unix/Linux environment Strong presentation skills 
ScrapedJobID1281:

ScrapedJobID1282:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1283:
Architect, design and evaluate novel approaches for solving complex business problems using machine learning techniques with high-volume real-time data streams Own the machine and present analyses and machine learning concepts to a broad technical audience initiate and drive projects to completion with minimal guidance Large data sets with low to mid-level analytical complexity Small data sets with high analytical complexity Data structures containing complex relationship patterns Data with low signal to noise Unstructured DataAlgorithm development with application to solving human problems Previous involvement in software development and/or distributed computing projects is a plus 2+ years of experience in building and deploying machine learning solutions at a production scale 1+ years of experience in software development at the production level, with proficiency in Python or Scala preferred Working knowledge of PyTorch, Tensorflow, or other similar frameworks Bachelor's or Master's degree or equivalent in Computer Science, Engineering, Mathematics or related field Flexibility to WFH For the third year in a row, we are proud to announce that we have been certified as a Great Place to Work We were also certified as one of the Best Workplaces for Mental Wellness in 2020 We are an open work environment that fosters collaboration, ownership, creativity, and urgency We ensure flexible hours outside of our core working hours Enrolment in the Group Health Benefits plan right from day 1, no waiting period Team building events Fuel for the day: Weekly delivery of groceries, and all types of snacks Catered lunches and desserts on a monthly basis Daily fun in the office with our competitive games of Ping Pong, Pool, Smash Bros competitions, or FIFA And of course, an unlimited amount of freshly made coffee and tea! We’re pretty serious about our coffee beans Online learning through the platform, UDEMY 
ScrapedJobID1284:
Experience leading a technical team, including managing tasks and processes Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline 3+ years of Software Development experience with modern programming languages (Python, C/C++, Julia) Experience with at least one deep learning framework (TensorFlow, PyTorch, MXNet …) Experience working in version control such as git Experience in big data architectures and pipelines to build and deploy models Experience in building machine learning models optimized for speed, accuracy, scalability, reliability and resiliency Ability to perform complex data analysis and present findings to stakeholders Master’s degree in Computer Science, Computer Engineering or related technical discipline Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations Experience with prototyping machine learning solutions (e.g. Kaggle, demos, hackathons) Experience working with cloud platforms (e.g. AWS, Azure …) Experience with web development for demonstrations Strong communication skills Competitive salary Health and lifestyle benefits Positive & creative work environment in a great location Leadership role on an expanding team with opportunities for career growth 
ScrapedJobID1285:
3+ years experience in a Data Engineering or Analytics role managing data pipelines Strong skills in Python, SQL, Airflow, Data Modeling and ETL pipelines Familiarity with: Snowflake, AWS Redshift, or BigQuery Experience working with Data Science and Machine Learning teams as stakeholders A passion for programming and solving problems with code A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience A love for technology, and an insatiable curiosity for new tools to tackle real problems We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process. We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners. We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy. We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality. 
ScrapedJobID1286:
Provides advanced data science expertise to AstraZeneca projects and recommends data science solutions. Delivers advanced data science solutions to AstraZeneca projects, appropriately communicating with non-technical stakeholders. Works within established frameworks to deliver a variety of tasks that support projects in meeting their objectives. Independently keeps own knowledge up to date and learns from senior team members, proposing appropriate training courses for personal development. Reviews working practices and ensures non-compliant processes are escalated Ensures own work is compliant within Clinical Development. Collaborate in a multidisciplinary environment with world leading clinicians, data scientists, biological experts, statisticians and IT professionals. M.Sc. degree in rigorous quantitative science (such as mathematics, computer science, engineering) or have demonstrated an outstanding track-record of industry experience with the desired data science methodologies Practical software development skills in standard data science tools: Python, Agile, Code versioning (bitbucket/git), UNIX skills, familiarity working in cloud environment (AWS preferred) AWS or other cloud compute experience including SysOps (provisioning resources required for analytics, Kubernetes, infrastructure as code is a bonus) Data visualization & interactive data visualization (interactive dashboards w/ DASH & static visualization) Experience developing machine learning first products including timeseries analysis, forecasting, behavioral analysis Knowledge of range of mathematical and statistical modelling techniques and drive to continue to learn and develop these skills. Minimum 2+ years of industry experience or post-doctoral work. Ph.D. degree in rigorous quantitative science (such as mathematics, computer science, engineering) Experience within the pharmaceutical industry Advanced experience with Kubernetes and machine learning product architecture Communication, business analysis, and consultancy Advanced machine learning models: transformer-based NLP models, reinforcement learning, GNNs, state-of-the-art timeseries & forecasting models ML Ops experience: model tracking, model governance, multiple models in different production contexts Data visualization & interactive data visualization (interactive dashboards w/ DASH & static visualization) Our Social Media, Follow AstraZeneca on LinkedIn https://www.linkedin.com/company/1603/ Follow AstraZeneca on Facebook https://www.facebook.com/astrazenecacareers/ Follow AstraZeneca on Instagram https://www.instagram.com/astrazeneca_careers/?hl=en 
ScrapedJobID1287:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID1288:
Define BI ramp-up strategy (including BI workflow, report hierarchy and catalog) and plan for engagement with business units Work with stakeholders to define business requirements for BI technology infrastructure including Data warehouse (DWH) platform and play a proactive part in the successful implementation of the platform Working as a trusted business partner, provide accurate, timely and actionable information in the form of reports, dashboards, etc. Make sure a robust end-to-end client engagement model (ingestion and prioritization to delivery and servicing) is implemented using appropriate tool Serve as primary client contact during all phases of the BI project from problem definition through presentation, appropriately managing client expectations throughout the project Apply business strategy while driving technology strategy, balancing short term and long term needs to ensure that the architecture can scale and evolve accordingly Accountable for the overall management of BI projects, including profitability, timeliness, quality, and client value Recruit, train, develop, and supervise managers and/or analyst-level employees Ensure accuracy of data and deliverables of direct reports with comprehensive policies and processes Create an environment where BI professionals can develop their skills and grow their careers through taking on increased responsibility and adding value to the organization Advanced Degree (PhD or Master’s) required (Data Science, Computer Science, Information Technology, Economics, Statistics, Information Systems, Applied Math, Business Administration, or any other related field) 12+ years of financial services experience Working knowledge of data extraction and reporting principles: mapping, collecting data from multiple data systems on premises and cloud-based data sources Understanding of and experience using data management and reporting concepts for analyzing data, drawing conclusions, and developing actionable recommendations for business units Experience working with and creating reports and dashboards using all relevant data to inform decisions Experience using analytics techniques to contribute to company growth efforts, increasing revenue and other key business outcomes Strong problem solving, quantitative and analytical abilities Strong ability to plan and manage numerous processes, people, and projects simultaneously Excellent communication, collaboration, and delegation skills Hands on experience with BI tools like Power BI, Tableau, Cognos, etc. Solid SQL skills for querying relational databases (e.g., SQL Server, DB2, MySQL) Good Excel, Word, and PowerPoint skills Strong analytical and problem-solving capabilities Strong results orientation Exhibits solid communication skills, both written and verbal with ability to communicate and articulate technical information into layperson terms Initiative and organizational skills Excellent team management & mentoring skills Able to adapt and quickly develop in-depth technical understanding of new/different applications Should have the ability to work independently and identify priorities for completion of multiple tasks/projects under pressure Ability to prioritize and follow-up on work Excellent organizational skills Detail oriented Sense of humor 
ScrapedJobID1289:
Diverse and inspiring colleagues and approachable leaders Stimulating work in a fast-paced, intellectually challenging environment Accelerated exposure and responsibility Global career development opportunities Being motivated every day by CPP Investments’ important social purpose and unshakable principles A deeply rooted culture of Integrity, Partnership and High Performance Develop and implement the next generation Analytics roadmap, prioritizing deliverables and products aligned to approved initiatives and firm-wide strategic priorities. Build and lead a team of highly impactful Data Science and advanced analytics resources. Determining priorities, providing development and growth opportunities and championing team across the organization. Work closely with departments across CPP Investments to understand investment needs for enterprise analytical products. Strengthen and forge relationships with key partners across the organization. Lead the development and execution of prototypes and products from an advanced analytics and data science perspective. Execution focused delivering value through Analytics. Lead the enterprise Development of data models and algorithms techniques for the use of financial market structure modeling. Bachelor’s degree, with a technology or business emphasis, or equivalent education and experience. Advanced degree preferred. Strong understanding of the investment lifecycle and proven track record of building analytical products for investment funds. Extensive background in analytical modeling, AI techniques. Track record in building and deploying data science products. Strong sense of teamwork Ability to create solutions to fit a diverse and complex environment Adaptable to new technologies and challenges not previously encountered Able to build strong relationships and communicate effectively with a diverse set of stakeholders, including business leaders, operational staff and technical engineers Proven project management experience Excellent written and oral communication skills, with the ability to work with both technical and business users Self-motivated with acute attention to detail Innovative and proactive Exemplify CPP Investments’ Guiding Principles of Integrity, High Performance and Partnership 
ScrapedJobID1290:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID1291:
Developing and supporting digital marketing campaigns, including paid Search Engine Marketing (SEM) and paid Social Media campaigns Acting as a subject matter expert for Search Engine Optimization (SEO) best practices, including ongoing technical audits of all digital properties Build Digital Results Report for clients for monthly review that encompasses all digital activities and important data KPI’s. Develop an understanding of what impact these KPI’s have on clients’ business. Manage effectiveness of Service Work Plan retention marketing Using available programs; plan, execute, and generate report on a targeted email marketing campaigns Act as a Data Scientist with regards to all the digital information we have available to us for our clients and communicate this data Oversee and manage all syndicated contents that includes various online platforms to promote business and products Working collaboratively across departments to understand company goals to develop customer acquisition, nurturing, and retention programs Study clients’ business and create a presentation based on potential and missed opportunity on the digital platform. Demonstrate to client your plan for their growth. Must be able to perform cold calls effectively and book appointments for consultation Visit businesses to generate new leads and perform updates on existing clients Requires travel 20%-50%%+ travel Bachelor’s degree or Diploma in Marketing, Business, Public Relations or 2-3 years of proven experience in sales, marketing, or communication Ability to put together effective, comprehensive, and multi-channelled marketing campaigns Have a high understanding of effective content for social media sites including Facebook, Twitter, and Instagram Manage, collaborate, and develop marketing and video assets Understanding of Google Analytics, Conversion Rate Optimization, User Experience (UX) Knowledge and Compliance with all provincial/federal advertising standards (CASL etc.) is a must. Graphical design understanding for digital properties and Point of Sale materials Excellent organizational, communication and leadership abilities. Team-oriented, relationship builder with a positive attitude. Strong oral/written communications skills. Strong organizational and multi-tasking skills with a high attention to detail Strong Proficiency in working with multiple software programs Automotive industry experience/ knowledge considered an asset. Must have valid driver’s license Passion for selling and building new relationships is a MUST. Bonus pay Commission pay Dental care Extended health care Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? No 
ScrapedJobID1292:
31% women, 57% BIPOC, 14% LGBTQIA+ 49% of our people were born in countries other than where our offices are located. Our team members collectively speak 19 different languages. 59% of our people speak more than one language In the past year Architech has increased the number of women in our technology function by 200%. We strive to do even better as our multi-year strategic plan unfolds. We analyzed salaries by gender of persons in the same role and are delighted to report a 0% gender pay gap in our delivery and technology roles! Build scalable, reliable, resilient, secure systems that are built open source with cloud first architecture. Implement responsible web and/or mobile design principles using the latest technologies. Work in an Agile team with Designers and Product Owners to continuously iterate and build feedback into the solution. Be part of the team that architects and delivers the nuances within our overall technical strategy. Commit to our ever-evolving CI/CD chain and working templates. Work with technologies such as AWS and our partner technologies within projects including Azure, DotCMS and Red Hat. Approach new projects with the client needs and users in mind. Be open to learn and absorb the rapid changes in the engineering industry. 5+ years of professional experience in a software engineering role, building large-scale software systems. Strong expertise in Node.js is a must have. Knowledge of Python, Scala, Java, including object-oriented design. Be willing to work with many teams, trying new methods and helping others learn new way. Gitflow workflow and CI/CD pipeline experience. Experience with cloud environments such as GCP, Azure, or AWS. Excellent understanding of software development life cycle and/or agile development environment. Excellent communication skills, both written and oral. Be passionate about providing inclusive and accessible experiences to our partners, including seeing products and features through the lens of Accessibility first and championing this vision across our teams. Post-secondary degree or diploma in Computer Science or related program. Knowledge of HTML / CSS / Javascript / Jquery /TypeScript/AJAX, is an asset. Knowledge of Machine Learning frameworks (Pytorch/TensorFlow) and algorithms such as pricing analytics, predictive modeling is an asset. Nano degree in Data Science is an asset. Exposure to PHP Framework. 
ScrapedJobID1293:
Clearly communicate project statuses with leaders and project teams Engage in quality assurance processes to create a high standard of accuracy Ensure exception and error handling techniques are used Use understanding of business rules to enhance logic used in reporting and analysis Seek out new technology and processes to improve team ability and reach Verbally and visually present reporting and analysis findings to leaders and stakeholders of various levels Submit work for quality assurance with a low number of errors Prioritize multiple projects within own work stream to deliver with little impact to timelines Manage relationships with data source providers for issues and support Consistently incorporate reconciliation in published reports and datasets Prove or disprove relationships between variables (causal) Forecast business measures with confidence and accuracy Assist with development planning with other team members Take on and seek out opportunities to mentor and coach Champion best practices in quality and reliability Over 8 years relevant industry experience within a telecom, client services or technology environment Undergraduate degree in a field linked to data engineering, business analytics, applied mathematics, computer science, IT, computer applications, or related field Ability to create reporting and analysis solutions that are delivered within scope, expected timelines and of high quality Demonstrated solid critical thinking and problem-solving skills Expert ability to identify issues and make difficult decisions, knowing when to escalate when required Strong ability to develop strategic relationships across the organization in a collaborative and foster trust from others Committed to personal and team excellence and ability to operate in a dynamic and constantly changing environment 
ScrapedJobID1294:
Define and drive the science vision for a platform-based solution for evaluating the long-term, incremental value of our millions of offerings. Lead R&D effort to develop innovative causal inference approaches that will extend current capabilities and scale our platform to new use cases. Work highly cross-functionally with business leadership, stakeholders, and partner data science and engineering teams to drive the integration of model outputs into company-wide business decision-making and existing production systems. Developing robust solutions to infer or recover causal relationships from observational data, in a way that minimizes self-selection or third-variable problems. Scope and prioritize new business or stakeholders needs, balancing between delivering MVP solutions and working towards long term platform development Develop and own communication strategy for both technical and business stakeholders (including product roadmap, planning, executive documentation, and progress updates) Act as a subject matter expert and thought leader on experimentation and causal inference techniques; research industry trends and best practices and bring them to life at Wayfair. Engage in the interview process and otherwise develop, grow, and mentor junior scientists; provide mentorship and technical guidance to develop your team as well to influence broader DS organization. Advanced degree (Master or PhD) in Economics, Statistics or other quantitative field with an emphasis on causal inference and/or experimental design. 5+ years of experience working as a professional data or research scientist. Consistent track record of autonomous delivery of DS/ML projects that drive measurable business impact. Collaborative team player who wants to see themselves and others thrive. Expertise in causal inference and interest in bringing best-in-class solutions to e-commerce space. Takes a customer-centric approach to ideation and problem-solving Track-record of influencing non-technical stakeholders on strategic direction by leveraging data-driven insights; excellent written and verbal communication. Strategic thinker with a customer-centric mindset and a desire for creative problem solving, looking to make a big impact in a growing organization Proficient in one or more programming languages, e.g. Python, R, etc. Nice-to-haves: Experience with GCP (BigQuery, GCS, Dataproc, Notebooks), Airflow, and containerization (Docker) Experience building scalable data processing pipelines with big data tools such as Hadoop, Hive, SQL, Spark, etc. 
ScrapedJobID1295:
Design, development and evaluation of highly innovative models Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation Work closely with software engineering teams to drive real-time model implementations and new feature creations Analyze internal behavior tracking data and forecast Wish demand Implement the strategies and set up A/B test experiments to gauge the impact, and reiterate Propose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process Create & own dashboards and analytical reports to track progress & share learnings Bachelor's or advanced degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics or similar) 3+ years of hands-on experience in predictive modeling and analysis 3+ years experience writing complex SQL queries in a business environment 2+ years in Python A/B test experience Experience collaborating with business & eng teams Analytical mindset and ability to see the big picture and influence others Detail-oriented and must have an aptitude for solving unstructured problems Ability to work effectively in a multi-task, high volume environment Ability to be adaptable and flexible in responding to deadlines and workflow fluctuations Experience operating in a Unix/Linux environment Strong presentation skills 
ScrapedJobID1296:

ScrapedJobID1297:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1298:
Architect, design and evaluate novel approaches for solving complex business problems using machine learning techniques with high-volume real-time data streams Own the machine and present analyses and machine learning concepts to a broad technical audience initiate and drive projects to completion with minimal guidance Large data sets with low to mid-level analytical complexity Small data sets with high analytical complexity Data structures containing complex relationship patterns Data with low signal to noise Unstructured DataAlgorithm development with application to solving human problems Previous involvement in software development and/or distributed computing projects is a plus 2+ years of experience in building and deploying machine learning solutions at a production scale 1+ years of experience in software development at the production level, with proficiency in Python or Scala preferred Working knowledge of PyTorch, Tensorflow, or other similar frameworks Bachelor's or Master's degree or equivalent in Computer Science, Engineering, Mathematics or related field Flexibility to WFH For the third year in a row, we are proud to announce that we have been certified as a Great Place to Work We were also certified as one of the Best Workplaces for Mental Wellness in 2020 We are an open work environment that fosters collaboration, ownership, creativity, and urgency We ensure flexible hours outside of our core working hours Enrolment in the Group Health Benefits plan right from day 1, no waiting period Team building events Fuel for the day: Weekly delivery of groceries, and all types of snacks Catered lunches and desserts on a monthly basis Daily fun in the office with our competitive games of Ping Pong, Pool, Smash Bros competitions, or FIFA And of course, an unlimited amount of freshly made coffee and tea! We’re pretty serious about our coffee beans Online learning through the platform, UDEMY 
ScrapedJobID1299:
Experience leading a technical team, including managing tasks and processes Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline 3+ years of Software Development experience with modern programming languages (Python, C/C++, Julia) Experience with at least one deep learning framework (TensorFlow, PyTorch, MXNet …) Experience working in version control such as git Experience in big data architectures and pipelines to build and deploy models Experience in building machine learning models optimized for speed, accuracy, scalability, reliability and resiliency Ability to perform complex data analysis and present findings to stakeholders Master’s degree in Computer Science, Computer Engineering or related technical discipline Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations Experience with prototyping machine learning solutions (e.g. Kaggle, demos, hackathons) Experience working with cloud platforms (e.g. AWS, Azure …) Experience with web development for demonstrations Strong communication skills Competitive salary Health and lifestyle benefits Positive & creative work environment in a great location Leadership role on an expanding team with opportunities for career growth 
ScrapedJobID1300:
3+ years experience in a Data Engineering or Analytics role managing data pipelines Strong skills in Python, SQL, Airflow, Data Modeling and ETL pipelines Familiarity with: Snowflake, AWS Redshift, or BigQuery Experience working with Data Science and Machine Learning teams as stakeholders A passion for programming and solving problems with code A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience A love for technology, and an insatiable curiosity for new tools to tackle real problems We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process. We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners. We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy. We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality. 
ScrapedJobID1301:
Provides advanced data science expertise to AstraZeneca projects and recommends data science solutions. Delivers advanced data science solutions to AstraZeneca projects, appropriately communicating with non-technical stakeholders. Works within established frameworks to deliver a variety of tasks that support projects in meeting their objectives. Independently keeps own knowledge up to date and learns from senior team members, proposing appropriate training courses for personal development. Reviews working practices and ensures non-compliant processes are escalated Ensures own work is compliant within Clinical Development. Collaborate in a multidisciplinary environment with world leading clinicians, data scientists, biological experts, statisticians and IT professionals. M.Sc. degree in rigorous quantitative science (such as mathematics, computer science, engineering) or have demonstrated an outstanding track-record of industry experience with the desired data science methodologies Practical software development skills in standard data science tools: Python, Agile, Code versioning (bitbucket/git), UNIX skills, familiarity working in cloud environment (AWS preferred) AWS or other cloud compute experience including SysOps (provisioning resources required for analytics, Kubernetes, infrastructure as code is a bonus) Data visualization & interactive data visualization (interactive dashboards w/ DASH & static visualization) Experience developing machine learning first products including timeseries analysis, forecasting, behavioral analysis Knowledge of range of mathematical and statistical modelling techniques and drive to continue to learn and develop these skills. Minimum 2+ years of industry experience or post-doctoral work. Ph.D. degree in rigorous quantitative science (such as mathematics, computer science, engineering) Experience within the pharmaceutical industry Advanced experience with Kubernetes and machine learning product architecture Communication, business analysis, and consultancy Advanced machine learning models: transformer-based NLP models, reinforcement learning, GNNs, state-of-the-art timeseries & forecasting models ML Ops experience: model tracking, model governance, multiple models in different production contexts Data visualization & interactive data visualization (interactive dashboards w/ DASH & static visualization) Our Social Media, Follow AstraZeneca on LinkedIn https://www.linkedin.com/company/1603/ Follow AstraZeneca on Facebook https://www.facebook.com/astrazenecacareers/ Follow AstraZeneca on Instagram https://www.instagram.com/astrazeneca_careers/?hl=en 
ScrapedJobID1302:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID1303:
Define BI ramp-up strategy (including BI workflow, report hierarchy and catalog) and plan for engagement with business units Work with stakeholders to define business requirements for BI technology infrastructure including Data warehouse (DWH) platform and play a proactive part in the successful implementation of the platform Working as a trusted business partner, provide accurate, timely and actionable information in the form of reports, dashboards, etc. Make sure a robust end-to-end client engagement model (ingestion and prioritization to delivery and servicing) is implemented using appropriate tool Serve as primary client contact during all phases of the BI project from problem definition through presentation, appropriately managing client expectations throughout the project Apply business strategy while driving technology strategy, balancing short term and long term needs to ensure that the architecture can scale and evolve accordingly Accountable for the overall management of BI projects, including profitability, timeliness, quality, and client value Recruit, train, develop, and supervise managers and/or analyst-level employees Ensure accuracy of data and deliverables of direct reports with comprehensive policies and processes Create an environment where BI professionals can develop their skills and grow their careers through taking on increased responsibility and adding value to the organization Advanced Degree (PhD or Master’s) required (Data Science, Computer Science, Information Technology, Economics, Statistics, Information Systems, Applied Math, Business Administration, or any other related field) 12+ years of financial services experience Working knowledge of data extraction and reporting principles: mapping, collecting data from multiple data systems on premises and cloud-based data sources Understanding of and experience using data management and reporting concepts for analyzing data, drawing conclusions, and developing actionable recommendations for business units Experience working with and creating reports and dashboards using all relevant data to inform decisions Experience using analytics techniques to contribute to company growth efforts, increasing revenue and other key business outcomes Strong problem solving, quantitative and analytical abilities Strong ability to plan and manage numerous processes, people, and projects simultaneously Excellent communication, collaboration, and delegation skills Hands on experience with BI tools like Power BI, Tableau, Cognos, etc. Solid SQL skills for querying relational databases (e.g., SQL Server, DB2, MySQL) Good Excel, Word, and PowerPoint skills Strong analytical and problem-solving capabilities Strong results orientation Exhibits solid communication skills, both written and verbal with ability to communicate and articulate technical information into layperson terms Initiative and organizational skills Excellent team management & mentoring skills Able to adapt and quickly develop in-depth technical understanding of new/different applications Should have the ability to work independently and identify priorities for completion of multiple tasks/projects under pressure Ability to prioritize and follow-up on work Excellent organizational skills Detail oriented Sense of humor 
ScrapedJobID1304:
Diverse and inspiring colleagues and approachable leaders Stimulating work in a fast-paced, intellectually challenging environment Accelerated exposure and responsibility Global career development opportunities Being motivated every day by CPP Investments’ important social purpose and unshakable principles A deeply rooted culture of Integrity, Partnership and High Performance Develop and implement the next generation Analytics roadmap, prioritizing deliverables and products aligned to approved initiatives and firm-wide strategic priorities. Build and lead a team of highly impactful Data Science and advanced analytics resources. Determining priorities, providing development and growth opportunities and championing team across the organization. Work closely with departments across CPP Investments to understand investment needs for enterprise analytical products. Strengthen and forge relationships with key partners across the organization. Lead the development and execution of prototypes and products from an advanced analytics and data science perspective. Execution focused delivering value through Analytics. Lead the enterprise Development of data models and algorithms techniques for the use of financial market structure modeling. Bachelor’s degree, with a technology or business emphasis, or equivalent education and experience. Advanced degree preferred. Strong understanding of the investment lifecycle and proven track record of building analytical products for investment funds. Extensive background in analytical modeling, AI techniques. Track record in building and deploying data science products. Strong sense of teamwork Ability to create solutions to fit a diverse and complex environment Adaptable to new technologies and challenges not previously encountered Able to build strong relationships and communicate effectively with a diverse set of stakeholders, including business leaders, operational staff and technical engineers Proven project management experience Excellent written and oral communication skills, with the ability to work with both technical and business users Self-motivated with acute attention to detail Innovative and proactive Exemplify CPP Investments’ Guiding Principles of Integrity, High Performance and Partnership 
ScrapedJobID1305:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID1306:
Developing and supporting digital marketing campaigns, including paid Search Engine Marketing (SEM) and paid Social Media campaigns Acting as a subject matter expert for Search Engine Optimization (SEO) best practices, including ongoing technical audits of all digital properties Build Digital Results Report for clients for monthly review that encompasses all digital activities and important data KPI’s. Develop an understanding of what impact these KPI’s have on clients’ business. Manage effectiveness of Service Work Plan retention marketing Using available programs; plan, execute, and generate report on a targeted email marketing campaigns Act as a Data Scientist with regards to all the digital information we have available to us for our clients and communicate this data Oversee and manage all syndicated contents that includes various online platforms to promote business and products Working collaboratively across departments to understand company goals to develop customer acquisition, nurturing, and retention programs Study clients’ business and create a presentation based on potential and missed opportunity on the digital platform. Demonstrate to client your plan for their growth. Must be able to perform cold calls effectively and book appointments for consultation Visit businesses to generate new leads and perform updates on existing clients Requires travel 20%-50%%+ travel Bachelor’s degree or Diploma in Marketing, Business, Public Relations or 2-3 years of proven experience in sales, marketing, or communication Ability to put together effective, comprehensive, and multi-channelled marketing campaigns Have a high understanding of effective content for social media sites including Facebook, Twitter, and Instagram Manage, collaborate, and develop marketing and video assets Understanding of Google Analytics, Conversion Rate Optimization, User Experience (UX) Knowledge and Compliance with all provincial/federal advertising standards (CASL etc.) is a must. Graphical design understanding for digital properties and Point of Sale materials Excellent organizational, communication and leadership abilities. Team-oriented, relationship builder with a positive attitude. Strong oral/written communications skills. Strong organizational and multi-tasking skills with a high attention to detail Strong Proficiency in working with multiple software programs Automotive industry experience/ knowledge considered an asset. Must have valid driver’s license Passion for selling and building new relationships is a MUST. Bonus pay Commission pay Dental care Extended health care Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? No 
ScrapedJobID1307:
31% women, 57% BIPOC, 14% LGBTQIA+ 49% of our people were born in countries other than where our offices are located. Our team members collectively speak 19 different languages. 59% of our people speak more than one language In the past year Architech has increased the number of women in our technology function by 200%. We strive to do even better as our multi-year strategic plan unfolds. We analyzed salaries by gender of persons in the same role and are delighted to report a 0% gender pay gap in our delivery and technology roles! Build scalable, reliable, resilient, secure systems that are built open source with cloud first architecture. Implement responsible web and/or mobile design principles using the latest technologies. Work in an Agile team with Designers and Product Owners to continuously iterate and build feedback into the solution. Be part of the team that architects and delivers the nuances within our overall technical strategy. Commit to our ever-evolving CI/CD chain and working templates. Work with technologies such as AWS and our partner technologies within projects including Azure, DotCMS and Red Hat. Approach new projects with the client needs and users in mind. Be open to learn and absorb the rapid changes in the engineering industry. 5+ years of professional experience in a software engineering role, building large-scale software systems. Strong expertise in Node.js is a must have. Knowledge of Python, Scala, Java, including object-oriented design. Be willing to work with many teams, trying new methods and helping others learn new way. Gitflow workflow and CI/CD pipeline experience. Experience with cloud environments such as GCP, Azure, or AWS. Excellent understanding of software development life cycle and/or agile development environment. Excellent communication skills, both written and oral. Be passionate about providing inclusive and accessible experiences to our partners, including seeing products and features through the lens of Accessibility first and championing this vision across our teams. Post-secondary degree or diploma in Computer Science or related program. Knowledge of HTML / CSS / Javascript / Jquery /TypeScript/AJAX, is an asset. Knowledge of Machine Learning frameworks (Pytorch/TensorFlow) and algorithms such as pricing analytics, predictive modeling is an asset. Nano degree in Data Science is an asset. Exposure to PHP Framework. 
ScrapedJobID1308:
Define and drive the science vision for a platform-based solution for evaluating the long-term, incremental value of our millions of offerings. Lead R&D effort to develop innovative causal inference approaches that will extend current capabilities and scale our platform to new use cases. Work highly cross-functionally with business leadership, stakeholders, and partner data science and engineering teams to drive the integration of model outputs into company-wide business decision-making and existing production systems. Developing robust solutions to infer or recover causal relationships from observational data, in a way that minimizes self-selection or third-variable problems. Scope and prioritize new business or stakeholders needs, balancing between delivering MVP solutions and working towards long term platform development Develop and own communication strategy for both technical and business stakeholders (including product roadmap, planning, executive documentation, and progress updates) Act as a subject matter expert and thought leader on experimentation and causal inference techniques; research industry trends and best practices and bring them to life at Wayfair. Engage in the interview process and otherwise develop, grow, and mentor junior scientists; provide mentorship and technical guidance to develop your team as well to influence broader DS organization. Advanced degree (Master or PhD) in Economics, Statistics or other quantitative field with an emphasis on causal inference and/or experimental design. 5+ years of experience working as a professional data or research scientist. Consistent track record of autonomous delivery of DS/ML projects that drive measurable business impact. Collaborative team player who wants to see themselves and others thrive. Expertise in causal inference and interest in bringing best-in-class solutions to e-commerce space. Takes a customer-centric approach to ideation and problem-solving Track-record of influencing non-technical stakeholders on strategic direction by leveraging data-driven insights; excellent written and verbal communication. Strategic thinker with a customer-centric mindset and a desire for creative problem solving, looking to make a big impact in a growing organization Proficient in one or more programming languages, e.g. Python, R, etc. Nice-to-haves: Experience with GCP (BigQuery, GCS, Dataproc, Notebooks), Airflow, and containerization (Docker) Experience building scalable data processing pipelines with big data tools such as Hadoop, Hive, SQL, Spark, etc. 
ScrapedJobID1309:
Design, development and evaluation of highly innovative models Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation Work closely with software engineering teams to drive real-time model implementations and new feature creations Analyze internal behavior tracking data and forecast Wish demand Implement the strategies and set up A/B test experiments to gauge the impact, and reiterate Propose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process Create & own dashboards and analytical reports to track progress & share learnings Bachelor's or advanced degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics or similar) 3+ years of hands-on experience in predictive modeling and analysis 3+ years experience writing complex SQL queries in a business environment 2+ years in Python A/B test experience Experience collaborating with business & eng teams Analytical mindset and ability to see the big picture and influence others Detail-oriented and must have an aptitude for solving unstructured problems Ability to work effectively in a multi-task, high volume environment Ability to be adaptable and flexible in responding to deadlines and workflow fluctuations Experience operating in a Unix/Linux environment Strong presentation skills 
ScrapedJobID1310:

ScrapedJobID1311:
Réaliser le développement des rapports et tableaux de bord dans le respect des Modifier les rapports et tableaux de bord existants afin de répondre aux besoins Effectuer les essais et l"assurance qualité des développements avant la mise en Assurer la performance des rapports et tableaux de bord développées Assurer le support de premier niveau des produits informationnels Travailler en étroite collaboration avec les équipes de gestion de l"information afin Assurer le lien avec l"équipe de l"entrepôt de données afin de spécifier les besoins et Participer au profilage des données des systèmes sources Tester les extractions et les requêtes afin d"assurer la qualité des données Créer des tables de faits, de dimensions, et des vues pouvant être utilisées dans les Créer des champs calculés directement dans les bases de données pour supporter Participer aux discussions et aux ateliers de gouvernance Proposer et utiliser les définitions et le lexique d"entreprise Assurer la conformité et l"alignement des indicateurs clefs de performance Recueillir les besoins d"affaires et ceux des clients et utilisateurs Organiser et conduire des séances de travail afin de développer et proposer des Effectuer l"analyse détaillée des besoins et rédiger les spécifications détaillées afin de Participer et conduire des réunions et des revues d"avancement des projets avec les Analyser, cartographier et schématiser les systèmes et les processus d"affaires Créer et supporter la mise en place d"une architecture des données Proposer les meilleures solutions possibles afin d"atteindre les objectifs de l"unité Proposer des indicateurs clefs de performance pertinents Rédiger la documentation des produits informationnels afin d"en permettre une Supporter le déploiement du portail web pour la diffusion des différents rapports et Mettre en place une structure temporaire pour le traitement et la transformation des Supporter l"automatisation des tâches de rafraichissement des données, des rapports Proposer et développer des solutions numériques afin de permettre le suivi des Participer aux initiatives en science des données (apprentissage machine, prévision, Diplôme universitaire en génie, en science informatique, en intelligence d"affaires ou en Diplôme universitaire de 2e cycle en intelligence d"affaires, en science des données, ou Idéalement 1 à 4 ans d"expérience, mais ouvert aux nouveaux diplômés Maîtrise du français et de l"anglais parlé et écrit Expérience de travail dans le secteur manufacturier ou aérospatial un atout Maîtrise de la suite Microsoft 365 Maîtrise avancée du logiciel Power BI Bonne compréhension des besoins d"affaires, des systèmes et des architectures dans un Expérience dans le développement et l"utilisation de modèles relationnels et Bonnes connaissances SQL (fonctions de fenêtre, requêtes imbriquées, tables Expérience de programmation dans un contexte d"analyse de données (ex. VBA, Python, Connaissances de base de SAP, PLM, Jupyter et HDFS un atout Connaissance de la méthodologie agile Connaissance des plateformes en gestion de projets et partage de codes (ex. Azure Le poste est présentement offert en télétravail. Un retour au bureau sera possible lorsque L"horaire de travail est flexible Une analyse de cas sera demandée aux candidats présélectionnés afin de valider les Develop reports and dashboards in compliance with Modify existing reports and dashboards to meet needs Perform tests and quality assurance of developments before implementation Ensure the performance of reports and dashboards developed Provide first level support for information products Work closely with information management teams to Liaise with the data warehouse team in order to specify the needs and Participate in the profiling of data from source systems Test extractions and queries to ensure data quality Create tables of facts, dimensions, and views that can be used in Create calculated fields directly in the databases to support Participate in governance discussions and workshops Propose and use the definitions and the business lexicon Ensure compliance and alignment of key performance indicators Collect business needs and those of customers and users Organize and lead working sessions in order to develop and propose Perform detailed needs analysis and write detailed specifications in order to Participate and lead meetings and project progress reviews with Analyze, map and map systems and business processes Create and support the implementation of a data architecture Propose the best possible solutions in order to achieve the objectives of the unit Propose relevant key performance indicators Write the documentation of information products in order to allow Support the deployment of the web portal for the distribution of the various reports and Set up a temporary structure for the processing and transformation of Support the automation of data refresh tasks, reports Propose and develop digital solutions to allow the monitoring of Participate in data science initiatives (machine learning, forecasting, University degree in engineering, computer science, business intelligence or 2nd year university diploma Ideally 1 to 4 years of experience, but open to new graduates Fluency in spoken and written French and English Work experience in the manufacturing or aerospace sector an asset Proficiency in the Microsoft 365 suite Advanced knowledge of Power BI software Good understanding of business needs, systems and architectures in a Good SQL knowledge (window functions, nested queries, tables Programming experience in a data analysis context (eg VBA, Python, Basic knowledge of SAP, PLM, Jupyter and HDFS an asset Knowledge of agile methodology Knowledge of project management and code sharing platforms (eg Azure The position is currently offered by telecommuting. A return to the office will be possible when The work schedule is flexible A case analysis will be requested from shortlisted candidates in order to validate the 
ScrapedJobID1312:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1313:
Architect, design and evaluate novel approaches for solving complex business problems using machine learning techniques with high-volume real-time data streams Own the machine and present analyses and machine learning concepts to a broad technical audience initiate and drive projects to completion with minimal guidance Large data sets with low to mid-level analytical complexity Small data sets with high analytical complexity Data structures containing complex relationship patterns Data with low signal to noise Unstructured DataAlgorithm development with application to solving human problems Previous involvement in software development and/or distributed computing projects is a plus 2+ years of experience in building and deploying machine learning solutions at a production scale 1+ years of experience in software development at the production level, with proficiency in Python or Scala preferred Working knowledge of PyTorch, Tensorflow, or other similar frameworks Bachelor's or Master's degree or equivalent in Computer Science, Engineering, Mathematics or related field Flexibility to WFH For the third year in a row, we are proud to announce that we have been certified as a Great Place to Work We were also certified as one of the Best Workplaces for Mental Wellness in 2020 We are an open work environment that fosters collaboration, ownership, creativity, and urgency We ensure flexible hours outside of our core working hours Enrolment in the Group Health Benefits plan right from day 1, no waiting period Team building events Fuel for the day: Weekly delivery of groceries, and all types of snacks Catered lunches and desserts on a monthly basis Daily fun in the office with our competitive games of Ping Pong, Pool, Smash Bros competitions, or FIFA And of course, an unlimited amount of freshly made coffee and tea! We’re pretty serious about our coffee beans Online learning through the platform, UDEMY 
ScrapedJobID1314:
Experience leading a technical team, including managing tasks and processes Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline 3+ years of Software Development experience with modern programming languages (Python, C/C++, Julia) Experience with at least one deep learning framework (TensorFlow, PyTorch, MXNet …) Experience working in version control such as git Experience in big data architectures and pipelines to build and deploy models Experience in building machine learning models optimized for speed, accuracy, scalability, reliability and resiliency Ability to perform complex data analysis and present findings to stakeholders Master’s degree in Computer Science, Computer Engineering or related technical discipline Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations Experience with prototyping machine learning solutions (e.g. Kaggle, demos, hackathons) Experience working with cloud platforms (e.g. AWS, Azure …) Experience with web development for demonstrations Strong communication skills Competitive salary Health and lifestyle benefits Positive & creative work environment in a great location Leadership role on an expanding team with opportunities for career growth 
ScrapedJobID1315:
3+ years experience in a Data Engineering or Analytics role managing data pipelines Strong skills in Python, SQL, Airflow, Data Modeling and ETL pipelines Familiarity with: Snowflake, AWS Redshift, or BigQuery Experience working with Data Science and Machine Learning teams as stakeholders A passion for programming and solving problems with code A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience A love for technology, and an insatiable curiosity for new tools to tackle real problems We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process. We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners. We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy. We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality. 
ScrapedJobID1316:
Provides advanced data science expertise to AstraZeneca projects and recommends data science solutions. Delivers advanced data science solutions to AstraZeneca projects, appropriately communicating with non-technical stakeholders. Works within established frameworks to deliver a variety of tasks that support projects in meeting their objectives. Independently keeps own knowledge up to date and learns from senior team members, proposing appropriate training courses for personal development. Reviews working practices and ensures non-compliant processes are escalated Ensures own work is compliant within Clinical Development. Collaborate in a multidisciplinary environment with world leading clinicians, data scientists, biological experts, statisticians and IT professionals. M.Sc. degree in rigorous quantitative science (such as mathematics, computer science, engineering) or have demonstrated an outstanding track-record of industry experience with the desired data science methodologies Practical software development skills in standard data science tools: Python, Agile, Code versioning (bitbucket/git), UNIX skills, familiarity working in cloud environment (AWS preferred) AWS or other cloud compute experience including SysOps (provisioning resources required for analytics, Kubernetes, infrastructure as code is a bonus) Data visualization & interactive data visualization (interactive dashboards w/ DASH & static visualization) Experience developing machine learning first products including timeseries analysis, forecasting, behavioral analysis Knowledge of range of mathematical and statistical modelling techniques and drive to continue to learn and develop these skills. Minimum 2+ years of industry experience or post-doctoral work. Ph.D. degree in rigorous quantitative science (such as mathematics, computer science, engineering) Experience within the pharmaceutical industry Advanced experience with Kubernetes and machine learning product architecture Communication, business analysis, and consultancy Advanced machine learning models: transformer-based NLP models, reinforcement learning, GNNs, state-of-the-art timeseries & forecasting models ML Ops experience: model tracking, model governance, multiple models in different production contexts Data visualization & interactive data visualization (interactive dashboards w/ DASH & static visualization) Our Social Media, Follow AstraZeneca on LinkedIn https://www.linkedin.com/company/1603/ Follow AstraZeneca on Facebook https://www.facebook.com/astrazenecacareers/ Follow AstraZeneca on Instagram https://www.instagram.com/astrazeneca_careers/?hl=en 
ScrapedJobID1317:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID1318:
Define BI ramp-up strategy (including BI workflow, report hierarchy and catalog) and plan for engagement with business units Work with stakeholders to define business requirements for BI technology infrastructure including Data warehouse (DWH) platform and play a proactive part in the successful implementation of the platform Working as a trusted business partner, provide accurate, timely and actionable information in the form of reports, dashboards, etc. Make sure a robust end-to-end client engagement model (ingestion and prioritization to delivery and servicing) is implemented using appropriate tool Serve as primary client contact during all phases of the BI project from problem definition through presentation, appropriately managing client expectations throughout the project Apply business strategy while driving technology strategy, balancing short term and long term needs to ensure that the architecture can scale and evolve accordingly Accountable for the overall management of BI projects, including profitability, timeliness, quality, and client value Recruit, train, develop, and supervise managers and/or analyst-level employees Ensure accuracy of data and deliverables of direct reports with comprehensive policies and processes Create an environment where BI professionals can develop their skills and grow their careers through taking on increased responsibility and adding value to the organization Advanced Degree (PhD or Master’s) required (Data Science, Computer Science, Information Technology, Economics, Statistics, Information Systems, Applied Math, Business Administration, or any other related field) 12+ years of financial services experience Working knowledge of data extraction and reporting principles: mapping, collecting data from multiple data systems on premises and cloud-based data sources Understanding of and experience using data management and reporting concepts for analyzing data, drawing conclusions, and developing actionable recommendations for business units Experience working with and creating reports and dashboards using all relevant data to inform decisions Experience using analytics techniques to contribute to company growth efforts, increasing revenue and other key business outcomes Strong problem solving, quantitative and analytical abilities Strong ability to plan and manage numerous processes, people, and projects simultaneously Excellent communication, collaboration, and delegation skills Hands on experience with BI tools like Power BI, Tableau, Cognos, etc. Solid SQL skills for querying relational databases (e.g., SQL Server, DB2, MySQL) Good Excel, Word, and PowerPoint skills Strong analytical and problem-solving capabilities Strong results orientation Exhibits solid communication skills, both written and verbal with ability to communicate and articulate technical information into layperson terms Initiative and organizational skills Excellent team management & mentoring skills Able to adapt and quickly develop in-depth technical understanding of new/different applications Should have the ability to work independently and identify priorities for completion of multiple tasks/projects under pressure Ability to prioritize and follow-up on work Excellent organizational skills Detail oriented Sense of humor 
ScrapedJobID1319:
Diverse and inspiring colleagues and approachable leaders Stimulating work in a fast-paced, intellectually challenging environment Accelerated exposure and responsibility Global career development opportunities Being motivated every day by CPP Investments’ important social purpose and unshakable principles A deeply rooted culture of Integrity, Partnership and High Performance Develop and implement the next generation Analytics roadmap, prioritizing deliverables and products aligned to approved initiatives and firm-wide strategic priorities. Build and lead a team of highly impactful Data Science and advanced analytics resources. Determining priorities, providing development and growth opportunities and championing team across the organization. Work closely with departments across CPP Investments to understand investment needs for enterprise analytical products. Strengthen and forge relationships with key partners across the organization. Lead the development and execution of prototypes and products from an advanced analytics and data science perspective. Execution focused delivering value through Analytics. Lead the enterprise Development of data models and algorithms techniques for the use of financial market structure modeling. Bachelor’s degree, with a technology or business emphasis, or equivalent education and experience. Advanced degree preferred. Strong understanding of the investment lifecycle and proven track record of building analytical products for investment funds. Extensive background in analytical modeling, AI techniques. Track record in building and deploying data science products. Strong sense of teamwork Ability to create solutions to fit a diverse and complex environment Adaptable to new technologies and challenges not previously encountered Able to build strong relationships and communicate effectively with a diverse set of stakeholders, including business leaders, operational staff and technical engineers Proven project management experience Excellent written and oral communication skills, with the ability to work with both technical and business users Self-motivated with acute attention to detail Innovative and proactive Exemplify CPP Investments’ Guiding Principles of Integrity, High Performance and Partnership 
ScrapedJobID1320:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID1321:
Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. AWS Cloud (certification is an asset) AWS services like AWS glue or other AWS services Python programming language. Big Data technologies (like a Spark, hive/HDFS, PySpark, Hadoop) SQL and NoSQL databases, including Postgres and Cassandra. Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. AWS cloud services: EC2, EMR, RDS, Redshift Stream-processing systems: Storm, Spark-Streaming, etc. Object-oriented/object function scripting languages: Java, C++, Scala, etc. 
ScrapedJobID1322:
Design, development and evaluation of highly innovative models Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation Work closely with software engineering teams to drive real-time model implementations and new feature creations Analyze internal behavior tracking data and forecast Wish demand Implement the strategies and set up A/B test experiments to gauge the impact, and reiterate Propose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process Create & own dashboards and analytical reports to track progress & share learnings Bachelor's or advanced degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics or similar) 3+ years of hands-on experience in predictive modeling and analysis 3+ years experience writing complex SQL queries in a business environment 2+ years in Python A/B test experience Experience collaborating with business & eng teams Analytical mindset and ability to see the big picture and influence others Detail-oriented and must have an aptitude for solving unstructured problems Ability to work effectively in a multi-task, high volume environment Ability to be adaptable and flexible in responding to deadlines and workflow fluctuations Experience operating in a Unix/Linux environment Strong presentation skills 
ScrapedJobID1323:
Linux GPU driver development in support of Machine Learning and Data Centre applications Contributes to software projects of significant technical importance Solves sophisticated non-recurring problems that leads to development and implementation Debug, analyze and resolve quality and certification issues as reported by Customers and QA Write detailed design notes for new features Coordinate closely with peers and colleagues to ensure timely and effective communication of all assigned work activities Coordinate with developers in the open-source development community Proficient in C and C++ programming Excellent debugging and trouble-shooting skills Strong general Linux systems administration, software development, and troubleshooting knowledge and experience. Linux kernel development experience, either core kernel development or device driver development. PC architecture knowledge Strong oral and written communication skills Experience with Linux containers kernel level implementation (cgroups, namespaces) Familiarity with Linux networking and network/cluster management Familiarity with Linux GPU driver development (kernel and user-mode), ideally on AMD hardware. Familiarity with compute, graphics, or multimedia GPU application development using APIs such as OpenCL, OpenGL, and VAAPI. Proven track record of contributions to open-source projects Familiarity with Linux security subsystems such as selinux and/or AppArmor Bachelor's degree or Master’s in Computer Science or related degree with validated experience 
ScrapedJobID1324:

ScrapedJobID1325:
You'll play a pivotal part in informing and delivering upon our data strategy, by providing sales and marketing performance data, creating custom dashboards and visualization, and supporting marketing and financial strategies Providing Advance analytical insights to the team and help them improve marketing strategies Provide technical leadership to internal team members and various stakeholders Operationalize and support our underlying data systems, improving our system reliability, accuracy and stability You are analytical and outcome-oriented with a proven ability to translate technical considerations into business implications as well as to synthesize data into actionable insights You are well-versed with Business Intelligence/ Market Intelligence processes and other marketing technologies You have demonstrated the ability to successfully deliver complex projects involving people, process, technology, and change management You have experience with agile ways of working and a bias for action to break down barriers to get results fast with a test and learn mindset You can assemble large complex datasets across multiple databases and sources by building automated pipelines (ETL) Strong analytic skills related to working with unstructured datasets. Strong Business Acumen Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. SAS knowledge Business Intelligence/ Market Intelligence processes and other marketing technologies understanding Technical or data-driven educational background (computer science, engineering, statistics, data science) and/or Masters of Business Administration (MBA) degree 5+ years of progressive and relevant work experience Takes ownership, initiates improvements, and is self-directed Able to effectively engage stakeholders to establish cross functional alignment for projects Prior telecommunications expertise B2B marketing Python experience Hive / Spark / Nifi experience Experience with cloud (GCP Amazon or Azure) Data Science / Modeling experience or working in a Data Science team 
ScrapedJobID1326:
Develop and maintain algorithms, data pipelines, automated processes, and services to create a data science solution that are customer focused Extract mission-critical insights from datasets Innovate and bring creative ideas to building mission critical customer facing products that depend on ML solutions Work with product and business teams to identify solutions and best practices Create scalable models that drive business decisions and enable our customers’ success Design and develop processes and systems which analyze and generate actionable insights from diverse data sources Develop tools to monitor models for evolving performance and accuracy Mentor team members in the areas of technical expertise and career building Contribute to best practices around feature extraction, model development, and knowledge sharing among multiple data science teams Directly contribute to architecture planning Been in the ML engineering game for some time. You have a Bachelors/Masters and 4+ years of industry experience Proven ability to architect data science solutions to complex problems and delivering solutions in customer facing products Experience delivering solutions that analyzes big datasets using tools such as Apache Spark Experience delivering solutions that analyzes time-series data Strong programming skills in Python A strong command of SQL and working with multiple relational databases and data warehouses (Redshift, Postgres, Athena, Snowflake, etc…) Experience in end-to-end machine learning project life cycle Experience working with unstructured data Are scrappy when extracting useful insights with partial data A solid experience in working with software development teams and using source version control tools like Git Experience deploying deep learning models Experience with frameworks for in-production ML code (e.g. Kedro) Developing and deploying using Docker With some of the AWS services (e.g. EC2, S3, Sage Maker, Cloudwatch) With accessing data from other datastores in the AWS ecosystem such as ElasticSearch, S3, and DynamoDB The BEST team. Remote-first culture. International Meetups. Access to Jungle Scout tools & experts. Performance Bonus. Flexible Vacation. Comprehensive Health Benefits & Retirement Program. 
ScrapedJobID1327:
Stay abreast of innovations and publications in the field of operations research and business intelligence systems. Research and solve complex scheduling, resource allocation and pricing scenarios involved in operations optimization. Analyze raw operational data and design algorithms that can automatically and consistently generate operational recommendations for clients. Contribute to the invention of novel solutions to client’s operational problems by collaboratively working with product managers, co-developers, and our client success team. Utilize efficient algorithm design in a parallelized fashion capable of crunching gigabytes of operations data in minutes and scaling up with client growth. Build dashboards that transform operational data into visualizations that are intuitive and actionable Contribute refinements to our existing product through the development of new features as well as refactoring existing code to make it more efficient and object-oriented. Advance your knowledge of new software tools, agile programming methods, business intelligence technologies and share your knowledge with the development team, thus catalyzing process / technology changes to help us be more effective. Languages: C#, JavaScript, TypeScript Frameworks: .NET Core, Angular Web Server: IIS, NGINX Databases: MS SQL, Azure SQL Infrastructure: Azure, Docker, Kubernetes, GitLab Logistics engine: algorithms for discrete optimization problems Operation Systems: Windows, Linux Development Processes: Agile, CI/CD 2+ years of experience in Software Development, preferably with high performance algorithms or data intensive applications. A deep and intuitive understanding of Algorithms and Data Structures. Ability to process, assimilate, and explain complex and abstract concepts from research publications. Operations Research or Management Engineering Mathematical Optimization Data Science / Machine Learning Master’s Degree or PhD in Applied Mathematics/ Management Science/ Operations Research/ Computer Science / Engineering, or related technical discipline. Base salary of $80K - $115K + performance-based bonus or stock options Work-Life Balance: Flex time, work from home days and travel incentives. Set-up: Standing / adjustable desks, massage chair & quiet rooms, employee lounge with Xbox, Switch & PS4. Benefits Plan: Fitness allowance, dental/prescription/vision, massage & physio, and healthcare spending account. Food & Fun: Fully stocked kitchen, fancy coffee machine, team lunches, long weekend bottle draws and monthly employee events. 
ScrapedJobID1328:
Responsible for server side applications Analysis, Design & Development. Collaborate with business partners on the trading floor to create performant applications that deliver real time insights on millions of data points. Responsible for creating high throughput applications leveraging existing Citi Big data framework, Part of an innovative team pursing boundaries to create innovative data visualization solutions. Ability to take initiative to research, learn and recommend emerging technologies. Be part of a dynamic group working towards a common goal. Work with developers onshore, offshore and matrix teams to implement a business solution Proficiency in Java or Python. Experience with customer analytics. Relish tackling new challenges, paying attention to details, and growing professionally. Basic shell commands and shell scripting. Adapts machine learning and deep learning technologies to the finance products Strong familiarity with machine learning and statistical techniques Knowledge and experience of distributed computing Knowledge of advanced statistical techniques and concepts. Extensive hand-coding expertise in Core Java development Experience with PySpark/Pandas and related data analytics libraries Adapts machine learning and deep learning technologies to the finance products Experience with messaging systems like Kafka & EMS (Solace, Tibco) Experience in Hadoop framework with good understanding of HDFS, Hive, HBase, Spark 
ScrapedJobID1329:
Bachelor’s degree in Data Science or Business Administration, MA or MBA preferred. Professional-level, current, subject matter expertise in various topics in Excel, Power Query and Power BI. Experience with adult instruction and/or training, with proven track record of online communication. Proficiency with MS suite, ability to connect to online hubs with reliable devices and internet access. Experience with online learning platforms such as D2L, Blackboard, and Moodle. 3-5 years teaching experience required. Documented experience working as an Instructor in a post-secondary or industry setting within a team environment is an asset. Ability to excel under pressure and ‘think on your feet’. Professional competence preparing, developing, delivering and administering post-secondary courses. Excellent English-language communication (written and verbal), and interpersonal and people-management skills. Demonstrated ability to deliver in class and within an online learning platform. Ability to motivate adult learners to achieve academic success. An established network of relevant professional contacts. Please note: These are the minimum required qualifications. Being a part of BC’s Top 100 Employers, and a member of the CCDI. A generous Total Compensation package which includes extended health and dental benefits and a superb pension plan. Access to Professional Development Funds and opportunities for career development. Increase your knowledge with Tuition waivers for BCIT courses. Enjoy discounted access to our fitness facilities (including classes like Yoga and Zumba). Additional Wellness and Employee Assistance programs. 
ScrapedJobID1330:

ScrapedJobID1331:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID1332:
Collaborate with our digital stakeholders to define KPIs, reporting requirements, and overall measurement strategy for our digital and mobile customer journeys Translate business requirements into technical specifications for custom digital analytics implementation using a combination of data layer, processing rules, SAINT classification, report suite configuration, custom JavaScript, JSON and applicable integrations with other systems Manage daily operations and implementation of TD's analytics stack (Adobe Analytics, Adobe Target, Adobe Audience Manager, Adobe Launch, Adobe Mobile Services, Ensighten) and 3rd party marketing tags (DoubleClick, Rakuten, Facebook, etc.) Develop and own all implementation documents such as SDR, Data Layer specifications, custom JavaScript Ensure the timely delivery and accuracy of documentation and technical coding (HTML, JavaScript, ActionScript) via our Tag Management System Collaborate with technology teams on implementation of analytics solutions, including guidance on data layer implementation and troubleshooting, data feeds and integrations with other systems Keep abreast of product updates (Adobe, Ensighten), best practices and proactively follow up with required changes in our implementation and appropriate communications Provide consultative service, training and validation support to quality assurance/testing teams. 4+ years' experience in analytics, with digital experience preferred 5+ years' experience of web development including JavaScript, jQuery and Angular Strong understanding of JSON structures and best practices Strong understanding of Native Mobile development standards Strong understanding of JavaScript & Node.js & DOM manipulation, web markup, including HTML5 and CSS3 Expertise with tag management tools (DTM, Adobe Launch, Tealium, Ensighten) and their configuration All-hands experience in implementing/troubleshooting/deploying the Adobe stack, Google 360 and/or 3rd party marketing tags using DTM or Adobe Launch or Ensighten Expert level knowledge in developing Adobe Analytics Solution Design Reference (SDR) Understanding of Adobe Analytics processing rules, SAINT classifications, report suite configuration, and data feeds Experience architecting a Data Layer Specification and guiding the development team on implementation and troubleshooting Experience debugging Adobe Analytics utilizing browser network calls, extensions, and tools such as Fiddler, Charles or Omnibug Ability to own and work independently on assigned deliverables, but also collaborate with multiple team members and stakeholders when necessary Solid communications skills – verbal and written Strong time-management skills and ability to work on multiple projects at once 
ScrapedJobID1333:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1334:

ScrapedJobID1335:
Lead a team of engineers to design and build a platform to analyze and evaluate every part of the self-driving stack, including pipelines and the web frontend Develop on-premises cluster projects as well as utilizing public cloud computing infrastructure services Build web-based tools to optimize manual workflows such as test cases design and result in analysis Proactively identify problems and make technical suggestions on requirements 5-7 years experience building full-stack web applications At least 2 years experience managing a high-performing team Excellent skills in architecture design Proven ability to coach/mentor junior engineers Experience with modern JavaScript development, with frameworks such as Node.js/npm, Vue.js, react.js, etc Experience with web frameworks such as Flask and Django Experience with cloud services, such as AWS Excellent knowledge of different API mechanisms such as REST and RPC/gRPC Experience in developing extensible APIs and highly maintainable services Excellent knowledge of databases like PostgreSQL, Dynamodb, MongoDB Passionate about discovering drawbacks of existing systems and working with users to improve their experience BS/MS in Computer Science or related field Experience with creative and intuitive data visualization (eg, D3.js) Development experience in large-scale data storage and processing Passionate about self-driving vehicles 100% employer-paid healthcare premiums for you and your family Work visa sponsorship available Relocation assistance available Gym membership reimbursement Monthly team building budget Learning/education budget Employer-paid life insurance 
ScrapedJobID1336:
Experience with Python in production environments and a strong understanding of computer science fundamentals Experience designing experiments, A/B testing and data analysis in the domain of quality metrics for machine learning services Experience with designing and building metrics collection and data visualization Solid understanding of modern web applications architecture and development process Passion for decision making based on sound data analysis. A strong sense of ownership and a persistent desire to grow and lead beyond the scope of the current role Basic understanding of modern frontend development frameworks (e.g., Angular or React) REST-based API design, e.g., Flask or Django. Interest in or experience with machine learning methodologies and tools (e.g. Natural Language Processing (NLP), sklearn, pandas, numpy, keras, tensorflow, etc.) Exposure to large-scale data processing tools like Kafka, Spark, or Hadoop Exposure to cloud-computing technologies like AWS/GCP, Docker, Kubernetes etc. Experience using modern frontend development frameworks (e.g., Angular or React) 
ScrapedJobID1337:
Take a hands-on role in several projects, including the Fundamental Review of the Trading Book (FRTB), data solutions for capital optimization, and data quality control processes. Prototype new approaches and enhance existing methodologies to advance market data management and data quality control. Develop production level code and collaborate with IT team for integration into daily bank processes. Assist team members for various ad-hoc analyses, data methodology, documentation, reporting, preparation of materials. Execute model runs on a regular basis for reporting and perform corresponding analyses. Communicate with model developers, trading desks, risk teams, and business lines to enhance data quality control and data management for capital optimization Become an active member of the team including our D&I initiatives and communities. Solid quantitative background and problem-solving skills with a keen interest in Data Science, Finance, Economics, Market Risk, Derivatives Pricing, Risk management or Regulations. Advanced degree in a mathematics, economics, or scientific discipline (e.g., Mathematics, Finance, Statistics, Physics, Engineering, Biology, Economics, etc.). Master’s degrees or PhDs are a bonus. Experience in code development in Python or other formal programing will be important to support day-day activity. Effective communication (written and oral), specifically the ability to summarize complex ideas in simple terms; you enjoy working in collaborations. The opportunity to join a forward-thinking company surrounded by a collaborative team of innovative thinkers. A rewarding career path with diverse opportunities for professional development. Internal development to support your growth and enhance your skills. A competitive compensation and benefits package. An organization committed to making a difference in our communities– for you and our customers. We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!

This position is located Downtown, Toronto. This is a contract role. 
ScrapedJobID1338:
Assess the current state of a client’s digital marketing and customer technology platforms and integrations. Advise customers in adopting and applying cloud platform technologies to challenges in digital analytics and marketing technologies. Plan and document solution architectures to solve integration and automation needs and work with Data Engineering, Business Intelligence, Data Science, Product Management, and Marketing Strategy teams to put solutions in place. Display pragmatism and take ownership of client, personal and team results. Contribute to building client-ready tools, processes, best practices, and capabilities. Mentor and develop more junior consultants and Strategy & Insights team members. 3+ years of relevant work experience in digital marketing, consulting, or analytics. 2+ years of relevant work experience in an agency environment, or an MBA or other relevant master’s degree. Expertise in digital analytics (Adobe Analytics, Google Analytics) and digital marketing (GMP, Facebook, Adobe Campaign, Amazon Advertising, etc.) platforms, and other marketing technology. Familiarity with cloud technologies (Google Cloud Platform, AWS, Azure) and their capabilities as they relate to customer data and digital analytics. Familiarity with lead generation and marketing automation technologies (CRMs such as Salesforce, Hubspot) and their capabilities as they relate to customer data and digital analytics. Industry knowledge of the advanced analytics landscape. Understanding of data governance, compliance, and privacy issues. Knowledge and familiarity with BI tools like Tableau, Power BI, or similar and SQL is a plus. Exemplary verbal and written communication skills. Strong cross-functional team management skills. Ability to manage multiple engagements and priorities at once. 
ScrapedJobID1339:
Help set the product vision and strategy for Achievers data, analytics and insights products Execute on new Insight Products and features in collaboration with Data Engineering, Data Science, and other Product Managers Work together with the Engineering team to ensure the Data Infrastructure supports Analytics and insights roadmap and requirements. Work with multiple stakeholders to understand business and user needs to prioritize work Develop and measure products metrics to drive product growth Articulate detailed user stories, participate in daily scrum rituals, and answer questions as the customer representative. Assist with product release communications, internal & external Drive launches with product marketing, including beta programs Gather ongoing feedback on both existing and upcoming product capabilities Act as an analytics and insights product expert and champion Work closely with other product managers to understand their product vision and trajectory so that you can help amplify it with the right data strategy. 5+ years of Product Management Experience You are a data story teller…you know that data is most valuable and powerful when it is unlocked as insights and intuitive visualizations and are an expert at such. Data minded with the ability to define, capture, and decompose relevant metrics Experience in building high quality products powered by machine learning Experience with relational databases, data warehouses and data visualization Experience acting as a product manager in an agile development and rapid prototyping environment An understanding of building for desktop and mobile applications Experience articulating detailed user stories, participating in daily scrum rituals, and answering questions as the customer representative. Experience using or building commercial business applications targeted at enterprise users with consumer-like interfaces Experience working with product marketing to launch products internally and externally An understanding of basic project management principles and the ability to prioritize work based on greatest business impact. Conceptual understanding of web development and APIs Strong appreciation for user design and user behaviors Natural leadership, communication, and influence skills The ability to work with product metric tools (bonus if you know Pendo) to make data informed decisions 
ScrapedJobID1340:

ScrapedJobID1341:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID1342:
Help create an outstanding research platform. You'll be a technical hands-on software engineering manager whose team will work with ML Scientists, Data Scientists, Data Engineers, and Biologists building a platform to train, evaluate, and move machine learning models into production. Mentor, coach, grow, and empower the people on your team. Work with your team to set the direction for ML tooling at Recursion. Accelerate drug discovery by helping us find new disease / compound interactions through the models your team will run and support Partner with product and internal customers to prioritize and develop the most important capabilities. Participate in deep technical discussions within your team and across partner teams, with extra attention toward clarifying unknowns. Establish and achieve quarterly goals, setting and adjusting expectations based on regular, iterative feedback from prototypes and delivering software into production. Recruit and grow an inclusive team, including sourcing candidates, interviewing candidates, and onboarding new employees. Experience developing machine learning models for production environments A passion for scaling Machine Learning products and helping Machine Learning Scientists design and train new models that push the boundaries of AI Experience leading technical teams focusing on managing both people and technologies. Demonstrate past record of learning from and teaching peers in areas of performance, scalability, and system architecture. Our current tech stack uses Python, PyTorch common pydata libraries, along with Kafka, PostgreSQL, Docker, and Kubernetes, our cloud services are provided by Google Cloud Platform. 100% Coverage of health, vision, and dental insurance premiums 401(k) with generous matching (immediate vesting) Stock option, restricted stock unit (RSUs) and employee stock purchase plan (ESPP) programs Two one-week paid company closures (summer and winter) Flexible vacation/sick leave Generous paid parental leave (including adoptive) Onsite daycare facility** (Salt Lake City) Commuter benefit and vehicle parking to ease your commute** Complimentary chef-prepared lunches and well-stocked snack bars** (Salt Lake City) Monthly fitness/wellness stipend One-of-a-kind 100,000 square foot headquarters complete with a 70-foot climbing wall, showers, lockers, and bike parking** (Salt Lake City) 
ScrapedJobID1343:
Bachelor’s degree in Data Science or Business Administration, MA or MBA preferred. Professional-level, current, subject matter expertise in various topics in Excel, Power Query and Power BI. Experience with adult instruction and/or training, with proven track record of online communication. Proficiency with MS suite, ability to connect to online hubs with reliable devices and internet access. Experience with online learning platforms such as D2L, Blackboard, and Moodle. 3-5 years teaching experience required. Documented experience working as an Instructor in a post-secondary or industry setting within a team environment is an asset. Ability to excel under pressure and ‘think on your feet’. Professional competence preparing, developing, delivering and administering post-secondary courses. Excellent English-language communication (written and verbal), and interpersonal and people-management skills. Demonstrated ability to deliver in class and within an online learning platform. Ability to motivate adult learners to achieve academic success. An established network of relevant professional contacts. Please note: These are the minimum required qualifications. Being a part of BC’s Top 100 Employers, and a member of the CCDI. A generous Total Compensation package which includes extended health and dental benefits and a superb pension plan. Access to Professional Development Funds and opportunities for career development. Increase your knowledge with Tuition waivers for BCIT courses. Enjoy discounted access to our fitness facilities (including classes like Yoga and Zumba). Additional Wellness and Employee Assistance programs. 
ScrapedJobID1344:
3+ years experience in a Data Engineering or Analytics role managing data pipelines Strong skills in Python, SQL, Airflow, Data Modeling and ETL pipelines Familiarity with: Snowflake, AWS Redshift, or BigQuery Experience working with Data Science and Machine Learning teams as stakeholders A passion for programming and solving problems with code A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience A love for technology, and an insatiable curiosity for new tools to tackle real problems We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process. We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners. We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy. We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality. 
ScrapedJobID1345:
You will extract and cleanse large datasets: Integrate data across a variety of data stores / platforms (eg. DB2, SQL server, SAS and Hive) in a way that helps building advanced analytical models Leverage distributed computing tools (e.g. Spark, Hadoop) for analysis, data mining and modeling Explore data sourced from other environments including (but not limited to) the data lake; apply newly available data to pricing problems (ie. flow of funds, transcribed calls, network analytics data etc.) Internal and external data source evaluation You will design and build predictive models that explain the customer behavior over the product life cycle: Origination models such as response, utilization and attrition Portfolio management models such as renewal models, re-pricing models, credit limit optimization, balance transfer and campaign acquisition models Portfolio segmentation/customer sensitivity modeling Performing revenue optimization for a chosen portfolio. You need to understand business objectives, translate them into mathematical optimization problems, create profit function and recommend optimal pricing for each product Create and apply model and algorithm testing strategies to conduct multi-variate testing and A/B testing to measure effectiveness of models and make ongoing changes Model validation You will advance the Pricing team competency: Collaborate with business lines and other stakeholders and identify opportunities to drive business value and influence future pricing strategy by leveraging Data Science Provide subject matter expertise on predictive modelling, data mining, statistical analysis and machine learning to Pricing team internal customers Effectively communicate results of highly technical projects to business audiences You have excellent problem solving and analytical skills (previous experience in an analyst function is required) You have good communication skills, and you can translate complex technical information to a non-technical audience You have good time management skills and are able to meet timelines You have an analytical background (Applied Math, Statistics, Physics, Engineering, Computer Science) It would be great if you also held a Masters or PHD in mathematics, statistics or a related discipline You have strong programming skills, ideally in Python or R You have some experience SQL skills for querying relational databases (SAS, SQL Server, DB2, MySQL) You have strong theoretical knowledge and practical understanding of statistical analysis and predictive modeling Have experience with common statistical and machine learning libraries in Python, R, Spark (Keras/Tensorflow, Sklean) Are familiar with Cloud computing (Microsoft Azure or Google cloud) We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success! We provide you with the tools and technology needed to succeed You'll get to work with and learn from diverse industry leaders We offer a competitive total rewards package that includes a base salary, a performance bonus, company matching programs (on pension & profit sharing), 4 weeks of vacation, personal & sick days, paternity/maternity leave top-ups and much more. 
ScrapedJobID1346:
As part of the development of the development and implementation the governance processes, understand stakeholder requests, define objectives, develop detailed project plans, develop strategies to mitigate and quantify risks. Support the development and implementation the governance processes to validate and syndicate changes to reference data across Oracle / SAS Modules that are approved by business. Understand business processes and systems as well as the various data flows, develop them if necessary, and establish new mapping tables, while ensuring their consistency and precision, in connection with conversion, integration, the mapping, transformation and analysis of financial data. Capture and track the measures and metrics related to the governance of data and report out any anomalies. Support the establishment of data quality management best practices, standards, guidelines & processes and ensure adherence across the organization through regular audits. Contribute to strong data analysis and solutioning in the data governance domain enabling stakeholders to manage, control and leverage quality information within and across business units and functional domains. This includes maintaining various dashboards, capability metrics and provision of reporting to identify trends, potential issues, support solutioning. Perform security and maintenance of EDMCS. Execute the loading of reference data into Oracle for new and existing dimensional data, execute create and change requests. Work with technical lead teams regarding customization and integration of finance applications. Interface and co-ordinate with the applicable functional business units to action changes to the master data files. With the team, act as an advisory role to the business team on future process models, product launches, support of acquisitions, changes in organizational structure. Execute requests for mass maintenance of reference data to ensure the appropriate standards and governance rules are maintained. Perform on-going 52-109 controls related to the data management and reporting (access, security, change management etc.). Act as support or back-up to the development and automation of reports defined as part of the current project. Bachelor's Degree in Accounting/Finance or equivalent experience. CPA Certified Public Accountant (asset). Experience and knowledge of integration / conversion and mapping of financial data. Experience in master data management strategies, data governance and/or data steward or equivalent experience (an asset). 3 to 4 years of relevant experience. Experience with 52-109/SOX controls Excellent oral/written communication skills. Strong analytical and problem-solving skills. Strong negotiation skills and ability to persuade, influence and motivate from a wide variety of functional background. Demonstrated ability to manage multiple priorities. An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID1347:

ScrapedJobID1348:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID1349:
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. 2+ years of non-internship professional software development experience Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design Bachelor’s degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline 1+ years of experience as a data/software developer/scientist or related technical job A passion for improving customer experience Excellent verbal and written communication skills and technical writing skills Graduate degree in a related technical field 2+ years of experience as a data/software developer/scientist or related technical job Experience with Agile Development Experience with statistical modeling or machine learning (Classification, Collaborative Filtering) Experience with AWS services A love of music! 
ScrapedJobID1350:
Experience leading a technical team, including managing tasks and processes Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline 3+ years of Software Development experience with modern programming languages (Python, C/C++, Julia) Experience with at least one deep learning framework (TensorFlow, PyTorch, MXNet …) Experience working in version control such as git Experience in big data architectures and pipelines to build and deploy models Experience in building machine learning models optimized for speed, accuracy, scalability, reliability and resiliency Ability to perform complex data analysis and present findings to stakeholders Master’s degree in Computer Science, Computer Engineering or related technical discipline Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations Experience with prototyping machine learning solutions (e.g. Kaggle, demos, hackathons) Experience working with cloud platforms (e.g. AWS, Azure …) Experience with web development for demonstrations Strong communication skills Competitive salary Health and lifestyle benefits Positive & creative work environment in a great location Leadership role on an expanding team with opportunities for career growth 
ScrapedJobID1351:

ScrapedJobID1352:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID1353:
Help create an outstanding research platform. You'll be a technical hands-on software engineering manager whose team will work with ML Scientists, Data Scientists, Data Engineers, and Biologists building a platform to train, evaluate, and move machine learning models into production. Mentor, coach, grow, and empower the people on your team. Work with your team to set the direction for ML tooling at Recursion. Accelerate drug discovery by helping us find new disease / compound interactions through the models your team will run and support Partner with product and internal customers to prioritize and develop the most important capabilities. Participate in deep technical discussions within your team and across partner teams, with extra attention toward clarifying unknowns. Establish and achieve quarterly goals, setting and adjusting expectations based on regular, iterative feedback from prototypes and delivering software into production. Recruit and grow an inclusive team, including sourcing candidates, interviewing candidates, and onboarding new employees. Experience developing machine learning models for production environments A passion for scaling Machine Learning products and helping Machine Learning Scientists design and train new models that push the boundaries of AI Experience leading technical teams focusing on managing both people and technologies. Demonstrate past record of learning from and teaching peers in areas of performance, scalability, and system architecture. Our current tech stack uses Python, PyTorch common pydata libraries, along with Kafka, PostgreSQL, Docker, and Kubernetes, our cloud services are provided by Google Cloud Platform. 100% Coverage of health, vision, and dental insurance premiums 401(k) with generous matching (immediate vesting) Stock option, restricted stock unit (RSUs) and employee stock purchase plan (ESPP) programs Two one-week paid company closures (summer and winter) Flexible vacation/sick leave Generous paid parental leave (including adoptive) Onsite daycare facility** (Salt Lake City) Commuter benefit and vehicle parking to ease your commute** Complimentary chef-prepared lunches and well-stocked snack bars** (Salt Lake City) Monthly fitness/wellness stipend One-of-a-kind 100,000 square foot headquarters complete with a 70-foot climbing wall, showers, lockers, and bike parking** (Salt Lake City) 
ScrapedJobID1354:
Bachelor’s degree in Data Science or Business Administration, MA or MBA preferred. Professional-level, current, subject matter expertise in various topics in Excel, Power Query and Power BI. Experience with adult instruction and/or training, with proven track record of online communication. Proficiency with MS suite, ability to connect to online hubs with reliable devices and internet access. Experience with online learning platforms such as D2L, Blackboard, and Moodle. 3-5 years teaching experience required. Documented experience working as an Instructor in a post-secondary or industry setting within a team environment is an asset. Ability to excel under pressure and ‘think on your feet’. Professional competence preparing, developing, delivering and administering post-secondary courses. Excellent English-language communication (written and verbal), and interpersonal and people-management skills. Demonstrated ability to deliver in class and within an online learning platform. Ability to motivate adult learners to achieve academic success. An established network of relevant professional contacts. Please note: These are the minimum required qualifications. Being a part of BC’s Top 100 Employers, and a member of the CCDI. A generous Total Compensation package which includes extended health and dental benefits and a superb pension plan. Access to Professional Development Funds and opportunities for career development. Increase your knowledge with Tuition waivers for BCIT courses. Enjoy discounted access to our fitness facilities (including classes like Yoga and Zumba). Additional Wellness and Employee Assistance programs. 
ScrapedJobID1355:
3+ years experience in a Data Engineering or Analytics role managing data pipelines Strong skills in Python, SQL, Airflow, Data Modeling and ETL pipelines Familiarity with: Snowflake, AWS Redshift, or BigQuery Experience working with Data Science and Machine Learning teams as stakeholders A passion for programming and solving problems with code A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience A love for technology, and an insatiable curiosity for new tools to tackle real problems We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process. We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners. We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy. We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality. 
ScrapedJobID1356:
You will extract and cleanse large datasets: Integrate data across a variety of data stores / platforms (eg. DB2, SQL server, SAS and Hive) in a way that helps building advanced analytical models Leverage distributed computing tools (e.g. Spark, Hadoop) for analysis, data mining and modeling Explore data sourced from other environments including (but not limited to) the data lake; apply newly available data to pricing problems (ie. flow of funds, transcribed calls, network analytics data etc.) Internal and external data source evaluation You will design and build predictive models that explain the customer behavior over the product life cycle: Origination models such as response, utilization and attrition Portfolio management models such as renewal models, re-pricing models, credit limit optimization, balance transfer and campaign acquisition models Portfolio segmentation/customer sensitivity modeling Performing revenue optimization for a chosen portfolio. You need to understand business objectives, translate them into mathematical optimization problems, create profit function and recommend optimal pricing for each product Create and apply model and algorithm testing strategies to conduct multi-variate testing and A/B testing to measure effectiveness of models and make ongoing changes Model validation You will advance the Pricing team competency: Collaborate with business lines and other stakeholders and identify opportunities to drive business value and influence future pricing strategy by leveraging Data Science Provide subject matter expertise on predictive modelling, data mining, statistical analysis and machine learning to Pricing team internal customers Effectively communicate results of highly technical projects to business audiences You have excellent problem solving and analytical skills (previous experience in an analyst function is required) You have good communication skills, and you can translate complex technical information to a non-technical audience You have good time management skills and are able to meet timelines You have an analytical background (Applied Math, Statistics, Physics, Engineering, Computer Science) It would be great if you also held a Masters or PHD in mathematics, statistics or a related discipline You have strong programming skills, ideally in Python or R You have some experience SQL skills for querying relational databases (SAS, SQL Server, DB2, MySQL) You have strong theoretical knowledge and practical understanding of statistical analysis and predictive modeling Have experience with common statistical and machine learning libraries in Python, R, Spark (Keras/Tensorflow, Sklean) Are familiar with Cloud computing (Microsoft Azure or Google cloud) We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success! We provide you with the tools and technology needed to succeed You'll get to work with and learn from diverse industry leaders We offer a competitive total rewards package that includes a base salary, a performance bonus, company matching programs (on pension & profit sharing), 4 weeks of vacation, personal & sick days, paternity/maternity leave top-ups and much more. 
ScrapedJobID1357:
As part of the development of the development and implementation the governance processes, understand stakeholder requests, define objectives, develop detailed project plans, develop strategies to mitigate and quantify risks. Support the development and implementation the governance processes to validate and syndicate changes to reference data across Oracle / SAS Modules that are approved by business. Understand business processes and systems as well as the various data flows, develop them if necessary, and establish new mapping tables, while ensuring their consistency and precision, in connection with conversion, integration, the mapping, transformation and analysis of financial data. Capture and track the measures and metrics related to the governance of data and report out any anomalies. Support the establishment of data quality management best practices, standards, guidelines & processes and ensure adherence across the organization through regular audits. Contribute to strong data analysis and solutioning in the data governance domain enabling stakeholders to manage, control and leverage quality information within and across business units and functional domains. This includes maintaining various dashboards, capability metrics and provision of reporting to identify trends, potential issues, support solutioning. Perform security and maintenance of EDMCS. Execute the loading of reference data into Oracle for new and existing dimensional data, execute create and change requests. Work with technical lead teams regarding customization and integration of finance applications. Interface and co-ordinate with the applicable functional business units to action changes to the master data files. With the team, act as an advisory role to the business team on future process models, product launches, support of acquisitions, changes in organizational structure. Execute requests for mass maintenance of reference data to ensure the appropriate standards and governance rules are maintained. Perform on-going 52-109 controls related to the data management and reporting (access, security, change management etc.). Act as support or back-up to the development and automation of reports defined as part of the current project. Bachelor's Degree in Accounting/Finance or equivalent experience. CPA Certified Public Accountant (asset). Experience and knowledge of integration / conversion and mapping of financial data. Experience in master data management strategies, data governance and/or data steward or equivalent experience (an asset). 3 to 4 years of relevant experience. Experience with 52-109/SOX controls Excellent oral/written communication skills. Strong analytical and problem-solving skills. Strong negotiation skills and ability to persuade, influence and motivate from a wide variety of functional background. Demonstrated ability to manage multiple priorities. An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID1358:

ScrapedJobID1359:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID1360:
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. 2+ years of non-internship professional software development experience Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design Bachelor’s degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline 1+ years of experience as a data/software developer/scientist or related technical job A passion for improving customer experience Excellent verbal and written communication skills and technical writing skills Graduate degree in a related technical field 2+ years of experience as a data/software developer/scientist or related technical job Experience with Agile Development Experience with statistical modeling or machine learning (Classification, Collaborative Filtering) Experience with AWS services A love of music! 
ScrapedJobID1361:
Experience leading a technical team, including managing tasks and processes Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline 3+ years of Software Development experience with modern programming languages (Python, C/C++, Julia) Experience with at least one deep learning framework (TensorFlow, PyTorch, MXNet …) Experience working in version control such as git Experience in big data architectures and pipelines to build and deploy models Experience in building machine learning models optimized for speed, accuracy, scalability, reliability and resiliency Ability to perform complex data analysis and present findings to stakeholders Master’s degree in Computer Science, Computer Engineering or related technical discipline Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations Experience with prototyping machine learning solutions (e.g. Kaggle, demos, hackathons) Experience working with cloud platforms (e.g. AWS, Azure …) Experience with web development for demonstrations Strong communication skills Competitive salary Health and lifestyle benefits Positive & creative work environment in a great location Leadership role on an expanding team with opportunities for career growth 
ScrapedJobID1362:
Building and integrating end to end lifecycles of large-scale, distributed machine learning systems using the latest open source and cloud technologies Building automated tests and validations for machine learning models and underlying data Comparing different versions of machine learning models using methods like AB testing, champion/challenger etc. Identifying model and data drifts Developing scalable tools and services for handling machine learning workflows Implementing cloud distributed training approaches for deep learning models Collaborating with engineers across functions to solve complex data problems at scale Collaborating with data scientists to test and deploy ML models at scale Identifying and evaluating new patterns and technologies to improve performance, maintainability and elegance of our machine learning systems Leading technical projects to completion and communicate with peers to build requirements and track progress Experience in MLOps to deploy and maintain machine learning models Experience building systems with scalable data processing technologies using Spark, Python, SQL Experience in CI/CD and be able to follow good branching practices Exposure to Databricks and associated tools like ML Flow and Delta Lake Familiarity with data-oriented workflow orchestration frameworks (Databricks Jobs, Azure DevOps, Azure Data Factory, Airflow etc.) Experience developing with containers and Kubernetes in cloud computing environments (Azure, AWS, GCloud, etc.) Exposure to machine learning and drift detection methodology and best practices. Exposure to deep learning approaches and modeling frameworks (PyTorch, Tensorflow, etc.) Strong software engineering skills in complex multi-language systems Rigor in high code quality, automated testing, and other engineering best practices Experience working with cloud computing and database systems Fluency in Python (asset only) Collaborative Self-motivated Innovative Able to work independently while part of a team 
ScrapedJobID1363:
Ongoing practice and process development looking for ways to improve and streamline company processes to not only deliver a superior service to our clients, but also to improve our efficiency and profitability. Mentoring/managing Data Science team members Partner with your Group Director to educate clients on the value of adding Data Science products to their business, capturing & defining needs and solutions Synthesize business needs and create business/functional design documents which can be used to build analysis and data models around. Assess data for validity in terms of predictive capabilities, required feature engineering, opportunities for data widening, or alignment to business requirements Develops, implements, and supports methodologies, standards, and tools for analysis and data science work. Build cooperative, productive relationships with clients and vendors by utilizing excellent communication skills, while also interacting effectively internally and externally. Research, prototype, and explore future, non-standard analytics approaches that push the limits of current analysis output. This will include exploring novel machine learning techniques which enable our teams to tackle segmentation, clustering, and predictive models used in a wide variety of areas. Bachelor’s degree in Mathematics, Statistics, Business Analysis or related 5+ years’ experience as an Analyst / Data Scientist 2+ years’ of managerial and leadership experience Advanced knowledge of R, Python or SAS for model development Previous experience with web analytics tools such as Adobe Marketing Cloud, Google Analytics Extensive experience with statistical modelling techniques Experience connecting Tableau or other visualization systems and using for dashboarding or analysis Self-motivated and ability to work independently in meeting deadlines Exceptional written and verbal communication skills and is comfortable working with remote teams Previous experience with marketing analytics including database marketing techniques, campaign lift, attribution and media mix modelling Familiarity with analyzing data for digital marketing and ecommerce, as well as all other non-digital aspects of a business SQL skills A solid knowledge of ETL tools Understanding of how to deal with larger data sets and parallel computing problem 
ScrapedJobID1364:
Diriger et gérer une équipe de spécialistes des sciences de la parole et des données : Planifier, coordonner et gérer l'équipe, y compris la dotation en personnel et la productivité des projets, la gestion des performances et le développement de carrière. S'assurer que les rapports directs sont formés sur leurs rôles, utilisent les meilleures pratiques alignées sur les disciplines mondiales de Nuance Professional Services, et réalisent des performances conformes aux normes de qualité de Nuance et aux attentes de nos clients. Vous comprenez parfaitement les compétences et les lacunes de l'équipe, et vous formez et encadrez les membres de l'équipe en conséquence. Agir en tant que contact d'escalade pour les rapports directs et s'associer avec d'autres membres du personnel de Nuance (tels que les gestionnaires de programmes, les responsables des ventes, etc.) et / ou le personnel du client pour résoudre les risques et les problèmes. Servir en tant que Professional Services Account Manager ou Project Manager et / ou Subject Matter Expert (SME) pour les clients assignés et / ou pour les clients assignés aux membres de l'équipe selon les besoins ou la demande. Soutenir les efforts de vente et fournir une planification stratégique et tactique de la rétention et de la croissance des comptes, selon les besoins ou les demandes. Identifier les besoins et les opportunités d'améliorer les meilleures pratiques existantes et aider à documenter les résultats, les approches et les stratégies éprouvées. Travailler avec d'autres chefs d'équipe pour favoriser les meilleures pratiques inter-équipes et l'adoption de celles-ci dans le cadre du programme de discipline globale de Nuance pour les disciplines Speech & Data Science et Analytics & Optimization. Déplacements limités sur les sites des clients pour présenter les résultats des comptes clés et des pratiques. Un diplôme universitaire de quatre ans est requis, de préférence un diplôme en ingénierie, en informatique, en linguistique ou dans un domaine connexe. 10 ans et plus Dix ans ou plus d'expérience avec : Les processus de science de la parole et des données, y compris le développement de grammaires NLU et de dialogue dirigé et les approches et outils de science des données. Les processus et les missions de conseil en technologie, de service à la clientèle, de commerce électronique et d'analyse et d'optimisation des applications. Trois ans ou plus d'expérience dans la gestion de personnes ou d'une équipe, y compris des compétences en matière de leadership et la capacité à encadrer les autres. Une vision globale et analytique, avec la capacité de comprendre et d'interpréter les buts et les objectifs des clients et de relier les solutions et/ou les recommandations à la façon dont elles amélioreront les résultats commerciaux et apporteront de la valeur (y compris l'encadrement des autres sur la façon de le faire). Capacité avérée à comprendre et à résoudre des systèmes et des problèmes techniques complexes, y compris ceux qui impliquent des interactions automatisées, des rapports et des analyses, ainsi que la capacité à traduire les résultats en impact commercial de manière claire et crédible afin d'orienter les parties prenantes du client vers le meilleur plan d'action. Connaissance des solutions vocales, de l'assistant virtuel, du chat en direct, des solutions sortantes, de la sécurité et de la biométrie, ainsi que de leurs cas d'utilisation et de leurs avantages dans le domaine de la vente et des soins aux entreprises. Vous avez démontré votre capacité à travailler avec des clients stratégiques complexes et omni-canaux. Capacité à définir les problèmes, à examiner les données, à établir les faits et à tirer des conclusions valables. Compréhension des indicateurs clés de performance (KPI) des applications de soins et de vente aux entreprises et des centres de contact. Connaissance des mathématiques, des statistiques et des principes de la finance afin d'interpréter les données (ou d'encadrer d'autres personnes) et connaissance avancée et application de techniques efficaces de reporting et de visualisation des données. Capacité à établir des priorités et à mener plusieurs tâches de front, avec des compétences organisationnelles clairement démontrées et une capacité avérée à accomplir des tâches avec un minimum de supervision et de direction. Excellentes compétences en matière de communication (écrite et orale), y compris en matière de présentation de groupe à tous les niveaux, y compris au niveau des cadres supérieurs, en interne et avec les clients finaux. Compétences avérées en matière de gestion de la clientèle, y compris au niveau des chefs de projet et des cadres supérieurs. Compréhension technique du cycle de vie du développement logiciel et des méthodologies (waterfall, agile, etc.). Connaissance de Microsoft Office, y compris la capacité à communiquer des données et des idées complexes à l'aide de PowerPoint, Excel, Visio, etc. Lead and manage a team of Speech & Data Scientists:
Plan, coordinate, and manage the team, including project staffing and productivity, performance management and career development.
Ensure direct reports are trained on their roles, utilize best practices aligned to Nuance Professional Services Global Disciplines, and perform to the quality standards of Nuance and the expectations of our clients.
Build a deep understanding of the skills and skill gaps within the team, and train and mentor team members accordingly.
Act as an escalation contact for direct reports and partner with other Nuance staff (such as Program Managers, Sales Executives, etc.) and / or customer staff to resolve risks and issues. Plan, coordinate, and manage the team, including project staffing and productivity, performance management and career development. Ensure direct reports are trained on their roles, utilize best practices aligned to Nuance Professional Services Global Disciplines, and perform to the quality standards of Nuance and the expectations of our clients. Build a deep understanding of the skills and skill gaps within the team, and train and mentor team members accordingly. Act as an escalation contact for direct reports and partner with other Nuance staff (such as Program Managers, Sales Executives, etc.) and / or customer staff to resolve risks and issues. Serve as a Professional Services Account Manager or Project Manager and / or Subject Matter Expert (SME) for assigned clients and / or for clients assigned to team members as needed or requested. Support sales efforts and provide strategic and tactical account retention / growth planning as needed or requested. Identify needs and opportunities to improve existing best practices and assist in documenting proven findings, approaches, and strategies. Work with other team leaders to drive cross-team best practices and adoption of those as part of Nuance’s Global Discipline program for the Speech & Data Science and Analytics & Optimization disciplines. Limited travel to client sites to present key account and practice findings. 10+. Ten or more years of experience with:
Speech & Data Science processes including NLU and Directed Dialogue grammar development and Data Science approaches and tools.
Technology consulting, customer care, eCommerce, and application analysis and optimization processes and engagements. Speech & Data Science processes including NLU and Directed Dialogue grammar development and Data Science approaches and tools. Technology consulting, customer care, eCommerce, and application analysis and optimization processes and engagements. Three or more years of experience managing people or a team including leadership skills and the ability to mentor others. Big picture, analytical thinker, with the ability to understand and interpret customer goals and objectives and tie solutions and / or recommendations back to how they will improve business results and deliver value (including coaching others on how to do this). Demonstrated ability to understand and troubleshoot complex technical systems and issues including those that involve automated interactions and reporting and analytics coupled with the ability to translate findings into business impact in a clear and credible manner to guide customer stakeholders toward the best course of action. Knowledge of Voice, Virtual Assistant, Live Chat, Outbound and Security and Biometrics solutions and their use cases and benefit drivers within the Enterprise care / sales space. Demonstrated success in working with complex, omni-channel strategic clients. Ability to define problems, review data, establish facts, and draw valid conclusions. Understanding of Enterprise care and sales application and contact center Key Performance Indicators (KPIs). Knowledge of mathematics, statistics, and principles of finance to interpret data (or coach others) and advanced knowledge and application of effective reporting and data visualization techniques. Ability to prioritize and multi-task with clearly demonstrated organizational skills and proven capability to perform duties with minimal supervision and direction. Excellent Communication skills (written and oral) including group presentation skills across all levels, including Sr. Executive levels both internally and with end customers. Demonstrated customer facing / customer management skills including those at the Project Manager and Executive levels. Technical understanding of the software development lifecycle and methodologies (waterfall, agile, etc.). Knowledge of Microsoft Office, including the ability to communicate complex data and ideas using PowerPoint, Excel, Visio etc. 4-year university degree is required, preferably a degree in engineering, computer science, linguistics, or a related field. Location is in the heart of downtown Montreal Flexible hours Transit reimbursement and parking Working with international teams to push the boundaries of technology Competitive benefit package 4 weeks’ vacation 10 paid sick days Bonus Plan, Group RRSP, Deferred Profit Sharing Plan, Employee Stock Purchase Plan Canada's Top 100 Employers – 7 consecutive years Montreal’s Top Employers – 6 consecutive years Canada's Top Employers for Young People - 3 consecutive years 
ScrapedJobID1365:
Incorporate data from multiple sources to provide comprehensive analysis and strategic insights. Employ, demonstrate, and advocate analytics best practices in the areas of data modeling, data wrangling, data visualization and data storytelling. Understand and prioritize business requirements while managing the expectations of stakeholders. Execute a portfolio of analytics projects that enable growth of the Martin Brower business, including enabling technologies such as self-service discovery and analytics that make it easier for Martin Brower personnel to use data to drive decisions, reduce costs, and optimize Martin Brower supply chain processes. Ensure current activities and program designs allow for future expansions into Machine Learning and Artificial Intelligence. Be a Power User of our data infrastructure – data flows from lake to visualization. Increase the Data Literacy of the Data and Analytics team by acting as a mentor to other analysts regarding core capabilities and cross functional work efforts and projects Anticipate and identify future demand from users/customers, provide input to requirements and align priorities to achieve goals. Monitor and control all project activities, issues, change requests and risks. Communicate with project sponsors, senior management, and functional area managers and/or consultants regarding the status of specific projects through formal and informal verbal and written communication methods. Building and assuring the proper data quality and governance processes Work with the Global Data Office to build and enhance Data Quality tests. This role will need to establish the escalation process of the Data Quality exception-based flags and work with internal divisions to fix issues related to data. Drive automation and efficiency by developing and implementing databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality Develop effective communication with all different parties in case of data issues. Restructure our data governance function by monitoring tasks and updating documentation. Analyze the data impact on the business and collaborate with the risk function to sign off on processes. Foster successful relationships and act as a trusted advisor for team members and stakeholders across the enterprise. Ensure the operations follow all Safe Food for Canadians Regulations (SFCR), Global Food Safety Initiative (GFSI) and Good Warehouse Practices (GWP)/Good Drivers Practices (GDP) for transport rules and regulations. Other projects or duties as assigned. 6+ years of experience as a data analyst or business analyst. 2+ years managing data analyst or business analyst. BA/BS in technical field (Computer Science, Math, Statistics, Physics, Engineering, etc.). Excellent programming skills, including expert level familiarity with DAX, SQL, Python, or similar. Demonstrated knowledge of Power BI functions such as analytics, data modeling & mining, reporting, data cleansing, Power Query. Knowledge of big data infrastructure. Strong analytical and problem-solving skills including a thorough understanding of how to interpret customer business needs and translate them into the application and operational requirements. Exceptional interpersonal skills in areas such as teamwork, facilitation, and negotiation. Skilled at precision questioning, ability to define and refine business questions to get to the root concern that can be specifically and concisely addressed. This position must pass a post-offer background and drug test. Post graduate degree Technical Certification Experience working both in a business and IT role. Experience as a liaison between IT and business. Experience within the distribution or Food Service industry. Familiarity with data science concepts like statistical modeling, machine learning and forecasting models with an ability to explain them to non-technical audiences. 
ScrapedJobID1366:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID1367:
Help create an outstanding research platform. You'll be a technical hands-on software engineering manager whose team will work with ML Scientists, Data Scientists, Data Engineers, and Biologists building a platform to train, evaluate, and move machine learning models into production. Mentor, coach, grow, and empower the people on your team. Work with your team to set the direction for ML tooling at Recursion. Accelerate drug discovery by helping us find new disease / compound interactions through the models your team will run and support Partner with product and internal customers to prioritize and develop the most important capabilities. Participate in deep technical discussions within your team and across partner teams, with extra attention toward clarifying unknowns. Establish and achieve quarterly goals, setting and adjusting expectations based on regular, iterative feedback from prototypes and delivering software into production. Recruit and grow an inclusive team, including sourcing candidates, interviewing candidates, and onboarding new employees. Experience developing machine learning models for production environments A passion for scaling Machine Learning products and helping Machine Learning Scientists design and train new models that push the boundaries of AI Experience leading technical teams focusing on managing both people and technologies. Demonstrate past record of learning from and teaching peers in areas of performance, scalability, and system architecture. Our current tech stack uses Python, PyTorch common pydata libraries, along with Kafka, PostgreSQL, Docker, and Kubernetes, our cloud services are provided by Google Cloud Platform. 100% Coverage of health, vision, and dental insurance premiums 401(k) with generous matching (immediate vesting) Stock option, restricted stock unit (RSUs) and employee stock purchase plan (ESPP) programs Two one-week paid company closures (summer and winter) Flexible vacation/sick leave Generous paid parental leave (including adoptive) Onsite daycare facility** (Salt Lake City) Commuter benefit and vehicle parking to ease your commute** Complimentary chef-prepared lunches and well-stocked snack bars** (Salt Lake City) Monthly fitness/wellness stipend One-of-a-kind 100,000 square foot headquarters complete with a 70-foot climbing wall, showers, lockers, and bike parking** (Salt Lake City) 
ScrapedJobID1368:
Bachelor’s degree in Data Science or Business Administration, MA or MBA preferred. Professional-level, current, subject matter expertise in various topics in Excel, Power Query and Power BI. Experience with adult instruction and/or training, with proven track record of online communication. Proficiency with MS suite, ability to connect to online hubs with reliable devices and internet access. Experience with online learning platforms such as D2L, Blackboard, and Moodle. 3-5 years teaching experience required. Documented experience working as an Instructor in a post-secondary or industry setting within a team environment is an asset. Ability to excel under pressure and ‘think on your feet’. Professional competence preparing, developing, delivering and administering post-secondary courses. Excellent English-language communication (written and verbal), and interpersonal and people-management skills. Demonstrated ability to deliver in class and within an online learning platform. Ability to motivate adult learners to achieve academic success. An established network of relevant professional contacts. Please note: These are the minimum required qualifications. Being a part of BC’s Top 100 Employers, and a member of the CCDI. A generous Total Compensation package which includes extended health and dental benefits and a superb pension plan. Access to Professional Development Funds and opportunities for career development. Increase your knowledge with Tuition waivers for BCIT courses. Enjoy discounted access to our fitness facilities (including classes like Yoga and Zumba). Additional Wellness and Employee Assistance programs. 
ScrapedJobID1369:
3+ years experience in a Data Engineering or Analytics role managing data pipelines Strong skills in Python, SQL, Airflow, Data Modeling and ETL pipelines Familiarity with: Snowflake, AWS Redshift, or BigQuery Experience working with Data Science and Machine Learning teams as stakeholders A passion for programming and solving problems with code A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience A love for technology, and an insatiable curiosity for new tools to tackle real problems We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process. We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners. We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy. We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality. 
ScrapedJobID1370:
You will extract and cleanse large datasets: Integrate data across a variety of data stores / platforms (eg. DB2, SQL server, SAS and Hive) in a way that helps building advanced analytical models Leverage distributed computing tools (e.g. Spark, Hadoop) for analysis, data mining and modeling Explore data sourced from other environments including (but not limited to) the data lake; apply newly available data to pricing problems (ie. flow of funds, transcribed calls, network analytics data etc.) Internal and external data source evaluation You will design and build predictive models that explain the customer behavior over the product life cycle: Origination models such as response, utilization and attrition Portfolio management models such as renewal models, re-pricing models, credit limit optimization, balance transfer and campaign acquisition models Portfolio segmentation/customer sensitivity modeling Performing revenue optimization for a chosen portfolio. You need to understand business objectives, translate them into mathematical optimization problems, create profit function and recommend optimal pricing for each product Create and apply model and algorithm testing strategies to conduct multi-variate testing and A/B testing to measure effectiveness of models and make ongoing changes Model validation You will advance the Pricing team competency: Collaborate with business lines and other stakeholders and identify opportunities to drive business value and influence future pricing strategy by leveraging Data Science Provide subject matter expertise on predictive modelling, data mining, statistical analysis and machine learning to Pricing team internal customers Effectively communicate results of highly technical projects to business audiences You have excellent problem solving and analytical skills (previous experience in an analyst function is required) You have good communication skills, and you can translate complex technical information to a non-technical audience You have good time management skills and are able to meet timelines You have an analytical background (Applied Math, Statistics, Physics, Engineering, Computer Science) It would be great if you also held a Masters or PHD in mathematics, statistics or a related discipline You have strong programming skills, ideally in Python or R You have some experience SQL skills for querying relational databases (SAS, SQL Server, DB2, MySQL) You have strong theoretical knowledge and practical understanding of statistical analysis and predictive modeling Have experience with common statistical and machine learning libraries in Python, R, Spark (Keras/Tensorflow, Sklean) Are familiar with Cloud computing (Microsoft Azure or Google cloud) We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success! We provide you with the tools and technology needed to succeed You'll get to work with and learn from diverse industry leaders We offer a competitive total rewards package that includes a base salary, a performance bonus, company matching programs (on pension & profit sharing), 4 weeks of vacation, personal & sick days, paternity/maternity leave top-ups and much more. 
ScrapedJobID1371:
As part of the development of the development and implementation the governance processes, understand stakeholder requests, define objectives, develop detailed project plans, develop strategies to mitigate and quantify risks. Support the development and implementation the governance processes to validate and syndicate changes to reference data across Oracle / SAS Modules that are approved by business. Understand business processes and systems as well as the various data flows, develop them if necessary, and establish new mapping tables, while ensuring their consistency and precision, in connection with conversion, integration, the mapping, transformation and analysis of financial data. Capture and track the measures and metrics related to the governance of data and report out any anomalies. Support the establishment of data quality management best practices, standards, guidelines & processes and ensure adherence across the organization through regular audits. Contribute to strong data analysis and solutioning in the data governance domain enabling stakeholders to manage, control and leverage quality information within and across business units and functional domains. This includes maintaining various dashboards, capability metrics and provision of reporting to identify trends, potential issues, support solutioning. Perform security and maintenance of EDMCS. Execute the loading of reference data into Oracle for new and existing dimensional data, execute create and change requests. Work with technical lead teams regarding customization and integration of finance applications. Interface and co-ordinate with the applicable functional business units to action changes to the master data files. With the team, act as an advisory role to the business team on future process models, product launches, support of acquisitions, changes in organizational structure. Execute requests for mass maintenance of reference data to ensure the appropriate standards and governance rules are maintained. Perform on-going 52-109 controls related to the data management and reporting (access, security, change management etc.). Act as support or back-up to the development and automation of reports defined as part of the current project. Bachelor's Degree in Accounting/Finance or equivalent experience. CPA Certified Public Accountant (asset). Experience and knowledge of integration / conversion and mapping of financial data. Experience in master data management strategies, data governance and/or data steward or equivalent experience (an asset). 3 to 4 years of relevant experience. Experience with 52-109/SOX controls Excellent oral/written communication skills. Strong analytical and problem-solving skills. Strong negotiation skills and ability to persuade, influence and motivate from a wide variety of functional background. Demonstrated ability to manage multiple priorities. An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID1372:

ScrapedJobID1373:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID1374:
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. 2+ years of non-internship professional software development experience Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design Bachelor’s degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline 1+ years of experience as a data/software developer/scientist or related technical job A passion for improving customer experience Excellent verbal and written communication skills and technical writing skills Graduate degree in a related technical field 2+ years of experience as a data/software developer/scientist or related technical job Experience with Agile Development Experience with statistical modeling or machine learning (Classification, Collaborative Filtering) Experience with AWS services A love of music! 
ScrapedJobID1375:
Experience leading a technical team, including managing tasks and processes Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline 3+ years of Software Development experience with modern programming languages (Python, C/C++, Julia) Experience with at least one deep learning framework (TensorFlow, PyTorch, MXNet …) Experience working in version control such as git Experience in big data architectures and pipelines to build and deploy models Experience in building machine learning models optimized for speed, accuracy, scalability, reliability and resiliency Ability to perform complex data analysis and present findings to stakeholders Master’s degree in Computer Science, Computer Engineering or related technical discipline Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations Experience with prototyping machine learning solutions (e.g. Kaggle, demos, hackathons) Experience working with cloud platforms (e.g. AWS, Azure …) Experience with web development for demonstrations Strong communication skills Competitive salary Health and lifestyle benefits Positive & creative work environment in a great location Leadership role on an expanding team with opportunities for career growth 
ScrapedJobID1376:

ScrapedJobID1377:
Building and integrating end to end lifecycles of large-scale, distributed machine learning systems using the latest open source and cloud technologies Building automated tests and validations for machine learning models and underlying data Comparing different versions of machine learning models using methods like AB testing, champion/challenger etc. Identifying model and data drifts Developing scalable tools and services for handling machine learning workflows Implementing cloud distributed training approaches for deep learning models Collaborating with engineers across functions to solve complex data problems at scale Collaborating with data scientists to test and deploy ML models at scale Identifying and evaluating new patterns and technologies to improve performance, maintainability and elegance of our machine learning systems Leading technical projects to completion and communicate with peers to build requirements and track progress Experience in MLOps to deploy and maintain machine learning models Experience building systems with scalable data processing technologies using Spark, Python, SQL Experience in CI/CD and be able to follow good branching practices Exposure to Databricks and associated tools like ML Flow and Delta Lake Familiarity with data-oriented workflow orchestration frameworks (Databricks Jobs, Azure DevOps, Azure Data Factory, Airflow etc.) Experience developing with containers and Kubernetes in cloud computing environments (Azure, AWS, GCloud, etc.) Exposure to machine learning and drift detection methodology and best practices. Exposure to deep learning approaches and modeling frameworks (PyTorch, Tensorflow, etc.) Strong software engineering skills in complex multi-language systems Rigor in high code quality, automated testing, and other engineering best practices Experience working with cloud computing and database systems Fluency in Python (asset only) Collaborative Self-motivated Innovative Able to work independently while part of a team 
ScrapedJobID1378:
Bachelor’s degree in computer science or relevant field. 5+ years of work experience as a software developer or engineer within a product development environment (Software and/or SaaS). 2+ years of industry experience in applied machine learning or deep learning. Proficiency in C# (or Java), SQL, Python, AWS and experience with ML frameworks. Strong knowledge of machine learning techniques. Experience with integrating applications and platforms with cloud technologies (AWS). Experience designing, building, and deploying statistical and machine learning models using frameworks. MS, or PhD degree in Computer Science or related field, or equivalent practical experience. Experience leading machine learning engineering teams of 1 – 5 people. Research and select the right ML tools and technology set required to solve various business problems. Identify relevant business problems and build prototype/proof-of-concept solutions employing state-of-art methods in a variety of areas including natural language processing, clustering, and recommendation systems. Develop a long-term sustainable technical architecture to complement our product development technology (C#, SQL Server, Python, AWS). Serve the team by participating in, and guiding the design, development and implementation of operational standards that result in highly available, scalable, and reliable customer experiences. Engage varying degrees of stakeholders, including other development teams, compliance groups, product management, and external audiences. Keep team members motivated and engaged while maintaining a positive atmosphere. Work with Product Management to guide the overall direction of our ML powered features and integrate them into the Product suite. Identify and propose innovative opportunities for deploying ML capabilities in the product. Facilitate and coordinate an understanding at the portfolio level of cross-project dependencies to ensure smooth integration at completion. Actively contribute to, execute, and monitor the teams process improvement efforts. Ad hoc duties as required. Software
Experience In at least 5 years of experience with/in Software Development
Experience In at least 3 years of experience with/in Machine Learning Experience In at least 5 years of experience with/in Software Development Experience In at least 3 years of experience with/in Machine Learning 
ScrapedJobID1379:
Ongoing practice and process development looking for ways to improve and streamline company processes to not only deliver a superior service to our clients, but also to improve our efficiency and profitability. Mentoring/managing Data Science team members Partner with your Group Director to educate clients on the value of adding Data Science products to their business, capturing & defining needs and solutions Synthesize business needs and create business/functional design documents which can be used to build analysis and data models around. Assess data for validity in terms of predictive capabilities, required feature engineering, opportunities for data widening, or alignment to business requirements Develops, implements, and supports methodologies, standards, and tools for analysis and data science work. Build cooperative, productive relationships with clients and vendors by utilizing excellent communication skills, while also interacting effectively internally and externally. Research, prototype, and explore future, non-standard analytics approaches that push the limits of current analysis output. This will include exploring novel machine learning techniques which enable our teams to tackle segmentation, clustering, and predictive models used in a wide variety of areas. Bachelor’s degree in Mathematics, Statistics, Business Analysis or related 5+ years’ experience as an Analyst / Data Scientist 2+ years’ of managerial and leadership experience Advanced knowledge of R, Python or SAS for model development Previous experience with web analytics tools such as Adobe Marketing Cloud, Google Analytics Extensive experience with statistical modelling techniques Experience connecting Tableau or other visualization systems and using for dashboarding or analysis Self-motivated and ability to work independently in meeting deadlines Exceptional written and verbal communication skills and is comfortable working with remote teams Previous experience with marketing analytics including database marketing techniques, campaign lift, attribution and media mix modelling Familiarity with analyzing data for digital marketing and ecommerce, as well as all other non-digital aspects of a business SQL skills A solid knowledge of ETL tools Understanding of how to deal with larger data sets and parallel computing problem 
ScrapedJobID1380:
Lead the translation of marketing requests and questions into analytical problems. Requests can be strategic or tactical in nature, including but not limited to targeting, segmentation, list generation and automation, development of dashboards, reports, and measurement. Responsible for the extraction, review, and preparation of complex operational and customer behavior information from a variety of databases (SQL, GCP, etc). Use Cloud based Python/Scala environment to process big data, conduct analysis, and visualizing the results. Generate meaningful insights to solve business problems, identify new opportunities and drive strategy. Build presentations to clearly articulate insights, while simplifying complex data and processes for various levels of audiences including senior management Support the execution of loyalty campaigns at Loblaws Work collaboratively with business partners in marketing, digital and tech teams. Synthesize large amounts of data from multiple sources, including customer transaction data, consumer & syndicated research, market share, and campaign results. Extrapolate and interpret appropriate information to deliver value-added recommendations University Degree in Data Science, Computer Science, Statistics, Mathematics, Economics, Engineering, Business or other relevant field 3-5 years related work experience in an analytical role. Experience ideally in Retail, Loyalty, CPG industry, Consumer Finance, Telecommunications, or Consulting Programming skills in various languages (Python, Spark, PySpark, SQL, R, Hive). Advanced SQL is mandatory. Advanced Python is preferred. Experience with cloud platforms (i.e. GCP and Azure) is preferred. Experience with building models on big data is preferred. Ability to synthesize large amounts of data into insights Strong ability to build presentations and present complex ideas in a clear, articulate way Strong interpersonal skills and comfortable leading discussions and collaborating with cross functional teams Demonstrate strong business acumen Strong skills in Microsoft Office suite (Excel, Powerpoint) Strong attention to detail Curiosity and willingness to ask questions 
ScrapedJobID1381:
Help set the product vision and strategy for Achievers data, analytics and insights products Execute on new Insight Products and features in collaboration with Data Engineering, Data Science, and other Product Managers Work together with the Engineering team to ensure the Data Infrastructure supports Analytics and insights roadmap and requirements. Work with multiple stakeholders to understand business and user needs to prioritize work Develop and measure products metrics to drive product growth Articulate detailed user stories, participate in daily scrum rituals, and answer questions as the customer representative. Assist with product release communications, internal & external Drive launches with product marketing, including beta programs Gather ongoing feedback on both existing and upcoming product capabilities Act as an analytics and insights product expert and champion Work closely with other product managers to understand their product vision and trajectory so that you can help amplify it with the right data strategy. 5+ years of Product Management Experience You are a data story teller…you know that data is most valuable and powerful when it is unlocked as insights and intuitive visualizations and are an expert at such. Data minded with the ability to define, capture, and decompose relevant metrics Experience in building high quality products powered by machine learning Experience with relational databases, data warehouses and data visualization Experience acting as a product manager in an agile development and rapid prototyping environment An understanding of building for desktop and mobile applications Experience articulating detailed user stories, participating in daily scrum rituals, and answering questions as the customer representative. Experience using or building commercial business applications targeted at enterprise users with consumer-like interfaces Experience working with product marketing to launch products internally and externally An understanding of basic project management principles and the ability to prioritize work based on greatest business impact. Conceptual understanding of web development and APIs Strong appreciation for user design and user behaviors Natural leadership, communication, and influence skills The ability to work with product metric tools (bonus if you know Pendo) to make data informed decisions 
ScrapedJobID1382:

ScrapedJobID1383:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID1384:
Help create an outstanding research platform. You'll be a technical hands-on software engineering manager whose team will work with ML Scientists, Data Scientists, Data Engineers, and Biologists building a platform to train, evaluate, and move machine learning models into production. Mentor, coach, grow, and empower the people on your team. Work with your team to set the direction for ML tooling at Recursion. Accelerate drug discovery by helping us find new disease / compound interactions through the models your team will run and support Partner with product and internal customers to prioritize and develop the most important capabilities. Participate in deep technical discussions within your team and across partner teams, with extra attention toward clarifying unknowns. Establish and achieve quarterly goals, setting and adjusting expectations based on regular, iterative feedback from prototypes and delivering software into production. Recruit and grow an inclusive team, including sourcing candidates, interviewing candidates, and onboarding new employees. Experience developing machine learning models for production environments A passion for scaling Machine Learning products and helping Machine Learning Scientists design and train new models that push the boundaries of AI Experience leading technical teams focusing on managing both people and technologies. Demonstrate past record of learning from and teaching peers in areas of performance, scalability, and system architecture. Our current tech stack uses Python, PyTorch common pydata libraries, along with Kafka, PostgreSQL, Docker, and Kubernetes, our cloud services are provided by Google Cloud Platform. 100% Coverage of health, vision, and dental insurance premiums 401(k) with generous matching (immediate vesting) Stock option, restricted stock unit (RSUs) and employee stock purchase plan (ESPP) programs Two one-week paid company closures (summer and winter) Flexible vacation/sick leave Generous paid parental leave (including adoptive) Onsite daycare facility** (Salt Lake City) Commuter benefit and vehicle parking to ease your commute** Complimentary chef-prepared lunches and well-stocked snack bars** (Salt Lake City) Monthly fitness/wellness stipend One-of-a-kind 100,000 square foot headquarters complete with a 70-foot climbing wall, showers, lockers, and bike parking** (Salt Lake City) 
ScrapedJobID1385:
Bachelor’s degree in Data Science or Business Administration, MA or MBA preferred. Professional-level, current, subject matter expertise in various topics in Excel, Power Query and Power BI. Experience with adult instruction and/or training, with proven track record of online communication. Proficiency with MS suite, ability to connect to online hubs with reliable devices and internet access. Experience with online learning platforms such as D2L, Blackboard, and Moodle. 3-5 years teaching experience required. Documented experience working as an Instructor in a post-secondary or industry setting within a team environment is an asset. Ability to excel under pressure and ‘think on your feet’. Professional competence preparing, developing, delivering and administering post-secondary courses. Excellent English-language communication (written and verbal), and interpersonal and people-management skills. Demonstrated ability to deliver in class and within an online learning platform. Ability to motivate adult learners to achieve academic success. An established network of relevant professional contacts. Please note: These are the minimum required qualifications. Being a part of BC’s Top 100 Employers, and a member of the CCDI. A generous Total Compensation package which includes extended health and dental benefits and a superb pension plan. Access to Professional Development Funds and opportunities for career development. Increase your knowledge with Tuition waivers for BCIT courses. Enjoy discounted access to our fitness facilities (including classes like Yoga and Zumba). Additional Wellness and Employee Assistance programs. 
ScrapedJobID1386:
3+ years experience in a Data Engineering or Analytics role managing data pipelines Strong skills in Python, SQL, Airflow, Data Modeling and ETL pipelines Familiarity with: Snowflake, AWS Redshift, or BigQuery Experience working with Data Science and Machine Learning teams as stakeholders A passion for programming and solving problems with code A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience A love for technology, and an insatiable curiosity for new tools to tackle real problems We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process. We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners. We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy. We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality. 
ScrapedJobID1387:
You will extract and cleanse large datasets: Integrate data across a variety of data stores / platforms (eg. DB2, SQL server, SAS and Hive) in a way that helps building advanced analytical models Leverage distributed computing tools (e.g. Spark, Hadoop) for analysis, data mining and modeling Explore data sourced from other environments including (but not limited to) the data lake; apply newly available data to pricing problems (ie. flow of funds, transcribed calls, network analytics data etc.) Internal and external data source evaluation You will design and build predictive models that explain the customer behavior over the product life cycle: Origination models such as response, utilization and attrition Portfolio management models such as renewal models, re-pricing models, credit limit optimization, balance transfer and campaign acquisition models Portfolio segmentation/customer sensitivity modeling Performing revenue optimization for a chosen portfolio. You need to understand business objectives, translate them into mathematical optimization problems, create profit function and recommend optimal pricing for each product Create and apply model and algorithm testing strategies to conduct multi-variate testing and A/B testing to measure effectiveness of models and make ongoing changes Model validation You will advance the Pricing team competency: Collaborate with business lines and other stakeholders and identify opportunities to drive business value and influence future pricing strategy by leveraging Data Science Provide subject matter expertise on predictive modelling, data mining, statistical analysis and machine learning to Pricing team internal customers Effectively communicate results of highly technical projects to business audiences You have excellent problem solving and analytical skills (previous experience in an analyst function is required) You have good communication skills, and you can translate complex technical information to a non-technical audience You have good time management skills and are able to meet timelines You have an analytical background (Applied Math, Statistics, Physics, Engineering, Computer Science) It would be great if you also held a Masters or PHD in mathematics, statistics or a related discipline You have strong programming skills, ideally in Python or R You have some experience SQL skills for querying relational databases (SAS, SQL Server, DB2, MySQL) You have strong theoretical knowledge and practical understanding of statistical analysis and predictive modeling Have experience with common statistical and machine learning libraries in Python, R, Spark (Keras/Tensorflow, Sklean) Are familiar with Cloud computing (Microsoft Azure or Google cloud) We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success! We provide you with the tools and technology needed to succeed You'll get to work with and learn from diverse industry leaders We offer a competitive total rewards package that includes a base salary, a performance bonus, company matching programs (on pension & profit sharing), 4 weeks of vacation, personal & sick days, paternity/maternity leave top-ups and much more. 
ScrapedJobID1388:
As part of the development of the development and implementation the governance processes, understand stakeholder requests, define objectives, develop detailed project plans, develop strategies to mitigate and quantify risks. Support the development and implementation the governance processes to validate and syndicate changes to reference data across Oracle / SAS Modules that are approved by business. Understand business processes and systems as well as the various data flows, develop them if necessary, and establish new mapping tables, while ensuring their consistency and precision, in connection with conversion, integration, the mapping, transformation and analysis of financial data. Capture and track the measures and metrics related to the governance of data and report out any anomalies. Support the establishment of data quality management best practices, standards, guidelines & processes and ensure adherence across the organization through regular audits. Contribute to strong data analysis and solutioning in the data governance domain enabling stakeholders to manage, control and leverage quality information within and across business units and functional domains. This includes maintaining various dashboards, capability metrics and provision of reporting to identify trends, potential issues, support solutioning. Perform security and maintenance of EDMCS. Execute the loading of reference data into Oracle for new and existing dimensional data, execute create and change requests. Work with technical lead teams regarding customization and integration of finance applications. Interface and co-ordinate with the applicable functional business units to action changes to the master data files. With the team, act as an advisory role to the business team on future process models, product launches, support of acquisitions, changes in organizational structure. Execute requests for mass maintenance of reference data to ensure the appropriate standards and governance rules are maintained. Perform on-going 52-109 controls related to the data management and reporting (access, security, change management etc.). Act as support or back-up to the development and automation of reports defined as part of the current project. Bachelor's Degree in Accounting/Finance or equivalent experience. CPA Certified Public Accountant (asset). Experience and knowledge of integration / conversion and mapping of financial data. Experience in master data management strategies, data governance and/or data steward or equivalent experience (an asset). 3 to 4 years of relevant experience. Experience with 52-109/SOX controls Excellent oral/written communication skills. Strong analytical and problem-solving skills. Strong negotiation skills and ability to persuade, influence and motivate from a wide variety of functional background. Demonstrated ability to manage multiple priorities. An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID1389:

ScrapedJobID1390:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID1391:
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. 2+ years of non-internship professional software development experience Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design Bachelor’s degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline 1+ years of experience as a data/software developer/scientist or related technical job A passion for improving customer experience Excellent verbal and written communication skills and technical writing skills Graduate degree in a related technical field 2+ years of experience as a data/software developer/scientist or related technical job Experience with Agile Development Experience with statistical modeling or machine learning (Classification, Collaborative Filtering) Experience with AWS services A love of music! 
ScrapedJobID1392:
Experience leading a technical team, including managing tasks and processes Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline 3+ years of Software Development experience with modern programming languages (Python, C/C++, Julia) Experience with at least one deep learning framework (TensorFlow, PyTorch, MXNet …) Experience working in version control such as git Experience in big data architectures and pipelines to build and deploy models Experience in building machine learning models optimized for speed, accuracy, scalability, reliability and resiliency Ability to perform complex data analysis and present findings to stakeholders Master’s degree in Computer Science, Computer Engineering or related technical discipline Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations Experience with prototyping machine learning solutions (e.g. Kaggle, demos, hackathons) Experience working with cloud platforms (e.g. AWS, Azure …) Experience with web development for demonstrations Strong communication skills Competitive salary Health and lifestyle benefits Positive & creative work environment in a great location Leadership role on an expanding team with opportunities for career growth 
ScrapedJobID1393:
Supports internal business partners globally by executing tasks outlined in the Global Data Operations Service Catalogue as well as the North America Portfolio Support Service Catalogue. Sets up, maintains, reviews, and validates security masters, brokers, and various reference data elements. Delivers production support tasks accurately and in a timely manner that meets established SLAs. Participates in the data reconciliation processes amongst various internal and external systems. Takes ownership, with some guidance (if needed), on complex escalated position, cash, coupon payment, and security master related reconciliation breaks requiring non-standard research and problem-solving abilities. Maintains an overall understanding of the assigned investment strategy (i.e. cash weights, financial instruments within the portfolio, cash management, etc.) Responsible for cash management support by calculating / verifying current day and net investable cash in multiple currencies for portfolio managers and resolve discrepancies within established deadlines. Participates in the analysis of the characteristics of new instruments to determine the associated data requirements and support procedures across all relevant systems. Participates in Product Shelf changes (e.g. new fund launch, new institutional mandates, portfolio manager change, fund name change, etc.) related activities within Support Services. Liaises with other functions to ensure the integrity of portfolio related data (position, cash, security master, pricing, corporate action, FX, derivatives, etc.) via reconciliation resolution oversight, coordination, and escalation globally. Acts as the escalation point for critical reconciliation breaks Contributes to the production of management reports and executive-level commentaries University degree in Accounting, Finance, Math or business area of concentration or equivalent experience MBA is an asset Certify Financial Analyst (CFA) or Professional accounting designation (CMA, CGA, CA, CPA) is an asset Minimum 3 years' financial services industry experience in a data analysis capacity Strong knowledge of investment products and global security markets is required Knowledge of market data services such as Bloomberg and Reuters is required Must have previous knowledge and work experience with data management applications (e.g. CADIS, Eagle PACE), order management systems (e.g. Charles River, Aladdin), portfolio administration applications (e.g. Eagle STAR, FMC), fund accounting applications (e.g. PAS, Eagle STAR), reconciliation tools (e.g. TLM), and data warehouse platforms (e.g. Eagle PACE) Must have a solid understanding of the end-to-end investment services processes, including but not limited to trade entry, trade process, settlement, security master set up/maintenance, valuation, corporate action processing, fund accounting and reconciliation resolution. Demonstrated ability to process and assimilate data and information into meaningful management and reporting information. Strong interpersonal, conflict resolution, written and verbal communication skills Customer focus and with a keen interest in providing superb services to clients. Strong organization skills and detail orientation, with an ability to understand the big picture and work under pressure with tight deadlines. Strong research, analytical as well as problem-solving skills. Aptitude for mathematical calculations and the ability to analyze detailed numerical data. Good Microsoft Office skills – in particular Excel, Access, Word, PowerPoint, Project, and Visio. Aptitude for learning new technology and adapting to rapid changes Rotating support coverage is required for international markets that are open during statutory holidays Participate in Business Recovery testing on an as-needed basis as defined by the manager Overtime, off-hours support, and travel may be required Staggering shift work is required on a rotational basis and as defined by the manager to provide global business coverage Current hours of business coverage for the North America Team (subject to change to fit global operations coverage needs): Mondays to Thursdays: Eastern Time 7:00a.m. – 8:00p.m, Fridays: Eastern Time 7:00a.m. – 6:00p.m, Sundays: Eastern Time 4:00p.m – 8:00p.m. Temporarily due to COVID-19 
ScrapedJobID1394:
Develop a deep understanding of the markets in each country and their data and analytical needs. Provide guidance to internal collaborators on advanced analytics Co-lead GAA's capability/product strategy, synthesizing business needs and advanced analytics expertise into capability/product roadmaps. Lead the development and deployment of strategic capabilities/products built around advanced analytics that create tangible business value. Coordinate across CoE roles and other business functions (sales, marketing, IT, external vendors, etc.) required to efficiently and effectively deliver new analytics capabilities/products Coordinate across markets the development of analytics capabilities to improve commonalities and efficiencies Collaborate with the Data & Insights Specialist on business adoption, and embedding analytics into business processes Find opportunities to evolve analytics capabilities/products and to use them across countries and brands Instil a culture of continuous improvement to refine and enhance existing capabilities. Monitor the external environment to stay up to date on leading advanced analytic capabilities, both within and outside of pharma, which can be applied within the organization. Oversee multiple capability related projects across different countries and markets. Extensive hands-on experience in application of advanced analytics and statistical methods on large and disparate datasets preferably in the context of Omnichannel marketing, specifically: Statistical Analysis and Modelling: (e.g. Design of Experiments, Time Series Analysis, Regression Analysis, Bayesian methods, etc), Machine Learning and Artificial Intelligence Extensive experience in deploying (and maintaining) production-grade advanced analytics capabilities. This includes not only the delivery of solutions but also the building of the business ecosystem (processes, organizational structure, change management, etc.) necessary. Strong organizational skills and time management; ability to manage diverse range of simultaneous projects. Strong leadership and interpersonal skills with demonstrated ability to work collaboratively with a significant number of business leaders and cross-functional business partners. Strong communication and influencing skills. Pharma commercial domain understanding. Experience with omnichannel analytics Experience with Agile methodology within an IT/business environment. Strategic and critical thinking with the ability to engage, build and maintain credibility with Commercial Leadership Team. Quantitative Master's or PhD degree from an accredited college or university is required in one of the following or related fields: Engineering, Operations Research, Management Science, Economics, Statistics, Math, Physics, Computer Science or Data Science. Cambridge, UK Gothenburg, Sweden Gaithersburg, US 
ScrapedJobID1395:
Provide quantitative analysis to key stakeholders to drive growth in the business Strong business acumen and enjoy telling stories with data Bring insights to optimize our business today and plan strategically for the future Generate tactical and strategic recommendations to improve marketing effectiveness Partner with senior leaders to evangelize data-driven business decisions and prioritize projects Develop statistical and machine learning algorithms to measure effectiveness of marketing Design experiments and casual inference methods to find actionable insights Build and maintain a data pipeline that can support complex data projects at scale Manage and prioritize ad hoc requests for analysis from GBUs and COEs. Develop core business metrics and create automated dashboards to track performance Perform analysis on market conditions and overall trends using third party data sources Drive forecasting model to be used in Integrated Marketing Reviews and Planning Conduct Marketing Mix Measurement, campaign analysis, program optimization, customer segmentation, ROI analysis, and predictive modeling Influence data science roadmap by performing exploratory analysis Provide technical guidance and mentorship to junior team members on solution design Create a set of heuristics backed by data that predicts product success Exceptional written and verbal communication skills, including ability to lead discussions with audiences of varying technical ability Self-starter attitude with sharp business judgement High attention to detail Working knowledge of marketing mathematical tools and methods, marketing test and learn plans, ROI development and data mining/multivariate analysis Thrive on finding creative solutions and adapting to constantly changing circumstances Knowledgeable about best practices around data manipulation, building data pipelines, feature engineering and creating dashboards Experience influencing strategy through data-centric presentations Capable of tackling very loosely defined problems with minimal guidance Experience working with real time and clickstream data 7+ years experience working with data and utilizing quantitative techniques Bachelor’s degree from a top school (preferably in a quantitative field) Expertise with at least two of the standard analysis tools: Excel, SQL, R, Python, Hadoop, Stata, SAS, etc. Working knowledge of Unix command-line/shell, git and review board Expertise running advanced analytics in a scripting language Experience leveraging government data or publicly available APIs 3+ years direct management experience of analysts and data scientists Proven track record of writing elegant code and coaching others to improve technical outputs We partner We invent We are open-minded We collaborate We get results We’ve got integrity We are entrepreneurs 
ScrapedJobID1396:
Data organization and analysis Partner with application experts in understanding the needs, be responsible in designing and developing predictive models. Test, improve and measure effectiveness of the developed approaches Contribute to writing scientific publications Must be a Ph. D. student in statistics / applied statistics A strong mathematical foundation, good computational and modeling (parametric, non-parametric, multi dimensional) skills Proven experience working in applied statistics Experience in handling large database Autonoumous, self motivated as well as a good team player Exceptional skills in programming and using open source libraries Ability to contribute to peer-reviewed publications Fluency in English and in French (written and spoken). 
ScrapedJobID1397:

ScrapedJobID1398:
Bachelor’s degree in Data Science or Business Administration, MA or MBA preferred. Professional-level, current, subject matter expertise in various topics in Excel, Power Query and Power BI. Experience with adult instruction and/or training, with proven track record of online communication. Proficiency with MS suite, ability to connect to online hubs with reliable devices and internet access. Experience with online learning platforms such as D2L, Blackboard, and Moodle. 3-5 years teaching experience required. Documented experience working as an Instructor in a post-secondary or industry setting within a team environment is an asset. Ability to excel under pressure and ‘think on your feet’. Professional competence preparing, developing, delivering and administering post-secondary courses. Excellent English-language communication (written and verbal), and interpersonal and people-management skills. Demonstrated ability to deliver in class and within an online learning platform. Ability to motivate adult learners to achieve academic success. An established network of relevant professional contacts. Please note: These are the minimum required qualifications. Being a part of BC’s Top 100 Employers, and a member of the CCDI. A generous Total Compensation package which includes extended health and dental benefits and a superb pension plan. Access to Professional Development Funds and opportunities for career development. Increase your knowledge with Tuition waivers for BCIT courses. Enjoy discounted access to our fitness facilities (including classes like Yoga and Zumba). Additional Wellness and Employee Assistance programs. 
ScrapedJobID1399:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1400:
Lead the architectural evolution of the SDV analytics platform in-vehicle and in the back-office edge/cloud Partner with other Architects to ensure consistent translation of enterprise architecture decisions to solution architects, conduct solution design reviews, and arbitrate solution design conflicts across domains Create and publish architecture strategies, designs, statements of direction, standards, and guidelines Ensure availability, scalability, extensibility, maintainability, and reusability for production-intended designs Promote design guidelines and coding practices to improve quality and reusability Advocate and drive for Dev/DataOps principles to ensure fast delivery, innovation, customer satisfaction, quality, reliability & teamwork Collaborate with development teams to decompose requirements and designs into technical stories, and ensure they are implemented as designed Deep dive time sensitive analytics challenges to develop quick solutions Research emerging technology and influence choices to advance the organization and ensure consistent tool usage Represent the team in requirements, architecture, systems integration, platform upgrades or operations discussions Write API / events specifications for different interfaces within the SDV Org Lead & conduct multiple technical forums for design discussions, Dev/DataOps processes, and Operational Challenges across teams Work with leadership to identify technical and process improvement opportunities for the organization Participate in developing the future state data architecture standards, guidelines, and principles Mentor & guide multiple teams on domain knowledge, design, and development practices. Bachelor's in Computer Science or Engineering, Software Engineering, Electrical Engineering, or related technical degree 10+ years developing enterprise or other large-scale systems 5+ years in a senior technical position as a lead or an architect Experience in Service Oriented and Event Driven Architectures, and Microservices principles Experience developing distributed systems using Java, J2EE, Python, and/or C++ Microservices Knowledge of big data technologies, data architecture, data analysis, data reports, and basic understanding of data science techniques in cloud environments such as:

Scripting languages (Python, PySpark and SQL)

Databases (Hadoop, Hive, Kafka, Cassandra, Elastic, and/or S3)

Data Visualizations (PowerBI and/or Kibana) Scripting languages (Python, PySpark and SQL) Databases (Hadoop, Hive, Kafka, Cassandra, Elastic, and/or S3) Data Visualizations (PowerBI and/or Kibana) Expert knowledge of software development standards, processes, and Dev/Data Ops principles Experience developing software design documentation and modeling diagrams Proficient with designing, implementing, and maintaining an analytics platform Experience with POSIX operating systems such as Android, and Linux Working knowledge of Software Telemetry data performance monitoring Experience with source code management tools such as GIT, Jira, Bitbucket, or Azure DevOps Experience with large data transfer mechanisms across embedded systems/cloud/Edge/backoffice such as WebSocket, webRTC, grpc, mqtt/DDS etc. Expertise in network security protocols Fundamental understanding of computer and network fundamentals Self-motivated, proactive, creative and team oriented Ability to work with ambiguity and able to communicate ideas to developers Exceptional interpersonal, written and verbal communication and presentation skills Outstanding interpersonal and relationship leadership skills to effectively collaborate with varying levels of the organization as needed Demonstrated ability to learn from and share knowledge with co-workers in a fast-paced environment Demonstrated ability to evaluate technology options and apply to complex business problems Proficient in Data Governance practices and experience Successful candidates will be required to attest to, and be prepared to provide proof of, their vaccination status and that any job offer will be conditional on the candidate being fully vaccinated. Advanced degree in a related technical field Scaled Agile Framework (SAFe) certification Experience with network engineering, telecommunications, network development and testing Experience with edge, cloud, IoT technologies, virtualization technologies, containerization/container development, Android App development Experience with Vehicle Telematics & Communications Experience with vehicle ECU/module integration Experience with Automotive SW platforms (E.g. Classic/Adaptive AutoSAR, Google Automotive Services, Automotive Linux) 
ScrapedJobID1401:
Overseeing the development of software to clean and investigate large, messy data sets of numerical and textual data Networking with various teams to explore internal and external data sources and APIs to help uncover new trends and improve analysis Designing and contributing to highly scalable data pipelines, tools, and products to enable the analyst community to fully leverage the power of AWS Working with your team to analyze large swaths of data in order to optimize various business programs Managing and developing talent to drive a highly performant and engaged team Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, you’re not afraid to blurt out your disruptive idea. You know how the latest tech works, yet you are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. Crafty: You know how to get things done. You can navigate a large organization, motivate people, and influence your peers. Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Inspiring: You have a passion for developing people and take great pride in your management system. You know how to deliver through others while paving the way for their growth. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook and all the monitors you want! You can travel to a relevant conference of your choice annually - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours, dress code and environment Bachelor’s Degree in a quantitative field At least 5 year of experience in open source programming languages for large scale data analysis (Python, Scala, or Java) At least 5 year of experience with version control system like Git and GitHub. At least 5 year of experience with relational databases and programming in SQL At least 2 years in lead positions (managing people/owning products/architecting and driving an agenda) Master’s Degree or PhD Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) Experience with CICD tools Experience with Machine Learning workflows 5+ years experience in Python 5+ years’ experience with SQL 3+ years in lead positions (managing people/owning products/architecting and driving an agenda) 
ScrapedJobID1402:
10+ years of experience in technical program/product/engineering management for large-scale business intelligence systems and/or complex software development initiatives. Bachelor’s degree (masters preferred) in business, engineering, computer science, or equivalent experience. SaaS experience / cloud native applications / backend data experience. AWS experience highly preferred; may consider other platform experience. Ability to influence at all levels and build strong partnerships across organizations to deliver the best outcome of complex programs. Excellent organizational and coordination skills along with multi-tasking capabilities to get things done in a fast-paced environment. Outstanding communication skills appropriate for executive-level audiences; ability to structure and communicate goals of program, relationship to business goals, and other relevant success criteria. Demonstrated ability to simultaneously understand and communicate the bigger picture while diving in to understand issues & risks to drive rapid resolution. Drive creation of data program roadmaps and data execution plans for complex, cross-organizational teams across all phases of planning, development, and production readiness and launch. Influence decisions by connecting strategy, priorities, and business/technical outcomes Lead execution in partnership across multiple functions including Data Engineering, Data Science, Data Analytics, as well as, with central data teams to align and deliver successful outcomes Ensure continued alignment of program scope, status, risks, and dependencies through effective communication across the organization and at all levels. Quickly and effectively identify critical issues and dependencies that need action and personally drive them through to closure. Balance business needs and technical constraints in resolving issues. Anticipate, recognize, and work through resistance or setbacks independently, work well with others when conflicts arise: see opportunities, ensure alignment with objectives, find common ground and promote understanding of alternative viewpoints before driving for closure and cooperation Effectively communicate program progress appropriately to varying levels of stakeholders. 
ScrapedJobID1403:
8+ years of experience in marketing data management, analysis, and insights, adtech, martech, and research techniques as well as an innovative vision on how to keep pace with the ever changing marketing environment. Experience leading an Analyst(s) and/or external resources in supporting multiple marketing lines of business to understand opportunities before and after campaign execution Solid experience enabling digital analytics tools, Adobe Analytics, Google Analytics, Power BI, and other marketing technologies: SMMS/ listening tools, conversion and/or media pixels, etc. Extensive knowledge of digital analytics implementation tools and techniques: tracking libraries and SDKs, cookies, Data Layer, Tag Management Systems, report suite configuration, listening keyword data collection etc. Demonstrated track record of developing and leverage media (paid, owned, and earned) performance analytics both in the context of forecasting expected results and supporting performance optimization / improvement. Strong internal client management experience both presenting and resolving issues You are naturally curious and can create a story from numbers: you have applied quantitative skills ,love identifying trends and have the ability to roll up your sleeves and dig into data when necessary You have experience with the end-to-end process of qualitative research, including planning, scoping, conducting, analyzing, and communicating results. You have the ability to problem solve and develop innovative approaches along with a drive to learn and master new technologies and techniques You understand high level technical requirements to communicate marketing needs to Technology (D&T) for efficient and effective campaign performance and measurement 
ScrapedJobID1404:
In this role, you will report to AVP, Modelling & Pricing Analytics in the Personal Lines Insurance department. You will be responsible for overseeing the development and lifecycle management of technical machine learning models across the countrywide portfolio within all personal product lines. You will have the opportunity to lead and manage a team of 5 to 8 staff and work closely in collaboration with other business partners to develop strategies and plans to jointly meet growth and profitability targets. You will also work closely with other managers on the team, as well as analytics practitioners in other teams to support the development in our overall data and analytics capabilities. University Degree in Data Science, Computer Science, Actuarial Science, or a relevant discipline. At least one of Associateship/Fellowship in the Casualty Actuarial Society, PhD or Master degree in a relevant discipline is required. At least 4 years of full-time experience in a relevant field with a preference for individuals who have experience managing a small of team analysts. Must have strong knowledge of statistical, predictive modelling and/or data science knowledge with at least 3 years of hands-on modelling experience. Good project management skills such as communication and organizational skills and an ability to promote and supervise a team effort toward project completion. We also take potential into consideration. If you don’t have this exact experience, but you know you have what it takes, be sure to give us more insight through your application and cover letter. Competitive salaries, with potential for an annual raise and bonus Pension and savings programs, with company-matched RRSP contributions Generous time away, including vacation and personal needs days Paid volunteer days and company matching on charitable donations Educational resources, tuition assistance, and paid time off to study for exams Two annual wellness campaigns — participants earn up to $300 each year to spend on almost anything supporting health and work-life balance (think things like spa days, daycare, pet grooming) An unlimited employee referral bonus program Flexible work schedule Discounts on products and services 
ScrapedJobID1405:
Work with project leadership to define project scope and develop approach Structure and develop therapy area forecast structure, forecast model input assessment through primary and/or desk research to derive insights and inform client decision making Lead project teams in design and execution of analyses to test hypotheses and improve client commercial effectiveness Lead project task execution by ensuring progress, organizing project data and coordinating team meetings Conduct issue analysis and develop hypotheses on the key client issues Synthesize findings, develop recommendations and communicate results to clients and internal teams Provide thought leadership and innovation within projects and practice areas Participate in business development Contribute to internal firm activities Coach and mentor junior team members MBA with a Bachelor's (and often graduate) degree in a quantitative, analytical discipline, such as Operations Research, Applied Mathematics, Management Science, Data Science, Statistics, Econometrics, or Engineering. Alternately, candidates may possess a PhD in marketing, economics, decision sciences or related field with a business application. In lieu of an MBA or PhD, 5-8 years of relevant work experience may substitute. Up to 3 years of post-MBA relevant work experience, and 3-5 years of pre-MBA relevant work experience doing forecasting and/or marketing analytics at a Pharma company or a Pharma focused consulting firm. Evidence of strong analytic work (including use of advanced modeling techniques and tools such as R, SAS, Tableau, or VBA) Deep knowledge of Pharma data sources – syndicated as well as non-syndicated High motivation, good work ethic, maturity and personal initiative Aptitude for, and enjoyment of, leading and managing teams Effective oral and written communication skills that enable personal impact with senior-level decision makers Strong attention to detail, with a quality-focused mindset Analytic problem-solving skills, with a creative and innovative outlook Client service orientation 
ScrapedJobID1406:
Degree in mathematics, computer science, engineering, physics, statistics, economics, computational sciences or a related quantitative discipline and 5+ years of analytical experience in an industrial or commercial setting OR PhD degree with at least 3+ years of industry experience Experience AI/ML/NLP modelling of complex datasets. Advanced software development skills in at least two of the standard data science languages (such as Python, R, Scala, C++, Julia) and strong data manipulations skills (e.g. SQL, NoSQL, graph, etc.) Knowledge of SQL and relational databases, query authoring (SQL) and designing variety of databases (e.g. Postgres SQL) Comfortable working in cloud and high-performance compute environments (e.g. AWS, Apache Spark) Disciplined AI/ML deployment (MLOps, CI/CD) and Agile delivery Experience in coordination of delivery teams and providing feedback to their management Excellent written and verbal communication, business analysis, and consultancy skills Knowledge on health care knowledge management systems (e.g. ICD, SNOMED, MedDRA, UMLS) preferred Experience AI/ML modelling of complex datasets, network analysis or direct experience in creating and maintaining graph data models Experience with a variety of graph technologies Knowledge of graph databases like Neo4J (Cypher, causal clusters), JanusGraph (Gremlin, GraphML), AWS Neptune, OrientDB Expertise in machine learning/deep learning-based graph algorithms relevant to link prediction, ranking/recommendation, completion, community detection, node embedding, etc. Lead data science area deliverables for digital products / programs / initiatives including the allocation of work within the team, monitors the quantitative and qualitative achievements of the team, and reports results Work as an individual contributor, providing data science expertise to digital products / programs / initiatives. Apply in-depth experience with both statistical and modern data science approaches, including unsupervised, supervised, regression algorithms. Apply advanced techniques such as neural networks, deep learning, NLP and federated learning. Build models, algorithms, simulations and experiments by writing highly optimized code and using state-of-the art machine learning technologies. Collaborate cross-functionally in teams involved in data driven analytics to maximize impact of graph-based capabilities Build and manage support models incorporated into digital or AI products; Work with Infrastructure and Ops teams to ensure appropriate architecture and tooling Capacity to mentor junior personnel Be able to apply in-depth experience with both statistical and modern data science approaches to business cases and knowledge management tasks Strong written and verbal communication skills - ability to communicate complex ideas up to people of varying technical skills Work with developers, engineers, and MLOps to deliver AI/ML solutions for new products/services 
ScrapedJobID1407:
Responsible for server side applications Analysis, Design & Development. Collaborate with business partners on the trading floor to create performant applications that deliver real time insights on millions of data points. Responsible for creating high throughput applications leveraging existing Citi Big data framework, Part of an innovative team pursing boundaries to create innovative data visualization solutions. Ability to take initiative to research, learn and recommend emerging technologies. Be part of a dynamic group working towards a common goal. Work with developers onshore, offshore and matrix teams to implement a business solution Proficiency in Java or Python. Experience with customer analytics. Relish tackling new challenges, paying attention to details, and growing professionally. Basic shell commands and shell scripting. Adapts machine learning and deep learning technologies to the finance products Strong familiarity with machine learning and statistical techniques Knowledge and experience of distributed computing Knowledge of advanced statistical techniques and concepts. Extensive hand-coding expertise in Core Java development Experience with PySpark/Pandas and related data analytics libraries Adapts machine learning and deep learning technologies to the finance products Experience with messaging systems like Kafka & EMS (Solace, Tibco) Experience in Hadoop framework with good understanding of HDFS, Hive, HBase, Spark 
ScrapedJobID1408:
Advise on the best technologies and frameworks to monitor performance for the team's and client's needs. Show your analysis through presentations and communication with technical and non-technical people. Develop performance measuring frameworks to track goals, user needs and work with KPIs. Work with marketing software and tools such as Google Analytics, Google Tag Manager, Google Search Console, Adobe Analytics, Hubspot, Salesforce Marketing Cloud, Facebook Ads, Google Ads, and LinkedIn Ads. Oversee the analytics, data layer, and tag management solution for accurate and efficient data capture. Help conceptualize, design, build and automate reports/dashboards that provide insights into client audiences. Manage ongoing audience data and KPI reporting on a weekly/monthly/quarterly basis, delivering insights and recommendations to both business and content teams. Provide data-driven feedback and actionable insights to our content teams regarding content/topic performance onsite & off-platform (social media, blog, video, etc..) As needed, work with developers for tracking needs and implementation 1-3+ years of experience working with or close to marketing data 1-3+ years of experience working directly with Google Analytics data Proven ability to manage, understand, discuss, and work with analytics accounts, goals, properties, dashboards, reports, segments, and custom channel/content groupings Experience using visualization tools, in particular Google Data Studio - expertise in Tableau a bonus Hands-on experience with Google Tag Manager; experience and expertise in web tagging concepts and the ability to lead tagging strategy highly desired A high degree of comfort with Excel and/or Google Sheets spreadsheet concepts A degree in marketing or statistics Entrepreneurial ability to diagnose web data tracking issues and propose solutions Ability to work with a fluid team at a fast pace Interest in statistical programming/query languages (R, Python, SQL) Understanding of data science processes and ability to implement these in an Agile environment Excellent communication skills and ability to simplify advanced statistical concepts for a layman audience Strong understanding of advertising data and advertising concepts HTML, Javascript, and other web development expertise Working knowledge of APIs, data connectors, and other pipelines Experience with UX/testing technologies such as Hotjar, Google Optimize An understanding of SEO and technical SEO concepts, search data CRM and email software marketing data Prior experience with project/workflow management software (we use Asana) 
ScrapedJobID1409:
Develop a deep understanding of the markets in each country and their data and analytical needs. Provide guidance to internal collaborators on advanced analytics Co-lead GAA's capability/product strategy, synthesizing business needs and advanced analytics expertise into capability/product roadmaps. Lead the development and deployment of strategic capabilities/products built around advanced analytics that create tangible business value. Coordinate across CoE roles and other business functions (sales, marketing, IT, external vendors, etc.) required to efficiently and effectively deliver new analytics capabilities/products Coordinate across markets the development of analytics capabilities to improve commonalities and efficiencies Collaborate with the Data & Insights Specialist on business adoption, and embedding analytics into business processes Find opportunities to evolve analytics capabilities/products and to use them across countries and brands Instil a culture of continuous improvement to refine and enhance existing capabilities. Monitor the external environment to stay up to date on leading advanced analytic capabilities, both within and outside of pharma, which can be applied within the organization. Oversee multiple capability related projects across different countries and markets. Extensive hands-on experience in application of advanced analytics and statistical methods on large and disparate datasets preferably in the context of Omnichannel marketing, specifically: Statistical Analysis and Modelling: (e.g. Design of Experiments, Time Series Analysis, Regression Analysis, Bayesian methods, etc), Machine Learning and Artificial Intelligence Extensive experience in deploying (and maintaining) production-grade advanced analytics capabilities. This includes not only the delivery of solutions but also the building of the business ecosystem (processes, organizational structure, change management, etc.) necessary. Strong organizational skills and time management; ability to manage diverse range of simultaneous projects. Strong leadership and interpersonal skills with demonstrated ability to work collaboratively with a significant number of business leaders and cross-functional business partners. Strong communication and influencing skills. Pharma commercial domain understanding. Experience with omnichannel analytics Experience with Agile methodology within an IT/business environment. Strategic and critical thinking with the ability to engage, build and maintain credibility with Commercial Leadership Team. Quantitative Master's or PhD degree from an accredited college or university is required in one of the following or related fields: Engineering, Operations Research, Management Science, Economics, Statistics, Math, Physics, Computer Science or Data Science. Cambridge, UK Gothenburg, Sweden Gaithersburg, US 
ScrapedJobID1410:
Minimum 5 years’ experience as a statistical programmer or an equivalent combination of education and experience in a CRO or Pharmaceutical setting Comprehensive knowledge of statistics and programming Knowledge in the field of natural health products and pharmaceuticals Excellent interpersonal skills Good working knowledge of computing applications such as SAS Strong communication, organizational, leadership and planning skills Ability to effectively handle multiple tasks and projects Excellent accuracy and attention to detail Strong problem solving and analytical skills Ability to work in a team setting Strong computer skills with demonstrated experience in working with Microsoft Office programs (Word, Excel, PowerPoint, and Outlook) Bonus pay 8 hour shift machine learning: 1 year (preferred) 
ScrapedJobID1411:
Supplemented Fees- 15.02(a) The employee may be eligible to receive supplemented fees in accordance with Schedule C of the Collective Agreement. The actual rate of pay when in excess of the base rate of pay is deemed to include any supplemented fees owing, to the extent of the excess amount. If the actual rate of pay is less than the sum of the base rate of pay and the supplemented fees owing, then the employee shall receive the difference. 
ScrapedJobID1412:
Data organization and analysis Partner with application experts in understanding the needs, be responsible in designing and developing predictive models. Test, improve and measure effectiveness of the developed approaches Contribute to writing scientific publications Must be a Ph. D. student in statistics / applied statistics A strong mathematical foundation, good computational and modeling (parametric, non-parametric, multi dimensional) skills Proven experience working in applied statistics Experience in handling large database Autonoumous, self motivated as well as a good team player Exceptional skills in programming and using open source libraries Ability to contribute to peer-reviewed publications Fluency in English and in French (written and spoken). 
ScrapedJobID1413:

ScrapedJobID1414:
Bachelor’s degree in Data Science or Business Administration, MA or MBA preferred. Professional-level, current, subject matter expertise in various topics in Excel, Power Query and Power BI. Experience with adult instruction and/or training, with proven track record of online communication. Proficiency with MS suite, ability to connect to online hubs with reliable devices and internet access. Experience with online learning platforms such as D2L, Blackboard, and Moodle. 3-5 years teaching experience required. Documented experience working as an Instructor in a post-secondary or industry setting within a team environment is an asset. Ability to excel under pressure and ‘think on your feet’. Professional competence preparing, developing, delivering and administering post-secondary courses. Excellent English-language communication (written and verbal), and interpersonal and people-management skills. Demonstrated ability to deliver in class and within an online learning platform. Ability to motivate adult learners to achieve academic success. An established network of relevant professional contacts. Please note: These are the minimum required qualifications. Being a part of BC’s Top 100 Employers, and a member of the CCDI. A generous Total Compensation package which includes extended health and dental benefits and a superb pension plan. Access to Professional Development Funds and opportunities for career development. Increase your knowledge with Tuition waivers for BCIT courses. Enjoy discounted access to our fitness facilities (including classes like Yoga and Zumba). Additional Wellness and Employee Assistance programs. 
ScrapedJobID1415:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1416:
Lead the architectural evolution of the SDV analytics platform in-vehicle and in the back-office edge/cloud Partner with other Architects to ensure consistent translation of enterprise architecture decisions to solution architects, conduct solution design reviews, and arbitrate solution design conflicts across domains Create and publish architecture strategies, designs, statements of direction, standards, and guidelines Ensure availability, scalability, extensibility, maintainability, and reusability for production-intended designs Promote design guidelines and coding practices to improve quality and reusability Advocate and drive for Dev/DataOps principles to ensure fast delivery, innovation, customer satisfaction, quality, reliability & teamwork Collaborate with development teams to decompose requirements and designs into technical stories, and ensure they are implemented as designed Deep dive time sensitive analytics challenges to develop quick solutions Research emerging technology and influence choices to advance the organization and ensure consistent tool usage Represent the team in requirements, architecture, systems integration, platform upgrades or operations discussions Write API / events specifications for different interfaces within the SDV Org Lead & conduct multiple technical forums for design discussions, Dev/DataOps processes, and Operational Challenges across teams Work with leadership to identify technical and process improvement opportunities for the organization Participate in developing the future state data architecture standards, guidelines, and principles Mentor & guide multiple teams on domain knowledge, design, and development practices. Bachelor's in Computer Science or Engineering, Software Engineering, Electrical Engineering, or related technical degree 10+ years developing enterprise or other large-scale systems 5+ years in a senior technical position as a lead or an architect Experience in Service Oriented and Event Driven Architectures, and Microservices principles Experience developing distributed systems using Java, J2EE, Python, and/or C++ Microservices Knowledge of big data technologies, data architecture, data analysis, data reports, and basic understanding of data science techniques in cloud environments such as:

Scripting languages (Python, PySpark and SQL)

Databases (Hadoop, Hive, Kafka, Cassandra, Elastic, and/or S3)

Data Visualizations (PowerBI and/or Kibana) Scripting languages (Python, PySpark and SQL) Databases (Hadoop, Hive, Kafka, Cassandra, Elastic, and/or S3) Data Visualizations (PowerBI and/or Kibana) Expert knowledge of software development standards, processes, and Dev/Data Ops principles Experience developing software design documentation and modeling diagrams Proficient with designing, implementing, and maintaining an analytics platform Experience with POSIX operating systems such as Android, and Linux Working knowledge of Software Telemetry data performance monitoring Experience with source code management tools such as GIT, Jira, Bitbucket, or Azure DevOps Experience with large data transfer mechanisms across embedded systems/cloud/Edge/backoffice such as WebSocket, webRTC, grpc, mqtt/DDS etc. Expertise in network security protocols Fundamental understanding of computer and network fundamentals Self-motivated, proactive, creative and team oriented Ability to work with ambiguity and able to communicate ideas to developers Exceptional interpersonal, written and verbal communication and presentation skills Outstanding interpersonal and relationship leadership skills to effectively collaborate with varying levels of the organization as needed Demonstrated ability to learn from and share knowledge with co-workers in a fast-paced environment Demonstrated ability to evaluate technology options and apply to complex business problems Proficient in Data Governance practices and experience Successful candidates will be required to attest to, and be prepared to provide proof of, their vaccination status and that any job offer will be conditional on the candidate being fully vaccinated. Advanced degree in a related technical field Scaled Agile Framework (SAFe) certification Experience with network engineering, telecommunications, network development and testing Experience with edge, cloud, IoT technologies, virtualization technologies, containerization/container development, Android App development Experience with Vehicle Telematics & Communications Experience with vehicle ECU/module integration Experience with Automotive SW platforms (E.g. Classic/Adaptive AutoSAR, Google Automotive Services, Automotive Linux) 
ScrapedJobID1417:
Overseeing the development of software to clean and investigate large, messy data sets of numerical and textual data Networking with various teams to explore internal and external data sources and APIs to help uncover new trends and improve analysis Designing and contributing to highly scalable data pipelines, tools, and products to enable the analyst community to fully leverage the power of AWS Working with your team to analyze large swaths of data in order to optimize various business programs Managing and developing talent to drive a highly performant and engaged team Investigating the impact of new technologies on the future of digital banking and the financial world of tomorrow Curious: You ask why, you explore, you’re not afraid to blurt out your disruptive idea. You know how the latest tech works, yet you are constantly exploring new open source tools, and hitting up stack overflow on a regular basis. Crafty: You know how to get things done. You can navigate a large organization, motivate people, and influence your peers. Creative: Big, undefined problems and petabytes of data don’t frighten you. You’re used to working with abstract data, and you love discovering new narratives in unmined territories. Inspiring: You have a passion for developing people and take great pride in your management system. You know how to deliver through others while paving the way for their growth. Proactive: You will want to share your knowledge with your peers and contribute back to inner/open source projects which you might consume. Your choice of hardware - latest MacBook Pro or HP EliteBook and all the monitors you want! You can travel to a relevant conference of your choice annually - PyCon, PyData, AWS re:Invent, KDD, etc. Various internal training opportunities across our US and Canada locations $5000/yr education budget Flexible work hours, dress code and environment Bachelor’s Degree in a quantitative field At least 5 year of experience in open source programming languages for large scale data analysis (Python, Scala, or Java) At least 5 year of experience with version control system like Git and GitHub. At least 5 year of experience with relational databases and programming in SQL At least 2 years in lead positions (managing people/owning products/architecting and driving an agenda) Master’s Degree or PhD Experience working with AWS (EC2, S3, Lambda, RDS, etc.) Experience working with advanced Git Workflows (Pull Requests, Code Reviews, Issues, and Branching) Experience with CICD tools Experience with Machine Learning workflows 5+ years experience in Python 5+ years’ experience with SQL 3+ years in lead positions (managing people/owning products/architecting and driving an agenda) 
ScrapedJobID1418:
10+ years of experience in technical program/product/engineering management for large-scale business intelligence systems and/or complex software development initiatives. Bachelor’s degree (masters preferred) in business, engineering, computer science, or equivalent experience. SaaS experience / cloud native applications / backend data experience. AWS experience highly preferred; may consider other platform experience. Ability to influence at all levels and build strong partnerships across organizations to deliver the best outcome of complex programs. Excellent organizational and coordination skills along with multi-tasking capabilities to get things done in a fast-paced environment. Outstanding communication skills appropriate for executive-level audiences; ability to structure and communicate goals of program, relationship to business goals, and other relevant success criteria. Demonstrated ability to simultaneously understand and communicate the bigger picture while diving in to understand issues & risks to drive rapid resolution. Drive creation of data program roadmaps and data execution plans for complex, cross-organizational teams across all phases of planning, development, and production readiness and launch. Influence decisions by connecting strategy, priorities, and business/technical outcomes Lead execution in partnership across multiple functions including Data Engineering, Data Science, Data Analytics, as well as, with central data teams to align and deliver successful outcomes Ensure continued alignment of program scope, status, risks, and dependencies through effective communication across the organization and at all levels. Quickly and effectively identify critical issues and dependencies that need action and personally drive them through to closure. Balance business needs and technical constraints in resolving issues. Anticipate, recognize, and work through resistance or setbacks independently, work well with others when conflicts arise: see opportunities, ensure alignment with objectives, find common ground and promote understanding of alternative viewpoints before driving for closure and cooperation Effectively communicate program progress appropriately to varying levels of stakeholders. 
ScrapedJobID1419:
8+ years of experience in marketing data management, analysis, and insights, adtech, martech, and research techniques as well as an innovative vision on how to keep pace with the ever changing marketing environment. Experience leading an Analyst(s) and/or external resources in supporting multiple marketing lines of business to understand opportunities before and after campaign execution Solid experience enabling digital analytics tools, Adobe Analytics, Google Analytics, Power BI, and other marketing technologies: SMMS/ listening tools, conversion and/or media pixels, etc. Extensive knowledge of digital analytics implementation tools and techniques: tracking libraries and SDKs, cookies, Data Layer, Tag Management Systems, report suite configuration, listening keyword data collection etc. Demonstrated track record of developing and leverage media (paid, owned, and earned) performance analytics both in the context of forecasting expected results and supporting performance optimization / improvement. Strong internal client management experience both presenting and resolving issues You are naturally curious and can create a story from numbers: you have applied quantitative skills ,love identifying trends and have the ability to roll up your sleeves and dig into data when necessary You have experience with the end-to-end process of qualitative research, including planning, scoping, conducting, analyzing, and communicating results. You have the ability to problem solve and develop innovative approaches along with a drive to learn and master new technologies and techniques You understand high level technical requirements to communicate marketing needs to Technology (D&T) for efficient and effective campaign performance and measurement 
ScrapedJobID1420:
In this role, you will report to AVP, Modelling & Pricing Analytics in the Personal Lines Insurance department. You will be responsible for overseeing the development and lifecycle management of technical machine learning models across the countrywide portfolio within all personal product lines. You will have the opportunity to lead and manage a team of 5 to 8 staff and work closely in collaboration with other business partners to develop strategies and plans to jointly meet growth and profitability targets. You will also work closely with other managers on the team, as well as analytics practitioners in other teams to support the development in our overall data and analytics capabilities. University Degree in Data Science, Computer Science, Actuarial Science, or a relevant discipline. At least one of Associateship/Fellowship in the Casualty Actuarial Society, PhD or Master degree in a relevant discipline is required. At least 4 years of full-time experience in a relevant field with a preference for individuals who have experience managing a small of team analysts. Must have strong knowledge of statistical, predictive modelling and/or data science knowledge with at least 3 years of hands-on modelling experience. Good project management skills such as communication and organizational skills and an ability to promote and supervise a team effort toward project completion. We also take potential into consideration. If you don’t have this exact experience, but you know you have what it takes, be sure to give us more insight through your application and cover letter. Competitive salaries, with potential for an annual raise and bonus Pension and savings programs, with company-matched RRSP contributions Generous time away, including vacation and personal needs days Paid volunteer days and company matching on charitable donations Educational resources, tuition assistance, and paid time off to study for exams Two annual wellness campaigns — participants earn up to $300 each year to spend on almost anything supporting health and work-life balance (think things like spa days, daycare, pet grooming) An unlimited employee referral bonus program Flexible work schedule Discounts on products and services 
ScrapedJobID1421:
Work with project leadership to define project scope and develop approach Structure and develop therapy area forecast structure, forecast model input assessment through primary and/or desk research to derive insights and inform client decision making Lead project teams in design and execution of analyses to test hypotheses and improve client commercial effectiveness Lead project task execution by ensuring progress, organizing project data and coordinating team meetings Conduct issue analysis and develop hypotheses on the key client issues Synthesize findings, develop recommendations and communicate results to clients and internal teams Provide thought leadership and innovation within projects and practice areas Participate in business development Contribute to internal firm activities Coach and mentor junior team members MBA with a Bachelor's (and often graduate) degree in a quantitative, analytical discipline, such as Operations Research, Applied Mathematics, Management Science, Data Science, Statistics, Econometrics, or Engineering. Alternately, candidates may possess a PhD in marketing, economics, decision sciences or related field with a business application. In lieu of an MBA or PhD, 5-8 years of relevant work experience may substitute. Up to 3 years of post-MBA relevant work experience, and 3-5 years of pre-MBA relevant work experience doing forecasting and/or marketing analytics at a Pharma company or a Pharma focused consulting firm. Evidence of strong analytic work (including use of advanced modeling techniques and tools such as R, SAS, Tableau, or VBA) Deep knowledge of Pharma data sources – syndicated as well as non-syndicated High motivation, good work ethic, maturity and personal initiative Aptitude for, and enjoyment of, leading and managing teams Effective oral and written communication skills that enable personal impact with senior-level decision makers Strong attention to detail, with a quality-focused mindset Analytic problem-solving skills, with a creative and innovative outlook Client service orientation 
ScrapedJobID1422:
Degree in mathematics, computer science, engineering, physics, statistics, economics, computational sciences or a related quantitative discipline and 5+ years of analytical experience in an industrial or commercial setting OR PhD degree with at least 3+ years of industry experience Experience AI/ML/NLP modelling of complex datasets. Advanced software development skills in at least two of the standard data science languages (such as Python, R, Scala, C++, Julia) and strong data manipulations skills (e.g. SQL, NoSQL, graph, etc.) Knowledge of SQL and relational databases, query authoring (SQL) and designing variety of databases (e.g. Postgres SQL) Comfortable working in cloud and high-performance compute environments (e.g. AWS, Apache Spark) Disciplined AI/ML deployment (MLOps, CI/CD) and Agile delivery Experience in coordination of delivery teams and providing feedback to their management Excellent written and verbal communication, business analysis, and consultancy skills Knowledge on health care knowledge management systems (e.g. ICD, SNOMED, MedDRA, UMLS) preferred Experience AI/ML modelling of complex datasets, network analysis or direct experience in creating and maintaining graph data models Experience with a variety of graph technologies Knowledge of graph databases like Neo4J (Cypher, causal clusters), JanusGraph (Gremlin, GraphML), AWS Neptune, OrientDB Expertise in machine learning/deep learning-based graph algorithms relevant to link prediction, ranking/recommendation, completion, community detection, node embedding, etc. Lead data science area deliverables for digital products / programs / initiatives including the allocation of work within the team, monitors the quantitative and qualitative achievements of the team, and reports results Work as an individual contributor, providing data science expertise to digital products / programs / initiatives. Apply in-depth experience with both statistical and modern data science approaches, including unsupervised, supervised, regression algorithms. Apply advanced techniques such as neural networks, deep learning, NLP and federated learning. Build models, algorithms, simulations and experiments by writing highly optimized code and using state-of-the art machine learning technologies. Collaborate cross-functionally in teams involved in data driven analytics to maximize impact of graph-based capabilities Build and manage support models incorporated into digital or AI products; Work with Infrastructure and Ops teams to ensure appropriate architecture and tooling Capacity to mentor junior personnel Be able to apply in-depth experience with both statistical and modern data science approaches to business cases and knowledge management tasks Strong written and verbal communication skills - ability to communicate complex ideas up to people of varying technical skills Work with developers, engineers, and MLOps to deliver AI/ML solutions for new products/services 
ScrapedJobID1423:
Responsible for server side applications Analysis, Design & Development. Collaborate with business partners on the trading floor to create performant applications that deliver real time insights on millions of data points. Responsible for creating high throughput applications leveraging existing Citi Big data framework, Part of an innovative team pursing boundaries to create innovative data visualization solutions. Ability to take initiative to research, learn and recommend emerging technologies. Be part of a dynamic group working towards a common goal. Work with developers onshore, offshore and matrix teams to implement a business solution Proficiency in Java or Python. Experience with customer analytics. Relish tackling new challenges, paying attention to details, and growing professionally. Basic shell commands and shell scripting. Adapts machine learning and deep learning technologies to the finance products Strong familiarity with machine learning and statistical techniques Knowledge and experience of distributed computing Knowledge of advanced statistical techniques and concepts. Extensive hand-coding expertise in Core Java development Experience with PySpark/Pandas and related data analytics libraries Adapts machine learning and deep learning technologies to the finance products Experience with messaging systems like Kafka & EMS (Solace, Tibco) Experience in Hadoop framework with good understanding of HDFS, Hive, HBase, Spark 
ScrapedJobID1424:
Du Lundi au Vendredi Êtes-vous légalement autorisé(e) à travailler au Canada? Baccalauréat (Souhaité) science des données: 1 an (Souhaité) Statistique: 1 an (Souhaité) Français (Obligatoire) 
ScrapedJobID1425:
Clearly communicate project statuses with leaders and project teams Engage in quality assurance processes to create a high standard of accuracy Ensure exception and error handling techniques are used Use understanding of business rules to enhance logic used in reporting and analysis Seek out new technology and processes to improve team ability and reach Verbally and visually present reporting and analysis findings to leaders and stakeholders of various levels Submit work for quality assurance with a low number of errors Prioritize multiple projects within own work stream to deliver with little impact to timelines Manage relationships with data source providers for issues and support Consistently incorporate reconciliation in published reports and datasets Prove or disprove relationships between variables (causal) Forecast business measures with confidence and accuracy Assist with development planning with other team members Take on and seek out opportunities to mentor and coach Champion best practices in quality and reliability Over 8 years relevant industry experience within a telecom, client services or technology environment Undergraduate degree in a field linked to data engineering, business analytics, applied mathematics, computer science, IT, computer applications, or related field Ability to create reporting and analysis solutions that are delivered within scope, expected timelines and of high quality Demonstrated solid critical thinking and problem-solving skills Expert ability to identify issues and make difficult decisions, knowing when to escalate when required Strong ability to develop strategic relationships across the organization in a collaborative and foster trust from others Committed to personal and team excellence and ability to operate in a dynamic and constantly changing environment 
ScrapedJobID1426:
Develop product plans and objectives; report progress against plans and KPIs to all stakeholders (Data Science, Engineering, and business leaders) Work with the partnership team to assess and integrate external data sources that could improve our products Assist on client discovery calls to inform roadmap, business requirements, and vet early outputs Guide the Data Science team through model development by clarifying business priorities for projects and identifying and scoping data pipelines as needed Prioritize features and resources to ensure critical data science resources are working on the highest impact solutions Coordinate with front-end Product team to ensure timely and successful launch of new features and functionality Work across Services, Marketing, Product, and Data Science to create and maintain educational materials, whitepapers, and other analytical documents 3+ years of product management or product development experience, preferably in a Data or Analytics role Understanding of data science and hands-on analytical skills (such as SQL, Data Science tools and workflows) Demonstrated ability to work with internal stakeholders to collect feedback, prioritize tasks, and manage the engineering backlog Strong oral and written communication skills, and ability to collaborate with, and influence cross-functional partners Self-motivated, self-directed, and the ability to thrive in a fast-paced environment in an industry that constantly changes Organized with a knack for managing complex projects Creative and resourceful when it comes to problem-solving A passionate can-do attitude; you are not afraid to try, learn, and improve Experience in the Market Research of CPG industry Experience working with consumer purchase panel data An inclusive and collaborative company culture - we work together in an open environment to get things done and adapt to the changing needs of the business and our clients An opportunity to have an impact at a high growth Technology and Data company Ownership over data and environments in an industry-leading product Competitive total compensation package Volunteer time off and charitable donation matching Strong support for career growth, including mentorship programs, leadership training, access to conferences, and employee resources groups Regular hackathons to build your own projects Great benefits package including health/vision/dental, unlimited PTO, flexible schedule, 401K matching, travel reimbursement, and more 
ScrapedJobID1427:
Work with project leadership to define project scope and develop approach Structure and develop therapy area forecast structure, forecast model input assessment through primary and/or desk research to derive insights and inform client decision making Lead project teams in design and execution of analyses to test hypotheses and improve client commercial effectiveness Lead project task execution by ensuring progress, organizing project data and coordinating team meetings Conduct issue analysis and develop hypotheses on the key client issues Synthesize findings, develop recommendations and communicate results to clients and internal teams Provide thought leadership and innovation within projects and practice areas Participate in business development Contribute to internal firm activities Coach and mentor junior team members MBA with a Bachelor's (and often graduate) degree in a quantitative, analytical discipline, such as Operations Research, Applied Mathematics, Management Science, Data Science, Statistics, Econometrics, or Engineering. Alternately, candidates may possess a PhD in marketing, economics, decision sciences or related field with a business application. In lieu of an MBA or PhD, 5-8 years of relevant work experience may substitute. Up to 3 years of post-MBA relevant work experience, and 3-5 years of pre-MBA relevant work experience doing forecasting and/or marketing analytics at a Pharma company or a Pharma focused consulting firm. Evidence of strong analytic work (including use of advanced modeling techniques and tools such as R, SAS, Tableau, or VBA) Deep knowledge of Pharma data sources – syndicated as well as non-syndicated High motivation, good work ethic, maturity and personal initiative Aptitude for, and enjoyment of, leading and managing teams Effective oral and written communication skills that enable personal impact with senior-level decision makers Strong attention to detail, with a quality-focused mindset Analytic problem-solving skills, with a creative and innovative outlook Client service orientation 
ScrapedJobID1428:
Data Science MS or Phd in Computer Science Data Science Statistics Mathematics or experience in a related field At least 10 years of experience in OCR Predictive model NLP time series model Strong in SQL ML libraries and frameworks like Scikit learn Spark ML TensorFlow Proficiency in programming languages including Python Java or similar Experience with visualization tools like Power BI Tableau In depth knowledge of statistical methods and test techniques as well as exceptional analytical skills Knowledge of best practices in data analysis and data science Exposure to cloud Machine Learning Azure AWS Plus but not required Residential whole loans data knowledge is a plus Monday to Friday Temporarily due to COVID-19 
ScrapedJobID1429:

ScrapedJobID1430:
Develop and maintain algorithms, data pipelines, automated processes, and services to create a data science solution that are customer focused Extract mission-critical insights from datasets Innovate and bring creative ideas to building mission critical customer facing products that depend on ML solutions Work with product and business teams to identify solutions and best practices Create scalable models that drive business decisions and enable our customers’ success Design and develop processes and systems which analyze and generate actionable insights from diverse data sources Develop tools to monitor models for evolving performance and accuracy Mentor team members in the areas of technical expertise and career building Contribute to best practices around feature extraction, model development, and knowledge sharing among multiple data science teams Directly contribute to architecture planning Been in the ML engineering game for some time. You have a Bachelors/Masters and 4+ years of industry experience Proven ability to architect data science solutions to complex problems and delivering solutions in customer facing products Experience delivering solutions that analyzes big datasets using tools such as Apache Spark Experience delivering solutions that analyzes time-series data Strong programming skills in Python A strong command of SQL and working with multiple relational databases and data warehouses (Redshift, Postgres, Athena, Snowflake, etc…) Experience in end-to-end machine learning project life cycle Experience working with unstructured data Are scrappy when extracting useful insights with partial data A solid experience in working with software development teams and using source version control tools like Git Experience deploying deep learning models Experience with frameworks for in-production ML code (e.g. Kedro) Developing and deploying using Docker With some of the AWS services (e.g. EC2, S3, Sage Maker, Cloudwatch) With accessing data from other datastores in the AWS ecosystem such as ElasticSearch, S3, and DynamoDB The BEST team. Remote-first culture. International Meetups. Access to Jungle Scout tools & experts. Performance Bonus. Flexible Vacation. Comprehensive Health Benefits & Retirement Program. 
ScrapedJobID1431:
Develop & implement advanced analytics roadmap (40%) Create and own the roadmap for advanced analytics use cases by securing buy-in across all stakeholders and ensuring alignment with the business’s top priorities and expected outcomes, assess progress and recalibrate when required Manage these advanced analytics projects and pipeline. Run multiple projects, oversee prioritization and ensure projects are aligned with strategic priorities Prepare presentation materials as required and support in the presentation of opportunities to VPs, SVPs and CEO Own ongoing evaluation of appropriate partners, tools, methodologies and analytical techniques to ensure that our measurement solutions are most complete, integrated, advanced and on par with latest industry trends Apply analytical thought leadership to problem solving (30%) Assess and diagnose information needs, design and define suitable analytical solutions to generate meaningful insights that address business problems Present key insights and recommendations based on research and data analysis Own forecasting for customer & deposit growth Use quantitative methods (i.e., Excel models) to develop insights that support decision making on new products & initiatives Use SQL to source necessary data for ongoing understanding of customer behaviour and to support internal consulting projects Develop familiarity with internal systems & processes, and gather relevant data from various internal sources Establish repeatable processes / methodology that enable quicker turnaround on analysis Brainstorm, structure and create problem solving processes for a range of strategic and tactical customer-facing topics (e.g., identifying fraud applications, cross-selling mortgages, features on prepaid card, digital ID solutions, etc.) Enable ongoing understanding of customers through design and maintenance of executive dashboards and metrics Perform ad-hoc analysis for various business units Manage cross-functional collaboration & team development (30%) Facilitate cross-functional collaboration by leading a diverse team of analytics resources to deliver quality analysis, interpretation of findings and clear articulation of results and insights to internal business partners Support Payments in assessing product features and customer needs to determine prioritization of features for Minimum Viable Product (MVP) and future build Support Product in assessing performance & developing better understanding of customer adoption through A/B testing Support Marketing, Customer Experience (CX) and Contact Center in planning & evaluating marketing campaigns and meeting their customer insights needs Support Fraud & AML by optimizing rule performance and improving customer experience Potentially manage 1 – 3 direct reports, including skills development, mentoring, career growth through regular structured and ad-hoc feedback 8+ years’ work experience in Analytics, Strategy, Data Science roles, ideally in Financial services Bachelor’s degree in Engineering, Computer Science, Commerce, Management. MBA or other graduate degree a plus Minimum 4 years of people management experience Strong business acumen and passion for understanding and solving problems for consumers of financial services using rigorous data-driven methods and advanced analytical approaches Subject Matter expert at building, modifying, and running Excel based business scenarios and predictive models (able to teach others) Experience synthesizing analyses and preparing power point presentations for C-Suite level executives or Board of Directors Strong understanding of the financial services landscape, particularly with respect to retail banking, card programs, and marketing analytics Experience, confidence, and maturity managing internal stakeholders across all levels of the organization, including VPs, SVPs, and CEO Experience leading projects and managing tasks of more junior team members, as well as supporting their growth and development Expert in MS Office (Excel, Access, PowerPoint), MySQL, Tableau, Python / R, and statistics (regression analysis, correlations, etc.) Strong attention to detail and time management skills Good verbal and written communication skills Project management experience 
ScrapedJobID1432:
Architecture the design and drive the development of highly robust, scalable and real-time machine learning platforms Build new features and tools for machine learning models and data scientists that help to amplify their effectiveness Drive efficiencies through automation and optimization Drive and uphold high engineering standards and best practices Collaborate with business leaders, subject matter experts, product managers, machine learning modelers etc. to solve interesting and highly impactful business problems 2+ years of software development experience Experiences in architecting scalable and low latency services A bachelor’s degree (or above) in computer science or related field is very helpful but we are open to be convinced that you are an exception Strong grasp of Computer Science fundamentals Strong ownership coupled with strong teamwork and collaboration A background in Machine Learning is preferred but not required The ability to clearly communicate complex results to technical and non-technical audiences and stakeholders (PMs, Operations, Engineers). Healthcare coverage Retirement Plans Employee Stock Purchase Program Wellness perks Paid parental leave Paid time off Learning and Development resources Healthcare coverage Retirement Plans Employee Stock Purchase Program Wellness perks Paid parental leave Paid time off Learning and Development resources 
ScrapedJobID1433:
Stay abreast of innovations and publications in the field of operations research and business intelligence systems. Research and solve complex scheduling, resource allocation and pricing scenarios involved in operations optimization. Analyze raw operational data and design algorithms that can automatically and consistently generate operational recommendations for clients. Contribute to the invention of novel solutions to client’s operational problems by collaboratively working with product managers, co-developers, and our client success team. Utilize efficient algorithm design in a parallelized fashion capable of crunching gigabytes of operations data in minutes and scaling up with client growth. Build dashboards that transform operational data into visualizations that are intuitive and actionable Contribute refinements to our existing product through the development of new features as well as refactoring existing code to make it more efficient and object-oriented. Advance your knowledge of new software tools, agile programming methods, business intelligence technologies and share your knowledge with the development team, thus catalyzing process / technology changes to help us be more effective. Languages: C#, JavaScript, TypeScript Frameworks: .NET Core, Angular Web Server: IIS, NGINX Databases: MS SQL, Azure SQL Infrastructure: Azure, Docker, Kubernetes, GitLab Logistics engine: algorithms for discrete optimization problems Operation Systems: Windows, Linux Development Processes: Agile, CI/CD 2+ years of experience in Software Development, preferably with high performance algorithms or data intensive applications. A deep and intuitive understanding of Algorithms and Data Structures. Ability to process, assimilate, and explain complex and abstract concepts from research publications. Operations Research or Management Engineering Mathematical Optimization Data Science / Machine Learning Master’s Degree or PhD in Applied Mathematics/ Management Science/ Operations Research/ Computer Science / Engineering, or related technical discipline. Base salary of $80K - $115K + performance-based bonus or stock options Work-Life Balance: Flex time, work from home days and travel incentives. Set-up: Standing / adjustable desks, massage chair & quiet rooms, employee lounge with Xbox, Switch & PS4. Benefits Plan: Fitness allowance, dental/prescription/vision, massage & physio, and healthcare spending account. Food & Fun: Fully stocked kitchen, fancy coffee machine, team lunches, long weekend bottle draws and monthly employee events. 
ScrapedJobID1434:

ScrapedJobID1435:
Manage and contribute to the delivery of reporting and analytics solutions, mainly in Looker Understand business needs and technical requirements to meet those needs Lead and develop your team of analysts Set and achieve challenging goals for yourself and your team (OKRs) Foster a culture of data-driven decision making throughout the company Keep up with the latest data industry tools and techniques Top-notch communication (verbal and written) and interpersonal skills Excellent math and statistical analysis skills Proficiency in the presentation and visualization of numbers and statistical data Ability to understand business imperatives and drivers, find relevant data correlations, and create processes by which the data correlations are translated to information flows that help drive the business 5+ years developing and coaching analytics teams 5+ years of quantitative analysis work experience 5+ years of experience handling, manipulating and analyzing data and creating analytical reports Strong expertise with an SQL language, database structures, and data lake architectures Experience with Looker Experience with Snowflake Proficiency with Python An understanding of the principles, tools, and processes of data science Post-secondary education in a technical field, or B.S./M.S. 
ScrapedJobID1436:
You love wrangling data to create performant streaming data that feeds Machine Learning models You enjoy straddling the worlds of Data Science and Developer, and when reviewing a Jupyter Notebook you find yourself drawn more to how to efficiently implement the solution space for product (even though the research is amazing) You love building tools for yourself to make working with Machine Learning solutions in production easier to troubleshoot You love to keep on top of the latest and greatest in technology, and are able to be opinionated on which are winners, and which are hype You’re a strong believer in Continuous integration, and the DevOps mindset You think it is critical to understand of how your software runs on infrastructure in detail, and are experienced in how it should be designed You like working in teams, mentoring, and sharing neat things you come across enjoy Design, develop, and support production grade streaming Machine Learning pipelines and solutions, including the areas of fast and efficient data processing, fault-tolerance, scalability Work closely with a Data Science team focused on the research aspects, and comprehend, design, and implement the path to product Drive the surrounding Machine Learning technology eco-system to support our product and workflows Work closely with product management, QA, and Support to build and support product Analyze, scope, review, and estimate development activities Be the subject matter expert of your ownership areas of the product Participate in evolving the team’s processes so we’re efficient, and loving what we do Mentor less experienced team members 2 years experience with building efficient and scalable data pipelines feeding Machine Learning models (including efficient and scalable preprocessing, training path, inference path, graceful degredation, dirty data mitigation) 2 years of experience with scalable data processing technologies (i.e. Spark, Flink, Apache Beam) 3 years of experience developing advanced Python using Object Oriented techniques, Modules (i.e. more than scripting) Experience with the Machine Learning Life-Cycle (i.e. scoping, data review, data processing, feature extraction, model development, testing, troubleshooting, performance monitoring) Experience with Tensorflow, or equivalents Multiple releases of your code deployed live and having to support it with customers at arms length Experience developing streaming data analytics including the storage and access challenges at scale and in production Clear verbal and written communication and the ability collaborate effectively in a geographically dispersed working environment Experience with Data Lake design, implementation, and life-cycle combining multiple disseparate types of data Advanced experience with the whole life-cycle of Python dependency management strategy across multiple repositories Experience with at least once IaaS provider Experience with the Power Systems domain and the software that manages it Knowledge, skills, and professional networking in one of the most exciting and positively impactful technology domains that is an intersection of machine learning, data science, electrical engineering, and software Startup experience and ground floor opportunities for growth in a team that includes PhD Smart Grid Engineers, Data Scientists, recent grads, and seasoned business professionals Competitive compensation High quality of life and career in Canada's National Capital Region Working on a team with a serious approach towards our work, rather than ourselves, together with fun and random team events such as Ice Cream Fridays and Cosmological Lunches. You will get the opportunity to come up with one 
ScrapedJobID1437:
Design and deployment of n-tier application and security design, documentation, and configuration for medium and large corporate implementations to the cloud. Coordinate the development and integration of large enterprise applications, Software defined storage, infrastructure, virtualization, technology roadmap, data architecture roadmap, data product roadmap. Direct cooperation with development teams on providing guidance about product development, roadmap and backlog Enhance platform capabilities, including data processing task automation, integration and deployment of analysis pipelines for internal use Knowledge and practical experience in data products development, that includes data processing and modelling techniques, tools, metadata structures, data lakes, and data dictionaries. BS/BA in computer sciences, mathematics, life sciences or related degrees Graduate degree in Data Science or other quantitative field is preferred Practical (ie. development) and conceptual (on the solution architecture level) knowledge and relevant experience on the front-end application development and integration with 3rd party tools and platforms (eg. Tibco Spotfire, Tableau, etc.) Product Ownership experience and skills, ie. ability to work directly with business users to determine the product direction and backlog Ability to translate business requirements into functional requirements Ability to perform Solution Architect role for web-based applications (both JS and TS) in the cloud environment Experience with AWS cloud infrastructure services Defined standards and lead implementation of software development processes Strong SAAS skills Monday to Friday front-end application development: 5 years (preferred) AWS cloud infrastructure service: 5 years (preferred) SaaS: 5 years (preferred) 
ScrapedJobID1438:
Du Lundi au Vendredi Êtes-vous légalement autorisé(e) à travailler au Canada? Baccalauréat (Souhaité) science des données: 1 an (Souhaité) Statistique: 1 an (Souhaité) Français (Obligatoire) 
ScrapedJobID1439:
Ongoing practice and process development looking for ways to improve and streamline company processes to not only deliver a superior service to our clients, but also to improve our efficiency and profitability. Mentoring/managing Data Science team members Partner with your Group Director to educate clients on the value of adding Data Science products to their business, capturing & defining needs and solutions Synthesize business needs and create business/functional design documents which can be used to build analysis and data models around. Assess data for validity in terms of predictive capabilities, required feature engineering, opportunities for data widening, or alignment to business requirements Develops, implements, and supports methodologies, standards, and tools for analysis and data science work. Build cooperative, productive relationships with clients and vendors by utilizing excellent communication skills, while also interacting effectively internally and externally. Research, prototype, and explore future, non-standard analytics approaches that push the limits of current analysis output. This will include exploring novel machine learning techniques which enable our teams to tackle segmentation, clustering, and predictive models used in a wide variety of areas. Bachelor’s degree in Mathematics, Statistics, Business Analysis or related 5+ years’ experience as an Analyst / Data Scientist 2+ years’ of managerial and leadership experience Advanced knowledge of R, Python or SAS for model development Previous experience with web analytics tools such as Adobe Marketing Cloud, Google Analytics Extensive experience with statistical modelling techniques Experience connecting Tableau or other visualization systems and using for dashboarding or analysis Self-motivated and ability to work independently in meeting deadlines Exceptional written and verbal communication skills and is comfortable working with remote teams Previous experience with marketing analytics including database marketing techniques, campaign lift, attribution and media mix modelling Familiarity with analyzing data for digital marketing and ecommerce, as well as all other non-digital aspects of a business SQL skills A solid knowledge of ETL tools Understanding of how to deal with larger data sets and parallel computing problem 
ScrapedJobID1440:
Lead, manage and mentor the Machine Learning Engineers on your team Collaborate with our Engineering teams to help build production features that leverage our machine learning technologies Develop infrastructure for rapid machine learning feature prototyping, deployment, and evaluation with customers Build and optimize data lakes and feature stores to feed research projects Apply best practices for ETL and batch processing of database, log, image, and HTML data. Participate in large-scale project planning and stakeholder education 5 or more years of experience working with MLOps or Machine Learning Engineering Experience leading major projects and managing team members Experience deploying machine learning models in production, and with production architecture, monitoring and logging Excellent communication and emotional intelligence is required Exceptional experience programming with Python and the associated data science/machine learning packages (e.g. scikit-learn, pandas, xgboost, numpy, scipy) Management of databases (we principally use MySQL, Postgres, and DynamoDB) Cloud infrastructure, preferably AWS, especially S3, and CloudFormation Running services in Docker environments Experience with web technologies, including APIs (we use REST and GraphQL) Linux administration and command line tools Agile development, version control, and code review processes Big Data ETL (we principally use PySpark) 
ScrapedJobID1441:
Execute on the overall administration of customer Power Platform environments, including maintaining environment health and functionality, troubleshooting, problem management, account management, and monitoring Maintain a deep and current understanding of end user facing cloud technologies and collaboration tools including M365, Power Apps, Power Platform, Power BI, Dataverse and others Serve as an advisor in the assessment, planning and implementation of new features and capabilities Gather and document requirements from stakeholders in order to maintain existing Power Apps, as well as design new ideas and assist with in-development projects. Integrate and align Compugen processes to meet the governance objectives of the stakeholder community Support Compugen management team with analysis and communication materials related to operational activities Act as a senior administrator for customer PowerApps environments and coach junior team members Facilitate requirements gathering sessions with technical and business stakeholders Plan and Execute an end-to-end implementation of the target workloads Assist with the development of cloud design standards related to Power Platform components Maintain a highly secure mobile messaging system through proper security configurations and governance Follow a formal problem management process for incident and problem reporting and resolution Participate in critical event management as required Bring forward thoughtful solutions and enhancements using Power Platform components in order to improve both internal efficiency and customer productivity by finding opportunities to optimize existing processes and tools Manage relevant ITSM processes using required ITSM tools A degree in data science or computer science, or equivalent experience in designing Power Platform solutions for enterprise corporations 3+ years’ experience building and administering Power Platform components in a Microsoft environment including administering Power Apps, Power Automate, Dataverse and others 2+ years’ experience managing Microsoft PowerApps platforms incl. using PowerShell Familiarity with Microsoft 365 Security and Compliance center and Cloud App Security as it pertains to Power Platform governance and best practice Knowledge of Microsoft MFA and SSO ITIL Foundation level certification or higher Microsoft Certified: Power Platform Fundamentals certification or higher Experience in administration of Dataverse applications such as Dynamics 365 Experience with SQL is an asset Experience in oil & gas is an asset Ability to effectively navigate and deliver results in a large and complex environment is a must Strong forward thinking, analytical, interpersonal, and problem-solving skills Strong verbal and written communication skills, with the ability to explain concepts and topics in layman’s terms to non-subject matter experts and build consensus and credibility among diverse stakeholder groups Able to work expeditiously as an individual contributor and as a team member Ability to coordinate, prioritize and complete multiple concurrent deliverables Experience with agile as well as waterfall project management concepts, practices, and deliverables Proven track record of successful requirements gathering and documentation using best practice standards Process and workflow engineering, design and implementation experience Experience in technical documentation writing, including knowledge transfer, SOP, runbooks, KB articles and training materials Previous experience in senior roles in IT project delivery and operational environments is an asset 
ScrapedJobID1442:
Follow NLP research and apply it to create technologies for business automation Own ML models end-to-end, from collecting training data to deploying in production Lead the planning, design, and implementation of the ML projects Serve as a mentor to junior team members and a standard-bearer for engineering best practice Manage the collaboration and communications with project stakeholders Minimum 3 years of industry experience in Machine Learning or related fields Solid understanding of Math and CS fundamentals related to Machine Learning algorithms Practical experience in modern NLP technologies (applying ML research to real-world projects) Previous experience in leading multi-person projects and building end-to-end Machine Learning systems Experience with one or more general purpose languages (Java, C/C++, Python, etc.) Team player with strong communication skills BS, MS or PhD in Computer Science, Engineering or a related technical field Top notch medical and dental coverage for you and your family 30 days of paid leave annually to help nurture work-life symbiosis Stock options Wellness stipend Pre-tax transportation and commuter benefits 6-month parental leave (or double salary to pay for your partner's unpaid leave) Free travel for any person accompanying a breastfeeding mother and her baby on a business trip A dependent care stipend up to $3,000 (USD) per month, per child, under the age of 21 for a maximum of $6,000 (USD) per month total Budget to attend conferences, train, and further your education $1,250 (CAD) one-time-use WFH stipend and $95 (CAD) monthly WFH stipend Relocation assistance 
ScrapedJobID1443:
Working closely with other data scientists and developers in building and deploying various machine learning models for Global Relay's customers Being a subject matter expert on current speech transcription and speaker identification techniques Interacting with product managers on enhancements to our core products Executing all steps in the data science process from understanding business requirements to deploying models Producing reports detailing model performance 5+ years of experience with solving machine learning/speech recognition problems Experience working with very large data sets in an enterprise-wide application environment Knowledge of signal processing methods for audio processing and time series analysis An understanding of different neural network architectures as applied to speech recognition such as: Attention-based models, RNNs and CNNs Python, Bash and C++ experience Knowledge of common machine learning libraries such as: Scikit-learn, TensorFlow, PyTorch, HTK, Kaldi, Julius, Sphinx and others Strong organizational and communication skills MSc or PhD in a STEM or Linguistics subject Data collection and cleaning experience Data engineering skills Experience building acoustic or language models for speech recognition Experience with:
Natural language processing models
Kubernetes and micro services
Working in an agile development environment Natural language processing models Kubernetes and micro services Working in an agile development environment 
ScrapedJobID1444:
Develop product plans and objectives; report progress against plans and KPIs to all stakeholders (Data Science, Engineering, and business leaders) Work with the partnership team to assess and integrate external data sources that could improve our products Assist on client discovery calls to inform roadmap, business requirements, and vet early outputs Guide the Data Science team through model development by clarifying business priorities for projects and identifying and scoping data pipelines as needed Prioritize features and resources to ensure critical data science resources are working on the highest impact solutions Coordinate with front-end Product team to ensure timely and successful launch of new features and functionality Work across Services, Marketing, Product, and Data Science to create and maintain educational materials, whitepapers, and other analytical documents 3+ years of product management or product development experience, preferably in a Data or Analytics role Understanding of data science and hands-on analytical skills (such as SQL, Data Science tools and workflows) Demonstrated ability to work with internal stakeholders to collect feedback, prioritize tasks, and manage the engineering backlog Strong oral and written communication skills, and ability to collaborate with, and influence cross-functional partners Self-motivated, self-directed, and the ability to thrive in a fast-paced environment in an industry that constantly changes Organized with a knack for managing complex projects Creative and resourceful when it comes to problem-solving A passionate can-do attitude; you are not afraid to try, learn, and improve Experience in the Market Research of CPG industry Experience working with consumer purchase panel data An inclusive and collaborative company culture - we work together in an open environment to get things done and adapt to the changing needs of the business and our clients An opportunity to have an impact at a high growth Technology and Data company Ownership over data and environments in an industry-leading product Competitive total compensation package Volunteer time off and charitable donation matching Strong support for career growth, including mentorship programs, leadership training, access to conferences, and employee resources groups Regular hackathons to build your own projects Great benefits package including health/vision/dental, unlimited PTO, flexible schedule, 401K matching, travel reimbursement, and more 
ScrapedJobID1445:
Work with project leadership to define project scope and develop approach Structure and develop therapy area forecast structure, forecast model input assessment through primary and/or desk research to derive insights and inform client decision making Lead project teams in design and execution of analyses to test hypotheses and improve client commercial effectiveness Lead project task execution by ensuring progress, organizing project data and coordinating team meetings Conduct issue analysis and develop hypotheses on the key client issues Synthesize findings, develop recommendations and communicate results to clients and internal teams Provide thought leadership and innovation within projects and practice areas Participate in business development Contribute to internal firm activities Coach and mentor junior team members MBA with a Bachelor's (and often graduate) degree in a quantitative, analytical discipline, such as Operations Research, Applied Mathematics, Management Science, Data Science, Statistics, Econometrics, or Engineering. Alternately, candidates may possess a PhD in marketing, economics, decision sciences or related field with a business application. In lieu of an MBA or PhD, 5-8 years of relevant work experience may substitute. Up to 3 years of post-MBA relevant work experience, and 3-5 years of pre-MBA relevant work experience doing forecasting and/or marketing analytics at a Pharma company or a Pharma focused consulting firm. Evidence of strong analytic work (including use of advanced modeling techniques and tools such as R, SAS, Tableau, or VBA) Deep knowledge of Pharma data sources – syndicated as well as non-syndicated High motivation, good work ethic, maturity and personal initiative Aptitude for, and enjoyment of, leading and managing teams Effective oral and written communication skills that enable personal impact with senior-level decision makers Strong attention to detail, with a quality-focused mindset Analytic problem-solving skills, with a creative and innovative outlook Client service orientation 
ScrapedJobID1446:
Data Science MS or Phd in Computer Science Data Science Statistics Mathematics or experience in a related field At least 10 years of experience in OCR Predictive model NLP time series model Strong in SQL ML libraries and frameworks like Scikit learn Spark ML TensorFlow Proficiency in programming languages including Python Java or similar Experience with visualization tools like Power BI Tableau In depth knowledge of statistical methods and test techniques as well as exceptional analytical skills Knowledge of best practices in data analysis and data science Exposure to cloud Machine Learning Azure AWS Plus but not required Residential whole loans data knowledge is a plus Monday to Friday Temporarily due to COVID-19 
ScrapedJobID1447:

ScrapedJobID1448:
Develop and maintain algorithms, data pipelines, automated processes, and services to create a data science solution that are customer focused Extract mission-critical insights from datasets Innovate and bring creative ideas to building mission critical customer facing products that depend on ML solutions Work with product and business teams to identify solutions and best practices Create scalable models that drive business decisions and enable our customers’ success Design and develop processes and systems which analyze and generate actionable insights from diverse data sources Develop tools to monitor models for evolving performance and accuracy Mentor team members in the areas of technical expertise and career building Contribute to best practices around feature extraction, model development, and knowledge sharing among multiple data science teams Directly contribute to architecture planning Been in the ML engineering game for some time. You have a Bachelors/Masters and 4+ years of industry experience Proven ability to architect data science solutions to complex problems and delivering solutions in customer facing products Experience delivering solutions that analyzes big datasets using tools such as Apache Spark Experience delivering solutions that analyzes time-series data Strong programming skills in Python A strong command of SQL and working with multiple relational databases and data warehouses (Redshift, Postgres, Athena, Snowflake, etc…) Experience in end-to-end machine learning project life cycle Experience working with unstructured data Are scrappy when extracting useful insights with partial data A solid experience in working with software development teams and using source version control tools like Git Experience deploying deep learning models Experience with frameworks for in-production ML code (e.g. Kedro) Developing and deploying using Docker With some of the AWS services (e.g. EC2, S3, Sage Maker, Cloudwatch) With accessing data from other datastores in the AWS ecosystem such as ElasticSearch, S3, and DynamoDB The BEST team. Remote-first culture. International Meetups. Access to Jungle Scout tools & experts. Performance Bonus. Flexible Vacation. Comprehensive Health Benefits & Retirement Program. 
ScrapedJobID1449:
Develop & implement advanced analytics roadmap (40%) Create and own the roadmap for advanced analytics use cases by securing buy-in across all stakeholders and ensuring alignment with the business’s top priorities and expected outcomes, assess progress and recalibrate when required Manage these advanced analytics projects and pipeline. Run multiple projects, oversee prioritization and ensure projects are aligned with strategic priorities Prepare presentation materials as required and support in the presentation of opportunities to VPs, SVPs and CEO Own ongoing evaluation of appropriate partners, tools, methodologies and analytical techniques to ensure that our measurement solutions are most complete, integrated, advanced and on par with latest industry trends Apply analytical thought leadership to problem solving (30%) Assess and diagnose information needs, design and define suitable analytical solutions to generate meaningful insights that address business problems Present key insights and recommendations based on research and data analysis Own forecasting for customer & deposit growth Use quantitative methods (i.e., Excel models) to develop insights that support decision making on new products & initiatives Use SQL to source necessary data for ongoing understanding of customer behaviour and to support internal consulting projects Develop familiarity with internal systems & processes, and gather relevant data from various internal sources Establish repeatable processes / methodology that enable quicker turnaround on analysis Brainstorm, structure and create problem solving processes for a range of strategic and tactical customer-facing topics (e.g., identifying fraud applications, cross-selling mortgages, features on prepaid card, digital ID solutions, etc.) Enable ongoing understanding of customers through design and maintenance of executive dashboards and metrics Perform ad-hoc analysis for various business units Manage cross-functional collaboration & team development (30%) Facilitate cross-functional collaboration by leading a diverse team of analytics resources to deliver quality analysis, interpretation of findings and clear articulation of results and insights to internal business partners Support Payments in assessing product features and customer needs to determine prioritization of features for Minimum Viable Product (MVP) and future build Support Product in assessing performance & developing better understanding of customer adoption through A/B testing Support Marketing, Customer Experience (CX) and Contact Center in planning & evaluating marketing campaigns and meeting their customer insights needs Support Fraud & AML by optimizing rule performance and improving customer experience Potentially manage 1 – 3 direct reports, including skills development, mentoring, career growth through regular structured and ad-hoc feedback 8+ years’ work experience in Analytics, Strategy, Data Science roles, ideally in Financial services Bachelor’s degree in Engineering, Computer Science, Commerce, Management. MBA or other graduate degree a plus Minimum 4 years of people management experience Strong business acumen and passion for understanding and solving problems for consumers of financial services using rigorous data-driven methods and advanced analytical approaches Subject Matter expert at building, modifying, and running Excel based business scenarios and predictive models (able to teach others) Experience synthesizing analyses and preparing power point presentations for C-Suite level executives or Board of Directors Strong understanding of the financial services landscape, particularly with respect to retail banking, card programs, and marketing analytics Experience, confidence, and maturity managing internal stakeholders across all levels of the organization, including VPs, SVPs, and CEO Experience leading projects and managing tasks of more junior team members, as well as supporting their growth and development Expert in MS Office (Excel, Access, PowerPoint), MySQL, Tableau, Python / R, and statistics (regression analysis, correlations, etc.) Strong attention to detail and time management skills Good verbal and written communication skills Project management experience 
ScrapedJobID1450:
Architecture the design and drive the development of highly robust, scalable and real-time machine learning platforms Build new features and tools for machine learning models and data scientists that help to amplify their effectiveness Drive efficiencies through automation and optimization Drive and uphold high engineering standards and best practices Collaborate with business leaders, subject matter experts, product managers, machine learning modelers etc. to solve interesting and highly impactful business problems 2+ years of software development experience Experiences in architecting scalable and low latency services A bachelor’s degree (or above) in computer science or related field is very helpful but we are open to be convinced that you are an exception Strong grasp of Computer Science fundamentals Strong ownership coupled with strong teamwork and collaboration A background in Machine Learning is preferred but not required The ability to clearly communicate complex results to technical and non-technical audiences and stakeholders (PMs, Operations, Engineers). Healthcare coverage Retirement Plans Employee Stock Purchase Program Wellness perks Paid parental leave Paid time off Learning and Development resources Healthcare coverage Retirement Plans Employee Stock Purchase Program Wellness perks Paid parental leave Paid time off Learning and Development resources 
ScrapedJobID1451:
Stay abreast of innovations and publications in the field of operations research and business intelligence systems. Research and solve complex scheduling, resource allocation and pricing scenarios involved in operations optimization. Analyze raw operational data and design algorithms that can automatically and consistently generate operational recommendations for clients. Contribute to the invention of novel solutions to client’s operational problems by collaboratively working with product managers, co-developers, and our client success team. Utilize efficient algorithm design in a parallelized fashion capable of crunching gigabytes of operations data in minutes and scaling up with client growth. Build dashboards that transform operational data into visualizations that are intuitive and actionable Contribute refinements to our existing product through the development of new features as well as refactoring existing code to make it more efficient and object-oriented. Advance your knowledge of new software tools, agile programming methods, business intelligence technologies and share your knowledge with the development team, thus catalyzing process / technology changes to help us be more effective. Languages: C#, JavaScript, TypeScript Frameworks: .NET Core, Angular Web Server: IIS, NGINX Databases: MS SQL, Azure SQL Infrastructure: Azure, Docker, Kubernetes, GitLab Logistics engine: algorithms for discrete optimization problems Operation Systems: Windows, Linux Development Processes: Agile, CI/CD 2+ years of experience in Software Development, preferably with high performance algorithms or data intensive applications. A deep and intuitive understanding of Algorithms and Data Structures. Ability to process, assimilate, and explain complex and abstract concepts from research publications. Operations Research or Management Engineering Mathematical Optimization Data Science / Machine Learning Master’s Degree or PhD in Applied Mathematics/ Management Science/ Operations Research/ Computer Science / Engineering, or related technical discipline. Base salary of $80K - $115K + performance-based bonus or stock options Work-Life Balance: Flex time, work from home days and travel incentives. Set-up: Standing / adjustable desks, massage chair & quiet rooms, employee lounge with Xbox, Switch & PS4. Benefits Plan: Fitness allowance, dental/prescription/vision, massage & physio, and healthcare spending account. Food & Fun: Fully stocked kitchen, fancy coffee machine, team lunches, long weekend bottle draws and monthly employee events. 
ScrapedJobID1452:

ScrapedJobID1453:
Manage and contribute to the delivery of reporting and analytics solutions, mainly in Looker Understand business needs and technical requirements to meet those needs Lead and develop your team of analysts Set and achieve challenging goals for yourself and your team (OKRs) Foster a culture of data-driven decision making throughout the company Keep up with the latest data industry tools and techniques Top-notch communication (verbal and written) and interpersonal skills Excellent math and statistical analysis skills Proficiency in the presentation and visualization of numbers and statistical data Ability to understand business imperatives and drivers, find relevant data correlations, and create processes by which the data correlations are translated to information flows that help drive the business 5+ years developing and coaching analytics teams 5+ years of quantitative analysis work experience 5+ years of experience handling, manipulating and analyzing data and creating analytical reports Strong expertise with an SQL language, database structures, and data lake architectures Experience with Looker Experience with Snowflake Proficiency with Python An understanding of the principles, tools, and processes of data science Post-secondary education in a technical field, or B.S./M.S. 
ScrapedJobID1454:
You love wrangling data to create performant streaming data that feeds Machine Learning models You enjoy straddling the worlds of Data Science and Developer, and when reviewing a Jupyter Notebook you find yourself drawn more to how to efficiently implement the solution space for product (even though the research is amazing) You love building tools for yourself to make working with Machine Learning solutions in production easier to troubleshoot You love to keep on top of the latest and greatest in technology, and are able to be opinionated on which are winners, and which are hype You’re a strong believer in Continuous integration, and the DevOps mindset You think it is critical to understand of how your software runs on infrastructure in detail, and are experienced in how it should be designed You like working in teams, mentoring, and sharing neat things you come across enjoy Design, develop, and support production grade streaming Machine Learning pipelines and solutions, including the areas of fast and efficient data processing, fault-tolerance, scalability Work closely with a Data Science team focused on the research aspects, and comprehend, design, and implement the path to product Drive the surrounding Machine Learning technology eco-system to support our product and workflows Work closely with product management, QA, and Support to build and support product Analyze, scope, review, and estimate development activities Be the subject matter expert of your ownership areas of the product Participate in evolving the team’s processes so we’re efficient, and loving what we do Mentor less experienced team members 2 years experience with building efficient and scalable data pipelines feeding Machine Learning models (including efficient and scalable preprocessing, training path, inference path, graceful degredation, dirty data mitigation) 2 years of experience with scalable data processing technologies (i.e. Spark, Flink, Apache Beam) 3 years of experience developing advanced Python using Object Oriented techniques, Modules (i.e. more than scripting) Experience with the Machine Learning Life-Cycle (i.e. scoping, data review, data processing, feature extraction, model development, testing, troubleshooting, performance monitoring) Experience with Tensorflow, or equivalents Multiple releases of your code deployed live and having to support it with customers at arms length Experience developing streaming data analytics including the storage and access challenges at scale and in production Clear verbal and written communication and the ability collaborate effectively in a geographically dispersed working environment Experience with Data Lake design, implementation, and life-cycle combining multiple disseparate types of data Advanced experience with the whole life-cycle of Python dependency management strategy across multiple repositories Experience with at least once IaaS provider Experience with the Power Systems domain and the software that manages it Knowledge, skills, and professional networking in one of the most exciting and positively impactful technology domains that is an intersection of machine learning, data science, electrical engineering, and software Startup experience and ground floor opportunities for growth in a team that includes PhD Smart Grid Engineers, Data Scientists, recent grads, and seasoned business professionals Competitive compensation High quality of life and career in Canada's National Capital Region Working on a team with a serious approach towards our work, rather than ourselves, together with fun and random team events such as Ice Cream Fridays and Cosmological Lunches. You will get the opportunity to come up with one 
ScrapedJobID1455:
Design and deployment of n-tier application and security design, documentation, and configuration for medium and large corporate implementations to the cloud. Coordinate the development and integration of large enterprise applications, Software defined storage, infrastructure, virtualization, technology roadmap, data architecture roadmap, data product roadmap. Direct cooperation with development teams on providing guidance about product development, roadmap and backlog Enhance platform capabilities, including data processing task automation, integration and deployment of analysis pipelines for internal use Knowledge and practical experience in data products development, that includes data processing and modelling techniques, tools, metadata structures, data lakes, and data dictionaries. BS/BA in computer sciences, mathematics, life sciences or related degrees Graduate degree in Data Science or other quantitative field is preferred Practical (ie. development) and conceptual (on the solution architecture level) knowledge and relevant experience on the front-end application development and integration with 3rd party tools and platforms (eg. Tibco Spotfire, Tableau, etc.) Product Ownership experience and skills, ie. ability to work directly with business users to determine the product direction and backlog Ability to translate business requirements into functional requirements Ability to perform Solution Architect role for web-based applications (both JS and TS) in the cloud environment Experience with AWS cloud infrastructure services Defined standards and lead implementation of software development processes Strong SAAS skills Monday to Friday front-end application development: 5 years (preferred) AWS cloud infrastructure service: 5 years (preferred) SaaS: 5 years (preferred) 
ScrapedJobID1456:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1457:
Deploy machine learning solutions to improve Skype/Teams real-time collaboration quality and reliability Design, develop, and own components, tools, platforms, and systems for real-time media communication and collaboration. Drive independent investigations resulting in shipping product code, patents, and publications. Ph.D. in Computer Science, Mathematics, Physics, Electrical Engineering, or Masters plus equivalent work experience Minimum 7 year experience in professional software development 3+ years C/C++ coding, design and testing in a production environment Comfortable with Python or other scripting for rapid prototyping. Minimum of 1 years of experience in machine learning using tools like TensorFlow/Pytorch/Scikit-learn, etc. Strong system development skills, with a long-range system view that leverages development ranging from rapid research prototypes to carefully architected complex systems Excellent inter-personal skills and ability to work well in a scrum team. Experience developing and testing code in large codebases Experience developing production applications for the edge/IoT is a strong plus 
ScrapedJobID1458:
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. 2+ years of non-internship professional software development experience Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design Bachelor’s degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline 1+ years of experience as a data/software developer/scientist or related technical job A passion for improving customer experience Excellent verbal and written communication skills and technical writing skills Graduate degree in a related technical field 2+ years of experience as a data/software developer/scientist or related technical job Experience with Agile Development Experience with statistical modeling or machine learning (Classification, Collaborative Filtering) Experience with AWS services A love of music! 
ScrapedJobID1459:
Architect implementation of scalable AI and machine learning algorithms Write efficient, performant, and maintainable code in Java, Kotlin, C/C++, Go, and/or SQL Efficiently store and retrieve large volumes of data for ML training and algorithm development Develop feature processing for machine learning models in TensorFlow and others Implement processing algorithms on real-time sensor data Collaborate closely with data scientists to invent algorithms Sense, understand, and derive insight into human motion while exercising Deliver personalized real-time feedback Dynamically adjust resistance to optimize training effectiveness and safety BS or higher degree in engineering field or equivalent experience Strong knowledge of Python and one of Java, C/C++, Kotlin, or Go Experience with databases, SQL or NoSQL Experience with signal processing or machine learning algorithms Team player with high integrity Open to feedback and constantly striving to improve High degree of self-awareness Experience with gyros and accelerometers, computer vision, machine learning, or control theory 
ScrapedJobID1460:
Developing NLP systems that help us structure and understand biomedical information and patient records Using a variety of structured and unstructured data sources Imagining and implementing creative data-acquisition and labeling systems, using tools and techniques like crowdsourcing and novel active learning approaches Working with the latest NLP approaches (BERT, Transformer) Training your models at scale (Horovod, Nvidia v100s) Employing and iterating on scalable and novel machine learning pipelines (Airflow on Kubernetes) Reading and integrating state of the art techniques into Fathom's ML infrastructure such as Mixed Precision on Transformer networks 5+ years of development experience in a company/production setting Experience with deep learning frameworks like TensorFlow or PyTorch Industry or academic experience working on a range of ML problems, particularly NLP Strong software development skills, with a focus on building sound and scalable ML A real passion for finding, analyzing, and incorporating the latest research, technologies and techniques directly into a production environment Good intuition for understanding what good research looks like, and where we should focus effort to maximize outcomes Developed and improved core NLP components and not by just 'grabbing things off the shelf' Led large-scale crowd-sourcing data labeling and acquisition (Amazon Turk, Crowdflower, etc.) 
ScrapedJobID1461:
Work with senior leadership to architect Wayfair’s Machine Learning platforms and ensure that we deliver the right functionality, in a timely manner Leverage your deep knowledge of distributed systems engineering to build Wayfair’s next generation Machine Learning capabilities Design scalable systems using Python, Go, Kubernetes, Kafka, GCP, Airflow, and other technologies Think outside of the current technology/stack limitations to push the boundaries on what is possible and deliver feasible solutions collaboratively Champion open source solutions and Google Cloud native technologies, and their application to our use cases Develop end to end software solutions that power the full range of Machine Learning initiatives at Wayfair Partner with product leaders to understand technical pain points for data scientists and other engineers and translate them into clear and robust engineering solutions Promote a culture of engineering excellence and strengthen the technical expertise of our engineering and product teams 3+ years of experience in software engineering and designing systems at scale 1+ years of experience in Linux-based development, and Python development while leading engineering teams Strong understanding of containerization (Docker, etc.), and associated software engineering best practices Excellent communication skills with demonstrated experience driving teams forward and ability to influence technical decisions to line up with the company’s strategy Hands-on experience driving software development within high-growth environments at scale Excellent organizational, analytical, and hypothesis- driven critical thinking skills to transform data into actionable insights Mix of start-up and large-company experience working on Machine Learning solutions Familiarity with Machine Learning platforms offered by Google Cloud and how to implement them on a large scale 
ScrapedJobID1462:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID1463:
real-time visibility on how Ubisoft titles are played; an understanding of the habits and preferences of the people playing them. Design, prototype, build and maintain APIs, tools, code and a scalable infrastructure for operating Merlin's machine learning pipeline at scale. Synch up with your team to discuss work-in-progress, ideas, and blockers; plan and prioritize; overcome issues; etc. Be a key member of the team, participate in the decisions and implementations to improve the platform’s quality. Work closely with Data Scientists to design and implement the optimal environment for their maximized efficiency. Advocate for automation and monitoring at all steps of the ML pipeline and help to define best practices based on personal industry experience and research. Stay current on technological advancements to help develop yourself, the platform and position Ubisoft as a leader of the domain. Experience in Software/Data engineering (or related experience). Experience with modern infrastructure, tools and cloud technology (e.g. AWS, EMR, Docker, Kubernetes, Terraform, etc.). Knowledge of Python, Java. Experience with big data technologies, like Kafka, S3, Spark, and Hive. Experience building and interacting with REST APIs. Familiar with GitLab and its CI/CD tool. A constant desire to grow and learn. Strong communication and collaboration skills. Ability to navigate between the big picture and the micro details. You love being responsible for owning and improving a new, fast-growing platform. You are curious and like asking questions until you fully understand why/what you are doing. A desire to see teammates succeed together. Experience with maintaining architectures for end-to-end Machine Learning in the cloud. Familiarity with industry standards such as MLFlow, Airflow... Knowledge of additional programming languages like Scala. Exposure to automated testing and CI/CD in the ML context. Good understanding of ML concepts. An understanding of the video game industry. Your CV, highlighting your background and skills 
ScrapedJobID1464:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID1465:

ScrapedJobID1466:
Work on ROCm stack packaging solution for individual and enterprise level deployment on distributed cloud infrastructure Debug Machine Learning/ High Performance Computing related issues on Radeon Open Compute Stack (ROCm) Develop test contents for sophisticated Machine Learning algorithms on distributed nodes Port High Performance computing application on ROCm Reproduce field defects and develop appropriate tests to prevent future issues. Design, develop and deploy testing tools and automation libraries vital to perform testing. Be responsible for the adoption of tooling and industry standard methodologies by means of advocacy and outreach to help our development communities’ level up. Languages: Python, C, C++, Linux Shell scripting. Frameworks/Libraries: TensorFlow, PyTorch, ONNXRT Tools: Prior experience with Linux, Docker, LLVM compilers, GNU make /CMAKE, Jenkins, Git/Gerrit Understanding of High-Performance Computing application, Machine learning and GPU Programming, MPI Parallel Programming 
ScrapedJobID1467:
Réaliser le développement des rapports et tableaux de bord dans le respect des Modifier les rapports et tableaux de bord existants afin de répondre aux besoins Effectuer les essais et l"assurance qualité des développements avant la mise en Assurer la performance des rapports et tableaux de bord développées Assurer le support de premier niveau des produits informationnels Travailler en étroite collaboration avec les équipes de gestion de l"information afin Assurer le lien avec l"équipe de l"entrepôt de données afin de spécifier les besoins et Participer au profilage des données des systèmes sources Tester les extractions et les requêtes afin d"assurer la qualité des données Créer des tables de faits, de dimensions, et des vues pouvant être utilisées dans les Créer des champs calculés directement dans les bases de données pour supporter Participer aux discussions et aux ateliers de gouvernance Proposer et utiliser les définitions et le lexique d"entreprise Assurer la conformité et l"alignement des indicateurs clefs de performance Recueillir les besoins d"affaires et ceux des clients et utilisateurs Organiser et conduire des séances de travail afin de développer et proposer des Effectuer l"analyse détaillée des besoins et rédiger les spécifications détaillées afin de Participer et conduire des réunions et des revues d"avancement des projets avec les Analyser, cartographier et schématiser les systèmes et les processus d"affaires Créer et supporter la mise en place d"une architecture des données Proposer les meilleures solutions possibles afin d"atteindre les objectifs de l"unité Proposer des indicateurs clefs de performance pertinents Rédiger la documentation des produits informationnels afin d"en permettre une Supporter le déploiement du portail web pour la diffusion des différents rapports et Mettre en place une structure temporaire pour le traitement et la transformation des Supporter l"automatisation des tâches de rafraichissement des données, des rapports Proposer et développer des solutions numériques afin de permettre le suivi des Participer aux initiatives en science des données (apprentissage machine, prévision, Diplôme universitaire en génie, en science informatique, en intelligence d"affaires ou en Diplôme universitaire de 2e cycle en intelligence d"affaires, en science des données, ou Idéalement 1 à 4 ans d"expérience, mais ouvert aux nouveaux diplômés Maîtrise du français et de l"anglais parlé et écrit Expérience de travail dans le secteur manufacturier ou aérospatial un atout Maîtrise de la suite Microsoft 365 Maîtrise avancée du logiciel Power BI Bonne compréhension des besoins d"affaires, des systèmes et des architectures dans un Expérience dans le développement et l"utilisation de modèles relationnels et Bonnes connaissances SQL (fonctions de fenêtre, requêtes imbriquées, tables Expérience de programmation dans un contexte d"analyse de données (ex. VBA, Python, Connaissances de base de SAP, PLM, Jupyter et HDFS un atout Connaissance de la méthodologie agile Connaissance des plateformes en gestion de projets et partage de codes (ex. Azure Le poste est présentement offert en télétravail. Un retour au bureau sera possible lorsque L"horaire de travail est flexible Une analyse de cas sera demandée aux candidats présélectionnés afin de valider les Develop reports and dashboards in compliance with Modify existing reports and dashboards to meet needs Perform tests and quality assurance of developments before implementation Ensure the performance of reports and dashboards developed Provide first level support for information products Work closely with information management teams to Liaise with the data warehouse team in order to specify the needs and Participate in the profiling of data from source systems Test extractions and queries to ensure data quality Create tables of facts, dimensions, and views that can be used in Create calculated fields directly in the databases to support Participate in governance discussions and workshops Propose and use the definitions and the business lexicon Ensure compliance and alignment of key performance indicators Collect business needs and those of customers and users Organize and lead working sessions in order to develop and propose Perform detailed needs analysis and write detailed specifications in order to Participate and lead meetings and project progress reviews with Analyze, map and map systems and business processes Create and support the implementation of a data architecture Propose the best possible solutions in order to achieve the objectives of the unit Propose relevant key performance indicators Write the documentation of information products in order to allow Support the deployment of the web portal for the distribution of the various reports and Set up a temporary structure for the processing and transformation of Support the automation of data refresh tasks, reports Propose and develop digital solutions to allow the monitoring of Participate in data science initiatives (machine learning, forecasting, University degree in engineering, computer science, business intelligence or 2nd year university diploma Ideally 1 to 4 years of experience, but open to new graduates Fluency in spoken and written French and English Work experience in the manufacturing or aerospace sector an asset Proficiency in the Microsoft 365 suite Advanced knowledge of Power BI software Good understanding of business needs, systems and architectures in a Good SQL knowledge (window functions, nested queries, tables Programming experience in a data analysis context (eg VBA, Python, Basic knowledge of SAP, PLM, Jupyter and HDFS an asset Knowledge of agile methodology Knowledge of project management and code sharing platforms (eg Azure The position is currently offered by telecommuting. A return to the office will be possible when The work schedule is flexible A case analysis will be requested from shortlisted candidates in order to validate the 
ScrapedJobID1468:
Diriger et gérer une équipe de spécialistes des sciences de la parole et des données : Planifier, coordonner et gérer l'équipe, y compris la dotation en personnel et la productivité des projets, la gestion des performances et le développement de carrière. S'assurer que les rapports directs sont formés sur leurs rôles, utilisent les meilleures pratiques alignées sur les disciplines mondiales de Nuance Professional Services, et réalisent des performances conformes aux normes de qualité de Nuance et aux attentes de nos clients. Vous comprenez parfaitement les compétences et les lacunes de l'équipe, et vous formez et encadrez les membres de l'équipe en conséquence. Agir en tant que contact d'escalade pour les rapports directs et s'associer avec d'autres membres du personnel de Nuance (tels que les gestionnaires de programmes, les responsables des ventes, etc.) et / ou le personnel du client pour résoudre les risques et les problèmes. Servir en tant que Professional Services Account Manager ou Project Manager et / ou Subject Matter Expert (SME) pour les clients assignés et / ou pour les clients assignés aux membres de l'équipe selon les besoins ou la demande. Soutenir les efforts de vente et fournir une planification stratégique et tactique de la rétention et de la croissance des comptes, selon les besoins ou les demandes. Identifier les besoins et les opportunités d'améliorer les meilleures pratiques existantes et aider à documenter les résultats, les approches et les stratégies éprouvées. Travailler avec d'autres chefs d'équipe pour favoriser les meilleures pratiques inter-équipes et l'adoption de celles-ci dans le cadre du programme de discipline globale de Nuance pour les disciplines Speech & Data Science et Analytics & Optimization. Déplacements limités sur les sites des clients pour présenter les résultats des comptes clés et des pratiques. Un diplôme universitaire de quatre ans est requis, de préférence un diplôme en ingénierie, en informatique, en linguistique ou dans un domaine connexe. 10 ans et plus Dix ans ou plus d'expérience avec : Les processus de science de la parole et des données, y compris le développement de grammaires NLU et de dialogue dirigé et les approches et outils de science des données. Les processus et les missions de conseil en technologie, de service à la clientèle, de commerce électronique et d'analyse et d'optimisation des applications. Trois ans ou plus d'expérience dans la gestion de personnes ou d'une équipe, y compris des compétences en matière de leadership et la capacité à encadrer les autres. Une vision globale et analytique, avec la capacité de comprendre et d'interpréter les buts et les objectifs des clients et de relier les solutions et/ou les recommandations à la façon dont elles amélioreront les résultats commerciaux et apporteront de la valeur (y compris l'encadrement des autres sur la façon de le faire). Capacité avérée à comprendre et à résoudre des systèmes et des problèmes techniques complexes, y compris ceux qui impliquent des interactions automatisées, des rapports et des analyses, ainsi que la capacité à traduire les résultats en impact commercial de manière claire et crédible afin d'orienter les parties prenantes du client vers le meilleur plan d'action. Connaissance des solutions vocales, de l'assistant virtuel, du chat en direct, des solutions sortantes, de la sécurité et de la biométrie, ainsi que de leurs cas d'utilisation et de leurs avantages dans le domaine de la vente et des soins aux entreprises. Vous avez démontré votre capacité à travailler avec des clients stratégiques complexes et omni-canaux. Capacité à définir les problèmes, à examiner les données, à établir les faits et à tirer des conclusions valables. Compréhension des indicateurs clés de performance (KPI) des applications de soins et de vente aux entreprises et des centres de contact. Connaissance des mathématiques, des statistiques et des principes de la finance afin d'interpréter les données (ou d'encadrer d'autres personnes) et connaissance avancée et application de techniques efficaces de reporting et de visualisation des données. Capacité à établir des priorités et à mener plusieurs tâches de front, avec des compétences organisationnelles clairement démontrées et une capacité avérée à accomplir des tâches avec un minimum de supervision et de direction. Excellentes compétences en matière de communication (écrite et orale), y compris en matière de présentation de groupe à tous les niveaux, y compris au niveau des cadres supérieurs, en interne et avec les clients finaux. Compétences avérées en matière de gestion de la clientèle, y compris au niveau des chefs de projet et des cadres supérieurs. Compréhension technique du cycle de vie du développement logiciel et des méthodologies (waterfall, agile, etc.). Connaissance de Microsoft Office, y compris la capacité à communiquer des données et des idées complexes à l'aide de PowerPoint, Excel, Visio, etc. Lead and manage a team of Speech & Data Scientists:
Plan, coordinate, and manage the team, including project staffing and productivity, performance management and career development.
Ensure direct reports are trained on their roles, utilize best practices aligned to Nuance Professional Services Global Disciplines, and perform to the quality standards of Nuance and the expectations of our clients.
Build a deep understanding of the skills and skill gaps within the team, and train and mentor team members accordingly.
Act as an escalation contact for direct reports and partner with other Nuance staff (such as Program Managers, Sales Executives, etc.) and / or customer staff to resolve risks and issues. Plan, coordinate, and manage the team, including project staffing and productivity, performance management and career development. Ensure direct reports are trained on their roles, utilize best practices aligned to Nuance Professional Services Global Disciplines, and perform to the quality standards of Nuance and the expectations of our clients. Build a deep understanding of the skills and skill gaps within the team, and train and mentor team members accordingly. Act as an escalation contact for direct reports and partner with other Nuance staff (such as Program Managers, Sales Executives, etc.) and / or customer staff to resolve risks and issues. Serve as a Professional Services Account Manager or Project Manager and / or Subject Matter Expert (SME) for assigned clients and / or for clients assigned to team members as needed or requested. Support sales efforts and provide strategic and tactical account retention / growth planning as needed or requested. Identify needs and opportunities to improve existing best practices and assist in documenting proven findings, approaches, and strategies. Work with other team leaders to drive cross-team best practices and adoption of those as part of Nuance’s Global Discipline program for the Speech & Data Science and Analytics & Optimization disciplines. Limited travel to client sites to present key account and practice findings. 10+. Ten or more years of experience with:
Speech & Data Science processes including NLU and Directed Dialogue grammar development and Data Science approaches and tools.
Technology consulting, customer care, eCommerce, and application analysis and optimization processes and engagements. Speech & Data Science processes including NLU and Directed Dialogue grammar development and Data Science approaches and tools. Technology consulting, customer care, eCommerce, and application analysis and optimization processes and engagements. Three or more years of experience managing people or a team including leadership skills and the ability to mentor others. Big picture, analytical thinker, with the ability to understand and interpret customer goals and objectives and tie solutions and / or recommendations back to how they will improve business results and deliver value (including coaching others on how to do this). Demonstrated ability to understand and troubleshoot complex technical systems and issues including those that involve automated interactions and reporting and analytics coupled with the ability to translate findings into business impact in a clear and credible manner to guide customer stakeholders toward the best course of action. Knowledge of Voice, Virtual Assistant, Live Chat, Outbound and Security and Biometrics solutions and their use cases and benefit drivers within the Enterprise care / sales space. Demonstrated success in working with complex, omni-channel strategic clients. Ability to define problems, review data, establish facts, and draw valid conclusions. Understanding of Enterprise care and sales application and contact center Key Performance Indicators (KPIs). Knowledge of mathematics, statistics, and principles of finance to interpret data (or coach others) and advanced knowledge and application of effective reporting and data visualization techniques. Ability to prioritize and multi-task with clearly demonstrated organizational skills and proven capability to perform duties with minimal supervision and direction. Excellent Communication skills (written and oral) including group presentation skills across all levels, including Sr. Executive levels both internally and with end customers. Demonstrated customer facing / customer management skills including those at the Project Manager and Executive levels. Technical understanding of the software development lifecycle and methodologies (waterfall, agile, etc.). Knowledge of Microsoft Office, including the ability to communicate complex data and ideas using PowerPoint, Excel, Visio etc. 4-year university degree is required, preferably a degree in engineering, computer science, linguistics, or a related field. Location is in the heart of downtown Montreal Flexible hours Transit reimbursement and parking Working with international teams to push the boundaries of technology Competitive benefit package 4 weeks’ vacation 10 paid sick days Bonus Plan, Group RRSP, Deferred Profit Sharing Plan, Employee Stock Purchase Plan Canada's Top 100 Employers – 7 consecutive years Montreal’s Top Employers – 6 consecutive years Canada's Top Employers for Young People - 3 consecutive years 
ScrapedJobID1469:
We’re a technology company delivering next generation tools to accelerate and simplify remarketing. We’re an analytics company leveraging data to inform and empower our customers with clear, actionable insights. And we’re an auction company powering the world’s most advanced and integrated mobile, digital and physical auction marketplaces. Can think for themselves and discover new and insightful ways to solve difficult problems without having a clear roadmap laid out Can communicate effectively with data science teammates and non-technical audiences alike Can deliver quality code in an Agile framework that ships to a production environment Has confidence, hustle, energy, and drive – accountability is key and the impact of your work is crucial to our success Build machine learning engineering systems required to efficiently operate our data science services (including computer vision, recommendations, and optimization systems) Partner with our data scientists and site reliability engineers to improve model performance Own the architecture decisions and implementation details for specific data science services that you will have responsibility over Work in an Agile environment with team members, delivering solutions quickly and continuously exploring ways to improve our results Work closely with colleagues in Product, Operations, and Sales to structure problems and understand the impact across various departments within the company Candidates tend to have at least a Bachelor's Degree in a quantitative field Significant experience (roughly 5 years) in a Data Science or Data Engineering position, specifically in building data science products and services in a production environment Experience designing and implementing machine learning models that are production-ready Familiarity with designing and implementing neural networks for computer vision models Experience coding with Python and SQL Experience with developing within an Amazon Web Services environment Familiarity with the Agile framework for software delivery 
ScrapedJobID1470:
Interacts with business stakeholders to gather business requirements Translates business requirements to technical specifications Be responsible for building dashboards and other tools required to automate manual work and make data-driven insights available to workers throughout the organization. Designs, builds and deploys BI solutions Maintains and supports data analytics platforms Creates tools to store data (e.g., OLAP cubes) Conducts unit testing and troubleshoots and remedies defects Collaborates with Prophix teams to integrate systems Develops and executes database queries and conducts analyses Creates visualizations and reports for requested projects Assist with Project Management duties including managing project timelines, budget, and providing regular status updates to clients Provide documentation for delivered solution Design and deliver end user training sessions Validate the quality and integrity of the data included in all reporting Work independently as the senior analyst / expert and may provide technical support to others Maintain expert knowledge of all main data sources for the data used within the business unit and ability to effectively utilize these data sources for reporting purposes Ideally have or acquire knowledge of broader enterprise reporting platforms and data sources and ability to integrate data across the enterprise 3+ years working with relational and dimensional database management systems 3+ years’ experience working with SQL Server recent versions (2019, 2016) 3+ years implementing ETL processes, including platforms such as SQL Server Integration Services and Matillion, SQL, SSIS, SSAS, Azure Data Factory, Informatica, Power Query 3+ years implementing advanced visualizations for a wide variety of business audiences-executives, operational managers and customer facing teams 2+ years implementing Tableau, PowerBI, Domo or similar technologies 3+ years’ experience in information technology and/or systems development Bachelor’s Degree in Computer Science, Mathematics, Data Science, Informatics, Data Analytics, Engineering or a related field and approximately 2-4 years of related work experience Knowledge of broad scope of architecture, technology, tools, processes and procedures, as well as broader organization issues and technology Excellent communication, negotiation and organizational skills specifically including the ability to present architectural options in business terms to both IT and business staff including executives Excellent client focused consulting skills Experience implementing and managing a data platform on Snowflake or similar technologies Advanced T-SQL and MDX skills Excellent knowledge of the data warehouse, data lake and data lakehouse development lifecycle Experience with range of data visualization tools, for example: Tableau, Qlik, SSRS, Cognos Experience with data virtualization, data automation, data architecture Familiarity with Machine Learning and Artificial Intelligence concepts Must be legally entitled to work in the country where the role is located. Must be able to travel to the United States, Canada and/or internationally, and have a valid passport An equivalent combination of education and experience may also be considered Proficient in designing and/or building business intelligence systems which are highly secure, highly available and highly performing Accuracy and attention to detail Demonstrated ability to solve problems and improve processes using structured analysis and methods Strong communication, presentation and business and technical writing skills You have a passion to make a difference Share our values Enjoy having honest conversations, about real things, as real people Believe that creating great experiences is totally within their control Build positive relationships and an understanding of what people’s needs are See solutions and possibilities (not problems!) Are simply outstanding at what you do 
ScrapedJobID1471:
Democratizing data access across the organization and providing tools and training to support data-informed decisions Acquiring and synthesizing all relevant information about our ecosystem, our competitors, the HR and benefits landscape, and our users, to provide high quality strategic advice to decision makers at all levels of the organization Raising the quality of data in our system, including improving our data infrastructure and modeling, and utilizing a variety of research methodologies to understand our users and their experiences Build and lead a team of data analysts and engineers Take ownership of the current Zenefits data architecture and future roadmap (including Snowflake, Looker, dbt, Fivetran) Work with data analysts to drive insights through dashboards, reports, and modeling (Marketing attribution models, churn prediction, account health, product analytics, etc) Work cross-functionally with product leaders to define KPIs and measure metric categories including adoption, engagement, and retention. Evangelize the use of data tools and best practices and ensure stakeholders' analytic needs are being met Enforce & maintain data governance throughout the organization Communicate results directly with senior management at Zenefits 5+ years working in business analytics or data science 3+ years experience with cloud data warehouses such as Snowflake, BigQuery and Redshift and ETL pipeline tooling such as Fivetran, dbt, Airflow 2+ years experience with Looker and/or similar self-service BI tools (e.g. Tableau) Experience in a startup data environment; exposure to common tools is a plus (Google Analytics, Salesforce, Marketo, Pendo, Segment, etc.) Experience synthesizing information and communicating takeaways to diverse audience Knowledge of traditional relational databases (MySQL) Expert level knowledge SQL with exposure to Jinja/Liquid a plus Enthusiasm for operating in a version-controlled (GitHub or similar) analytic code environment Practice data visualization and dashboard design best practices Familiarity with R (particularly the Tidyverse and Shiny) and/or Python (particularly Scikit-learn) is positive but not a requirement The ability to work remote and collaborate with a team that spans borders and timezones - we have clusters of employees in Vancouver, BC; San Francisco/Bay Area, CA; Tempe, AZ; and Bangalore, Karnataka, India if you happen to live in one of those areas Competitive, market-based pay, based on your experience, abilities, impact, and geographic region - just ask us the range for your location Solid benefits package including 401(k), medical, dental, vision, disability, life, and more for our US employees and a comprehensive ancillary package for our Canadian employees Generous time off including holidays, vacation, sick, civic, and volunteering time off The opportunity to build solutions that help drive small business success stories Boundless opportunities for professional growth and leadership across a global organization 
ScrapedJobID1472:
Take a hands-on role in several projects, including the Fundamental Review of the Trading Book (FRTB), data solutions for capital optimization, and data quality control processes. Prototype new approaches and enhance existing methodologies to advance market data management and data quality control. Develop production level code and collaborate with IT team for integration into daily bank processes. Assist team members for various ad-hoc analyses, data methodology, documentation, reporting, preparation of materials. Execute model runs on a regular basis for reporting and perform corresponding analyses. Communicate with model developers, trading desks, risk teams, and business lines to enhance data quality control and data management for capital optimization Become an active member of the team including our D&I initiatives and communities. Solid quantitative background and problem-solving skills with a keen interest in Data Science, Finance, Economics, Market Risk, Derivatives Pricing, Risk management or Regulations. Advanced degree in a mathematics, economics, or scientific discipline (e.g., Mathematics, Finance, Statistics, Physics, Engineering, Biology, Economics, etc.). Master’s degrees or PhDs are a bonus. Experience in code development in Python or other formal programing will be important to support day-day activity. Effective communication (written and oral), specifically the ability to summarize complex ideas in simple terms; you enjoy working in collaborations. The opportunity to join a forward-thinking company surrounded by a collaborative team of innovative thinkers. A rewarding career path with diverse opportunities for professional development. Internal development to support your growth and enhance your skills. A competitive compensation and benefits package. An organization committed to making a difference in our communities– for you and our customers. We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!

This position is located Downtown, Toronto. This is a contract role. 
ScrapedJobID1473:

ScrapedJobID1474:
Collaborate with our digital stakeholders to define KPIs, reporting requirements, and overall measurement strategy for our digital and mobile customer journeys Translate business requirements into technical specifications for custom digital analytics implementation using a combination of data layer, processing rules, SAINT classification, report suite configuration, custom JavaScript, JSON and applicable integrations with other systems Manage daily operations and implementation of TD's analytics stack (Adobe Analytics, Adobe Target, Adobe Audience Manager, Adobe Launch, Adobe Mobile Services, Ensighten) and 3rd party marketing tags (DoubleClick, Rakuten, Facebook, etc.) Develop and own all implementation documents such as SDR, Data Layer specifications, custom JavaScript Ensure the timely delivery and accuracy of documentation and technical coding (HTML, JavaScript, ActionScript) via our Tag Management System Collaborate with technology teams on implementation of analytics solutions, including guidance on data layer implementation and troubleshooting, data feeds and integrations with other systems Keep abreast of product updates (Adobe, Ensighten), best practices and proactively follow up with required changes in our implementation and appropriate communications Provide consultative service, training and validation support to quality assurance/testing teams. 4+ years' experience in analytics, with digital experience preferred 5+ years' experience of web development including JavaScript, jQuery and Angular Strong understanding of JSON structures and best practices Strong understanding of Native Mobile development standards Strong understanding of JavaScript & Node.js & DOM manipulation, web markup, including HTML5 and CSS3 Expertise with tag management tools (DTM, Adobe Launch, Tealium, Ensighten) and their configuration All-hands experience in implementing/troubleshooting/deploying the Adobe stack, Google 360 and/or 3rd party marketing tags using DTM or Adobe Launch or Ensighten Expert level knowledge in developing Adobe Analytics Solution Design Reference (SDR) Understanding of Adobe Analytics processing rules, SAINT classifications, report suite configuration, and data feeds Experience architecting a Data Layer Specification and guiding the development team on implementation and troubleshooting Experience debugging Adobe Analytics utilizing browser network calls, extensions, and tools such as Fiddler, Charles or Omnibug Ability to own and work independently on assigned deliverables, but also collaborate with multiple team members and stakeholders when necessary Solid communications skills – verbal and written Strong time-management skills and ability to work on multiple projects at once 
ScrapedJobID1475:
Develop the internal actuarial claims reserving function and ensuring on-going regulatory compliance Build, create, and implement sophisticated claims development models and other actuarial or predictive analytics Provide recommendations for and assist in the creation of reserve-based metrics to be monitored by the business Using research and development best practices, contribute with innovative approaches and propose effective solutions to meet the organization’s objectives Ensure alignment with the organization’s strategic direction and other administrative units, in a performance management context Provide leadership, coaching, training, and development opportunities to team members Understand our purpose and values, exploring opportunities for impact Minimum 6 to 8 years of Actuarial experience, ideally within the Property & Casualty insurance industry; corporate actuarial or reserving experience preferred A Fellow from the Canadian Actuarial Society (FCAS) or equivalent Master’s / Bachelor’s Degree in Actuarial Science, Statistics, Math or Data Science Some leadership experience preferred Solid technical knowledge and programming skills with experience using modern predictive modelling techniques (i.e. GLM, GAM, GBM) and creating models from scratch Excellent analytical, quantitative and critical thinking skills, with the ability to conduct detailed analysis of information, and implement best solutions in a timely manner 
ScrapedJobID1476:
Deploy machine learning solutions to improve Skype/Teams real-time collaboration quality and reliability Design, develop, and own components, tools, platforms, and systems for real-time media communication and collaboration. Drive independent investigations resulting in shipping product code, patents, and publications. Ph.D. in Computer Science, Mathematics, Physics, Electrical Engineering, or Masters plus equivalent work experience Minimum 7 year experience in professional software development 3+ years C/C++ coding, design and testing in a production environment Comfortable with Python or other scripting for rapid prototyping. Minimum of 1 years of experience in machine learning using tools like TensorFlow/Pytorch/Scikit-learn, etc. Strong system development skills, with a long-range system view that leverages development ranging from rapid research prototypes to carefully architected complex systems Excellent inter-personal skills and ability to work well in a scrum team. Experience developing and testing code in large codebases Experience developing production applications for the edge/IoT is a strong plus 
ScrapedJobID1477:
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. 2+ years of non-internship professional software development experience Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design Bachelor’s degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline 1+ years of experience as a data/software developer/scientist or related technical job A passion for improving customer experience Excellent verbal and written communication skills and technical writing skills Graduate degree in a related technical field 2+ years of experience as a data/software developer/scientist or related technical job Experience with Agile Development Experience with statistical modeling or machine learning (Classification, Collaborative Filtering) Experience with AWS services A love of music! 
ScrapedJobID1478:
Architect implementation of scalable AI and machine learning algorithms Write efficient, performant, and maintainable code in Java, Kotlin, C/C++, Go, and/or SQL Efficiently store and retrieve large volumes of data for ML training and algorithm development Develop feature processing for machine learning models in TensorFlow and others Implement processing algorithms on real-time sensor data Collaborate closely with data scientists to invent algorithms Sense, understand, and derive insight into human motion while exercising Deliver personalized real-time feedback Dynamically adjust resistance to optimize training effectiveness and safety BS or higher degree in engineering field or equivalent experience Strong knowledge of Python and one of Java, C/C++, Kotlin, or Go Experience with databases, SQL or NoSQL Experience with signal processing or machine learning algorithms Team player with high integrity Open to feedback and constantly striving to improve High degree of self-awareness Experience with gyros and accelerometers, computer vision, machine learning, or control theory 
ScrapedJobID1479:
Developing NLP systems that help us structure and understand biomedical information and patient records Using a variety of structured and unstructured data sources Imagining and implementing creative data-acquisition and labeling systems, using tools and techniques like crowdsourcing and novel active learning approaches Working with the latest NLP approaches (BERT, Transformer) Training your models at scale (Horovod, Nvidia v100s) Employing and iterating on scalable and novel machine learning pipelines (Airflow on Kubernetes) Reading and integrating state of the art techniques into Fathom's ML infrastructure such as Mixed Precision on Transformer networks 5+ years of development experience in a company/production setting Experience with deep learning frameworks like TensorFlow or PyTorch Industry or academic experience working on a range of ML problems, particularly NLP Strong software development skills, with a focus on building sound and scalable ML A real passion for finding, analyzing, and incorporating the latest research, technologies and techniques directly into a production environment Good intuition for understanding what good research looks like, and where we should focus effort to maximize outcomes Developed and improved core NLP components and not by just 'grabbing things off the shelf' Led large-scale crowd-sourcing data labeling and acquisition (Amazon Turk, Crowdflower, etc.) 
ScrapedJobID1480:
Work with senior leadership to architect Wayfair’s Machine Learning platforms and ensure that we deliver the right functionality, in a timely manner Leverage your deep knowledge of distributed systems engineering to build Wayfair’s next generation Machine Learning capabilities Design scalable systems using Python, Go, Kubernetes, Kafka, GCP, Airflow, and other technologies Think outside of the current technology/stack limitations to push the boundaries on what is possible and deliver feasible solutions collaboratively Champion open source solutions and Google Cloud native technologies, and their application to our use cases Develop end to end software solutions that power the full range of Machine Learning initiatives at Wayfair Partner with product leaders to understand technical pain points for data scientists and other engineers and translate them into clear and robust engineering solutions Promote a culture of engineering excellence and strengthen the technical expertise of our engineering and product teams 3+ years of experience in software engineering and designing systems at scale 1+ years of experience in Linux-based development, and Python development while leading engineering teams Strong understanding of containerization (Docker, etc.), and associated software engineering best practices Excellent communication skills with demonstrated experience driving teams forward and ability to influence technical decisions to line up with the company’s strategy Hands-on experience driving software development within high-growth environments at scale Excellent organizational, analytical, and hypothesis- driven critical thinking skills to transform data into actionable insights Mix of start-up and large-company experience working on Machine Learning solutions Familiarity with Machine Learning platforms offered by Google Cloud and how to implement them on a large scale 
ScrapedJobID1481:
Develop algorithms for deep learning, data analytics, machine learning, or scientific computing Construct and curate large problem specific datasets Analyze and improve performance of GPU implementations Collaborate with team members and other partners Publish state-of-the-art results on Github and scientific publications Keep up with the latest DL research and collaborate with diverse teams (internal and external to NVIDIA), including DL researchers, hardware and software engineers PhD or Master's Degree or equivalent experience 3+ years industry experience in Computer Science, Artificial Intelligence, Applied Math, or related field Strong Mathematical fundamentals and algorithms skills or experience Excellent programming, debugging, performance analysis, and test design skills Ability to work independently and manage individuals’ R&D efforts Good communication and documentation habits A Masters or PhD in Computer Science, AI, Applied Math, or related field 5 years of experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch, MXNet) Excellent C/C++ and Python programming skills GPU programming (CUDA or OpenCL) Experience doing performance analysis and tuning Exposure to HW architecture, ideally accelerators, and to numerical software Project management tools (e.g. JIRA, Git, Microsoft Project) 
ScrapedJobID1482:
real-time visibility on how Ubisoft titles are played; an understanding of the habits and preferences of the people playing them. Design, prototype, build and maintain APIs, tools, code and a scalable infrastructure for operating Merlin's machine learning pipeline at scale. Synch up with your team to discuss work-in-progress, ideas, and blockers; plan and prioritize; overcome issues; etc. Be a key member of the team, participate in the decisions and implementations to improve the platform’s quality. Work closely with Data Scientists to design and implement the optimal environment for their maximized efficiency. Advocate for automation and monitoring at all steps of the ML pipeline and help to define best practices based on personal industry experience and research. Stay current on technological advancements to help develop yourself, the platform and position Ubisoft as a leader of the domain. Experience in Software/Data engineering (or related experience). Experience with modern infrastructure, tools and cloud technology (e.g. AWS, EMR, Docker, Kubernetes, Terraform, etc.). Knowledge of Python, Java. Experience with big data technologies, like Kafka, S3, Spark, and Hive. Experience building and interacting with REST APIs. Familiar with GitLab and its CI/CD tool. A constant desire to grow and learn. Strong communication and collaboration skills. Ability to navigate between the big picture and the micro details. You love being responsible for owning and improving a new, fast-growing platform. You are curious and like asking questions until you fully understand why/what you are doing. A desire to see teammates succeed together. Experience with maintaining architectures for end-to-end Machine Learning in the cloud. Familiarity with industry standards such as MLFlow, Airflow... Knowledge of additional programming languages like Scala. Exposure to automated testing and CI/CD in the ML context. Good understanding of ML concepts. An understanding of the video game industry. Your CV, highlighting your background and skills 
ScrapedJobID1483:
Own and design data-focused product features start to finish, including user stories, specifications, quality control checks, and data dictionaries Collaborate with Data Scientists to find meaning in high volumes of data using statistical analysis in an approach that can be productized at scale Author high-quality design specifications within an agile methodology Support release and sprint planning to ensure product enhancements support customers at the right time and the right sequence Collaborate closely with a team of Data Scientists, Product Managers, and Engineering to design and deliver capabilities from prototype to scale, then iterate and enhance 3+ years of hands-on Product Management or related experience Experience working on statistical driven data products, such as productizing models Experience and focus on the elements critical to supporting data science-driven products - reliable inbound data, managing data gaps and variation, data cleansing, and data quality Experience implementing statistical models or machine learning algorithms and scaling to “productize” with production-ready insights Comfortable with SQL and/or Python Comfortable (and excited!) about ambiguity, breaking goals down into tangible and actionable work plans, and able to adapt quickly to the evolving requirements of new products Strong communication skills and ability to work across internal teams B.S. or M.S. in Applied Statistics, Mathematics, Computer Science, Machine Learning or another quantitative discipline Experience with prescription claims data Conveniently located in downtown Toronto Snacks, beverages, and weekly lunches from local restaurants Team events and rec league sports teams Allocations for continuous learning & development Health & wellness programs Weekly yoga classes Ping pong and other games 
ScrapedJobID1484:

ScrapedJobID1485:
Work on ROCm stack packaging solution for individual and enterprise level deployment on distributed cloud infrastructure Debug Machine Learning/ High Performance Computing related issues on Radeon Open Compute Stack (ROCm) Develop test contents for sophisticated Machine Learning algorithms on distributed nodes Port High Performance computing application on ROCm Reproduce field defects and develop appropriate tests to prevent future issues. Design, develop and deploy testing tools and automation libraries vital to perform testing. Be responsible for the adoption of tooling and industry standard methodologies by means of advocacy and outreach to help our development communities’ level up. Languages: Python, C, C++, Linux Shell scripting. Frameworks/Libraries: TensorFlow, PyTorch, ONNXRT Tools: Prior experience with Linux, Docker, LLVM compilers, GNU make /CMAKE, Jenkins, Git/Gerrit Understanding of High-Performance Computing application, Machine learning and GPU Programming, MPI Parallel Programming 
ScrapedJobID1486:
You will extract and cleanse large datasets: Integrate data across a variety of data stores / platforms (eg. DB2, SQL server, SAS and Hive) in a way that helps building advanced analytical models Leverage distributed computing tools (e.g. Spark, Hadoop) for analysis, data mining and modeling Explore data sourced from other environments including (but not limited to) the data lake; apply newly available data to pricing problems (ie. flow of funds, transcribed calls, network analytics data etc.) Internal and external data source evaluation You will design and build predictive models that explain the customer behavior over the product life cycle: Origination models such as response, utilization and attrition Portfolio management models such as renewal models, re-pricing models, credit limit optimization, balance transfer and campaign acquisition models Portfolio segmentation/customer sensitivity modeling Performing revenue optimization for a chosen portfolio. You need to understand business objectives, translate them into mathematical optimization problems, create profit function and recommend optimal pricing for each product Create and apply model and algorithm testing strategies to conduct multi-variate testing and A/B testing to measure effectiveness of models and make ongoing changes Model validation You will advance the Pricing team competency: Collaborate with business lines and other stakeholders and identify opportunities to drive business value and influence future pricing strategy by leveraging Data Science Provide subject matter expertise on predictive modelling, data mining, statistical analysis and machine learning to Pricing team internal customers Effectively communicate results of highly technical projects to business audiences You have excellent problem solving and analytical skills (previous experience in an analyst function is required) You have good communication skills, and you can translate complex technical information to a non-technical audience You have good time management skills and are able to meet timelines You have an analytical background (Applied Math, Statistics, Physics, Engineering, Computer Science) It would be great if you also held a Masters or PHD in mathematics, statistics or a related discipline You have strong programming skills, ideally in Python or R You have some experience SQL skills for querying relational databases (SAS, SQL Server, DB2, MySQL) You have strong theoretical knowledge and practical understanding of statistical analysis and predictive modeling Have experience with common statistical and machine learning libraries in Python, R, Spark (Keras/Tensorflow, Sklean) Are familiar with Cloud computing (Microsoft Azure or Google cloud) We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success! We provide you with the tools and technology needed to succeed You'll get to work with and learn from diverse industry leaders We offer a competitive total rewards package that includes a base salary, a performance bonus, company matching programs (on pension & profit sharing), 4 weeks of vacation, personal & sick days, paternity/maternity leave top-ups and much more. 
ScrapedJobID1487:
Build solutions for machine learning inference for AMD GPUs. Design and develop lower level system software that works with underlying libraries, runtime systems and hardware. Analyze and optimize solutions to achieve the highest performance. Test and deploy these solutions. Work with cutting-edge compiler technologies. Apply one's knowledge of software engineering best practices. Excellent C/C++ programming and software design skills including debugging, performance analysis, and test design. Experience developing software in Linux environment including commonly used tools. Basic understanding of Deep Learning. Bachelor's, Master's, or PhD or equivalent experience in Computer Science, Computer Engineering, or related field. 
ScrapedJobID1488:
As part of the development of the development and implementation the governance processes, understand stakeholder requests, define objectives, develop detailed project plans, develop strategies to mitigate and quantify risks. Support the development and implementation the governance processes to validate and syndicate changes to reference data across Oracle / SAS Modules that are approved by business. Understand business processes and systems as well as the various data flows, develop them if necessary, and establish new mapping tables, while ensuring their consistency and precision, in connection with conversion, integration, the mapping, transformation and analysis of financial data. Capture and track the measures and metrics related to the governance of data and report out any anomalies. Support the establishment of data quality management best practices, standards, guidelines & processes and ensure adherence across the organization through regular audits. Contribute to strong data analysis and solutioning in the data governance domain enabling stakeholders to manage, control and leverage quality information within and across business units and functional domains. This includes maintaining various dashboards, capability metrics and provision of reporting to identify trends, potential issues, support solutioning. Perform security and maintenance of EDMCS. Execute the loading of reference data into Oracle for new and existing dimensional data, execute create and change requests. Work with technical lead teams regarding customization and integration of finance applications. Interface and co-ordinate with the applicable functional business units to action changes to the master data files. With the team, act as an advisory role to the business team on future process models, product launches, support of acquisitions, changes in organizational structure. Execute requests for mass maintenance of reference data to ensure the appropriate standards and governance rules are maintained. Perform on-going 52-109 controls related to the data management and reporting (access, security, change management etc.). Act as support or back-up to the development and automation of reports defined as part of the current project. Bachelor's Degree in Accounting/Finance or equivalent experience. CPA Certified Public Accountant (asset). Experience and knowledge of integration / conversion and mapping of financial data. Experience in master data management strategies, data governance and/or data steward or equivalent experience (an asset). 3 to 4 years of relevant experience. Experience with 52-109/SOX controls Excellent oral/written communication skills. Strong analytical and problem-solving skills. Strong negotiation skills and ability to persuade, influence and motivate from a wide variety of functional background. Demonstrated ability to manage multiple priorities. An award-winning, inspiring workplace that supports its people and recognizes great work Stimulating, challenging projects and development opportunities to help you grow your skills and career A comprehensive financial rewards program that recognizes your success An extensive, flexible benefits package An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased A $350 annual wellness account that promotes an active lifestyle 
ScrapedJobID1489:
Diverse and inspiring colleagues and approachable leaders Stimulating work in a fast-paced, intellectually challenging environment Accelerated exposure and responsibility Global career development opportunities Being motivated every day by CPP Investments’ important social purpose and unshakable principles A deeply rooted culture of Integrity, Partnership and High Performance Develop and implement the next generation Analytics roadmap, prioritizing deliverables and products aligned to approved initiatives and firm-wide strategic priorities. Build and lead a team of highly impactful Data Science and advanced analytics resources. Determining priorities, providing development and growth opportunities and championing team across the organization. Work closely with departments across CPP Investments to understand investment needs for enterprise analytical products. Strengthen and forge relationships with key partners across the organization. Lead the development and execution of prototypes and products from an advanced analytics and data science perspective. Execution focused delivering value through Analytics. Lead the enterprise Development of data models and algorithms techniques for the use of financial market structure modeling. Bachelor’s degree, with a technology or business emphasis, or equivalent education and experience. Advanced degree preferred. Strong understanding of the investment lifecycle and proven track record of building analytical products for investment funds. Extensive background in analytical modeling, AI techniques. Track record in building and deploying data science products. Strong sense of teamwork Ability to create solutions to fit a diverse and complex environment Adaptable to new technologies and challenges not previously encountered Able to build strong relationships and communicate effectively with a diverse set of stakeholders, including business leaders, operational staff and technical engineers Proven project management experience Excellent written and oral communication skills, with the ability to work with both technical and business users Self-motivated with acute attention to detail Innovative and proactive Exemplify CPP Investments’ Guiding Principles of Integrity, High Performance and Partnership 
ScrapedJobID1490:
Bachelor’s degree in Data Science or Business Administration, MA or MBA preferred. Professional-level, current, subject matter expertise in various topics in Excel, Power Query and Power BI. Experience with adult instruction and/or training, with proven track record of online communication. Proficiency with MS suite, ability to connect to online hubs with reliable devices and internet access. Experience with online learning platforms such as D2L, Blackboard, and Moodle. 3-5 years teaching experience required. Documented experience working as an Instructor in a post-secondary or industry setting within a team environment is an asset. Ability to excel under pressure and ‘think on your feet’. Professional competence preparing, developing, delivering and administering post-secondary courses. Excellent English-language communication (written and verbal), and interpersonal and people-management skills. Demonstrated ability to deliver in class and within an online learning platform. Ability to motivate adult learners to achieve academic success. An established network of relevant professional contacts. Please note: These are the minimum required qualifications. Being a part of BC’s Top 100 Employers, and a member of the CCDI. A generous Total Compensation package which includes extended health and dental benefits and a superb pension plan. Access to Professional Development Funds and opportunities for career development. Increase your knowledge with Tuition waivers for BCIT courses. Enjoy discounted access to our fitness facilities (including classes like Yoga and Zumba). Additional Wellness and Employee Assistance programs. 
ScrapedJobID1491:
3+ years experience in a Data Engineering or Analytics role managing data pipelines Strong skills in Python, SQL, Airflow, Data Modeling and ETL pipelines Familiarity with: Snowflake, AWS Redshift, or BigQuery Experience working with Data Science and Machine Learning teams as stakeholders A passion for programming and solving problems with code A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience A love for technology, and an insatiable curiosity for new tools to tackle real problems We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process. We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners. We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy. We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality. 
ScrapedJobID1492:
Developing and supporting digital marketing campaigns, including paid Search Engine Marketing (SEM) and paid Social Media campaigns Acting as a subject matter expert for Search Engine Optimization (SEO) best practices, including ongoing technical audits of all digital properties Build Digital Results Report for clients for monthly review that encompasses all digital activities and important data KPI’s. Develop an understanding of what impact these KPI’s have on clients’ business. Manage effectiveness of Service Work Plan retention marketing Using available programs; plan, execute, and generate report on a targeted email marketing campaigns Act as a Data Scientist with regards to all the digital information we have available to us for our clients and communicate this data Oversee and manage all syndicated contents that includes various online platforms to promote business and products Working collaboratively across departments to understand company goals to develop customer acquisition, nurturing, and retention programs Study clients’ business and create a presentation based on potential and missed opportunity on the digital platform. Demonstrate to client your plan for their growth. Must be able to perform cold calls effectively and book appointments for consultation Visit businesses to generate new leads and perform updates on existing clients Requires travel 20%-50%%+ travel Bachelor’s degree or Diploma in Marketing, Business, Public Relations or 2-3 years of proven experience in sales, marketing, or communication Ability to put together effective, comprehensive, and multi-channelled marketing campaigns Have a high understanding of effective content for social media sites including Facebook, Twitter, and Instagram Manage, collaborate, and develop marketing and video assets Understanding of Google Analytics, Conversion Rate Optimization, User Experience (UX) Knowledge and Compliance with all provincial/federal advertising standards (CASL etc.) is a must. Graphical design understanding for digital properties and Point of Sale materials Excellent organizational, communication and leadership abilities. Team-oriented, relationship builder with a positive attitude. Strong oral/written communications skills. Strong organizational and multi-tasking skills with a high attention to detail Strong Proficiency in working with multiple software programs Automotive industry experience/ knowledge considered an asset. Must have valid driver’s license Passion for selling and building new relationships is a MUST. Bonus pay Commission pay Dental care Extended health care Profit sharing Store discount Monday to Friday Weekend availability Are you located in Calgary? No 
ScrapedJobID1493:
Experience with Python in production environments and a strong understanding of computer science fundamentals Experience designing experiments, A/B testing and data analysis in the domain of quality metrics for machine learning services Experience with designing and building metrics collection and data visualization Solid understanding of modern web applications architecture and development process Passion for decision making based on sound data analysis. A strong sense of ownership and a persistent desire to grow and lead beyond the scope of the current role Basic understanding of modern frontend development frameworks (e.g., Angular or React) REST-based API design, e.g., Flask or Django. Interest in or experience with machine learning methodologies and tools (e.g. Natural Language Processing (NLP), sklearn, pandas, numpy, keras, tensorflow, etc.) Exposure to large-scale data processing tools like Kafka, Spark, or Hadoop Exposure to cloud-computing technologies like AWS/GCP, Docker, Kubernetes etc. Experience using modern frontend development frameworks (e.g., Angular or React) 
ScrapedJobID1494:
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintains data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools. Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools. Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures. Prepare and maintain documentation and reports such as user guides, procedure manuals, metadata, code documentation, and data security policies and data dictionaries. Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to. Bachelor’s Degree in Health Information Science or Computer Science or equivalent and three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience. Write data management and analysis programs using data programming tools such as SAS or R. Demonstrate experience managing and querying data in large relational or multidimensional databases and data warehouses an asset. Create data visualizations. Communicate effectively, both verbally and in writing. Operate related equipment Carry out the duties of the position. Standard software packages, spreadsheet, statistical, graphical, database, communication and web software. Descriptive statistics. PC systems and applications. Health-related terminology. Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development. Access to professional development opportunities through our in-house training programs, including +2,000 courses, such as our San’yas Indigenous Cultural Safety Training course, or Core Linx for Leadership roles. Enjoy a comprehensive benefits package, including municipal pension plan, and psychological health & safety programs and holistic wellness resources. Annual statutory holidays (13) with generous vacation entitlement and accruement. PHSA is a remote work friendly employer, welcoming flexible work options to support our people (eligibility may vary, depending on position). Perks include access to fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more. 
ScrapedJobID1495:
Architect, design and evaluate novel approaches for solving complex business problems using machine learning techniques with high-volume real-time data streams Own the machine and present analyses and machine learning concepts to a broad technical audience initiate and drive projects to completion with minimal guidance Large data sets with low to mid-level analytical complexity Small data sets with high analytical complexity Data structures containing complex relationship patterns Data with low signal to noise Unstructured DataAlgorithm development with application to solving human problems Previous involvement in software development and/or distributed computing projects is a plus 2+ years of experience in building and deploying machine learning solutions at a production scale 1+ years of experience in software development at the production level, with proficiency in Python or Scala preferred Working knowledge of PyTorch, Tensorflow, or other similar frameworks Bachelor's or Master's degree or equivalent in Computer Science, Engineering, Mathematics or related field Flexibility to WFH For the third year in a row, we are proud to announce that we have been certified as a Great Place to Work We were also certified as one of the Best Workplaces for Mental Wellness in 2020 We are an open work environment that fosters collaboration, ownership, creativity, and urgency We ensure flexible hours outside of our core working hours Enrolment in the Group Health Benefits plan right from day 1, no waiting period Team building events Fuel for the day: Weekly delivery of groceries, and all types of snacks Catered lunches and desserts on a monthly basis Daily fun in the office with our competitive games of Ping Pong, Pool, Smash Bros competitions, or FIFA And of course, an unlimited amount of freshly made coffee and tea! We’re pretty serious about our coffee beans Online learning through the platform, UDEMY 
ScrapedJobID1496:
Ongoing practice and process development looking for ways to improve and streamline company processes to not only deliver a superior service to our clients, but also to improve our efficiency and profitability. Mentoring/managing Data Science team members Partner with your Group Director to educate clients on the value of adding Data Science products to their business, capturing & defining needs and solutions Synthesize business needs and create business/functional design documents which can be used to build analysis and data models around. Assess data for validity in terms of predictive capabilities, required feature engineering, opportunities for data widening, or alignment to business requirements Develops, implements, and supports methodologies, standards, and tools for analysis and data science work. Build cooperative, productive relationships with clients and vendors by utilizing excellent communication skills, while also interacting effectively internally and externally. Research, prototype, and explore future, non-standard analytics approaches that push the limits of current analysis output. This will include exploring novel machine learning techniques which enable our teams to tackle segmentation, clustering, and predictive models used in a wide variety of areas. Bachelor’s degree in Mathematics, Statistics, Business Analysis or related 5+ years’ experience as an Analyst / Data Scientist 2+ years’ of managerial and leadership experience Advanced knowledge of R, Python or SAS for model development Previous experience with web analytics tools such as Adobe Marketing Cloud, Google Analytics Extensive experience with statistical modelling techniques Experience connecting Tableau or other visualization systems and using for dashboarding or analysis Self-motivated and ability to work independently in meeting deadlines Exceptional written and verbal communication skills and is comfortable working with remote teams Previous experience with marketing analytics including database marketing techniques, campaign lift, attribution and media mix modelling Familiarity with analyzing data for digital marketing and ecommerce, as well as all other non-digital aspects of a business SQL skills A solid knowledge of ETL tools Understanding of how to deal with larger data sets and parallel computing problem 
ScrapedJobID1497:
Bachelor’s degree in computer science or relevant field. 5+ years of work experience as a software developer or engineer within a product development environment (Software and/or SaaS). 2+ years of industry experience in applied machine learning or deep learning. Proficiency in C# (or Java), SQL, Python, AWS and experience with ML frameworks. Strong knowledge of machine learning techniques. Experience with integrating applications and platforms with cloud technologies (AWS). Experience designing, building, and deploying statistical and machine learning models using frameworks. MS, or PhD degree in Computer Science or related field, or equivalent practical experience. Experience leading machine learning engineering teams of 1 – 5 people. Research and select the right ML tools and technology set required to solve various business problems. Identify relevant business problems and build prototype/proof-of-concept solutions employing state-of-art methods in a variety of areas including natural language processing, clustering, and recommendation systems. Develop a long-term sustainable technical architecture to complement our product development technology (C#, SQL Server, Python, AWS). Serve the team by participating in, and guiding the design, development and implementation of operational standards that result in highly available, scalable, and reliable customer experiences. Engage varying degrees of stakeholders, including other development teams, compliance groups, product management, and external audiences. Keep team members motivated and engaged while maintaining a positive atmosphere. Work with Product Management to guide the overall direction of our ML powered features and integrate them into the Product suite. Identify and propose innovative opportunities for deploying ML capabilities in the product. Facilitate and coordinate an understanding at the portfolio level of cross-project dependencies to ensure smooth integration at completion. Actively contribute to, execute, and monitor the teams process improvement efforts. Ad hoc duties as required. Software
Experience In at least 5 years of experience with/in Software Development
Experience In at least 3 years of experience with/in Machine Learning Experience In at least 5 years of experience with/in Software Development Experience In at least 3 years of experience with/in Machine Learning 
ScrapedJobID1498:

ScrapedJobID1499:
Use Scala, Spark, GitHub, Maven, Jenkins and Airflow to develop and deploy AI models Design and execution of integration & execution of AI models with internal RBC products, as well as external RBC partners Develop methodologies & frameworks for systematically validating the performance, security, and trustworthiness of deployed ML models Focus on component reusability, data sharing and security while complying with the standards and processes set within the Enterprise Apply design thinking and an agile mindset in working with other engineers, data scientists and business stakeholders to continuously experiment, iterate and deliver on new initiatives Leverage best practices in continuous integration and delivery, with a strong commitment to quality Explore new capabilities and technologies to drive innovation Proven track record of building and managing Data Engineering teams leveraging big data technologies (Spark, Kafka, Data Pipelines) to build data products Proven track record of setting exemplary standards and the ability to tap in to hands on experience when necessary to ensure quality and timely deliverables Active participation in design and code reviews, establishing of best practices, continuously inspiring a team of high calibre data Engineers to deliver excellence Experience with containers and orchestration (e.g. Docker, Kubernetes, Mesos); experience with data modeling, data access and data storage techniques; experience building APIs; experience with public cloud Development A passion for simplifying and automating work, making things better, continuous learning and helping others A comprehensive Total Rewards Program including bonuses and flexible benefits, competitive compensation, commissions, and stock where applicable Leaders who support your development through coaching and managing opportunities Ability to make a difference and lasting impact Work in a dynamic, collaborative, progressive, and high-performing team A world-class training program in financial services Flexible work/life balance options Opportunities to do challenging work Opportunities to take on progressively greater accountabilities Opportunities to building close relationships with clients Access to a variety of job opportunities across business and geographies 
ScrapedJobID1500:
Interacts with business stakeholders to gather business requirements Translates business requirements to technical specifications Be responsible for building dashboards and other tools required to automate manual work and make data-driven insights available to workers throughout the organization. Designs, builds and deploys BI solutions Maintains and supports data analytics platforms Creates tools to store data (e.g., OLAP cubes) Conducts unit testing and troubleshoots and remedies defects Collaborates with Prophix teams to integrate systems Develops and executes database queries and conducts analyses Creates visualizations and reports for requested projects Assist with Project Management duties including managing project timelines, budget, and providing regular status updates to clients Provide documentation for delivered solution Design and deliver end user training sessions Validate the quality and integrity of the data included in all reporting Work independently as the senior analyst / expert and may provide technical support to others Maintain expert knowledge of all main data sources for the data used within the business unit and ability to effectively utilize these data sources for reporting purposes Ideally have or acquire knowledge of broader enterprise reporting platforms and data sources and ability to integrate data across the enterprise 3+ years working with relational and dimensional database management systems 3+ years’ experience working with SQL Server recent versions (2019, 2016) 3+ years implementing ETL processes, including platforms such as SQL Server Integration Services and Matillion, SQL, SSIS, SSAS, Azure Data Factory, Informatica, Power Query 3+ years implementing advanced visualizations for a wide variety of business audiences-executives, operational managers and customer facing teams 2+ years implementing Tableau, PowerBI, Domo or similar technologies 3+ years’ experience in information technology and/or systems development Bachelor’s Degree in Computer Science, Mathematics, Data Science, Informatics, Data Analytics, Engineering or a related field and approximately 2-4 years of related work experience Knowledge of broad scope of architecture, technology, tools, processes and procedures, as well as broader organization issues and technology Excellent communication, negotiation and organizational skills specifically including the ability to present architectural options in business terms to both IT and business staff including executives Excellent client focused consulting skills Experience implementing and managing a data platform on Snowflake or similar technologies Advanced T-SQL and MDX skills Excellent knowledge of the data warehouse, data lake and data lakehouse development lifecycle Experience with range of data visualization tools, for example: Tableau, Qlik, SSRS, Cognos Experience with data virtualization, data automation, data architecture Familiarity with Machine Learning and Artificial Intelligence concepts Must be legally entitled to work in the country where the role is located. Must be able to travel to the United States, Canada and/or internationally, and have a valid passport An equivalent combination of education and experience may also be considered Proficient in designing and/or building business intelligence systems which are highly secure, highly available and highly performing Accuracy and attention to detail Demonstrated ability to solve problems and improve processes using structured analysis and methods Strong communication, presentation and business and technical writing skills You have a passion to make a difference Share our values Enjoy having honest conversations, about real things, as real people Believe that creating great experiences is totally within their control Build positive relationships and an understanding of what people’s needs are See solutions and possibilities (not problems!) Are simply outstanding at what you do 
